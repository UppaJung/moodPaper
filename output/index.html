

<html>
<head>
	<title>Ethics Mood experiment</title>
	<link rel='stylesheet' type='text/css' href='styles.css'/>
	<script type='text/javascript' src='js/jquery-2.0.3.min.js'></script>
	<script type='text/javascript' src='js/clio.js'></script>
</head>

<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<body>
<div class='cap' style='max-width:25%;'>
	<div class='header'>Summary</div>
	<div class='body'>
		<p>We have <code class="knitr inline">3539</code> participants, out of which <code class="knitr inline">2102</code>
		(<code class="knitr inline">59.4%</code>) were unaware of the Facebook Mood experiment.</p>
		
		<p>Main questions:</p>
		<ul>
		<li><em>Proceed question</em>: "Do you believe the researchers should be allowed to proceed with this experiment?"</li>
		<li><em>Surrogate question</em>: "If someone you cared about were a candidate participant for this experiment, would you want that person
		to be included as a participant?"</li>
		</ul>
		
		<p>Conditions:</p>
		<table class='simple' cellspacing='0'>
<tr><th class='l'>Control</td><td>207</td><td>9.8%</td></tr>
<tr><th class='l'>WithoutRemovingNegativePosts</td><td>220</td><td>10.5%</td></tr>
<tr><th class='l'>WithoutRemovingPositivePosts</td><td>184</td><td>8.8%</td></tr>
<tr><th class='l'>WithoutPublication</td><td>220</td><td>10.5%</td></tr>
<tr><th class='l'>WithoutImprovingProduct</td><td>212</td><td>10.1%</td></tr>
<tr><th class='l'>NoAdvertising</td><td>219</td><td>10.4%</td></tr>
<tr><th class='l'>InsertPosts</td><td>212</td><td>10.1%</td></tr>
<tr><th class='l'>InsertOnlyPostiveposts</td><td>230</td><td>10.9%</td></tr>
<tr><th class='l'>UnnamedCompany</td><td>193</td><td>9.2%</td></tr>
<tr><th class='l'>Twitter</td><td>205</td><td>9.8%</td></tr>


		</table>
	</div>
</div>

<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<div class='cap' style='max-width:30%;'>
	<div class='header'>Graph: Proceed question by awareness</div>
	<div class='body'>
		<p>Responses to the Proceed question, split by awareness of the Facebook Study. This graph was built over the whole dataset (N=<code class="knitr inline">3539</code>).</p>
<div class="chunk" id="unnamed-chunk-2"><div class="rimage default"><img src="figure/unnamed-chunk-2.png" title="plot of chunk unnamed-chunk-2" alt="plot of chunk unnamed-chunk-2" class="plot" /></div></div>

	</div>
</div>

<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<div class='cap' style='max-width:30%;'>
	<div class='header'>Graph: Surrogate question by awareness</div>
	<div class='body'>
		<p>Responses to the Surrogate question, split by awareness of the Facebook Study. This graph was built over the whole dataset (N=<code class="knitr inline">3539</code>).</p>
<div class="chunk" id="unnamed-chunk-3"><div class="rimage default"><img src="figure/unnamed-chunk-3.png" title="plot of chunk unnamed-chunk-3" alt="plot of chunk unnamed-chunk-3" class="plot" /></div></div>

	</div>
</div>


<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<div class='cap' style="max-width:30%;">
	<div class='header'>Graph: Proceed question by condition</div>
	<div class='body'>
		<p>Responses to the Proceed question, split by condition (i.e., variation of Facebook study). This graph was built over those participants who were
		not aware of the Facebook study (N=<code class="knitr inline">2102</code>).</p>
<div class="chunk" id="unnamed-chunk-4"><div class="rimage default"><img src="figure/unnamed-chunk-4.png" title="plot of chunk unnamed-chunk-4" alt="plot of chunk unnamed-chunk-4" class="plot" /></div></div>

	</div>
</div>

<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<div class='cap' style="max-width:30%;">
	<div class='header'>Graph: Surrogate question by condition</div>
	<div class='body'>
		<p>Responses to the Surrogate question, split by condition (i.e., variation of Facebook study). This graph was built over those participants who were
		not aware of the Facebook study (N=<code class="knitr inline">2102</code>).</p>
<div class="chunk" id="unnamed-chunk-5"><div class="rimage default"><img src="figure/unnamed-chunk-5.png" title="plot of chunk unnamed-chunk-5" alt="plot of chunk unnamed-chunk-5" class="plot" /></div></div>

	</div>
</div>

<hr style='clear:both;'/>

<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<div class='cap' style='max-width:30%;'>
	<div class='header closed'>BotnetSpam study, answers to Proceed question</div>
	<div class='body'>
<ul><li>P6: Doing this could hurt a person from returning to a computer again.</li>
<li>P11: This seems to be an attempt to quantify something that is useless</li>
<li>P12: The researchers should be able to proceed with the experiment while assuring the safety of the participants. </li>
<li>P15: I feel that the experimenters have not created an ethical or safe experiment for participants.  There are too many risks involved with this study.</li>
<li>P16: It will help us to understand the positive and negative aspects of SPAMMMING</li>
<li>P20: It seems like the research results could be valuable in fighting spammers but I'm not sure if this is the best way to conduct the research.</li>
<li>P21: There is no informed consent and obvious deception at work here. Deception is allowable if the participants are aware that they are at least in a study. </li>
<li>P27: I think this is a fair and ethical way to research the problem of spam.</li>
<li>P33: with caution it would be ok I guess.</li>
<li>P43: I feel that this would make people anxious. </li>
<li>P46: Eventually the participants need to be notified that they were a part of an experiment. </li>
<li>P48: It's unethical. No debriefing.</li>
<li>P52: It's interesting and not hurting anyone.</li>
<li>P54: The researchers aren't informing their participants that they are a part of the experiment or that the store isn't working. This seems unethical to me.</li>
<li>P55: Because they are allowing their computer to be infected, there is a chance that the botnet software placed on their computer could steal participants' data, which would them jeopardize the sanitized spam of the experiment. In addition, some spammers advertise using porn and that is sent out to every email address, so therefore the researchers could unwittingly send porn links to children. The risk involved in executing this project is very great.</li>
<li>P56: Spam might be a problem for some users and not a problem for other users. It depends on how careful the users are about using their emails.</li>
<li>P59: they should proceed, but make sure that all the information remains anonymous.</li>
<li>P61: Is spam illegal?  If it were, then they shouldn't proceed. If it's not illegal, then I don't see what the difference is between "allowing" a research computer to spam (indirectly) and setting up a spam/online sales room that directly measures.  If recording # of attempts to purchase is the measure, then that could be done on their own spam too.</li>
<li>P69: LIKE I SAID I DONT REALLY UNDERSTAND THIS SCENERIO</li>
<li>P77: The researchers must in my opinion find a way to obtain the consent of its participants prior to proceeding with this experiment.</li>
<li>P80: Spammers could probably find a way around researcher safeguards with relative ease and endanger computers.</li>
<li>P84: only if it has helpful benefits.</li>
<li>P93: It seems like researchers are illegally hacking.</li>
<li>P96: It is very necessary to protect people online and since the users will be redirected it will not affect them negatively.</li>
<li>P97: Spammers aren't to be trusted, they can still collect personal details.</li>
<li>P100: Please see above</li>
<li>P101: I just don't think there are very many benefits to this experiment and a lot could go wrong.</li>
<li>P102: Depends if the compensation is enough to make it worthwhile.</li>
<li>P105: While the information would be beneficial to gain, I question the ability of the researchers to maintain control of the environment and risk factors involved.  The level of risk to the participants is too great.</li>
<li>P106: The research is worthwhile and participants will not be harmed (whereas if the spam site were real they would be)</li>
<li>P111: I wonder if the results from this research could be used to make spam email even worse than it already is</li>
<li>P117: I'm concerned with how infecting one computer results in spam going to multiple e-mail addresses.  Most people use web mail.  Is this one infected machine causing multiple web mail accounts to be infected?  Also, I'm concerned with the participants believing they have purchased things when they haven't.  This could cause the participants harm when the purchased item doesn't ever arrive.</li>
<li>P119: Just do a survey like this. Its false advertising.</li>
<li>P121: It is their computer their risk</li>
<li>P122: Maybe this could help to get rid of spammers</li>
<li>P124: This experiment doesn't look harmful to normal users.</li>
<li>P135: It seems like a good start for having more technical ways to stop spam.</li>
<li>P141: Accessing spammers' stuff could result in spammers accessing the researcher's stuff.</li>
<li>P143: See comment on last question</li>
<li>P152: Having inside knowledge of these types of attacks/viruses would give us a greater likelihood of being able to stop them completely.</li>
<li>P155: The subjects of the experiment are not being given a chance to give informed consent. The study is unethical.</li>
<li>P156: I mean I hate spam as much as anyone else but I still feel its a violation of rights.</li>
<li>P157: i do not see any problem</li>
<li>P159: It's wrong to involve people in scientific studies without their knowledge and permission.</li>
<li>P166: See just how effective spam emails are. It might even prove their ineffectiveness and stop them once and for all.</li>
<li>P167: People do not know they are part of the study, have not agreed to be in a study and will not be informed after</li>
<li>P169: The design seems to mimic the intended result in a responsible way, since participants are not asked or expected to make an actual purchase.</li>
<li>P171: Kind of very invasive </li>
<li>P179: It will be important not to participate in taking advantage of anyone with the spammers.</li>
<li>P183: This doesn't seem ethical. You're essentially infecting people's computers to study them.</li>
<li>P184: The researchers are accessing information about buying habits and online behavior without the consent beforehand of the participants. The way in which this information is treated needs to be thoroughly explained beforehand.</li>
<li>P185: I think they could be sued for hacking someones computer.</li>
<li>P188: I simply do agree with the way in which it is being conducted.</li>
<li>P191: dont know about this one</li>
<li>P192: Unethical</li>
<li>P198: This could compromise the subjects private information.</li>
<li>P200: This is a waste of time, and effort, especially with the setup as they have it.  I do not have a solution for how to do it better, but this sounds completely worthless.</li>
<li>P211: important to figure how to stop these people from doing this</li>
<li>P218: it's a thin line, but I think there could be potential problems</li>
<li>P219: There is no reason not to</li>
<li>P220: It's uncalled for.</li>
<li>P228: The fact that they are letting computers become infected with malware is a red flag - even if they intend to change the store link, the malware could be conducting other processes in the background</li>
<li>P231: Allowing unsuspecting participants to try follow a spam link to a store that doesn't work is not really ethical.</li>
<li>P232: Doesn't seem ethical to steal possible customers from peoples online stores</li>
<li>P239: I'm leaning a bit toward no because there's no knowledge or consent of any of this by the end users.</li>
<li>P248: safety nets/deterrents should be built into the study for anyone who has access to the information to take advantage of the data collected via the spam.</li>
<li>P253: It's a grey area.</li>
<li>P256: The gathered information would be useful.</li>
<li>P258: All research should be pursued, even if only theoretically.</li>
<li>P261: This could end up being a very serious breach in security.</li>
<li>P270: violation of Constitutional rights</li>
<li>P271: The activities of the researchers constitute illegal conduct.</li>
<li>P272: I still think researchers should inform people.</li>
<li>P273: It keeps people from being able to purchase products they want, which seems illegal.</li>
<li>P275: It seems strange not to inform the people targeted by the spam, at least after the fact--so they're not waiting for their products.</li>
<li>P284: I think experiments like this is necessary to removal of spam.</li>
<li>P289: This is just one possible idea, and they really need to brainstorm and come up with about 3 or 4 more ideas. This project cannot possibly be the best option.</li>
<li>P291: Too many undisclosed details.</li>
<li>P297: this would help people in the long run to avoid/prevent spamming</li>
<li>P308: I do because I personally would be interested to hear the results - as long as they are simulating the conditions it is ok</li>
<li>P309: Participants should be notified of their involvement. </li>
<li>P313: WILLING PARTICIPATION.</li>
<li>P314: seems like an interesting study. </li>
<li>P317: You guys don't want to get discovered or they will possibly jeopardize your results or institution.</li>
<li>P322: i think that taking over and redirecting traffic interferes with someones site, and whether or not they are spammers, this is wrong to do.</li>
<li>P326: That is going way to far in my opinion</li>
<li>P327: you do not want the spam to ruin their computers </li>
<li>P334: Hijacking is illegal.</li>
<li>P335: yes i do</li>
<li>P347: I think it is a worthwhile survey, but at some point the worker needs to be notified of the real purpose and that no information was shared and no purchase was made.</li>
<li>P350: Measures need to be taken to make sure credit card info or other personal info isn't somehow acquired. </li>
<li>P354: Not really a security risk</li>
<li>P370: Anything that reduces the volumn of spam generated is a good thing.</li>
<li>P371: Sounds to risky.  The attackers might be able to detect that the site is being altered and monitored.</li>
<li>P386: Only if the people were informed afterwards.</li>
<li>P388: n/a</li>
<li>P390: I think it is morally wrong to not tell selected random participants what is going on. </li>
<li>P391: The participants are not fully debriefed. </li>
<li>P397: Unlike the previous studies, this one seemingly records no personal data whatsoever, simply noting whether or not the individual wanted to make a purchase.</li>
<li>P402: I don't see any harm in this experiment so yes, they should be allowed to proceed with this experiment.</li>
<li>P403: Experiment sounds dicy to me.</li>
<li>P406: There is too much chance for something to go awry, like the infected computer sending more than just spam to participants.</li>
<li>P409: No real benefit to end user.</li>
<li>P412: There seems to be too many "what ifs" and the possibility for too much personal/financial info to be shared.</li>
<li>P415: analyzing spam email can be a good way of determining how it is sent</li>
<li>P417: I don't think is legal or ethical.</li>
<li>P418: I am all for research when it going to possibly have a positive benefit. But such things should be contained. Meaning on their own equipment only.</li>
<li>P422: What does knowing how effective spam is in attracting purchases have to do with stopping spam? Spam is relatively easy to spot, so if users opt to make a purchase, isn't that their right?</li>
<li>P423: Seems like too many variables and not enough security</li>
<li>P425: how else are they going to find out these result. But spaming for sales is a low business practice.</li>
<li>P427: No, this should be against the law.</li>
<li>P428: I believe they should be allowed as long as they don't steal information</li>
<li>P429: seems really risky</li>
<li>P437: Contain control of someone computer without their knowledge is illegal.</li>
<li>P442: It could affect the person's computer. </li>
<li>P445: I believe that the researchers should not be collecting data from people who are unknowingly being held prey to spam. </li>
<li>P446: yea because it would be nice if spam could be stopped</li>
<li>P449: there's no negative impact</li>
<li>P450: The intentions are good but the researchers won't notify the users that get spam so it's kind of bad for those users and it can get out of control .</li>
<li>P453: to save people from themselves.</li>
<li>P458: To show how spammers are so clever and conniving.</li>
<li>P462: An ethical review board is necessary to ensure ethical standards are being met. </li>
<li>P463: Researchers are not informing users about all aspects of the study and I'm not sure if that's okay</li>
<li>P467: This doesn't add up. There must be a better way to test spam emails.</li>
<li>P470: I'm not sure that researchers should be allowed to proceed because, even though the research is needed, the chance for something to go wrong and provide hackers with the info is very high.</li>
<li>P472: Seems very thoughtfullly made</li>
<li>P473: Yes with caution I think by modification the experiment can be enabled.</li>
<li>P475: No really, anything to stop the spammers.  Cluttering up my inbox with crap and redirecting me to unsafe links...jerks.</li>
<li>P480: the more we know the better</li>
<li>P485: I'm 50-50 on this one.</li>
<li>P486: They are not causing harm or changing any behavior. they are simply observing. </li>
<li>P487: People's time is valuable</li>
<li>P488: Spammers are smart people. I would recommend being careful about letting your computer be infected with spam as it could have spyware added on.</li>
<li>P494: It would be useful data.</li>
<li>P496: I don't think it'll help with stopping spam. </li>
<li>P502: I would have questions concerning how users would attempt to make a purchase without the revealing some type of personal information such as name, or payment method?</li>
<li>P505: This seems totally fine to me. Since they don't actually keep any of their information. </li>
<li>P513: There are only certain content that they should be able to send.</li>
<li>P515: Researchers should not be able to use spam to infect someone's computer.</li>
<li>P517: This experiment should be closely monitored so that people's personal information will not be compromised. The spam could get into the wrong hands and cause viruses everywhere if not closely guarded.</li>
<li>P519: The experiment is working for a good cause (stopping spam).</li>
<li>P531: Spam is a real problem and any research that will eliminate it is valuable.</li>
<li>P532: This experiment is reckless and potentially destructive. Allowing a spam virus to take over a computer and then taking it over is too much trouble for too little gain. Finding the empirical effectiveness of spam doesn't contribute to stopping spam, and the experiment gathers too many other types of data to be credible.</li>
<li>P535: I would need to see more about how they would plan to protect the personal information of their participants.</li>
<li>P538: This is a ethical issue.</li>
<li>P539: I would just hope that everything can then be put back to the original setup.  This could also constitute a violation of privacy by tracking someone's activity on the computer without them knowing about it. </li>
<li>P541: It's hacking the hackers.  One bad turn does not negate the obligation of another to act ethically.</li>
<li>P548: I think it's work looking into. The results would potentially be helpful.</li>
<li>P553: To try to put an end to spammers and hackers online.</li>
<li>P554: this experiment does not harm anyone.</li>
<li>P555: While this is one way of understanding the infrastructure of spam mail and the rate spam mail results in sales but the damage spammers can do to the operation or mechanisms of the computer is too high.</li>
<li>P558: This is unethical.  It's misleading.  Nobody opted in to this.  You're actively causing participation and encouraging looking at spam emails.</li>
<li>P561: I think these are very valid areas for research</li>
<li>P573: Due to the invasive, and sometimes unpredictable contents (malware, spyware, trojans) of spam, I do not believe that the researchers can properly maintain a secure environment for their test subjects.</li>
<li>P578: Please see the above answer.</li>
<li>P583: People would be upset</li>
<li>P585: People should know of the importance of spam.</li>
<li>P590: Seems like it puts people at risk.</li>
<li>P594: I'm not sure, because I feel like they would be violating people's privacy. However, the spammers are already doing this and the researcher's paper could bring light to that. </li>
<li>P599: It would be helpful to get rid of scamming, but the means by which that is achieved seems risky</li>
<li>P603: I'm on the fence with this one.  There's a part of me that is worried here that says the researchers are not really exposing any additional risk beyond what is already out there.  However, there is a a concern that I have about the code that is swapping out the hackers links for a white hand link.  Mistakes happen and if an email is missed are you unwittingly propagating the hack.</li>
<li>P604: It is very interesting, but they should be very careful.</li>
<li>P606: It is risky, because someone might try to make a purchase that researchers miss, so they can't stop it, which is dangerous to the participants. </li>
<li>P608: Little or no risk to those involved. </li>
<li>P610: not sure if it is ethical to hijack a link</li>
<li>P612: I definitely think this should be pursued since I hate spam email. maybe this can put a stop to it.</li>
<li>P622: too risky.</li>
<li>P628: Check the legality of infecting a persons computer without them knowing.</li>
<li>P629: As stated before anyone who falls for said spam would be a victim anyway.</li>
<li>P631: Please see above. I'm not really sure what they'd be learning in any case.</li>
<li>P633: As long as the researchers can make sure no one else's computers get infected, it should be OK.</li>
<li>P646: Sure, why not.</li>
<li>P647: Researchers should perform all necessary precautions to ensure safety and privacy of research participants data. That's the least you can do in an experiment like this.</li>
<li>P652: I do not think that it is right that the researcher will not let people involved know about this after the research is done. </li>
<li>P656: It seems like an interesting subject.</li>
<li>P660: Same as above</li>
<li>P672: The research on it is important. </li>
<li>P676: Spam is bad! While the libertarian in me says if people are stupid enough to fall for spammers, they deserve what they get. But the other side of me realizes that not everyone is computer savvy enough to always recognize spam.</li>
<li>P678: the data will help people to be careful and more aware</li>
<li>P682: I see this as deceiving the individual when they are trying to purchase something from a place they believe offers the product when in fact they are not working with the advertised company.</li>
<li>P685: As long as they are careful this should be ok.</li>
<li>P689: The experiment seems perfectly acceptable, but I can see how this might cause some controversy.</li>
<li>P692: Must ensure they have total control of the computer</li>
<li>P694: yes very helpful study</li>
<li>P696: Data would not be very meaningful, and the potential for conflict from the users would be too great.</li>
<li>P705: Ir seems that the researchers would be spying on the spammers without their consent.</li>
<li>P708: Researchers should do any type of research they want~</li>
<li>P717: This could result in unforeseen outcomes that harm the people they experiment on.</li>
<li>P721: Even though they wouldn't be purchasing anything, I still think it is wrong. </li>
<li>P722: Still seems too risky.</li>
<li>P726: I'm not sure how I feel about people who try to make purchases not being told after the attempt was made that it was recorded.</li>
<li>P729: As long as no personal info is taken its seems ok.</li>
<li>P732: To help the fight against spam</li>
<li>P735: All participants must be aware they are participating. Basic ethics.</li>
<li>P737: there is simply no other way to effectively understand the process and how to thwart it in the future.</li>
<li>P741: At the end they are not collecting private info</li>
<li>P749: If the participants are not told, I don't agree with it.</li>
<li>P761: It is somewhat unethical, even if the spammers were informed of the study.  </li>
<li>P763: I suppose if they are willing also to be prosecuted if any laws are broken.</li>
<li>P765: They should be allowed to there research because they can use the data that they get to help people in the \r\nsame situation. </li>
<li>P772: Too many negative consquences and no consent given by subjec</li>
<li>P776: There would not be too much risk involved  with personal information and this may help solve the problem.</li>
<li>P780: If they are not infringing on anyones privacy sure, but its not really going to benefit anyone </li>
<li>P787: I'm not sure why we need this research or who is benefits, and it seems like a lot of sneaking around for something that does seem to really help with safety. </li>
<li>P788: You lost me at "Researchers maintain sufficient control." That sounds like a recipe for disaster. </li>
<li>P792: This study is unethical because it is collecting data from people without their consent on their personal computers. This is a breech of privacy.</li>
<li>P796: It seems like a real threat</li>
<li>P800: Does not seem like an ethical experiment. There must be other ways to gather this information.</li>
<li>P802: As long as no personal information is taken, and the subjects remain anonymous, then the only issue is the participant's desire to buy a certain product may come to light in someway. </li>
<li>P803: Spamming for science instead of profit. </li>
<li>P810: although it is said that privacy will be maintained to a certain degree, giving over your computer to someone is ill advised.</li>
<li>P811: Many people do not understand spam and are targets everyday for being scammed.</li>
<li>P812: It's more beneficial to teach people about the caution of opening up spam e-mails than monitor their effectiveness.</li>
<li>P819: Since it's for research purposes and it is in a controlled environment</li>
<li>P820: I think they can do it, but there is a line to where I think they have to stop a scam from happening. </li>
<li>P821: I don't see a problem with is as long as they aren't being malicious or stealing information</li>
<li>P824: experiments are necessary for progress although I wouldn't want someone I care about to participate I'm indifferent towards the participation of strangers</li>
<li>P827: so people can learn to be safe</li>
<li>P828: Have to make sure no personal data is corrupted.</li>
<li>P833: It seems like a good idea, but I'm just not sure about not disclosing information to the participants.  I think transparency is pretty important.</li>
<li>P835: No risk</li>
<li>P836: I feel conflicted</li>
<li>P837: All of the risks I can think of seem to be addressed with the measures the researchers are taking.</li>
<li>P841: This experiment will not harm the participants at all except for a little frustration at not being able to complete a purchase, which may not be all bad because many people shouldn't be spending as much anyway.</li>
<li>P845: I see no harm here and if anything can be done to reduce spam, I'm for it.</li>
<li>P847: There is less potential for abuse.</li>
<li>P861: This could be misused by the spammers</li>
<li>P865: when people enter their credit card or bank account numbers, it could be risky, so the researcher should be very careful. </li>
<li>P866: It is not appropiated.</li>
<li>P870: The researchers need to be able to understand how spam works and without testing participants this will be impossible. My only concern is how is this going to help stop spamming or is this just for statistical purposes?</li>
<li>P874: Could provide great insight about how spammers operate in order to better understand them</li>
<li>P882: I feel that it compromises the privacy of the subject to a great degree.</li>
<li>P884: I would be afriad that my information would get out, Even though it would be a great tool for technical.</li>
<li>P886: This seems illegal.  I know spammers are annoying and can cause lots of fraudulent activity, even for the sake of an experiment, creating fraudulent spammer accounts of the spammers is wrong.</li>
<li>P890: It depends whether the participants are debriefed and given the opportunity to have their date removed from the study.</li>
<li>P898: it will show that spam emails do sway your buying preferences towards buying things from suspicious sites</li>
<li>P899: Seems pretty foolproofed </li>
<li>P901: I'm not entirely sure how or why participants would be encouraged to make purchases from a specific online store meant to mimic the spammer's store.  People generally make purchases on their personal computer, not a work or lab computer.</li>
<li>P903: The experiment should be allowed to help educate individuals in regards to spammers. </li>
<li>P906: i have mixed feelings, could be a bad precedent</li>
<li>P914: I think it is an interesting proposal to see how many people actually make purchases from spam email.</li>
<li>P921: The researchers need to be certain that the altered links do in fact work so that people aren't scammed for real.</li>
<li>P925: I think there is too much danger as I indicated above</li>
<li>P926: I think that it would be interesting to see the results of this experiment but I think the researchers should be careful how they initiate this. </li>
<li>P927: i believe the researcher should be allowed to proceed with the experiment, this experiment would give a good result on the issue. and concept is also good to find out the proposed result</li>
<li>P929: It seems to have a lot of risky factors.</li>
<li>P936: Researchers could have access to personal financial details, this must be protected.</li>
<li>P940: They should be very careful to contain the spam that infects the computer.</li>
<li>P942: I am sick of spam and anything to stop it has my support</li>
<li>P948: Seems morally acceptable</li>
<li>P951: there are security issues with this study</li>
<li>P953: Again, it seems really unethical to let people follow a link and try to buy something when they really can't.</li>
<li>P955: I don't have enough information to know if it's ethical, in my opinion. Would the subjects be informed? My greatest concern is the lack of informing the consumer---such as not informing them that the store has been disabled or their purchase recorded.</li>
<li>P957: I am not sure what the rules are regarding this type of research.  If there is no risk to the participant, it is possible if the participant knowingly agrees to this type of experiment.</li>
<li>P958: It is fine as long as nobody's info is compromised. I'd be interested in knowing the results. Spammers send so much stuff out constantly, I do wonder how many people they are actually fooling.</li>
<li>P960: It involves deception.</li>
<li>P962: I think something like this could easily get out of hand. The spammers could figure out what is happening and change their programs.</li>
<li>P963: Caution should be exercised, but the results could be helpful.</li>
<li>P967: Seems risky. some spammers may be able to gain control of the infected computer and any information on it.</li>
<li>P972: My above answer explains.</li>
<li>P976: against privacy rights</li>
<li>P984: They need to make sure that no one's computer's are infected.</li>
<li>P987: To many variables.</li>
<li>P989: The dilemma of conducting this sort of research is challenging, but it sounds interesting at the same time and the results would be interesting.</li>
<li>P1004: They could get in trouble for not informing users that follow spam links.</li>
<li>P1005: Too complicated a study, too much risk to have things go wrong. This is a very complicated setup involving many different groups.</li>
<li>P1007: I don't like spam, and if someone wants to respond to it, then buyer beware.</li>
<li>P1012: I see no harm in it since they aren't actually taking money from participants.</li>
<li>P1016: This seems like an interesting study.</li>
<li>P1017: may not be ethical but probably ok... as long as not a virus but just a spam email</li>
<li>P1018: Sure. As long as they are willing to.</li>
<li>P1026: I think there is too much risk at exposing their computer to a spammer but then "maintaining control" - it does not seem to be guaranteed to be safe for participants.  Also, it seems unethical to present a dummy site of products that participants would try to buy but then not really have those products. </li>
<li>P1031: Due to the fact that the researchers would be "listening in" on what was taking place anyway, I think the results of the experiment could be worth the intrusion into people's lives. </li>
<li>P1039: I'm not sure how important this research question is.</li>
<li>P1041: As long as no payment or personal information is being collected, I don't see any risks to the participants. </li>
<li>P1045: Even if this research is not being conducted, the participants would still be getting spammed. So might as well gain empirical evidence of its efficiency.</li>
<li>P1051: I've often wondered about this....Do people REALLY buy from these places?</li>
<li>P1055: I would be cautious about any experiment that involves getting people's passwords, but if you can trust the researher, and they only kept the information as long as needed on their one computer and wouldn't  allow anyone else access to that computer, it would be alright.</li>
<li>P1056: It sets a virus in place. They say they will not collect payments or personal information but this could make a lot of people angry</li>
<li>P1059: As long as no one is harmed, there should be no problem.</li>
<li>P1062: This seems like it may yield positive results and be quite beneficial.</li>
<li>P1063: Hard to say, since they would be deliberately annoying poeple</li>
<li>P1069: This is too risky for the participants, especially without their knowledge.</li>
<li>P1076: I would be interested to learn this myself, because companies keep sending spam for a reason, so people must be clicking on the links and ordering products.</li>
<li>P1081: I don't like that the researchers will not inform the people that receive the spam sent by the attackers. I don't think that is right. I would want to know.</li>
<li>P1084: There are always legal issues, and for most studies the participants are informed.  I do see however, that this is the only way to get real data which will be beneficial to many in the end.</li>
<li>P1088: Spam is awful, and it would be very beneficial to the public to put a stop to it... I myself find it very annoying.</li>
<li>P1089: It is not ethical to know that someone is being cheated and not help them, or not to report a website that is hurting people.</li>
<li>P1109: This violates a number of ethical guidelines and could result in identity theft if the coding of the spam is not correct.</li>
<li>P1110: I would be very cautious about using any coding or programming created by a spammer. They often infect other computers and could easily infect the computers of participants.</li>
<li>P1111: I think it would be great if researchers can figure out a way to stop spammers before they target unknowing people.</li>
<li>P1112: I think it is deceptive and not a good idea to conduct research in this way.</li>
<li>P1113: Lack of benefit or explanation to participants make me uncomfortable with this one.</li>
<li>P1116: The idea of the research is good and needs to be done.</li>
<li>P1119: They should be given permission, but they must have the best anti-virus measures in place to ensure the spamware doesn't bloat out of control and to make sure there is no spyware included with the spam.</li>
<li>P1123: I think this study is different than most and would definitely be a great experiment to obtain data that could be very effective in changing how spam emails are sent.</li>
<li>P1130: As long as they're safe and careful with the data.</li>
<li>P1131: I believe that becoming infected with spam software is too dangerous.</li>
<li>P1140: I don't think it is a wise idea to allow your computer to be infected with spam. It just does not sound like a good idea at all.</li>
<li>P1157: With all the problems facing the nation and the world, why devote time, resources and thought to spam?  It is what it is.  If it results in a good rate of return in the form of purchases, so what?  If it doesn't, people will stop wasting their effort.</li>
<li>P1158: Not without proper consent. Also, if consent is given, the user should immediately be taken to a secure site that explains what is happening as soon as they attempt to buy the product.</li>
<li>P1162: I believe it is a worthy experiment and nobody is harmed in any way</li>
<li>P1163: I feel like the whole experiment violates privacy and manipulates the subjects choices in a dishonest manner. </li>
<li>P1165: I just think we people get enough annoying spam emails and advertisements that we do not need anyone messing with us in an experiment.</li>
<li>P1173: It may backfire if the spammers find out. Their computer could be hacked or get viruses. </li>
<li>P1174: if your doing it to yourself its ok</li>
<li>P1178: I don't think the researchers should endanger people</li>
<li>P1179: It needs to be studied so it can be stopped in the future.</li>
<li>P1191: So long as the researchers have a solid website that cannot receive any information from a subject, and that the infected computer cannot harm the subject's computer(s), I think this is okay.</li>
<li>P1192: As though it were conducted as described, without participants information being obtained.</li>
<li>P1195: Always use caution when dealing with unsuspecting participants.</li>
<li>P1196: This experiment involves the collection of individuals personal financial information.  The potential for misuse is not great.</li>
<li>P1199: they need to make sure that no personal information gets leaked.</li>
<li>P1203: This would result in good data. They should do it. </li>
<li>P1206: They may not have the technical knowledge to ensure the computer isn't really compromised.</li>
<li>P1209: This seems like an invasion of privacy. </li>
<li>P1211: There is no consent provided by pts. </li>
<li>P1216: The experiment is unethical</li>
<li>P1220: it is too dangerous.</li>
<li>P1229: sure we all hate spam and anything to help get less of it can not hurt.</li>
<li>P1230: I feel like that is dangerous and you could possibly get into a scenario where the researchers thought they had things under control but one mistake may send people to the actual spam site.</li>
<li>P1233: It sounds like a great idea.</li>
<li>P1234: the implementation is unsound.</li>
<li>P1238: why not if people don't care</li>
<li>P1243: I do not see anything alarming about it</li>
<li>P1244: This research would not be ethical.  The participants needs to be notified.</li>
<li>P1245: I'm pretty sure the users have to be notified that they are in a study </li>
<li>P1246: there is no reason not to </li>
<li>P1247: As long as the results are anonymized and stored securely.</li>
<li>P1248: I would be interested in the results of this study. I have never personally bought something from a spam email.</li>
<li>P1253: The lies and tricks are too extensive to allow this research program to proceed.</li>
<li>P1260: I don't see why anyone would sign up to be a part of this study. </li>
<li>P1261: Yes they should continue but make sure that they do it carefully because these type of things can lead to viruses and malware. </li>
<li>P1262: So they can carefully craft a defense.</li>
<li>P1264: Please see previous response.</li>
<li>P1265: Spam doesn't seem like a huge issue to me. Just request to stop getting them or delete the few you get from your inbox everyday.</li>
<li>P1266: Too easy for something to go wrong, or to have people go to the wrong site or something and actually purchase things they should not. And I don't think it would be as educational as the computer privacy research because it wouldn't be able to be as generalized to other spam.</li>
<li>P1267: This sounds like a breach of privacy.</li>
<li>P1270: i think the data collected would be interesting</li>
<li>P1272: Only if there are checks & balances in place to prevent actual fraud/scams.</li>
<li>P1273: Seems a little complicated and not in full control.</li>
<li>P1274: n/a</li>
<li>P1278: I think all studies where people are "tricked" should be cautioned.</li>
<li>P1283: Participants are deceived and are not made aware that they are in a study.</li>
<li>P1286: Sounds as though it's treading the line of getting super personal information from the participants.</li>
<li>P1289: it is beneficial to learn how spammers are successful so we can deal with them</li>
<li>P1295: I just don't think it will be successful.</li>
<li>P1296: It would see how easily people are influenced by spam and might help people with impulse purchasing problems.</li>
<li>P1299: I think this can be a good way to help eliminate spam without bothering the general public.</li>
<li>P1300: As long as no payment is allowed to go through and all identifying data is removed it should be fine to do so.</li>
<li>P1301: Just don't let it get out of control, or someone else take over your botnet.</li>
<li>P1309: Unethical</li>
<li>P1310: I think things could go badly. Reverse engineering infected computers can have the chance of missing something.</li>
<li>P1316: It seems kosher to me, since info won't be stored or collected, but the researchers will have access to personal information. </li>
<li>P1318: There will be anonymous participants which is good and it is safe.</li>
<li>P1319: It would be important for the banking info to be purged from the system so that it couldn't be used to harm anyone.</li>
<li>P1320: I think the experiment is an interesting idea but not acquiring consent is problematic.</li>
<li>P1326: Even though the participants would remain anonymous I feel that it is misleading and an invasion of privacy.</li>
<li>P1328: It seems awfully easy to mess up</li>
<li>P1330: I don't know why the researchers would not inform the users of the purpose of the study.</li>
<li>P1331: I would find the results of this interesting personally and I don't see how any harm is done by collecting information like this.</li>
<li>P1332: It seems very easy to actually get the person caught in real spamming. Plus, it seems very dishonest.</li>
<li>P1340: I don't know if this research should be started because I think the spammers will take over the project computer. </li>
<li>P1343: With the condition that people are informed after going to the site that they were part of a research study. </li>
<li>P1344: They would have to ensure that there was no way for the spammer's to infect the shopper's computer.</li>
<li>P1346: Only if they inform the participants of the study afterwards and give them the choice to opt out of the study.</li>
<li>P1348: Yes, if it is just an experiment I see no problem with it. </li>
<li>P1356: I just don't think they will have the control that they think they will have</li>
<li>P1357: Don't like the deception</li>
<li>P1360: I am leery about the downloaded spam program and would not want to proceed for that reason.</li>
<li>P1363: I don't know if I would trust researchers with payment attempts.</li>
<li>P1371: It seems like it would be impossible to gain consent to conduct the experiment without compromising the results</li>
<li>P1373: They are being misleading</li>
<li>P1374: I see no harm in this except to the spammers.</li>
<li>P1386: It sounds like it is the kind of experiment that could backfire, and have negative results.</li>
<li>P1389: I'm not entirely sure of the legality of this experiment. If legal, the researchers should be allowed to proceed.</li>
<li>P1395: I do not see the harm in the above experiment.</li>
<li>P1406: I think the researchers should alter their approach. I don't like the thought of being used like that.</li>
<li>P1411: Seems potentially risky</li>
<li>P1419: Any options that need to be done to stop spammer from destroying a person's security and well being should be research and put in place.  </li>
<li>P1421: I'm worried about how ethical it is deceiving people and if there are some other dangers involved that might not be outlined.</li>
<li>P1427: Yes, spammer are horrible. It would be beneficial to find out new and different way on how to stop them. </li>
<li>P1432: Im not sure it this would be legal but it sounds interesting</li>
<li>P1433: I don't see a problem since they're not actually collecting payment information.</li>
<li>P1436: feels too unethical</li>
<li>P1446: If you can notify the people that they have been spammed and their purchase has been denied and recorded.</li>
<li>P1456: Frankly no as its both Unethical and Illegal!".....</li>
<li>P1462: The results could help produce software that will be helpful to consumers in the future.</li>
<li>P1465: It seems too risky of an experiment.</li>
<li>P1470: The information that would be gathered from this experiment would not benefit mankind.  It is unnecessary.</li>
<li>P1472: Just curious of the effectiveness of spam</li>
<li>P1479: There isn't any harm in this experiment.</li>
<li>P1486: The information found will be very helpful </li>
<li>P1487: It is worthwhile information to collect.</li>
<li>P1488: I SAY THIS BECAUSE IT WILL ULTIMATELY HELP INDIVIDUALS, BUT THEY WOULD DEFINITELY HAVE TO BE CAREFUL THAT NOTHING LEAKS</li>
<li>P1489: It's a little dangerous.  The hackers could out smart you!</li>
<li>P1492: I don't think its right to trick people who haven't volunteered for this study. I also think it sets a bad precedent to allow researchers to essentially become part of a spammers botnet in the name of research. </li>
<li>P1503: It would give them valuable information </li>
<li>P1507: This shouldn't be allowed its risking people's private information saved on their machines.</li>
<li>P1508: it's deceptive and not fair to the people being studied</li>
<li>P1510: This may run afoul of federal anti-spam laws, I have no idea.  I'm sure you have a better sense than I do.  </li>
<li>P1513: As long as no privacy was invaded this could be beneficial. I hate spam emails!</li>
<li>P1514:  consiquences may vary</li>
<li>P1517: Once again, they are not doing harm to anyone and the information is kept anonymous so I do not see any reason that the experiment should not be allowed to proceed.</li>
<li>P1522: I think that as long as they aren't taking actual payment this could be helpful.</li>
<li>P1524: This one sees a little risky - messing around with people's intended purchases and their money.</li>
<li>P1525: Awful experimentation</li>
<li>P1528: The dangers of stupidity are vast. Also having high knowledge of these things to make sure that the infection is completely gone, otherwise you could be infecting your network and those who connect to it.</li>
<li>P1538: While the researchers have good reason for not divulging information about the experiment to the participants during the experiment I believe they should be required to tell the participants about it afterward to give them the option the exclude themselves if necessary. It's an ethical matter.</li>
<li>P1540: I don't believe that it is morally wrong because they are not taking people's money. </li>
<li>P1542: If the spammers don't do what they are supposed to do, this experiment could cause a lot of problems.</li>
<li>P1546: It would provide interesting results about who uses these services.</li>
<li>P1547: Some spam also include a virus or phishing scam. They'd have to be careful not to compromise the computer security of subjects.  Using a honeypot is fairly common these days though.</li>
<li>P1552: im not really sure about the value of the data that would be gleaned from this experiment</li>
<li>P1553: Even though spam offers are ridiculous it is still the right of the consumer to make these purchases and if you create a fake mirror website in which they cannot make the purchases then that would be unethical/possibly illegal.</li>
<li>P1556: It seems wrong to not inform the participants.</li>
<li>P1558: This method doesn't appear to be secure enough, nor does the research seem especially relevant to the goal of stopping spam.</li>
<li>P1582: You are messing with fire here.  You don't necessarily know what the software will do to the researchers computer.  It may do something harmful before the researchers can stop it.</li>
<li>P1583: I think that spam is a dangerous and strong threat to the online community and that it should be stopped, or at least hindered, at (almost) any cost.</li>
<li>P1597: This is highly dependent upon whether the researchers are qualified and able enough to maintain control.</li>
<li>P1598: We already know the hit rate on spam is extremely low.  It only pays off because email is extremely cheep.</li>
<li>P1604: The researchers should be monitored to ensure that they are NOT collecting the buyers information for nefarious reasons.</li>
<li>P1612: I think there are better ways to analyze spam emails.</li>
<li>P1615: Could hurt online business, also users don't know about it</li>
<li>P1617: As long as everything is anonymous and payment information is not stored than its fine.</li>
<li>P1618: I don't think it's ethical to refrain from telling participants that they were part of such an experiment.</li>
<li>P1620: They are hacking hackers which seems a little not okay.</li>
<li>P1633: The ease at which this could go wrong is apparent. The scientists have seemed to think of most of the harmful ways that it could go wrong. As long as they are save they should be fine. </li>
<li>P1643: Using spam in practice is cumbersome to users of email and a nuisance.</li>
<li>P1649: They would absolutely need to be cautious with this as sensitive material may be leaked.</li>
<li>P1650: anything dealing with e-security should be done with much precaution</li>
<li>P1651: With anything online like this, just make sure data is secure. </li>
<li>P1655: This study seems that a lot could go wrong and that there could be potential privacy issues.</li>
<li>P1657: It would be nice to cut down on spam, but they would need to carefully screen for willing participants.</li>
<li>P1664: A lot of sensitive information is in the researchers hands which can be dangerous if not disposed of post study.</li>
<li>P1668: I think the results of this experiment would be good and could possibly help prevent scammers from operating in the future!</li>
<li>P1671: I would modify the study to include a notification that they had been duped.</li>
<li>P1674: It doesn't seem to be creating harm where there was none - just substituting their own spam for someone else's.</li>
<li>P1676: 0</li>
<li>P1678: This seems perfectly okay with me. </li>
<li>P1680: This research is a little strange to me.</li>
<li>P1683: the findings or results arent meaningful or worthy enough to study.</li>
<li>P1686: People already know about spam and I don't think it would help reduce spam</li>
<li>P1696: I believe the researchers should make their own spambot, not use an existing one. To me, it seems more secure for the purposes of the study. I believe people should be informed if they were included in the study, maybe on the "checkout" page. </li>
<li>P1704: See above</li>
<li>P1705: this will advance protection of common problems</li>
<li>P1707: hackers are a creative bunch, and can alter the experiment themselves if they figured out the system.  They would then have access to a lot more then desired.</li>
<li>P1708: Yes I still think they should be allowed to continue.</li>
<li>P1710: It seems like a good idea.</li>
<li>P1715: I agree it would be somewhat interesting to learn more about the spamming process.</li>
<li>P1722: This could lead to the results being used by corporations to sell more products</li>
<li>P1729: the amount of people that could be helped would out weigh any moral hang ups</li>
<li>P1733: I believe it's important for the researches to measure the effectiveness of spam emails so that perhaps one day spam can be stopped. </li>
<li>P1738: Yes but with the cautions already expressed in the above.</li>
<li>P1740: Always was interested if people actually bought things from spam e-mails.</li>
<li>P1744: Too much personal info being given out without knowledge </li>
<li>P1746: This could lead to some valuable results.</li>
<li>P1752: NO I understand the want to do the research but theres no way to do this without invading someones personal space and property</li>
<li>P1753: they are acting almost the same as the spammer using people to get what they want and not telling them about it. </li>
<li>P1757: No one is harmed in any way as a direct result of the study.</li>
<li>P1758: This seems to have a lot of flaws. </li>
<li>P1763: The research being performed isn't worth the invasion of privacy</li>
<li>P1764: This research could provide valuable insight into spammers and their habits.</li>
<li>P1770: Seems like an invasion of privacy</li>
<li>P1774: Not without the participants being notified of their monitoring activities. </li>
<li>P1775: AS I said. I hope this is a joke. My computer is my private domain. I hate cookies, but they are forced on us. I hate Facebooks lack of privacy and have my site fastened down to the best of my abilities. I don't care about research to the extent it feels the right ro use my private space for an experiment.</li>
<li>P1784: Doing things with peoples activities and making notes of what people are doing, even anonymously is a slippery slope. </li>
<li>P1785: While I don't want someone I know to be tricked I don't see a reason to stop the experiment.</li>
<li>P1786: The experiment sounds entirely illegal and unethical in every way.</li>
<li>P1806: Just not sure how I feel about it. If I wouldn't want someone I care about doing it then why would I want someone else too. </li>
<li>P1808: Not enough participant consent, ethical issues arise</li>
<li>P1812: If you're doing research on something you should be included to collect data </li>
<li>P1814: They might think the information is valuable, but there is no way to do this without endangering people's safety.</li>
<li>P1821: Because people might get mad because they might have really wanted to purchase something from the store and cannot. </li>
<li>P1825: may lose control of computer</li>
<li>P1829: Even though it would be useful to know how successful spam emails were, this study to me seems like a breach of privacy. </li>
<li>P1835: This experiment has potential to make a lot of people feel angry and unsafe with their information but it could also prove very useful</li>
<li>P1837: Research is very important</li>
<li>P1839: This wouldn't be an important enough experiment to validate the "trickery" involved with getting someone's financial information</li>
<li>P1841: We all get enough spam as it is.  Everyone hates it, and that is already known.  </li>
<li>P1842: This seems unethical.</li>
<li>P1848: I'd hope that they'd find negative results about the effectiveness of spam and hopefully companies would stop spamming as much.</li>
<li>P1850: The experiment seems harmless and has a positive outcome.</li>
<li>P1851: As with the passwords, always use caution with spam.</li>
<li>P1853: This experiment seems to involve people's intimate personal lives too much. </li>
<li>P1857: One reason I'm not sure they should perform the experiment, is how valid the results would be. When I was reading the description of the experiment, I had doubts about it working and felt like it wasn't the "right" way to go about measuring the effectiveness of spam. </li>
<li>P1864: Maybe if the researcher offered some kind of compensation for the subjects lost time and effort.</li>
<li>P1865: I think stopping spam would be a great thing.</li>
<li>P1870: They should be able to proceed as they are taking all steps to ensure the participants privacy and security. They should be cautious to make sure that no information about the participants is leaked, as they are unaware they are participating.</li>
<li>P1871: Help the cause but don't add to the problems.</li>
<li>P1873: This seems dangerous.</li>
<li>P1874: This could easily be seen as even more people trying to take more money from people who don't know better.</li>
<li>P1876: If by chance someone finds out about the experiment they might bring legal charges against the researchers.</li>
<li>P1878: Spam has so much negative connotations, perhaps theres a better way to go about it</li>
<li>P1884: Just make sure all the rules are laid out clearly. </li>
<li>P1890: The researchers should inform the participants because they have a right to know that they are part of an experiment.</li>
<li>P1893: I feel like this experiment could end poorly or backfire, way too dangerous.</li>
<li>P1894: I'm for anything that might result in less spam</li>
<li>P1897: Making sure they are not causing spam while researching it.</li>
<li>P1901: The more we know, the better we can deal with spammers.</li>
<li>P1902: If they do their jobs correctly no one should be hurt in any way shape or form </li>
<li>P1906: Just because it's spam doesn't always mean the product isn't legitimate. I would be surprised if it wasn't illegal to prevent them from purchasing the products they want.</li>
<li>P1913: People need to be informed after the study that they were involved in it, or permission needs to be asked beforehand</li>
<li>P1916: If you are doing this, do it with the intent of assisting or attempting to eliminate SPAM emails.</li>
<li>P1917: I think the risks outweigh the benefits. </li>
<li>P1920: I don't think it is ethical to perform experiments on people that have not consented to participate in any kind of study.</li>
<li>P1938: Tough call, but given that no personal info will be collected and it's more about just collecting the numbers on who bought into the spam, I think it could be okay.</li>
<li>P1942: The links MUST be changed and the researchers must know about EVERYTHING that the spammers have infected the computer with.</li>
<li>P1951: It would give a good idea of how many attempts to buy products are produced by spammers.</li>
<li>P1953: I support the research and think it could be very valuable, but the researchers should be cautious and make sure no one is actually affected by real spam or other unwanted intrusions.</li>
<li>P1955: This seems like a bad idea. For one, it doesn't seem a reliable way to get data. Too many variables outside the researchers control. It also makes them passive observers of criminal behavior and exploitation.</li>
<li>P1960: I think it would be helpful information to know, but dangerous to the people receiving the spam emails and potentially purchasing through the links. </li>
<li>P1963: I can see how it could possibly be beneficial but the level of deceit that has to be used to innocent people doesn't sit well with me. I'm not sure.</li>
<li>P1970: Once again, there's no harm one way or another and the results would be interesting.</li>
<li>P1973: It is unethical to mimic other businesses for research purposes.</li>
<li>P1978: It is borderline unethical, it should also help companies like Norton to create better Spam-blockers after the study is done!</li>
<li>P1982: I think the feedback to the users is not defined well enough.  They are left not knowing until the final paper which is summarized.</li>
<li>P1991: There are risks regarding the security of the information they are collecting. </li>
<li>P1998: This experiment may or may not involve breaking several laws. In the event that it does involve breaking laws, it does involve compromising peoples' security. This is wrong.</li>
<li>P2002: It puts the computers of the subjects at risk.</li>
<li>P2003: I've never thought as purposely letting a virus onto my system as being valuable. Hopefully they can monitor this in the ways they think possible.</li>
<li>P2004: It's informative but can make lots of people upset because nobody enjoys spam.</li>
<li>P2007: If they're not collecting data, then it should be fine, but they should let them know afterwards once they finish attempting to buy the product or after the study was finished</li>
<li>P2016: Great experiment.</li>
<li>P2025: They should use caution as to what information they are allowed to gather.</li>
<li>P2026: I think the researchers should notify the participants after they visit the store to make a purchase. I don't see how they would compromise the study after the fact.</li>
<li>P2027: i think the study would be beneficial to the research</li>
<li>P2032: No tampering with the computers please.</li>
<li>P2036: Researchers should use the utmost caution to make sure they can stay one step ahead of the spammers and the codes they are using.</li>
<li>P2040: As long as personal information is not collected, there is nothing compromising about this study.</li>
<li>P2043: I'm not sure if this is necessary</li>
<li>P2048: No personal information is being recorded, however, when financial information is in any way involved, the situation is precarious.</li>
<li>P2051: I believe that even with the best of intentions, reworking or otherwise resending the spam original sent to the "Test Computer". Might result in unwanted back doors opening on computer recipients of the "Reworked Spam". This could result in even more dangerous viruses or worse. I'm not a computer expert, but it just sounds dangerous. I wonder if the study could be conducted differently. An online survey perhaps, or consumer reports of websites that use spam or extracting the information another way. Again I'm no scientist or expert. These are just my opinions. How you continue from here is up to you.</li>
<li>P2053: please see above</li>
<li>P2060: It is something that really needs to be studied.</li>
<li>P2061: its a very helpful data to know the process of how it goes</li>
<li>P2063: Yes again as long as they remove the spam software once the experiment is completed.</li>
<li>P2070: As long as their not causing harm, it should be okay</li>
<li>P2072: Seeing how successful spam emails are doesn't seem harmful to me.</li>
<li>P2082: It is starting to be unethical with how deceptive the experiment actually is.</li>
<li>P2094: I wasn't aware that doing what this project suggest was possible (to basically take over a spammer's work without the spammer becoming aware). However, if it is is certainly isn't hurting anyone (although it isn't directly helping anyone either).</li>
<li>P2097: The researchers themselves are spamming, using their own computer to do so, and they are spoofing a retailer's website.  </li>
<li>P2114: Spam is a big issue these days.  It would be good if we could learn more about it and its economic impact.</li>
<li>P2117: There really ought to be a disclosure at the end of the study and researcher contact info. Perhaps a debriefing that warns them of how stupidly dangerous going to spammer sites can be for their personal information and fiscal information as well so their is a benefit to having participated. </li>
<li>P2119: As I said before, there's really not enough information, but according to the information provided, I am leaning towards "no".</li>
<li>P2121: This could be a potentially dangerous study, since it's dealing with spam and people attempting to make purchases.</li>
<li>P2123: they will not be informing people  they were part of experiment</li>
<li>P2125: The study findings would be useful.</li>
<li>P2126: It is a harmless experiment</li>
<li>P2132: Not ethical</li>
<li>P2134: There are causes for concern.  The participant's personal information will be deceptively given to someone other than they thought they were giving it to.  This would amount to fraud because the participant's would act in reliance of false statements made for misrepresentations.  </li>
<li>P2135: Could be useful, but may allow to much harm.</li>
<li>P2144: It's important to get to know how spammers operate. </li>
<li>P2155: This does not seem safe.</li>
<li>P2159: it helps not harms</li>
<li>P2164: This experiment never lets the participant know that they have been deceived in a safe way and allows a more permanent monetary loss to occur.  They are also stuck with monitoring software on their computer. </li>
<li>P2172: It gives the researchers more information on spam-related sales and how effective they are.</li>
<li>P2175: There is no way to guarantee the safety of everyone involved. The researchers might think they can control it but if they are wrong the ramifications would be severe.</li>
<li>P2176: If researchers are not wanting to send spam themselves, then it'll be difficult to get information. If they do send spam, they might get a bad reputation especially if their research doesn't bring back good results.</li>
<li>P2177: I'd participate, but not all people would be willing.</li>
<li>P2179: It seems like there could be some ethical complications regarding this approach.</li>
<li>P2183: If they want to do it with their own lab computer, go for it.</li>
<li>P2184: The researchers should be careful with engaging with spammers, but I think the experiment is worthwhile pursuing.</li>
<li>P2193: I wouldn't let a friend do it but someone's got to.</li>
<li>P2194: How do I know this isn't some type of government project to keep tabs on what people are doing without their knowledge</li>
<li>P2208: As long as no personal information is collected it seems okay.</li>
<li>P2212: I feel that there are other methods of measuring spam e-mails, and one's that are not so much in an ethical gray area.</li>
<li>P2213: As stated before, I can't really parse the morality because I'm not sure how it would actually occur.</li>
<li>P2216: There doesn't seem to be too much ethically wrong, but it may make some participants feel uneasy once the truth is revealed</li>
<li>P2218: It is a highly unethical experiment, due to it's secretive nature, and also for the temptation available to the research group, and their staff to violate their personal ethics for profit.</li>
<li>P2219: This experiment seems especially shady and dishonest. </li>
<li>P2221: Yes, while it sounds a little scary, it will be extremely controlled and monitored, and there will be no risk of harm to the participant.</li>
<li>P2228: It seems like it would be difficult to completely control what a hacker/spammer has access to. </li>
<li>P2231: There seems to be a violation of privacy and no consent is given but it seems like a safe experiment if no personal info is taken.</li>
<li>P2233: This information could be valuable and protect people in the future</li>
<li>P2237: Sounds helpful to stop spam.</li>
<li>P2238: Sounds unethical.</li>
<li>P2244: In the end this will still effect the consumer who is trying to purchase a product. Since the store will "technically" be "fake" the consumer will not receive a product however they will also not be charged but at the same time expectations are that there will be a product delivery.</li>
<li>P2245: This is a waste of another persons time.</li>
<li>P2250: I would not be happy if I put my credit card number and address into that only to find out it was fake. </li>
<li>P2253: It is a subject I think many people are curious about.</li>
<li>P2254: all computer activity as we become more dependent on the use should be researched and studied</li>
<li>P2260: If they change the spam code so it would not actually infect the computers. </li>
<li>P2273: I think  an explanation  afterwards would be  warranted. </li>
<li>P2275: effectiveness of spam isn't an ethical topic</li>
<li>P2276: The nature of this experiment isn't nearly as controlled as the previous ones so caution would absolutely be required.</li>
<li>P2280: To allow spammers free range can be opening a door that could expose some security breaches</li>
<li>P2281: Researchers would be using deceiving methods to collect information and I do not think this is right.</li>
<li>P2284: They might damage the person's computer.</li>
<li>P2286: This is a situation that could deteriorate quickly if the utmost precautions are not taken. </li>
<li>P2289: They should be able to proceed with this because spamming has become a real problem in the age we live in.</li>
<li>P2302: This experiment puts too many innocent people at risk.</li>
<li>P2307: It is potentially very dangerous, but more knowledge is always better.</li>
<li>P2309: Same reason as above. The study is unethical because participants are not aware they are included in the study.</li>
<li>P2314: This is a very prevalent issue these days and finding could be useful.</li>
<li>P2316: Yes, so they could come up with an extension, or add-on to stop email spam scripts. </li>
<li>P2323: It's important that their information is kept private.</li>
<li>P2324: See above. Not sure on the morality of all that. But I might not be totally understanding how it works. Had to read the first few lines a few times.</li>
<li>P2326: The results of the research could be beneficial in the long run, and the persons participating in the study are not being harmed.</li>
<li>P2328: the participants should be told after they make the purchase that the store had been disabled and their purchase was recorded.</li>
<li>P2338: I'm not sure, I would like to see more information</li>
<li>P2339: This study might be a little unnecessary</li>
<li>P2340: I could see the benefits. It might allow for better control of the spammers. But I don't like the idea of users not knowing.</li>
<li>P2341: People are very intolerant of what they would consider their privacy being violated.</li>
<li>P2348: It seems well thought out and fine</li>
<li>P2349: Anything to stop spam, its so annoying.</li>
<li>P2350: It sounds to risky and some of the researchers could use the information that they receive against the unwilling participants.</li>
<li>P2351: This experiment doesnt seem totally safe.</li>
<li>P2353: Too big a chance that personal data will be collected.</li>
<li>P2354: Consent could not be obtained and it could not possibly be anonymous.</li>
<li>P2357: We don't need more spam</li>
<li>P2368: As described above, it doesn't seem safe.</li>
<li>P2370: researchers should be allowed to test the effectiveness of email spam for the sake  of acquiring data that can help with advertising.</li>
<li>P2372: Not much of a way to do it except this one.  </li>
<li>P2378: Too much risk involved</li>
<li>P2382: There are good stop-gaps to ensure anonymity and that there wouldn't be loss of property/money, but this is a delicate experiment that requires a lot of observation/regulation.</li>
<li>P2386: I think this should be tried on a very select few people at first.</li>
<li>P2392: It may make someone change their email passwords and believe their friends are infected by spam, causing annoyance to the anonymous users. But I guess it happens enough in real life anyway.</li>
<li>P2396: Seems like it could help understand spamming and also save a few people from bad decisions.</li>
<li>P2397: Although I do not see the duplicate spam site getting a lot of hits the few it does get are bound to think something is amiss and become very angry when they purchase something and literally nothing happens.  </li>
<li>P2401: The fact that nothing is divulged to the people that participated unwillingly is what makes this study troubling. They have a right to know that they were being spamming as well as their actions recorded and reported. </li>
<li>P2403: Researchers may not be able to control everything like they want to.</li>
<li>P2409: I want to say no as I feel it is a bit dangerous. But at the same time, perhaps the findings of the experiment can help people.</li>
<li>P2428: Perhaps if we are aware of what triggers work, we can educated the general public and then spammers will lose thier audience and their incentives.</li>
<li>P2435: A great idea like the previous one but as always we need to be careful so that nobody else gets this information. </li>
<li>P2445: The researchers aren't actually collecting any sensitive information, so I don't see the harm in it.</li>
<li>P2450: I have no ideal how you would go about it with out losing data (even if it is slim}</li>
<li>P2451: Research of this nature is valuable.</li>
<li>P2453: This sounds like it might be risky and dangerous if not handled well.</li>
<li>P2456: Seems unethical.</li>
<li>P2457: too many privacy issues</li>
<li>P2461: They need to ensure privacy measures are taken. </li>
<li>P2463: This sounds like a harmless experiment.</li>
<li>P2473: Definitely have to take their time and be careful as to not hurt anyone in the process</li>
<li>P2478: There doesn't seem to be any harm in this. </li>
<li>P2480: Spamming needs to be stopped this research will help make that heppen</li>
<li>P2483: I am interested in understanding how and why spammers gather information.</li>
<li>P2488: A lot of people will read/respond/react to spam e-mails, despite the warnings out there.  Since I'm sure the researchers would take every precaution to ensure others' computers would remain uninfected, I see no reason why they shouldn't be allowed to carry out the experiment.</li>
<li>P2491: It's is an invasion into the shopping privacy people deserve.</li>
<li>P2495: this can be a very tricky thing to duplicate and can backfire</li>
<li>P2496: They need to be careful and keep the spam in control. </li>
<li>P2499: This can help real attacks.</li>
<li>P2501: I don't think this is the best idea because it seems possible that people's personal information, such as credit card numbers, could potentially be exposed. </li>
<li>P2507: I've never bought anything from a spam email. I'd be interested to see the results of the study.</li>
<li>P2518: The data may be useful, but the method could be open to criticism. </li>
<li>P2522: I think it would give great insight into the topic so I think they should be alowed to proceed</li>
<li>P2530: If researchers want information this bad, they should use themselves as test subjects (or people in their field) rather than unassuming people I care about.</li>
<li>P2532: Researchers could figure out how and why spam works.</li>
<li>P2535: this sounds a little dangerous</li>
<li>P2536: Are you sure that information isn't available somewhere else without being deceptive?</li>
<li>P2539: This would not be justifiable. This is too much interference in the personal affairs of the person that is being redirected to the research website.</li>
<li>P2542: Same as above.</li>
<li>P2543: It seems pointless. The statistics are unnecessary.</li>
<li>P2545: I have an issue with the researchers allowing spammers to infect the computer because if something goes wrong then those people are in trouble. I do, however, like the fact that this time they are not asking for any personal information or passwords. </li>
<li>P2547: Same reason as above. Because if it can help stop the spam, then it is a good thing. </li>
<li>P2549: It is frustrating to receive spam, even if it is for educational purposes</li>
<li>P2555: unethical not to tell people the store is not real</li>
<li>P2556: I would not like to deceive people</li>
<li>P2561: There is no harm done to anybody, but rather the researchers will help those guilible enough to click on the spam link. </li>
<li>P2563: I don't like experiments where the subject is unaware & has not given consent to be a participant in such an experiment, but since everyone has a problem with spam it is a necessary evil if it helps stop or reduce spam.</li>
<li>P2565: I sont think it is a good idea</li>
<li>P2571: What`s the point? I don`t think it could be validated.</li>
<li>P2574: I believe they should be able to do a similar study, because it could be helpful, but the users must have informed consent. </li>
<li>P2575: Too much to expect from a worker to trust.</li>
<li>P2576: "Without collecting payments"? Would you collect payment info? This seems to be a slippery slope.</li>
<li>P2578: The notion of allowing the computer to be infected, and sending people spam with fake store info seems a little questionable. Also, I'm not sure it is the best measure of how people would actually behave if they got emails from a familiar store.</li>
<li>P2579: This would save a lot of people money who have trouble with their computers due to spam emails.</li>
<li>P2581: I think its important to know the tricks of scammers, but they need to be careful to not harm the participants. </li>
<li>P2584: This seems like a lawsuit waiting to happen. What if something happened so all the payment info was compromised? It seems like there would definitely be better ways to do this.</li>
<li>P2586: For the value of the end result of the research, the ethical implications of a totally blind deception racket can hardly be justified. Furthermore, the actual empirical data could be used to further the goals of spammers.</li>
<li>P2588: Might fall into a legal grey area under some jurisdictions</li>
<li>P2590: Same reasons as above. I don't understand how this works without spamming people. I don't like that the users aren't informed that the store isn't real. They might try to make a purchase with personal information.</li>
<li>P2592: They could be damaging people's personal property.</li>
<li>P2595: Maybe, but with extreme caution.</li>
<li>P2599: It would raise awareness about Spam & how dangerous it is.  Maybe even bring forth legislation to stop it.</li>
<li>P2605: Be careful not to enable these spammers</li>
<li>P2610: Just make sure that there is no financial information entered and kept.</li>
<li>P2612: This sounds ridiculous! Spam is easily blocked, deleted or ignored.  If certain people are going to spend money on it than any attempt to get rid of it is folly. I am against spam but if it makes money than it must have people that want it to continue.  I do not feel there is a need to get so in deep as a fake spammer.  I disapprove. </li>
<li>P2618: Same as previous box. You could probably have it to see if they add to cart and try to check out. Then where they usually enter info say "JK, this is spam"</li>
<li>P2619: I think there should be a way to allow the customer to make their purchase. Otherwise you set up a situation where there is untrue bad experiences with a retailer. </li>
<li>P2623: those involved in the experiment are being uses as test subjects without their approval</li>
<li>P2626: It would be a potential privacy issue and there would be a problem with people not getting the product that they are purchasing that they may file a lawsuit. </li>
<li>P2627: seems risky to my computer</li>
<li>P2628: I don't think this is ethical.</li>
<li>P2654: Violates privacy rights.</li>
<li>P2674: data may be useful on affects of spam</li>
<li>P2678: There's already enough spam emails in existence.</li>
<li>P2684: Again, it's important to have ample resources available to users so they are not as susceptible to a SPAM website's influence.</li>
<li>P2685: It would allow us to see just how effective spam emails really are.</li>
<li>P2686: The researchers are using their own computer and are lessening the impact of the natural course of a spam email. The precautions they take are very good.</li>
<li>P2688: I can think of no other way to obtain reliable data on the matter.</li>
<li>P2689: As above.  But participants need to be debriefed and informed of the study's purpose at the end.</li>
<li>P2690: security purposes</li>
<li>P2692: Illegal</li>
<li>P2713: Using people in this way is wrong.</li>
<li>P2717: Since the results of the research are predicted to be inconclusive, I am not sure that the researchers should be allowed to have access to participants' information. </li>
<li>P2723: they should be careful as to what they expose people to </li>
<li>P2727: I think the idea is great.  You are mimicking a spammer's store to get information, and at the same time actually protecting the people who would have otherwise been scammed.  I think the idea is hilarious.</li>
<li>P2735: This experiment is in the grey area. Even though no real purchase will be make or any real monetary losses, this is still an invasion of privacy.</li>
<li>P2746: I think it would be very interesting to see the results of the experiment and I don't believe anybody would be harmed in any way.</li>
<li>P2747: I feel this is a waste of time what is the point of this experiment does it matter how many people try to buy things through spam mail?</li>
<li>P2750: there are other ways without having to do all that</li>
<li>P2762: If people are actually clicking spam emails w/ the intent to buy something, and not don't that item, that's wrong.</li>
<li>P2771: Spam is usually pretty obvious. The researchers should be able to figure out a way to make recommendations without going through all that. </li>
<li>P2773: It will/may further security technology integrity </li>
<li>P2777: If they know what it is they're doing. </li>
<li>P2781: This experiment could result in spammers using the email addresses of the participants.</li>
<li>P2786: See above.</li>
<li>P2787: They have to be absolutely sure the spammers cannot block their own efforts to keep the spam sites "safe"</li>
<li>P2792: I think there are too many uncontrolled variables.  All it would take was for the spammer to subtly change their email to cause the entire thing to break down.  Also, it is dangerous to allow the computer to become compromised.  I think this is a bad idea.</li>
<li>P2793: Spam is unwelcome by anyone.</li>
<li>P2794: I think they should be allowed to proceed with the experiment but with caution because they could potentially send viruses through the spam emails.</li>
<li>P2802: Spam mail like this needs to be eliminated not studied.</li>
<li>P2804: Is this even legal?</li>
<li>P2807: I am not convinced that know how many "victims" respond to spammers will help people combat spammers.</li>
<li>P2813: Dealing with spam is no joke you need to know exactly what you are doing so you wont mess up.</li>
<li>P2818: spam emails suck</li>
<li>P2821: spamming will get you blocked from most broad range ip's and probably your isp looked at and sent a nastygram. as well as you risk provaking someone who can do something about it.</li>
<li>P2822: YES</li>
<li>P2823: I actually believe people should be informed that they are part of an experiment once they try to make the purchase and it doesn't go through. I also am a person who is curious about what mostly enables spam and how many people actually make purchases based on spam.</li>
<li>P2827: it doesn't seem like this would be appropriate</li>
<li>P2828: Spammers are a big problem and there is very little that can be done to stop them in the normal way.  If responses are significantly cut down and their success rate drops this is probably the only effective way to deal with them. </li>
<li>P2829: Yes I think a lot could be learned from this. Though I wish the researchers would divulge that it is a test the people who try to make a purchase so that maybe they would learn a lesson and realize this is a problem on the internet.</li>
<li>P2830: I believe this research would help reduce spam on computers and make users more aware of the problems spam creates.</li>
<li>P2834: As above.</li>
<li>P2837: Must gather informed consent.</li>
<li>P2838: Yes, because more knowledge will be known about why spammers spam.  </li>
<li>P2844: The only way to find the answer to spam and if it actually works is to do research.</li>
<li>P2850: Again, the ethics of this study seem highly questionable. Since the participants are not aware that they are in a study they cannot give consent. This means that personal information of theirs is being used and reported on without proper consent, or even their knowledge. </li>
<li>P2853: Because there is benefit from this study, and minimal risk, this study should be performed.</li>
<li>P2856: It is an informative study but users who buy and never receive their things, even though they did not lose any money, will be upset</li>
<li>P2860: If you let the candidate know what you were doing, then it would be okay.  You could still track spam somehow.</li>
<li>P2861: VERY EDUCATIONAL FOR SOME PEOPLE.</li>
<li>P2869: I would love to read this paper. Spam should be studied more.  </li>
<li>P2872: Spams are becoming too serious an issue. Such efforts are always welcome.</li>
<li>P2874: Helps to stop spam, which is very annoying to receive.</li>
<li>P2879: The above explanation was rather convoluted to me.</li>
<li>P2880: Too many margins for error.</li>
<li>P2882: Because of the deception.</li>
<li>P2886: I think people who are foolish enough to fall for spam should be included in this study.</li>
<li>P2888: I think it is risky and kind of wrong, but for a good purpose. </li>
<li>P2892: they should careful who they select to participate</li>
<li>P2893: Maybe, but I don't know if they will be able to maintain enough control over the computer.</li>
<li>P2896: There needs to be some sort of caution involved with this. </li>
<li>P2906: The infected computed used could in turn easily spread the infection to other computers. The abstract mentions no safety measures against this possibility.</li>
<li>P2910: Working with virus's can be risky and things can go wrong but it seems like a good experiment.</li>
<li>P2920: I don't quite know how any of this works, obviously I find it risky to allow someone to let a spammer attack your computer but since I don't know what techniques can be used by the researchers it might be safer than what I thnk.</li>
<li>P2924: it seems important but I don't like it</li>
<li>P2929: I believe this is borderline fraud and should not be permitted. People would be using their real information and payment forms on false websites for products that aren't real.</li>
<li>P2933: Too many things could potentially go wrong. I don't know the experience that the researchers have, and whether or not they might accidently leak the personal information of the test subjects.</li>
<li>P2934: Honestly, I think this is a difficult one. It isn't really harming people, but like I mentioned above, it is very intrusive and people may have real problems with it. Spam is very easy to recognize. What is wrong with sticking to the spam filter until they come up with a better idea?</li>
<li>P2941: it helps people understand what spamming really is all about</li>
<li>P2944: Consent is a big issue, especially when it comes to the participant thinking they're making a purchase. It's hard with this kind of study because it relies on the lack of informing the participants.</li>
<li>P2945: Any progress in getting rid of theft problems are worth the studies needed to make that happen.</li>
<li>P2946: Some might feel offended.</li>
<li>P2948: They have to be really careful not to mess up and have the people actually go to a spam site and lose money; also collecting financial information is always dangerous</li>
<li>P2955: Possibly they should be allowed to proceed with the experiment if it involved compensating the participants.</li>
<li>P2959: They are making others vulnerable to attack on their pc by running an infected computer.</li>
<li>P2979: It seems that all IRB protocol is being followed and data is anonymized</li>
<li>P2999: Could leek all your information on your computer</li>
<li>P3002: Yes I believe that the researchers should be allowed to proceed with this experiment because it may lead to the discovery of techniques that could stop spamming.</li>
<li>P3003: I think participants should be warned after the study is over about being careful with spam messages and how to identify them.</li>
<li>P3004: Peoples private data is being exposed.</li>
<li>P3008: I'm pretty sure this is fraud.  The researchers could just ask people if they ever bought anything from spammers and to estimate how many spam emails they get a day.</li>
<li>P3009: If it can be done in an isolated setting & provided a way to remove the spam from participants' PCs after the experiment I'd be OK w/ it.</li>
<li>P3016: no</li>
<li>P3022: I find the lack of candor unethical in the context of experimentation. </li>
<li>P3023: I don't think they should be allowed to use this information without the person's knowledge or consent.</li>
<li>P3028: if they publish results from this experiments and it will help end users to know how to protect their computers as well.</li>
<li>P3032: I think in a properly controlled environment it could still be a good idea.</li>
<li>P3034: This sort of experiment would need heavy monitoring to ensure no one does anything wrong.</li>
<li>P3036: This is too risky. Too much could go wrong. Might not have total control over the pc.</li>
<li>P3039: To deceiving.</li>
<li>P3042: respect the users privacy</li>
<li>P3043: See above</li>
<li>P3046: yes , i think it would help to defeat spammers.</li>
<li>P3047: The end result old be beneficial.  </li>
<li>P3061: I think they would not have enough control over the spammers. I think this is also harmful to the people (subjects) they are testing.</li>
<li>P3063: It definitely couldn't hurt to begin reducing spam. I think most current email filters do a good job of filtering it out themselves but more security and research can't hurt.</li>
<li>P3064: I think it's important for researchers to make sure that the spam is variable, and not all to the same "store" and whatnot.</li>
<li>P3065: I always wondered how spammers made money, I can't imagine anybody falling for that stuff.</li>
<li>P3066: personally yes. I do not think the experiment would be passed by a review board.</li>
<li>P3068: It's possible they could scare the attackers away</li>
<li>P3076: Spamming and scamming purchases is illegal</li>
<li>P3077: too high of risk of infected computers</li>
<li>P3079: Divided opinion on this one, could see benefits but also severe drawbacks</li>
<li>P3081: Because they participants are not ultimately informed of their participation, I would have to say that this experiment should not be performed.</li>
<li>P3084: Keyword:  Infected computer</li>
<li>P3095: Anything we can do to reduce spam is good.</li>
<li>P3103: There doesn't appear to be any harm in this, in fact, other than making them feel foolish, it might save participants some grief. However, I would consult and perhaps request direct involvement of local law enforcement in the study, to avoid possible legal issues and perhaps create an opportunity to identify some of the spammers.</li>
<li>P3110: I dislike the idea of someone being monitored even if no personal information is gathered, but the motive is good and the ends may justify the means. I'm undecided.</li>
<li>P3117: I think this is a worthwhile experiment with small risk.</li>
<li>P3124: Yes, if they can use the data to stop spammers. </li>
<li>P3126: I'm all for the necessary research, but the whole thing seems like asking for trouble.</li>
<li>P3130: Because the results will be skewed by filters preventing emails from ever reaching the user.</li>
<li>P3132: Again, I'm not sure if the person buying something would get the product or not since they are replacing the "store front" with a fake one but that would upset me if I ordered something and never received it.  But again, that would come to question that the original spammer should know this is happening. I wonder how many would catch this?</li>
<li>P3136: The researchers need to be very careful they keep the spammer under control so they don't end up actually ripping people off</li>
<li>P3148: I think this is a great experiment in something the public should be made aware of.</li>
<li>P3152: The benefits of this experiment are non-existent. You will never "beat" spam.</li>
<li>P3159: The experiment could upset people too much.</li>
<li>P3161: People like my parents have been affected. I think raising awareness for spam email is important.</li>
<li>P3166: Again, This is an unneeded process. No matter how effective spam is. it is not needed for people to survive.</li>
<li>P3176: Seems too dangerous to test that idea.</li>
<li>P3177: They aren't telling people that they are involved in the study (even afterwards) or giving them the option to withdraw their data.</li>
<li>P3183: anything to help fight against spam is welcomed</li>
<li>P3184: I feel like everything online is fair game so they should be allowed to do what they want/ </li>
<li>P3196: I feel an experiment such as this is too invasive.</li>
<li>P3202: With the increasing technology and on-line services and activity of our era, it is critical that studies address some of the serious technology issues known.  As the article mentioned, real scammers will most likely not contribute honestly to any study interviewer, so this is a logical step. AS long as true safety features and protocols are in place, there should be little to no harm to any of the participants.</li>
<li>P3208: This is not much better than anything scammers do. It is deceptive and will not result in much research results that could be put to good use.</li>
<li>P3209: People in the survey need to be aware </li>
<li>P3217: This is another case that sounds very interesting.  I like that the data can be gathered safely, and no actual payment information will be collected.</li>
<li>P3223: it seems like valuable research </li>
<li>P3228: It would really provide insight to the effectiveness of SPAM, I think.</li>
<li>P3236: spam sucks and people fall for it</li>
<li>P3240: Yes, it would be interesting to see what happens when the people go onto the special computer. See if they really try to purchase anything from the spam. I don't I just find spam irritating.</li>
<li>P3243: Anything to educate users about phishing is good</li>
<li>P3246: no personal hazards are present, except the annoying spam mail</li>
<li>P3252: I think they should tell the participants</li>
<li>P3258: This experiment seems to have cautions set in place such as replacing the spam link with a researcher link, to ensure safety.</li>
<li>P3260: Essentially they are attempting to perform a sting operation upon unwilling participants.</li>
<li>P3262: The people that buy something online should be sent an email saying why their order will not be processed</li>
<li>P3269: It would be beneficial to learn the spammers tactics and success levels. As a bonus, you would actually be helping those who fall victim by not actually charging them as the scammer would.</li>
<li>P3274: it didn't matter</li>
<li>P3275: I would not like it if a friend was not warned of spam on the computer they were using or a false website where they are not going to get the product they thought they bought.  </li>
<li>P3276: Ensure that there is not such a perceived risk that the candidate will back out of the study altogether.</li>
<li>P3279: If enough people are doing this that it is an issue, then researchers should be able to research it to prevent spammers in the future.</li>
<li>P3289: Again, because it may deal with financial information, I don't know how much I trust it.</li>
<li>P3296: Yes I think they should be able to do this experiment. </li>
<li>P3301: They have to be extremely careful that the spammers don't catch wind of said plan and override their experiment somehow.</li>
<li>P3306: The researchers would be contributing to spam and I do not see how their research would be able to help anyone to reduce spam.</li>
<li>P3311: Once again I'm concerned with the method in which this would be carried out.  Allowing Spammers to infect a computer and try to redirect the hits, seems like it would just increase the amount Spam received by everyday people and doesn't deal with the issue.</li>
<li>P3314: A lot of people would like to stop receiving spam</li>
<li>P3316: The results of the experiment are important.</li>
<li>P3319: I think it could help the researchers evaluate the marketing strategy behind spam and possibly make it appear less effective.</li>
<li>P3320: It would be interesting to find out the amount of sales generated by spam, though I am not sure I would approve the methods to get those results.</li>
<li>P3321: Invasion of privacy.</li>
<li>P3326: people who are deceived will be less engaged in the future when using technology.</li>
<li>P3328: especially since peoples credit cards may be used</li>
<li>P3333: Ihe experiment might cause emotional damage to the subjects who tried to make purchases from the simulated spammers.</li>
<li>P3338: This seems like a potential privacy invasion, but it might be OK.</li>
<li>P3340: It could be helpful.</li>
<li>P3341: Seems risking people's info via allowing spammers in</li>
<li>P3343: The information they obtain in this research can be very valuable.</li>
<li>P3346: This research needs to be modified. The original infection may be illegitimate or illegal but the purchase transaction is not. I'm really uncomfortable with making the buyer think he or she has actually contacted the company. It seems to me the researcher is acting illegally by interfering with the transaction.</li>
<li>P3347: Maybe the user should be informed that they were being recorded.</li>
<li>P3354: It seems too risky to me.</li>
<li>P3359: I think the research could shed some good light into how many people actually put their personal financial information into a spammer site.</li>
<li>P3360: it is unneceessary not ethical.</li>
<li>P3367: I think the spammers will recognize what they are doing.</li>
<li>P3373: I feel the ethical considerations indicated above are sufficient to warrant reevaluation of this experiment and an effort to frame it in a different way.</li>
<li>P3376: There is no other effective means</li>
<li>P3378: Maybe crate a program that mimics spam rather than being infected. </li>
<li>P3379: This experiment could get very complicated with people trying to make purchases and giving personal information of a fake website.  There could potentially be more negative consequences than anticipated, so the research would have be carefully conducted.</li>
<li>P3387: I think this study would be on the hairy edge of ethical. </li>
<li>P3389: It seems wrong to have someone think they ordered something only to never receive it. Also, it violates their privacy a little. Although they're on a public computer, so they should know better. </li>
<li>P3391: The research does not sound ethical</li>
<li>P3393: I think that this is a real issue facing the internet today and I think that it tends to be that when people are looking for something to buy they try to find the place that offers it cheapest. Unfortunately for most people that means that they run the risk of having their information stolen in the process.</li>
<li>P3397: yes, the more knowledge we have about this the more we can do to prevent it</li>
<li>P3403: I feel like it is a law(?) that you need to debrief the participants afterwards and let them know what the experiment was about?</li>
<li>P3405: Anything to mess with spammers</li>
<li>P3406: It could be very helpful</li>
<li>P3408: N/A.</li>
<li>P3411: I think by modifying it slightly it will be more acceptable. Participants who unwittingly attempt to make a purchase should afterwards be informed that it was for a study and their information is safe. </li>
<li>P3412: People's digital information shouldn't be subject to manipulation.</li>
<li>P3413: Spam is a very serious and uncontrollable issue most people who use emails and the internet in general usually have. I am in total support of doing a research that would help stop spam permanently.</li>
<li>P3416: They need to make sure they are in full control.</li>
<li>P3426: These seems to be walking a fine line, although there probably wouldn't be too much of a risk to "participants" there could be some if the researchers can't adequately control the spammers.</li>
<li>P3427: I think the ability to tack spam traffic is good, but I am not sure about the impact to the user/participant who is unknowingly being duped into participating without consent. </li>
<li>P3428:  This could be a useful study, and the results could help understand how exactly spam emails work / under what conditions they are successful. At the same time, spam emails are annoying.</li>
<li>P3431: It sounds like this would mess with spammers a bit, which is always a good thing.</li>
<li>P3438: The spammers are basically a 3rd party source that the researchers are supplying with users information. If they wanted to do this they should make their own "spam" program and keep it in a controlled setting.</li>
<li>P3440: They should try to protect the people and find another way to get this data</li>
<li>P3442: It's not ethical to lead people to believe they're making a purchase online wen really they aren't, especially when they are never told that their purchase didn't go through.</li>
<li>P3445: It is risky dealing with spam software that the researchers themselves did not create. As long as there is no way that spammers can actually benefit from the study, it can proceed.</li>
<li>P3447: This one is a bit more difficult, because these people who try to buy things from these fake spam sites will actually be expecting to be charged, and to receive something, I'm not sure if this is a good idea. I think it needs to be altered, but I'm not sure how.</li>
<li>P3453: Making sure no data is collected and the researchers can be trusted. Liability issues here as well.</li>
<li>P3456: Participants are being deceived, to a degree, but it is not malicious.</li>
<li>P3462: There is some deceit involved in users believing their purchase is going through when it is not</li>
<li>P3463: In my opinion, spam is just a normal part of email. The problem would be if the same email address was sent multiple messages over time.</li>
<li>P3466: As long as it is under control, it wouldn't be that bad.</li>
<li>P3467: That is deceptive and if someone wants to buy something from spam mail then you shouldn't interfere. I am sure there is a better way to monitor purchases.</li>
<li>P3472: That is just not right.</li>
<li>P3482: This is a borderline one.  Your research subjects aren't being told they're lab rats, which is always wrong.  On the other hand, being directed to a fake version of the webstore the spam directs them to might actually prevent them from being preyed upon by spam they otherwise would have received and responded to.  I don't know.  It's right on the borderline.</li>
<li>P3487: I think these are important questions and this research could help strengthen computer security.</li>
<li>P3495: I believe you have to know how something works to prevent it.</li>
<li>P3498: This one seems very tricky, because again malicious people (spammers) could use the data and the researchers are being misleading to the participatants.</li>
<li>P3499: This can be a way to perform this experiment that doesn't involve any actual spammers. </li>
<li>P3503: Publishing recommendations for technical or policy approaches to stopping spam would be nice however doing it without peoples consent is not ideal, I also find it hard to see how doing this will help them figure out how to stop spam. </li>
<li>P3508: They would need to find out if it is legal.</li>
<li>P3510: Make sure no real information is collected.</li>
<li>P3516: This appears to be necessary research</li>
<li>P3518: I don't think this experiment would be beneficial to them</li>
<li>P3520: researchers will have access to credit card numbers</li>
<li>P3523: it would help teach people about hackers</li>
<li>P3524: I think they should find another way to approach the issue.</li>
<li>P3525: If they gather useful data they should keep it, but it seems dangerous to become purposely infected because it might get out of control.</li>
<li>P3526: Caution is key.</li>
<li>P3532: It's an interesting experiment, but I believe that purchasers should be informed after they make the purchase of the experiment. </li>
<li>P3534: Again, good information, but to not be able to interject and stop the scam doesn't sit right with me.</li>
<li>P3536: Anything that sheds light on how to improve our way of life is a net positive as far as I'm concerned.</li></ul>	</div>
</div>

<div class='cap' style='max-width:30%;'>
	<div class='header closed'>Facebook study, answers to Proceed question</div>
	<div class='body'>
<ul><li>P5: They need to ensure that participants' privacy is strictly kept.</li>
<li>P6: I feel they should, but this could turn bad for them and Facebook due to people thinking it is to just invade them to serve ads.</li>
<li>P11: they are just trying to prove the obvious</li>
<li>P12: I don't think that the researchers should be able to manipulate the participants' Facebook pages.</li>
<li>P15: I feel that the experiment is ethical and practical when it comes to the mental health of facebook users.</li>
<li>P16: Yeah sure it will be interesting to see the results.</li>
<li>P20: This one seems a bit too sneaky as well.</li>
<li>P21: There is no informed consent nor is there any debriefing. </li>
<li>P27: I think it is wrong to exclude posts from candidate participants.</li>
<li>P33: I think facebook is a powerful tool and could hurt the persons feelings.</li>
<li>P43: I don't see anything unethical or illegal with this. This would be a good study. </li>
<li>P45: By picking and choosing comments they are attempting to control the situation which changes the end result.  The researchers cannot control the flow of positive or negative results or they will possibly skew the results.</li>
<li>P52: It's interesting, but I am concerned with missing posts.  It's something that probably shouldn't be messed with.</li>
<li>P54: As long as the participants are aware that they're a part of an experiment, I don't see any problems with this.</li>
<li>P55: This study has very little scientific merit, if any. And it is being conducted by a for-profit company, not an institution with a research arm that will benefit the community as a whole. This is just another ploy cooked up by facebook to learn how to better market to its users. This study is an awful idea.</li>
<li>P56: I believe that it is hard to judge the moods of social media users based on the postings. Plus this experiment is selectively hiding some of the friends' posts which feels like deception.</li>
<li>P59: It's unethical and there is no substantial contribution to the world from this research.</li>
<li>P61: see above</li>
<li>P65: I think they should be allowed but only with Facebook members they have approached and given the option to opt-in to a study like that.</li>
<li>P69: AS LONG AS NO LAWS ARE BROKEN</li>
<li>P77: See above.</li>
<li>P80: It seems to be a solid sociological experiment.</li>
<li>P84: If it can have helpful benefits. otherwise it is just an invasion of privacy.</li>
<li>P89: Because it will prove how much facebook really does affect people lives.</li>
<li>P93: Researchers are going into people's accounts and messing with their content without their knowledge.</li>
<li>P96: I view it as invading one's privacy even though people give up some degree of privacy when being part of a social network in the first place. I also don't think it is Facebook's responsibility to the protect their users' moods. If the experiment is done, I believe users should be made aware first and given the choice to participate.</li>
<li>P97: It doesn't make anything up, scam people, or harm them. </li>
<li>P99: I don't think it's right to play with someone's emotions like this.</li>
<li>P100: Only if the candidate had signed up to be in some type of study, even if they did not know the content.</li>
<li>P101: Yes, I do think they should be allowed to proceed because there don't seem to be any real risks.</li>
<li>P102: They're a private company so they can do whatever they want within their own terms of service.</li>
<li>P106: The researchers should utilize an "opt-in" feature, with participants who elect to opt-in to the research receiving some incentive to do so.</li>
<li>P117: It depends.  Do the participants know this is being done to them?  The description doesn't say.  If they are telling people what the experiment will do then sure they should be allowed.  Otherwise, no, they should not.</li>
<li>P119: Facebook is a personal page to express ones life</li>
<li>P121: Its already know that positive breeds positive.</li>
<li>P122: invasion of privacy</li>
<li>P135: I don't really see the point. It seems like a waste of the research team's time.</li>
<li>P136: I see no reasons why not.  It might be mildly irritating to see so much negativity, but not damaging.</li>
<li>P143: No harm, but seems of very little real value in terms of the understanding it provides.</li>
<li>P145: Facebook shouldn't control your newsfeed to manipulate you. </li>
<li>P152: Researchers should be allowed to proceed with any experiment as long as it doesn't directly hurt somebody on purpose.</li>
<li>P155: Again, as long as it's conducted ethically, I see no reason not to do so.</li>
<li>P156: Facebook should just show what we want to see and stop meddling into our personal lives. I mean they are sort of violating privacy measures.</li>
<li>P159: Playing mind games with people is wrong.</li>
<li>P161: The results from this experiment would be interesting</li>
<li>P166: It would help answer some questions surrounding the effects of social media.</li>
<li>P167: The people's post being studied or used have not agreed to be in a study, however this could be considered data that belongs to Facebook so it might be like any other store or internet company using their data or manipulating it to see what happens</li>
<li>P169: The description above does not state whether participants are informed of their participation, and thus, may unknowingly encounter ill effects.</li>
<li>P170: I would be a little skeptical that this experiment could be a platform for some of the other proposed experiments </li>
<li>P179: I don't see the benefit - facebook doesn't need features to protect vulnerable people. </li>
<li>P180: Even though I'm sure users give consent in the TOS, most are probably not aware. I think direct consent for this specific experiment should have to be attained before the experiment takes place.</li>
<li>P181: As long as it is in a controlled environment</li>
<li>P183: I think there are better ways of getting the data they want, something that will lead to a more general and useful conclusion.</li>
<li>P184: I see no reason not to perform the study, although the participants will have to agree to have their facebook streams modified.</li>
<li>P185: I don't care if I don't know the people they want to use.</li>
<li>P188: I do not believe the researchers should be allowed to do this even though it is just research purposes. It is a form of infringement on participants rights by withholding ANY information.</li>
<li>P197: i think they need to help make a solution</li>
<li>P200: "Caution" in this case is the closest to "I can turn this stupid thing off if I notice it."</li>
<li>P205: I take issue with experimentation done without a person's consent.</li>
<li>P206: I would need to know by what mechanism the researchers plan on filtering results</li>
<li>P208: Even though there are no identifiers, the researchers must still abide to all requirements of the ethical board</li>
<li>P211: affects peoples personal posts </li>
<li>P218: there's no harm that I can see</li>
<li>P220: If someone's facebook page/ timeline is going to be altered they should have the right to chose whether they want to participate or not.</li>
<li>P228: I use facebook as a primary method to keep in touch with friends from college and high school - that the study would be excluding some of their posts is very upsetting to me, as I might not get important news</li>
<li>P231: I believe in the free flow of information, and and unbias and unaltered news media.</li>
<li>P232: Their heart seems to be in the right place, however it also seems like emotional manipulation</li>
<li>P248: As above stated, I think studies such as this will help people and society  understand the impact of social media in individual's emotions, reactions, behavior. I hope such better understanding can lead to making use of social media for the betterment of individuals and societies.</li>
<li>P253: There is no risk.</li>
<li>P256: It might have negative consequences in real life.</li>
<li>P258: I see no harm in it, and it could help understand people.</li>
<li>P270: privacy and libel issues</li>
<li>P271: Sure, go ahead. Anyone on Facebook should already know the vast amount of bogus content on that site already. </li>
<li>P272: I don't mind it too much, but I can see it upsetting people.</li>
<li>P273: If I want my friends to see my posts, I want to know that it happens.</li>
<li>P282: Same reason as above.</li>
<li>P284: I think it will help.</li>
<li>P289: I cannot think of any valid reason for doing this experiment unless you have absolutely nothing else to do.</li>
<li>P292: I think that as long as nobody is deceived in a harmful way, I don't see anything wrong with it.</li>
<li>P303: Excluding posts could affect participants greatly; they will have to be careful with how people are informed about/included in the study.</li>
<li>P308: I think the valuable insights learned from this test is worth some momentary down ladden emotions</li>
<li>P309: This experiment is moral and seems interesting.</li>
<li>P313: I think people should/could be informed that a study was being performed and given the option to opt out.</li>
<li>P314: seems harmless. </li>
<li>P316: I would think you should ask permission of the participants after the study has been performed</li>
<li>P317: It seems feasible and it does not cost the participants any money but a lot of privacy.</li>
<li>P326: Only because of the ability to go into someone's account</li>
<li>P333: only if the users consent to having their posts edited/deleted to create the stimulus</li>
<li>P334: See above.  </li>
<li>P347: same answer as above</li>
<li>P350: I believe people should be aware that they are involved in this somehow, so they know that their news feed is being manipulated, but I know doing so might alter the study results. Something along the lines of a sign up saying you're willing to participate in research for Facebook without the researchers having to blatantly state what they're looking for?</li>
<li>P354: This is greedy research it doesn't help anyone but facebook</li>
<li>P370: Sounds like a waste of time to me.</li>
<li>P371: This research seems pretty harmless.</li>
<li>P376: I think they need to have consent. </li>
<li>P386: FB is bad enough decided what it thinks I want to see!</li>
<li>P391: Everything posted to Twitter is considered public information.</li>
<li>P402: I don't see any harm in conducting this experiment.</li>
<li>P406: This could be harmful to participants who are already struggling with depression or other disorders and to put people through this without consent seems wrong, as does tampering with posts.</li>
<li>P409: No, if they want to find out about this type of information, they must find a way to do so with the permission of the participants.  This is a blantant invasion of their privacy</li>
<li>P412: I think that by changing a person's Facebook posts, there is a possibility of causing problems for the person whose post is being altered.</li>
<li>P415: i think injecting certain story lines to see if people's moods are affected seems troublesome</li>
<li>P417: I think maybe only do this to those who explicitly opt in to do this kind of testing.</li>
<li>P418: Facebook fails to follow their own TOS/Community Standards. I do not support them nor their supposed research.</li>
<li>P422: This a morally corrupt experiment. It's already bad enough that users are bombarded with ads based on their Google and cache history. People do NOT need Facebook to control their moods on top of that. To me, it's scary that researchers would even consider conducting this experiment.</li>
<li>P423: As long as all the appropriate consents are given and no personal info. is used.</li>
<li>P425: I don't really know what good this would produce.</li>
<li>P427: In certain setting I think this is ok.  I wouldn't want my news feed altered for very long, because I would potentially be missing out on news about my friends.</li>
<li>P428: As long as the participants are aware that something is going on</li>
<li>P429: seems like invasion of privacy</li>
<li>P437: Hacking an account is against the law.</li>
<li>P444: It´s important to have experiments about how social networks affect us.</li>
<li>P445: I think that if not done cautiously, people could feel like their privacy is being invaded</li>
<li>P446: it is a waste of money that could be spent in something more productive</li>
<li>P447: I don't think it provides very valuable information, and allows the researchers too much access to information.</li>
<li>P449: it doesn't seem like anything negative will come of it</li>
<li>P450: I think it's okay to take info about public post as long as the user remains anonymous </li>
<li>P453: Studying human behavior must be very interesting.. and its seems worth while</li>
<li>P458: If an individual begins to post more negative thoughts, that can eat away at one's negativity</li>
<li>P462: I am not sure at this point if it violates certain ethical standards. </li>
<li>P463: I think people should be aware that it's going on even if it doesn't negatively impact them (physically or emotionally)</li>
<li>P466: it'd be interesting to know the results </li>
<li>P467: Studies on emotions should be done in good taste.</li>
<li>P470: I believe they should be allowed to proceed with this experiment because it really doesn't have a harsh effect on the participants. </li>
<li>P472: Some messages might go too far. ie: Too many negatives could be disastrous on behavior</li>
<li>P473: I don't see any issue with the experiment.</li>
<li>P475: I get trying to protect psychologically-sensitive users, but I don't think algorithms and cold hard data can determine whether a post is happy or sad.  Sure there are trigger words but then there's sarcasm and the CAPSLOCK HAPPY generations.</li>
<li>P476: some of the negative comments may be harmful but they were going to be presented without this experiment anyway</li>
<li>P480: ofcourse and the public should be able to see the results</li>
<li>P484: I don't see why they wouldn't be able to proceed. </li>
<li>P485: everything is confidential.</li>
<li>P486: There are some ethical issues surrounding this. How safe is it? What if one user is in the negative mood and then falls into depression, or even become suicidal? What are the safeguards?</li>
<li>P491: See previous explanation. The same hypothesis could be tested not only with greater control, but also with less invasion and manipulation of the participants "personal" life. </li>
<li>P496: Sounds like borderline censorship.</li>
<li>P505: I honestly dont think this would offend too many people, it isn't really an invasion of privacy. </li>
<li>P513: Its not good to manipulate like this. </li>
<li>P517: The researchers have the right to make websites better. We should all should know there are security issues in general and privacy is lost when going online.</li>
<li>P519: A lot of personal information can be garnered from Facebook, I would be very careful in proceeding. </li>
<li>P528: This experiment seems silly. </li>
<li>P531: I think posting untrue information could compromise the entire premise of Facebook.</li>
<li>P532: The experiment seems silly at best. My only problem with it lies in the automated algorithm used to measure the mood of posts. It could single-handedly skew results if it's not made right.</li>
<li>P535: So long as they pay attention to the privacy and security of the participant's data.</li>
<li>P539: This is, in essence, altering someone's information without their permission.</li>
<li>P541: I see nothing wrong with this as long as the objective is stated and the researchers are up front about what they are doing.</li>
<li>P548: Again, I see no harm towards the participants and it would be interesting to see the results. </li>
<li>P553: I think it is too personal to read negative or positive posts in FaceBook even though it is for a scientific experiment or determination.</li>
<li>P555: For those facebook users that would want to be a part of the experiment I would not object to the researchers proceeding with this experiment</li>
<li>P558: I don't see how it's ethical to exclude chunks of people's lives from what is essentially their blog - enough is given up to Facebook already</li>
<li>P573: From an academic perspective, it might be interesting to know how people view their friends' and families' posts.  Positively (empathetically) or negatively (jealously)</li>
<li>P578: It's unethical to interfere with something like that.</li>
<li>P583: Might put things in perspective </li>
<li>P590: Seems like a pretty simple experiment.  I would like to know how they intend to classify "negative" vs "positive"</li>
<li>P591: Don't see any harm</li>
<li>P594: I think the researchers should only be allowed to proceed if they allow people on Twitter to "opt in" to the experiment with full knowledge of what the experiment is about. </li>
<li>P599: It's not worthwhile information for such an invasion of privacy</li>
<li>P606: I don't believe in hacking into people's social media sites and keeping some posts hidden from a person without the original poster's permission. </li>
<li>P608: Seems little or no risk involved. </li>
<li>P609: this can be showen in many other ways</li>
<li>P612: They are manipulating people's moods for their own gain and it isn't right. This should not be allowed to proceed.</li>
<li>P622: just be careful with it.</li>
<li>P628: I think that manipulating a personal account for mood research is a little to far.</li>
<li>P629: Seems hard to get data</li>
<li>P631: It seems odd that FB would allow researchers to have any access to users' news feeds so it seems pretty implausible in general.</li>
<li>P633: Again, as long as people are debriefed I don't see much risk here.</li>
<li>P634: I see no real harm as Facebook users display all kinds of behavior.</li>
<li>P644: i see nothing which can stop it</li>
<li>P646: It's just that too much negativity can really impact a person. And I believe this would actually happen if you surrounded the person with "negative social posts". It's a window into another world sometimes, a world that isn't the actual representation of a person. But it could be for some who might be isolated and on the sad side leaving them with totally negative posts could have a drastic affect.</li>
<li>P652: I am not sure if I agree with allowing people to get on your facebook page and mess with information that is there. </li>
<li>P656: no harm will come to anyone. It is just for research. </li>
<li>P657: No harm being done</li>
<li>P660: They need to be sure the people understand they will not be viewing all of the news feeds they would have otherwise.</li>
<li>P668: because there is not a risk</li>
<li>P672: The answers would be interesting. </li>
<li>P676: Micro-managed social engineering is a slippery slope.</li>
<li>P678: some happy things that are posted may include personal information not wished to be released</li>
<li>P682: Deceptive.</li>
<li>P685: You can't just hack people's private website accounts because you feel like it.</li>
<li>P691: They need to be extra cautious to ensure privacy.</li>
<li>P692: Privacy concerns </li>
<li>P694: The nature of this research seems harmless</li>
<li>P696: I doubt anyone would get hurt from this experiment, but Facebook might look bad for allowing it in the publication.</li>
<li>P702: They can seriously damage someone by adding negativity to their life.</li>
<li>P708: I think it's good for them to see if excluding negative is a good thing.</li>
<li>P709: You don't want to exclude enough positive tweets so that the subject suddenly worries about their friend's well being</li>
<li>P717: They could be doing more useful research.</li>
<li>P721: I think that people should be allowed to choose whether or not they want to participate - and should be able to opt out at any time.</li>
<li>P722: I wouldn't want to participate, but I don't see any trouble.</li>
<li>P729: I don't think its going to hurt anyone so I suppose.</li>
<li>P732: Seems unfair</li>
<li>P735: I am not sure why this would even be an issue. All the participants have to give permission. They are all adults and know what they are doing.</li>
<li>P737: I see no value to this study.</li>
<li>P740: There is nothing harmful in this experiment</li>
<li>P761: It is unethical.</li>
<li>P763: Yes. Let Facebook shoot themselves in the foot.  I doubt this scenario is real.  Also, 'negative (unhappy) thoughts' is certainly a subjective thing...  Even if this was real, I doubt the findings would be of much value or interest.</li>
<li>P769: Only if the participants were aware of the experiment.</li>
<li>P772: The experiment is victimless and not overly violating.</li>
<li>P776: It appears to violate privacy between X and Y</li>
<li>P780: I don't think its necessary but I do think its intrusive </li>
<li>P787: With caution because they are dealing with individuals person Facebook websites and making changes can have a long term effect. </li>
<li>P788: The experiment does not seem harmful and might be beneficial.</li>
<li>P792: I am weary of this study because of the effect it has on people's moods and possibly well-being. I would require this study to monitor those who are in the positive posts controlled group and provide counseling as a resource through and after the study if I were to proceed.</li>
<li>P800: This seems unethical.</li>
<li>P802: People didn't sign up for face to be part of social experiments. These experiments should only proceed if given permission by the users.</li>
<li>P803: There is no risk involved.</li>
<li>P811: This is an important study to them to see how people respond to someone's negative or positive post.</li>
<li>P812: People are using Facebook to keep in touch with their friends. It's already glitchy enough, this might make them miss something important.</li>
<li>P820: Like I said, it's not a bad experiment and can have interesting results. </li>
<li>P821: Facebook is meant for privacy, not tests of any sort.</li>
<li>P824: facebook shouldn't take advantage of its users this study has no benefits to society</li>
<li>P827: n/a</li>
<li>P835: No risk</li>
<li>P836: it seems like a fair study</li>
<li>P837: Be aware of what negative feedback could do to someone suffering from depression, a death in the family, or worse.</li>
<li>P841: The researchers would be holding back posts from some peoples' views and this may inadvertently upset some people or affect their personal lives.</li>
<li>P845: It's not clear to me whether people I this experiment volunteer to have their posts altered.  If they do not know and so done is randomly coming into their feed and messing with it, that would be troublesome to me.</li>
<li>P847: It infringes upon their First Amendment rights to freedom of speech, and is unscrupulous.</li>
<li>P850: I feel that way but others may not.</li>
<li>P865: sounds like it would make an interesting article and i would love to read the results. </li>
<li>P866: Only if the people is agree and had receive a full and cler explanation of the experiment.</li>
<li>P870: No where does it seem to mention that participants will be informed about what took place, furthermore this experiment seems to be manipulating data to prove a point.</li>
<li>P874: Social media experiments are very important and the data could provide great benefits</li>
<li>P880: The participants must completely understand that the researchers have access to their informaiton.</li>
<li>P882: I believe that an experiment like this is probably covered by the terms and conditions one agrees to when signing up to the website.</li>
<li>P884: To understand how social media affect society.</li>
<li>P886: See above.</li>
<li>P890: I don't see any real risks involved with this, but people are not agreeing to have their information manipulated.</li>
<li>P893: it says optional</li>
<li>P898: i have no real feeling about this either way</li>
<li>P901: It seems a little too manipulative and intrusive on participant's personal lives.</li>
<li>P903: The experiment should be allowed to see if positive or negative post have any effects on Facebook users.</li>
<li>P904: It's a violation of privacy</li>
<li>P906: Facebook is a social media outlet, they agreed to put themselves out there in the public eye, therefore it is fair game.</li>
<li>P908: I think it could have benefits to the researchers but I can see the data being misused.</li>
<li>P912: Thats messing with things they are posting. 2nd same as above, my mood does not ususally reflect in Facebook. I can be in a crappy mood but wouldn't know it by my FB posts. </li>
<li>P914: I think people should be made aware that they are dealing with an experiment involving facebook.</li>
<li>P922: I don't think its right to mess with people you care for. It sounds more like a study to find people more prone to getting agitated( because they care) and label them with a disorder.  </li>
<li>P925: I don't like anything where someone hacks into someone else's personal information and changes things</li>
<li>P926: I don't think that changed someone status would hurt in anyway. </li>
<li>P927: as this done in a real time scenario, so it can be allowed and also the result would be accurate , participants would not be aware and also the result would be proper</li>
<li>P928: Alteration of personal information should be denied</li>
<li>P934: because it has access in to people's personal account and their privacy.</li>
<li>P936: Censoring messages from friends could have consequences.</li>
<li>P939: I think this is digging on a too-personal level. Excluding someones 'negative' posts is really wrong. This person might be reaching out to his/her friends and the very thing they may need, is someone to talk to. This experiment is too risky, I think.</li>
<li>P940: I think this is pushing the limits of privacy a little too far.</li>
<li>P942: I'm not sure if this will be beneficial or a waste of the researchers' time</li>
<li>P948: If people agreed to it.</li>
<li>P951: it seems safe</li>
<li>P953: I would like to see results of an experiment like this.</li>
<li>P955: I don't think the benefits of this research outweigh (or even equal) the cons. First, I didn't read if the subjects are informed of this study after the data is gathered during their Facebook session. Second, some people spend a lot of time on Facebook and their emotional happiness is improved by learning about their friends activities, positive thoughts and feelings, etc. I think it is unethical to alter something so personal as a Facebook experience. If it's hypothesized that a person will almost be put in a negative mood by the content they read, the researchers are not being ethical in deliberately trying to upset someone just to collect research data. The potential benefits of this are not great enough to warrant this study. Emotionally manipulating people is not ethical research.</li>
<li>P957: I think it would be okay for researchers to continue with the experiment, as so long as participants were aware of all the facts and gave their consent.</li>
<li>P962: I do not think that this is a good experiment. I don't think an algorithm would be able to properly distinguish happy from unhappy posts.</li>
<li>P963: I do not know if this an entirely good idea.</li>
<li>P976: privacy matters</li>
<li>P984: It's not harmful - so I think they could proceed.</li>
<li>P986: this is cesnorship</li>
<li>P989: This research would be interesting because I read about this idea on a blog where it talked about how people would become increasingly depressed as they grew up because they only saw positive posts on their Facebook feed. Examples of this could be a depressed person seeing someone else have a successful life, whereas they personally have been struggling to find a job and would feel shame to post about their shortcomings on Facebook, resulting in a snowball of positive posts and diminishing negative posts which perpetuates the cycle of sad and envious people. \r\n</li>
<li>P991: The more you know about something the better you can use it.</li>
<li>P1004: If participants were forewarned about it and simply not told whether they would have positive or negative posts removed, and if they were closely monitored to ensure the moods were not affecting them too much, I might think it allowable, but I am not sure.</li>
<li>P1005: Again, this data is already available. </li>
<li>P1012: It's harmless and I don't think anyone would mind.</li>
<li>P1016: This study seems like it manipulates people's feelings.  I am not sure if I like this.</li>
<li>P1017: i think facebook should try to get some permission to do this or find a way to get it w/o compromising the experiment</li>
<li>P1026: I find this study to be manipulative.  Also, I find the idea of an automated algorithm to measure positive or negative moods to be too subjective. </li>
<li>P1031: I don't really see the worth. Can it really teach us something new? I would think not. </li>
<li>P1039: I'm not sure how ethical it is to change someone's Facebook news feed without their knowledge, but I guess this isn't hurting anyone.</li>
<li>P1041: I don't believe in censoring. </li>
<li>P1054: It doesn't do anything wrong.</li>
<li>P1055: For some reason facebook seems very personal.. I don't think people's really personal information.</li>
<li>P1059: They are interfering with personal conversations of people.</li>
<li>P1062: Facebook can do whatever facebook pleases, as far as I'm concerned. I wouldn't want to be a part of theirs study though.</li>
<li>P1076: Users may not want some of their social networking posts excluded without their specific permission</li>
<li>P1077: It is not harming anyone.</li>
<li>P1083: I think it would make a really interesting article to what people mostly post on facebook and their moods.</li>
<li>P1084: It is wrong to exclude someone's friend's posts from popping up on their timeline because if it was some important life event they would want to know about it.  It is wrong to hack into people's Facebook page.</li>
<li>P1088: It would help identify mood inhibitors and therefore, maybe making a happier society?</li>
<li>P1089: People get important information from Facebook feeds and it is important that information that may be sad about health conditions of relatives are shown.</li>
<li>P1108: Anger is an issue with this. Some people might get mad if you don't show them all of their facebook posts.</li>
<li>P1109: It is okay to do this, but I don't see the point.</li>
<li>P1110: I could see participants becoming angered that their Facebook feed was tampered with or that certain items they would normally otherwise see were suppressed.</li>
<li>P1111: The findings could be beneficial, but it seems a different, more anonymous, less intrusive method is needed.</li>
<li>P1112: They should not be editing the news feed.  The reason they are wanting to do this experiment does not seem valid to me.</li>
<li>P1113: I'm very selective about who I actually see Facebook updates from - around a dozen people total. I follow them because they're the people actually close to me, and I would not like arbitrary hiding of their content.</li>
<li>P1116: I think the idea of the research is good.</li>
<li>P1119: The researchers should make sure that they do not invade the privacy of the Facebook users without permission, others they will be violating their privacy rights.</li>
<li>P1123: I believe the researchers should be allowed to do this experiment and would most likely not bring any harm.</li>
<li>P1131: Should not be allowed without more informed consent, since examining emotional state is more dangerous than imagining internet security, etc.</li>
<li>P1140: It sounds alright to me, but I am not sure if people who use facebook on a regular basis would be alright with it.</li>
<li>P1147: Privacy issues with Facebook</li>
<li>P1153: be careful of the importance of the tweets being omitted from the feed</li>
<li>P1156: Because you do not want to invade the rights of others by posting information</li>
<li>P1157: Doing so would be an improper use of the communications available to the researchers.  </li>
<li>P1158: This is an invasion of privacy, and worse, could affect someone psychologically in a negative manner.</li>
<li>P1162: It is a harmless experiment</li>
<li>P1165: I want to see my real friends' posts and Facebook should not be the place for an experiment.</li>
<li>P1167: I mean these researches are made for a reason if one person does not except it then someone else would.</li>
<li>P1174: its for facebook</li>
<li>P1176: THis kind of psychology is tough to determine</li>
<li>P1178: Yes if people are willing to participate</li>
<li>P1179: It would be interesting to know the answer. </li>
<li>P1181: People would be upset and possibly think they were still being decieved.</li>
<li>P1186: It does not seem harmful in any way. </li>
<li>P1187: Facebook is not worth studying.</li>
<li>P1191: Sure, it doesn't hurt anyone and there's no risk involved in doing it.r</li>
<li>P1192: I'd need to know the benefits to the experiment before agreeing to it.</li>
<li>P1195: It seems OK, but when you are dealing with people posting some things that may be personal, care should be taken to people's privacy, safety, and security.</li>
<li>P1196: There is a possibility that the information could be used to, influence people using FaceBook.</li>
<li>P1197: This is a violation of trust and common sense.</li>
<li>P1199: Its not to save the world, but it is an interesting study.</li>
<li>P1203: Sounds fine. </li>
<li>P1206: It could mess with an emotionally unstable person's head</li>
<li>P1209: They shouldn't be able to affect someone's facebook news feed or get access to their statuses. </li>
<li>P1211: Some people take Facebook rather seriously. There will be a lot of negative feedback assuming that the researchers are "hacking" their feeds or hiding "important posts." </li>
<li>P1216: The research isn't intrinsically unethical so long as people whose feeds are being manipulated have agreed to having this done.  </li>
<li>P1220: the research is for scientific purposes and is in no way harmful, there is no reason not to participate in it if there is no harm.</li>
<li>P1230: Twitter is allowed to do what they want on their own site. Every social media site uses algorithms.</li>
<li>P1233: Be careful not to traumatize people.</li>
<li>P1234: It could produce insight into social media usage.</li>
<li>P1238: doesn't hurt anyone</li>
<li>P1239: The research is not really hurting anyone involved, but I don't know all the details involved.</li>
<li>P1243: as long as they do infringe rights or privacy</li>
<li>P1247: This study has no foreseeable value.</li>
<li>P1248: I believe they should be allowed to proceed and I'd guess that the results would be that most people would tend to be more positive.</li>
<li>P1253: This would be a violation of people trust in the system.</li>
<li>P1260: I don't see how it could negatively impact anyone and if it is something they are wanting to know then there is no harm in doing a experiment about what people post on facebook </li>
<li>P1261: No problem with the experiment. </li>
<li>P1262: Privacy is a fine line to walk.  It also seems a bit deceitful to shape what a person is more likely to post.</li>
<li>P1264: Please see previous response.</li>
<li>P1265: Dealing with people's emotions and personal Facebook information can be a testy subject so the researchers should be careful how they treat the participants.</li>
<li>P1266: I don't think there is a way to control that would be safe and not cause some harm.</li>
<li>P1267: Like I said above there is very little risk to the experiment. It is very unlikely someone would kill themselves or commit murder because of the posts...as long as the posts are reasonable.</li>
<li>P1268: I know sometimes people say experiments are rejected for being unethical but this should be fine. </li>
<li>P1269: I don't think this data is valuable.</li>
<li>P1270: facebook is personal they could find another way to collect data they need</li>
<li>P1272: You are misrepresenting someone when you post fake feeds.</li>
<li>P1273: Don't see any problems with this one. Pretty safe experiment and have enough controlled variables to work.</li>
<li>P1274: It is the person's experiment and if they want to do one or not, let them go ahead, </li>
<li>P1279: The researchers could take a feed out of context.</li>
<li>P1286: Sounds shady and mean to be quite honest.</li>
<li>P1288: I don't think they should be included if they're unaware of the experiment or haven't agreed to it.</li>
<li>P1289: why bother with this research?  doesn't common sense dictate that people are influenced by their freinds' posts, whether happy or sad?</li>
<li>P1296: Some people are negatively effected by being surrounded by people only posting positive or negative posts all the time.</li>
<li>P1297: Only if users have agreed to be apart of it.</li>
<li>P1300: It would be interesting to see the results and what implications they have.</li>
<li>P1301: It sounds like a safe social experiment, but I don't want someone to hurt them selves over manipulated data.</li>
<li>P1309: Unethical. You can't just hack into someones account and choose what they see</li>
<li>P1310: I don't think purposefully messing with someone's emotions without their knowledge is moral.</li>
<li>P1311: This doesn't seem to be much of a problem.</li>
<li>P1316: It seems invasive to manipulate someone's newsfeed.</li>
<li>P1318: Afraid of what this could be used for on the part of Facebook.</li>
<li>P1319: I don't think it's okay to experiment on people without consent, what if those being experimented on were psychologically unstable and suffered ill effects?</li>
<li>P1320: They are just censoring information that should be available to me.</li>
<li>P1326: Its altering the participants view of their world. </li>
<li>P1327: It seems relatively harmless.</li>
<li>P1328: It seems unfair to alter facebook newsfeeds</li>
<li>P1330: This seems like a silly experiment.</li>
<li>P1331: I don't see how it can cause any harm.</li>
<li>P1332: I don't even think the results would tell much, to be honest.</li>
<li>P1336: It is wrong to mess with the postings of another person without their knowledge or permission.</li>
<li>P1340: They should use extreme caution since people don't like to share their private messages with everyone </li>
<li>P1343: I think that the experiment itself is sound, but not how it's being carried out. </li>
<li>P1344: I think that much of the answers can be determined just by following the posts of various people.  It is my experience that when a friend posts about negative occurrences or feeling bad for some reason, friends reach and try to uplift them.  </li>
<li>P1346: It sounds like a study whose results could be of some benefit to science.</li>
<li>P1356: Again, its all about trust and safety</li>
<li>P1360: I am not certain that this would help learn anything new or anything of value.</li>
<li>P1363: How can they tell if a post is positive or negative?</li>
<li>P1367: The experiment seems harmless</li>
<li>P1371: There is nothing unethical that I can see based on the experiment's description</li>
<li>P1373: Some people may not get important news via FB</li>
<li>P1374: Thye should be able to just gather the raw data on positive versus negative and rates of replies and so on without partially blocking content. </li>
<li>P1386: Some people may be affected by the amount of positive and negative posts they see.</li>
<li>P1389: The end does not justify the means.</li>
<li>P1406: The idea is pretty well known, that people's moods affect those around them, but how much does it affect people at this kind of distance. I wonder, will the participants be informed later and the excluded posts be restored?</li>
<li>P1419: The study will show how connection with friendships will be able to influence the behavior of that group based on the moods that has been set.    </li>
<li>P1420: Too intrusive.</li>
<li>P1421: I am nervous about possible ramifications with ads and information being sold so easily today, and am not sure if this study has any great benefits to it.</li>
<li>P1423: They should just be careful with the data.</li>
<li>P1426: It can make people happier.</li>
<li>P1427: You don't want to push someone into a serious depression but this is a very interesting study </li>
<li>P1431: 0</li>
<li>P1432: This might be a violation of privacy and offend some people, not me but maybe others</li>
<li>P1433: Participants in the group with a higher proportion of negative posts would needs to be watched carefully, to ensure that the study doesn't harm them.</li>
<li>P1446: I don't see that it harms anyone. We know they mess with our feed.</li>
<li>P1456: Not Sure??????</li>
<li>P1462: The user may have important info about friends excluded that can affect their friendship off-line.</li>
<li>P1466: I think it's potentially psychologically dangerous.</li>
<li>P1470: It provides no scientific value.  How would they know which users are psychologically vulnerable?</li>
<li>P1472: Happiness! </li>
<li>P1479: The conclusion of the experiment would be very interesting.</li>
<li>P1486: There doesn't seem to be any risk </li>
<li>P1487: Yes, it's interesting and non-invasive.</li>
<li>P1488: make facebook a better social experience</li>
<li>P1489: Yea but I would be careful with negative post on the interest.  Could be dangerous if a person was a little unstable.</li>
<li>P1492: I don't think its right to mess with someone's social media account as part of an experiment unless they volunteer for it. I also don't think facebook should be in the business of censoring posts to "protect the moods of psychologically-vulnerable users". </li>
<li>P1497: Excluding some things that would normally appear feels too invasive, though rationally everything about facebook is too invasive.</li>
<li>P1503: they would get useful information</li>
<li>P1507: I would be curious too as to the findings.</li>
<li>P1508: yes, as long as the peoples account affected understand what is happening</li>
<li>P1513: As long as no privacy is invaded and things are kept cautious, sure.</li>
<li>P1514: never know the outcome....</li>
<li>P1517: Nobody would be harmed in the experiment and we could potentially learn some valuable things about social media and psychology.</li>
<li>P1522: I think that researchers should be allowed to intervene for the sake of study but with limits to doing so. </li>
<li>P1524: I don't agree with this experiment unless the subjects were informed ahead of time.</li>
<li>P1525: In the event they figure something is going on</li>
<li>P1526: If participants are unaware, I think it would be a form of censorship. If they are aware of their participation, I think the knowledge might affect their tweeting patterns.</li>
<li>P1528: There is nothing wrong with it.</li>
<li>P1538: Access to one Facebook account allows access to their Friends' Facebook accounts making it extremely unethical. The person in the experiment may have consented but their Friends did not.</li>
<li>P1540: I don't think it's right to tamper with this information. </li>
<li>P1542: I think it is interesting, and I don't really see how it could cause any harm.\r\n</li>
<li>P1546: It seems like an interesting experiment.</li>
<li>P1551: Have the researchers done a content analysis of selected newsfeeds before trying to do this experiement?  Are there any preliminary results that suggest this experiment would actually yield any results?</li>
<li>P1552: WITH THE INCREASE OF SOCIAL MEDIA, SCIENTISTS NEED TO BE ABLE TO PREDICT / UNDERSTAND THE EFFECT ON THE WELL BEING OF USERS</li>
<li>P1553: Facebook does have rights to their content, however this study may actually affect peoples moods.</li>
<li>P1556: Again some may not like secretive tinkering of their feed.</li>
<li>P1558: By tampering with the information shared with users without their consent, they may miss out on positive events in friends' or relatives' lives - births, engagements, etc - which would upset them later. I think that participants should have to sign a waiver for this experiment, acknowledging their rights to information without interference.</li>
<li>P1559: What is the harm of  knowing how people experience security</li>
<li>P1563: I am not sure you can really judge the emotion behind every post.</li>
<li>P1572: Could it harm the person if more negative posts are on that person's site?</li>
<li>P1580: There are privacy issues. involved.</li>
<li>P1582: It is interesting to see what the results would be and I can't think of anything negative associated with this.</li>
<li>P1583: I think that this experiment is emotionally manipulative to the subjects; I also think that it invades the privacy of unknowing Facebook users. I do not think that the intended outcome justifies the means.</li>
<li>P1598: Same as above.</li>
<li>P1604: As I said above, if it could potentially save a life, GO FOR IT! If would could have "happier" people in this world, it would most definately be a better world.</li>
<li>P1610: I don't know because they are messing with someones facebook account and I would be mad if I found out the someone did this to my account.</li>
<li>P1614: This seems like a violation of privacy, also.</li>
<li>P1615: While I understand the need to conceal the study, it does seem a little wrong to monitor people in this way without their knowledge</li>
<li>P1617: I think its fine, but changing excluding facebook posts seems relatively invasive.</li>
<li>P1618: I can see where this study may be beneficial by helping people to see how their thoughts/posts might affect others, however, participants should be very aware that they may be portrayed in a negative light to their friends and family.</li>
<li>P1620: You are dealing with peoples social media which again can make people upset.</li>
<li>P1624: The posts could all be available to view if the user chose the "Most recent posts" view, so I don't think preferentially showing positive vs negative posts is unethical. However, I am skeptical that "protect[ing] the moods of psychologically-vulnerable users" would be the only use to which this research would be put.</li>
<li>P1633: The researchers should not be allowed to interfere with someone's life. They need to find a different way to get their results. </li>
<li>P1634: Some people may benefit while others become angry. </li>
<li>P1646: It's not dangerous </li>
<li>P1650: There is a point to this, but who would be comfortable giving out their e-info</li>
<li>P1651: Theres not much you could do about it anyhow. But use caution with the anonymity of the data. Who would have access to that? </li>
<li>P1655: I see no real harm in doing this experiment.</li>
<li>P1657: It sounds like it is ultimately to try to curb free speech, which is a fundamental right in our nation's Constitution.</li>
<li>P1660: No, because it is invading people's privacy. </li>
<li>P1664: They need to verify the privacy issues with the candidates </li>
<li>P1668: The experiment seems harmless enough. </li>
<li>P1671: In the end, Twitter can do whatever they want, but again, blocking communication goes directly against what they provide to their end users.</li>
<li>P1674: It seems unethical to me, to manipulate people's social interactions when they believe they are acting freely</li>
<li>P1680: They should be allowed because there is no harm in this experiment. It may, however, bring the question of privacy. If they genuinely care only about studying the moods of people, then it's okay. But if it has some other reasoning that invades someone privacy, then it shouldn't be proceeded.</li>
<li>P1682: No, it is invasion of privacy.</li>
<li>P1683: Messing with someones feed may cause further problems. per say lets say its true negative posts makes someone negative in that case they might act that way all day.</li>
<li>P1686: People need to be aware they are participating.  It sounds like it might be done secretly, which seems unethical.</li>
<li>P1687: It violates the privacy of the individuals involved.</li>
<li>P1696: Only be allowed with consent of participants</li>
<li>P1704: See above..manipulation of information...also they will never tell the subjects they have been subjects.</li>
<li>P1706: I am uncertain how ethical this experiment really is. This smacks to much of emotional manipulation bordering on possible abuse.</li>
<li>P1707: They are interfering with a personal aspect of their lives without them knowing about it.</li>
<li>P1708: Yes, I don't see and risks.</li>
<li>P1709: All candidates should be screened before being allowed to partake in the study.</li>
<li>P1710: seems fishy</li>
<li>P1721: I don't believe it is the job of Facebook or any social media, to "protect the mood" of users.</li>
<li>P1724: IT has a valid thesis and i think it should be tested</li>
<li>P1729: again, i think any study that the participants are not aware of is wrong</li>
<li>P1733: Yes I think it would be a beneficial tool in helping to discover how people's minds work. </li>
<li>P1738: Yes but rather than automated algorithms, I think that each part of this should be overseen by actual people. I am imagining a situation where perhaps someone has passed away and news of that is excluded from someone's feed. That would be a very important thing for the person to know and some people I know maintain contact with others primarily through Facebook so this would have a real negative impact on their lives.</li>
<li>P1740: I see no harm in this experiment.</li>
<li>P1744: It just measures positive and negative Facebook posts</li>
<li>P1746: As long as the study is anonymous, I don't see a harm, but they need to be careful messing with people's moods. You don't want to make someone feel negative and then do something in their daily life that could harm someone else or themselves.</li>
<li>P1751: It's a little risky but worth it.</li>
<li>P1753: what if the friend who posted the negative thought really needs someone to reach out to them but there friend doesnt because they werent able to see the tweet. </li>
<li>P1757: It is actively interfering with someone's internet usage without their consent.</li>
<li>P1758: I understand there are reasons (producing features that might protect the moods of psychologically-vulnerable users) but there are probably other ways to do it, and if a person feels psychologically vulnerable they should be able to decide that for themselves, such as there are ways to download a program that can block certain tags on tumblr.</li>
<li>P1763: It's Facebook, let them do what they want</li>
<li>P1770: It is an invasion of privacy</li>
<li>P1774: Yes. I think this experiment is mostly safe for those involved and has the potential for a very positive outcome.</li>
<li>P1775: Facebook users should determine for themselves what posts they want to see and possibly block or unfriend. </li>
<li>P1779: It seems like fraud to post fake items. How is a study about moods important?</li>
<li>P1785: Again I see no reason to stop the experiment.</li>
<li>P1786: Same reasons as above. </li>
<li>P1806: They shouldn't be able to exclude what someone is posting. </li>
<li>P1808: It would muddle the exchange of information, which may be important for many people to function</li>
<li>P1811: If the deception is later explained to the participants then it's ok. </li>
<li>P1814: They would have control over Facebook's servers and accounts on those servers? That's an invasion of privacy.</li>
<li>P1827: They should make people aware that facebook will alter/influence posts.</li>
<li>P1835: This research causes no harm and is an interesting experiment</li>
<li>P1836: I don't think people will appreciated if their friend post, either negative or positive, if being experiment with.</li>
<li>P1839: There is no risk for anyone involved</li>
<li>P1841: Facebook invades enough privacy on its own.  No further experiments are needed.  </li>
<li>P1848: Sounds like a good experiment, but I'd be cautious of people believing researchers are unethically spying on their facebook/personal lives.</li>
<li>P1850: It feels like the researchers are trying to change the moods of people to what they want, which seems wrong in my opinion. Peoples mood should be based on what happens in life, good or bad, not a modified news feed. </li>
<li>P1851: I don't believe there would be any harm in that. </li>
<li>P1853: The experiment doesn't seem to violate anything moral, nor does it simulate anything dangerous as the a couple of the previous ones did. </li>
<li>P1857: I don't think they should manipulate the newsfeed. It is wrong in my opinion. The subjects are never made aware of the experiment and the content of their postings are being monitored by someone outside of their contacts. It is just wrong. </li>
<li>P1864: To me it is just plain not ethical to do this.</li>
<li>P1865: I do think this study could be valuable if they were able to produce features that might protect the moods of psychologically-vulnerable users. </li>
<li>P1870: I see no risk to the participants in performing this study.</li>
<li>P1871: I'm sure there are risks out there with the MAJOR time waster called facebook.</li>
<li>P1873: They should really address how they could do this without invading someone's privacy.</li>
<li>P1874: While it's a nice thought, it's also intrusive and somewhat shady.</li>
<li>P1875: Facebook users are so paranoid nowadays about people spying on their accounts that  think this experiment would do more harm than good.</li>
<li>P1876: They just want to see the positive vs negative effect.</li>
<li>P1877: I have my doubts as to the effectiveness of the methods, and the usefulness of the data that would be collected.</li>
<li>P1878: I'm not sure its ok to take that information without their permission, that is if I understand this experiment correctly</li>
<li>P1884: Just be sure the rules are well written out. </li>
<li>P1890: It is invading one's privacy and it is illegal if they don't inform the participants first.</li>
<li>P1892: This is a manipulation of users.</li>
<li>P1893: Not only this a huge invasion of privacy from a company, these people wouldn't be consenting to being toyed with.</li>
<li>P1897: They should not assume anything from their data.</li>
<li>P1901: I don't see any harm in this experiment.</li>
<li>P1902: It does not seem like this study would hurt anybody </li>
<li>P1904: Very interesting study!</li>
<li>P1906: I don't agree with trying to purposely shape peoples moods, but honestly the service belongs to them and they can do whatever they want with it.</li>
<li>P1913: It is a good experiment</li>
<li>P1916: Yes because it is a good way to develop an idea about people's daily habits as it pertains to their positngs and what moods or actions are directly influencing it.</li>
<li>P1917: They need to come up with a better way of doing this besides messing with someones newsfeed. </li>
<li>P1918: They should not manipulate what a person sees without permission or knowledge of being in a study.</li>
<li>P1920: Features that would censor social networks are not necessarily a good thing.</li>
<li>P1934: Care needs to be taken to preserve privacy, and the posts destroyed afterwards. </li>
<li>P1938: Facebook should not be able to censor anybody like this.</li>
<li>P1942: Not allowing users to see all posts doesn't give me a good vibe.</li>
<li>P1951: Again anybody should be able to post whatever they want when they want and have whoever they want to be able to see it.</li>
<li>P1952:  </li>
<li>P1953: It seems valuable so I support it but they should proceed with caution so as not to intrude upon people's privacy.</li>
<li>P1955: Some folks might get depressed, obviously, and that could lead to bad places, especially if any of the participants have poor mental stability already.</li>
<li>P1956: the data may breached and then used for real crimes</li>
<li>P1960: I don't think any harm could come from the experiment.</li>
<li>P1963: Technically Facebook is their platform so they should be allowed, but at the same time I feel like this is deceptive for the people using their service, so I'm not sure at this point.</li>
<li>P1977: It sounds interesting to me. I'm curious to see how much other people's moods affect their own.</li>
<li>P1978: They are not a University or medical-psych company!</li>
<li>P1979: I don't think researchers should be asking for real passwords that people use.</li>
<li>P1982: I think it is important more these days to identify online moods of certain people who might be trending in a negative direction and can be stopped before something bad happens.</li>
<li>P1986: I don't feel comfortable with social media platforms being used for psychological and social experiments (even though I would not be surprised if it's been done before or is currently being done).</li>
<li>P1989: Since the researchers are not creating posts themselves and only filtering which ones they deem positive or negative, then I see no ethical or moral reasons against the experiment.</li>
<li>P1991: I'm sure there are some people who would find this interesting and not mind participating. </li>
<li>P1998: It's simply a question of ethics and the methodology for this experiment is unethical, therefore the experiment is unethical despite the potential benefits of carrying out the experiment.</li>
<li>P2001: Without user consent, I believe the study is unethical. </li>
<li>P2002: Yes, it does not take any personal information.</li>
<li>P2003: If they deem it important, then so be it. I just don't really think facebook to be an integral part of society. </li>
<li>P2007: As long as they stated upfront that their posts would be looked at & people let them, then I think they should be allowed to do the study.</li>
<li>P2018: It's just wrong</li>
<li>P2025: I don't see it as very scientific.</li>
<li>P2026: It is a harmless study.</li>
<li>P2027: if it helps facebook researchers and makes facebook better then go for it</li>
<li>P2036: The benefit of the results seems negligible at best and not worth the expense of the users they are experimenting on</li>
<li>P2038: Just because a person sees a positive doesn't mean they are going to post a positive status.</li>
<li>P2040: There is nothing compromising about this study.</li>
<li>P2043: It would be interesting to see if other peoples' moods affect others.</li>
<li>P2044: it seems a little like an invasion of privacy</li>
<li>P2048: Researchers are not allowing the individuals to convey an accurate profile of themselves.  They are manipulating a person's emotions/personality/character.  The results would be inauthentic.</li>
<li>P2049: I dont see that it will hurt anyone</li>
<li>P2051: I think that purposefully manipulating someone private and personal facebook posts is dangerous and unethical territory to tread on. It should be done with full consent of the participating party at least, however that would more than likely taint the results. Hrrmmm. This is a hard on folks. </li>
<li>P2053: I think there are people on facebook who may be more vulnerable to getting persuaded by negative p[osts.</li>
<li>P2060: I want to see all my feeds.</li>
<li>P2061: there are no definite reason to do so</li>
<li>P2065: People expect Facebook to be impartial and not be performing experiments on them. </li>
<li>P2070: Why not?</li>
<li>P2072: See no harm here.</li>
<li>P2076: It seems like an interesting but harmless study. </li>
<li>P2082: It would be too easy for the test to be compromised by someone looking at someone else's Facebook and realize something was up.</li>
<li>P2094: Since researchers would not be prohibiting the participant from viewing friends' posts (only removing them from the easily accessible newsfeed), I see minimal down sides and the up side of completing such research seems to merit this minimal risk.</li>
<li>P2097: " . . . the researchers will not be able to produce features that might protect the moods of psychologically-vulnerable users."\r\n\r\nLOL, controlling the moods of Facebook users?  Hope the "researchers" are kidding.  If not, please tell me they are not given public money for their social engineering efforts.</li>
<li>P2100: It sounds like a valid study.</li>
<li>P2105: This could be detrimental to people</li>
<li>P2109: I suppose it is a legitimate study and if participants are willing to be a part of this study I suppose it's fine but it seems a bit personal.</li>
<li>P2114: I don't like the idea of certain posts being suppressed.</li>
<li>P2117: As above, validity of findings would be questionable at best due to operationalization of mood, the researchers "manipulate" users' moods without permission/consent of participants, they control flow of information that users receive without users being aware...no, this whole thing, just no. Unethical.  </li>
<li>P2119: I know it would help research, but this sounds like it would be crossing a line that I'm not sure should be crossed.</li>
<li>P2123: it just does not seem right, maybe if the people were asked to be part of an experiment</li>
<li>P2125: I don't see how it's important.</li>
<li>P2126: Depends on the type of comments posted</li>
<li>P2130: Yes so that they can obtain what they are looking for.</li>
<li>P2132: Although facebook is public, some things are private</li>
<li>P2134: Caution should be avoided to protect the participant's identity.  </li>
<li>P2135: Yes, it doesn't seem harmful.</li>
<li>P2137: so we can have solution</li>
<li>P2144: It seems harmless. </li>
<li>P2148: It is a very interesting idea but regardless if they want to use it for advertising purposes or not, eventually the results could be used by someone clever enough to make sense of it. </li>
<li>P2154: Seems like the results would be interesting. </li>
<li>P2155: The experiment seems safe.</li>
<li>P2160: As long as everyone in study remains anonymous.</li>
<li>P2164: Facebook already has access to all this information, willingly on behalf of the participant, who has agreed to have their information used by being on facebook.  Might as well make use of it.</li>
<li>P2172: It would provide information on factor that could or would lead to someone being depressed.</li>
<li>P2175: I don't think this is an ethical use of a social media site.</li>
<li>P2177: It really depends on the approach and consent.  Also, what is the broader impact of this research?  It's hard to see the benefit of the experiment that is proposed.</li>
<li>P2183: Again unless you hack someone's Facebook account, how would this work.  Plus, I would hate to see a negative experience be posted on a friend's Facebook and be worried about them only to find out it's a fake.  Couldn't they do this research by simply looking at Facebook accounts and not making posts?</li>
<li>P2189: Because there's no point without a definite outcome.</li>
<li>P2191: This sounds like it is altering what we see to measure our reactions. it also has the potential to be a real big invasion of privacy. </li>
<li>P2193: If it will help achieve something useful, research is necessary first.</li>
<li>P2194: I don't want nothing to infringe on my rights. facebook is my go to place and people should be allowed to post what they want without somebody tracking their mood or behavior.</li>
<li>P2204: This seems like a very interesting and different study. </li>
<li>P2208: This experiment could alter peoples lives in a negative way.</li>
<li>P2212: I don't necessarily see a correlation between facebook statuses and psychological vulnerability.</li>
<li>P2213: As stated before, people might get angrier if they don't get all of their news feed. Plus, how would they figure out emotions?</li>
<li>P2218: Altering someone else's Facebook feed without their consent or knowledge is a fundamental abuse of trust. It also has potential social alienating consequences that may cause DIRECT personal harm to the participants.</li>
<li>P2219: This experiment seems less intrusive or dangerous. </li>
<li>P2221: Effective and harmless, this experiment would be a great idea.</li>
<li>P2227: It is not right to edit someone's feed without them knowing. </li>
<li>P2231: Moods may be altered without their consent.</li>
<li>P2233: I think people would have to be willing to subject themselves to this experiment. They would have to make sure it is not affecting people too much.</li>
<li>P2237: Not sure, because I believe we should be able to see everything and not only what is picked out for us.</li>
<li>P2238: If they are public tweets they are already obserable.</li>
<li>P2244: I am not sure really how realistic the qualitative or quantitative information received from this study would be.</li>
<li>P2245: It sounds manipulative.</li>
<li>P2254: yes, Twitter has become a part of everyday life and there should be studies to see the effect of its use.</li>
<li>P2260: Shouldnt be allowed to change the words of another person </li>
<li>P2261: It scares me the more psychology knows about us and can manipulate us.  </li>
<li>P2273: I think it is  a  good  idea.</li>
<li>P2280: I'm not sure of the validity of the purpose of this  statement. The thought that comes to mind is " to what end ". why ?</li>
<li>P2281: I think the researchers would use sneaky tactics to gather information.</li>
<li>P2284: If Facebook is ok with it, I guess they can do whatever they want.</li>
<li>P2285: Again, I see no harm and its an interesting theory</li>
<li>P2286: Caution must be observed because by excluding "negative" posts there is a slight chance that the participants will miss some information that might be important to them e.g. learning of the death of an acquaintance or relative. </li>
<li>P2289: This would be interesting to find out because so many people post their whole life stories on Facebook.</li>
<li>P2291: why not</li>
<li>P2302: There is no one harmed in this experiment.</li>
<li>P2305: Facebook or any other group should not modify the content of news feeds.</li>
<li>P2307: The negative posts could cause negative reactions in people who are at risk.  Also, the people who are exposed to the negative and positive should have a control group of some sort.</li>
<li>P2309: The researchers should obtain the consent of the people whose Twitter feeds will be modified to hide negative tweets before the study can continue. This shouldn't affect the outcome of the study if the friends of those involved remain unaware that the person's feed is being filtered. As long as the person whose feed is being filtered is ok with the researchers manipulating it, the study could proceed.</li>
<li>P2314: It is not harmful and could produce interesting results for some people</li>
<li>P2316: Yes, because there are people who think in positive and negatives which I think is silly. </li>
<li>P2324: Again, doesn't seem very important and even though Facebook is public, it's a bit of an invasion of privacy unless they are told their profile information was used.</li>
<li>P2325: Facebook is untrustworthy</li>
<li>P2326: Breech in privacy, and may mess with the participants' psyche. May make them depressed to see all their friends happy?</li>
<li>P2328: No one's emotional state should be manipulated without their knowledge.</li>
<li>P2339: The idea of social media continuing to try to direct our thoughts more is slightly disturbing.</li>
<li>P2340: I can't think of a reason researchers should be allowed to proceed.</li>
<li>P2341: This would be very grey area as it would tamper with the posting on an external site.</li>
<li>P2348: It could affect the research if not done right</li>
<li>P2349: If the results of this experiment could save life and prevent other tragedies I am all for it. </li>
<li>P2350: I think they could do this experiment but if i was one of the participants I would want to know what they are doing and what information is being kept from me.</li>
<li>P2354: Yes.  The subjects are anonymous.  I am interested in psychology and think the results would be very interesting.</li>
<li>P2356: Only if participants were aware</li>
<li>P2357: I believe manipulating people's twitter feed is harmless.</li>
<li>P2368: The idea of "protecting psychologically-vulnerable users" is off-putting to me. Who is deemed "psychologically-vulnerable? Why should facebook filter what we see or decide who is stable and who is not? It's the user's choice what they want to see, and if their friends post negative things, they should be able to filter that content on their own. (Wouldn't they want to know if something important but bad happened, like a family member passing away? It seems cruel to disclude them like that.) Plus there's no accounting for sarcasm if an algorithm is involved. It would have to be moderated by humans, and that is not necessarily infallible either. </li>
<li>P2372: The wrong approach is being used.  Supporting people's positive attitudes and empowering individuals is more important.</li>
<li>P2378: Again, it intrudes on privacy and someone's private account.  Also, I don't see the benefit in this study.</li>
<li>P2382: There's no harm being brought to the participants, as long as they are aware of the research being conducted.</li>
<li>P2386: I think Facebook should concentrate more on other issues with their site, for instance, privacy, which doesn't seem to be as private as people believe.</li>
<li>P2392: This sounds like an involuntary experiment. Many of my friends ARE psychologically vulnerable. If it were voluntary, then sure, though that might affect results. Also, if they can make an algorithm to exclude more negative posts, they can make a program and people can voluntarily turn it on on their own twitter if they don't want to see negative posts. Wasn't there something in the news that people's positive posts on facebook make some people depressed because they think their imperfect life doesn't measure up, anyway? But some days anyone would just not want to see negative posts.</li>
<li>P2396: I would suggest heavy review of what is being ignored.</li>
<li>P2397: I guess I don't understand all the rules to this one. Will they be using other peoples Facebook accounts with the person in questions permission? If so Then I think the experiment should be allowed to proceed. </li>
<li>P2403: Keeping information from users is wrong, but study does have a purpose.</li>
<li>P2409: It does not seem harmful. And everyone knows that Facebook is not private anyway so there really should be no expectation of privacy while using it. I think this study is more than ethical.</li>
<li>P2412: I believe there are benefits to the experiment, but it seems slightly shady to me.</li>
<li>P2419: I don't think it would hurt anyone.</li>
<li>P2428: I would want to make sure that potential participants weren't suffering from mental disorders that could be exacerbated by the experiment.</li>
<li>P2432: They should continue the experiment,but be careful because this experiment can corrupt the mental state of people, which is not healthy.</li>
<li>P2435: Just seems like it's a bit of an invasion of privacy and not everyone would want to do this.</li>
<li>P2441: As long as people's privacy is protected and they are willing to share their facebook information, this will be an interesting study.</li>
<li>P2445: I doubt there are that many risks involved in this experiment, it's only Facebook after all.</li>
<li>P2449: they need to get peoples permission first. If there is a disclaimer when you sign up with twitter saying you can be a test subject than that is fine, but twitter should provide an option to opt out if they want. otherwise there might be some bad press for them </li>
<li>P2450:  No one should tamper with our FREE SPEECH. </li>
<li>P2451: The resear ch is valuable.</li>
<li>P2453: It may help understand the efects of others ones emoshions.</li>
<li>P2456: As long as they inform the people they are studying I have no problem with it.</li>
<li>P2457: seems harmless enough</li>
<li>P2461: Making sure privacy is not compromised</li>
<li>P2463: I don't use facebook myself but i can't think of any negative effect of this research</li>
<li>P2466: Again, there is deception and also manipulation.</li>
<li>P2468: No comments</li>
<li>P2473: I don't find this necessary at all.  Basically, who cares.</li>
<li>P2475: It would make people feel a little worse to see that negativity so consistently, but it wouldn't really be for any useful information. </li>
<li>P2478: This should only be done if the person consents to the experiment. </li>
<li>P2480: Again, it seems like the gains outweigh the risks - no harm no foul. </li>
<li>P2483: I am curious about the results of this experiment.</li>
<li>P2488: Again, I don't believe participants are going to be hurt in any way.  </li>
<li>P2489: They do not have the right to edit a legal company software without permisson.</li>
<li>P2491: I believe it slightly violates some privacy.</li>
<li>P2494: I think it's interesting but I'm not sure what it would amount to and would probably be a waste of funds.</li>
<li>P2495: it is a study and there can come no harm in doing it</li>
<li>P2496: No, researchers shouldn't be allowed to control peoples social media accounts. </li>
<li>P2501: I do not see any risks to this study so I don't see any reason why the experiment should not proceed.</li>
<li>P2516: Is there a control group? This does not really seem like a worthwhile experiment</li>
<li>P2528: Good idea.</li>
<li>P2530: The flimsy reasoning that this is all done to protect the moods of psychologically-vulnerable users is silly. The research is done with no regard for the test subjects, and only for the gain of the researchers' studies.</li>
<li>P2532: It would be interesting to see if people do react this way to posts on facebook. </li>
<li>P2535: this is taking away free speech and directly interfering with someone's life</li>
<li>P2536: There are other ways to get the same result if you're hesitant about taping into users facebook accounts.</li>
<li>P2539: I like the use of experimentation to gain insight but I don't like that some posts would be randomly excluded.</li>
<li>P2542: See above. Social networks shouldn't be allowed to play God.</li>
<li>P2543: It is highly unnecessary to see how people react to positive and negative posts because it depends on the person's reputation and there is also a lot of sucking up on social networks of any sort.</li>
<li>P2545: I think this is going a bit too far. Users should make the decision themselves whether or not they want to view certain things. It is already an option to not view posts from certain people. I don't think it is necessary or right to do something like that. If I want to say something negative or complain about my day, I should have that right.</li>
<li>P2547: Because it doesn't seem that important. It's cutting into people's private life for unnecessary research.  </li>
<li>P2549: It is gaming the system and possibly prevents people from seeing other posts that might be more relevant than the positive posts.</li>
<li>P2550: They must be careful not to interfere too much in order to not anger users about invasion of privacy. </li>
<li>P2555: a bit manipulative but as long as the posts are real but a big deal</li>
<li>P2556: do not like</li>
<li>P2561: This is intrusion of people's privacy and against the terms of use of Facebook.</li>
<li>P2563: Again, HUGE invasion of privacy. People log in to Facebook for a reason- to find out "what's up" with family & friends. Anyone would be upset to know that they are having information withheld!</li>
<li>P2565: They should not be able to impact someones twitter feed like that</li>
<li>P2572: I think it is ok to research but need to protect privacy</li>
<li>P2574: The people who participate need to have informed consent and debriefing. </li>
<li>P2575: Continue to has too invasive of questions.</li>
<li>P2578: Yes, the experiment could produce useful information, and should not be harmful.</li>
<li>P2579: I think a lot of people would like to know the results from this study.</li>
<li>P2581: They should proceed, but the users should be debriefed first. They should see some form of consent. </li>
<li>P2584: It seems a little invasive, and like there would be better ways to do it</li>
<li>P2586: It doesn't seem particularly harmful, though I suppose the idea could be extrapolated into some form of persuasive manipulation.</li>
<li>P2588: Let me see everything my friends post, not what you determine is better for me.</li>
<li>P2590: The potential for harm seems low, but some people already at risk might be affected by the negative posts.</li>
<li>P2595: I think it would show a lot about how the human brain works.</li>
<li>P2596: it is immoral without consent.</li>
<li>P2599: Facebook should not have the power to limit someone's voice because it's negative.  Constitutional rights are being violated.  Bad call.</li>
<li>P2605: I don't foresee any negative side effects resulting from this study</li>
<li>P2610: It's not invasive.  It's not nice, but it's not using personal information or collecting anything sensitive.</li>
<li>P2612: Are you saying that actual Facebook accounts will be hacked into and edited somehow? I do not see how you can do this in a real account without interfering where you are not given permission to go? </li>
<li>P2613: Everyone needs more positive thoughts</li>
<li>P2618: I don't think it's really a big deal. It would also be kind of interesting to see how many people are followers or trying to "one up" their friends.</li>
<li>P2619: People can get very territorial about their Facebook accounts. Messing with what they see and don't see on their feeds could make users uncomfortable. </li>
<li>P2623: this experiment would exploit Facebook users trust in the company</li>
<li>P2626: It is not unethical to do this study. </li>
<li>P2638: Low risk.</li>
<li>P2639: What's the harm?</li>
<li>P2674: No opinion as not sure if the research has a lot of benefits</li>
<li>P2682: Sounds reasonable.</li>
<li>P2686: Unless the researchers are obtaining informed consent, this is highly unethical because it causes people to be denied information they would otherwise have. For example, the post of the death of a close friend or family member might be excluded.</li>
<li>P2688: It seems harmless and could provide some good data for researchers.</li>
<li>P2689: As above</li>
<li>P2690: it is perfectly fine.</li>
<li>P2692: Corrupt process can not win for science any clue but the researcher is fool</li>
<li>P2700: If participants discover what the researchers are doing, they may find a way to get them in trouble. </li>
<li>P2713: Deception is wrong. The manipulation of the friends feeds isn't wonderful but ok.</li>
<li>P2716: I also believe that the participants should be compensated in some fashion.</li>
<li>P2717: This experiment does not seem to be too risky or intrusive.</li>
<li>P2723: i dont see any harm in the experiment</li>
<li>P2727: My personal feeling is that it's a really bad kind of manipulative.  My gut feeling, again, is that there is something wrong with doing this.  People who find out they have been a part of this experiment might feel anger and a sense of being victimized.  </li>
<li>P2735: No harm will be done except a few people might feel deceived by the fake posts on Facebook. Not really beneficial to the society though. </li>
<li>P2747: I feel it is a complete waste of time and energy one day facebook will be gone just like myspace was gone overnight</li>
<li>P2750: sounds interesting and harmless</li>
<li>P2753: too intrusive, and information gathered almost useless.</li>
<li>P2762: I don't see why not.</li>
<li>P2768: It seems safe.</li>
<li>P2777: Maybe not the best idea to mess with people's moods.</li>
<li>P2781: I believe the experiment should be done but they have to be careful not to violate the privacy of its participants.</li>
<li>P2785: In my day to day activities, it seems as if the negative posts come around the same time as each other. This leads me to believe that when people see other negative posts, it encourages them to do the same. </li>
<li>P2786: Screwing with people like that is just wrong.  Purposely hiding positive posts from people could have an actual effect on people's mental health.</li>
<li>P2787: I'm not quite sure exactly how this is supposed to work,</li>
<li>P2792: The research is particularly useful.  Even if they prove the point that about mood being affected by other's posts, to what end would the information be used.</li>
<li>P2793: I understand that research needs to be done for things, but to manipulate the news feed isn't getting an accurate measure.</li>
<li>P2795: I don't believe that someone feeling being hurt should stand in the way of a scientific study.</li>
<li>P2800: Once it's posted on Facebook you are giving them permission to use it. </li>
<li>P2802: I think that this could be done and results recorded without using any participants specific name.</li>
<li>P2811: For me, I just don't see the necessity and the mass appeal, but I could be wrong.</li>
<li>P2813: There's not many risk in this so its ok.</li>
<li>P2818: not a big deal either way</li>
<li>P2819: I think it would be a good thing to see if there is any truth to it.</li>
<li>P2821: same as above</li>
<li>P2823: It seems like a pointless study to me. Facebook posts from friends should not be censored or manipulated by an outside source. That is making choices for people. That is invading their privacy. </li>
<li>P2825: Not important enough information coming from the study to block users from seeing posts in the news feed, especially since there will be no way to know if the posts were important.</li>
<li>P2828: I am not sure an algorithm can effectively detest positive/negative thoughts and feelings e.g. sarcasm but it may be an interesting study. </li>
<li>P2829: No.  No one should change people private social media without telling them even if for a experiment.</li>
<li>P2830: I don't think this is a positive experiment and goes a little far in interfering with someones personal life. Maybe my friend is having a bad day and needs advice I would want to respond to that and by blocking it I wouldn't know.</li>
<li>P2834: But only with conditions as above.</li>
<li>P2837: No informed consent is required since the data are already publicly available on Twitter; the researchers are simply applying a new analysis to posted tweets.</li>
<li>P2838: This experiment is an invasion of privacy.  </li>
<li>P2850: Farming users for their data is a very slippery slope to go down. While this research has well meaning intentions it could be used as a precedent for another round that has much less noble pursuits (i.e. how to exploit people for money). In addition the end result is terribly flawed. Judging a person solely upon their online activity could be very misleading and does not provide a full picture. Moreover people who are psychologically-vulnerable do not need a feature to protect them online, rather they need people to protect them and help them in real life.</li>
<li>P2856: Only choose people who seem to be doing well and in good spirits, nothing that could send someone spiraling into depression</li>
<li>P2857: It's too much like censorship. And a post could be removed that may be very important in some regards.</li>
<li>P2861: IT MIGHT CAUSE MORE HARM THEN GOOD. </li>
<li>P2862: Yes, it sounds like an exciting study.</li>
<li>P2865: I think social psychology is interesting, and would bet that people do match their "base's" moods, when possible.</li>
<li>P2869: I don't know if I trust the "automated algorithm" to measure emotion. </li>
<li>P2872: This sounds like a useful experiment.</li>
<li>P2874: Important psychological study.</li>
<li>P2879: I don't think any poster should be edited or censored.</li>
<li>P2882: I have reservations about the validity of the study.</li>
<li>P2885: I'm just not sure about it</li>
<li>P2886: I mean it's okay to perform this survey if you have people's consent otherwise I don't think you should be allowed to filter people's feeds however you see fit.</li>
<li>P2888: Well, if they are getting these positive posts in peoples newsfeed, wouldn't that mean they have to be their friend/someone they know. So to me, it may be ignored if it's just like an advertisement, not sure how they will do this effectively. </li>
<li>P2892: as long as they have permission and are carefully watching the people with negative posts</li>
<li>P2893: Seems harmless, but I'm not sure if they should be changing what posts they are able to see.</li>
<li>P2896: There is nothing to gain from messing with peoples Facebooks. </li>
<li>P2905: NO NEED for this "service" to that social network...spend the money somewhere else...perhaps researching energy options...or water salination...or feeding hungry kids, eh??</li>
<li>P2910: Again, the experiment seems harmless as long as the participants agree to be in it.</li>
<li>P2913: Yes because we need to understand how the media effects us.</li>
<li>P2920: No private information is really necessary, since many people have tweets that are viewable by the public. I would be interested to know the result of this study.</li>
<li>P2923: It bothers me to manipulate someones social network w/o their knowing it.</li>
<li>P2929: This should not be permitted.  It amounts to censorship.  What someone posts online is their intellectual property and editing it without their knowledge or permission should not be allowed.  What if the algorithm changes or deletes an important post about a persons health or relationship they are trying to share with family?  Unacceptable.</li>
<li>P2930: No caution needed for this</li>
<li>P2934: I think that Facebook can be a competition of emotions a lot of the time. People try to one-up each other, trying to get the most likes by being "depressed, angry, or awesome." I myself have found that I tend to want to post the highlights of my life to convince old high school acquaintances that I am indeed, awesome. It sounds really stupid, but I think this could explain a lot about human nature. I want to see this happen.</li>
<li>P2941: I don't believe in this to be only used for research purposes</li>
<li>P2946: I don't see what difference it would make but it'd be interesting to find out the results.</li>
<li>P2947: no harm in posting positive things.</li>
<li>P2956: Doesn't really seem like the study would be of any benefit, but it doesn't hurt either.</li>
<li>P2959: I would not like my personal communication blocked.</li>
<li>P2964: It show who people react to post.</li>
<li>P2966: It seems harmless</li>
<li>P2967: They are allready aware of the research so this would affect their emotions and therefore affect the outcome of the research.</li>
<li>P2972: People should be brought in and observed in a blind study and can measure in almost anyway one would like. Set up an area and have participant (students) come hang out check email and monitor or record computer activity and mood/behavior this way. I would be upset if I knew a researcher had altered my friends post and I don't even do Facebook However I do watch my kids reactions and talk with them while they are using their devices so it can be done ethically.</li>
<li>P2979: IRB rules are being followed</li>
<li>P2982: Yes, it could prove insight on depression and moods.</li>
<li>P2985: This study is an invasion of privacy and the purpose of the study doesn't really justify the means of collecting the data.  In other words, what will be learned isn't worth the deceit.</li>
<li>P3000: The study is unethical in that at no point is it stated that respondents will be told about the deception before or after its conclusion.</li>
<li>P3003: I don't think they have the right to fiddle with someone's life like that.</li>
<li>P3004: Its playing with peoples emotions.</li>
<li>P3008: It kind of defeats the purpose of Facebook, doesn't it?  Excluding posts, I mean.  I would think a better way to study it would be to ask participants if the researchers can look at past posts and use their algorithm to study the effects of negative and positive posts.</li>
<li>P3009: I don't see the harm in participants but would compare this w/ results of similar experiments.</li>
<li>P3016: yes</li>
<li>P3022: The researchers are essentially tampering with an individual's experience of their product. While I understand that it is being done in the name of bettering that product, one must account for the fact that someone may be affected psychologically by this. </li>
<li>P3028: for better understanding of peoples behavior in a social media website.</li>
<li>P3036: Always need to be cautious</li>
<li>P3039: I think this is good information.</li>
<li>P3043: As I mentioned, as long as the posts were with permission and were true but the user would not have posted them without prompting because they thought they were irrelevant-ie, the user might have a cat, and the user might not have posted a picture of their cat doing something loving usually, but the researchers decided it was a good positive post to use in their experiment, that would be alright.</li>
<li>P3045: There doesn't seem to be any enormous benefits in this study.  Just wasting time and money for the research.</li>
<li>P3046: yes , it seems harm less enough.</li>
<li>P3047: What difference does it make if the moods of psychologically vulnerable users were not protected in this case?</li>
<li>P3060: Thats just an invasion of privacy</li>
<li>P3061: Don't let someone be exposed to fake negative comments, or don't let someone be exposed to too extreme negative comments like death and suicide or other depressing subjects to that degree.</li>
<li>P3062: I don't think it's really an appropriate experiment, but maybe it wouldn't do too much harm.</li>
<li>P3063: My personal opinion of Facebook should not stand in the way of what could prove to be valuable research.</li>
<li>P3064: People can be very defensive about having their facebook pages used in a study.</li>
<li>P3065: Since when is facebook resposible for protecting the moods of psychologically-vulnerable users?  This is why I deleted my facebook when the company went public.</li>
<li>P3066: i do not see a problem with this experiment</li>
<li>P3068: People might post more happy thoughts</li>
<li>P3077: risk is too high</li>
<li>P3079: It would be interesting to see a correlation. </li>
<li>P3081: As long as users are informed of the study after the fact, the experiment should be okay.</li>
<li>P3084: Yes, I'm actually curious about the results!</li>
<li>P3086: There are more important things to be researching. Not to mention that in this case, if someone doesn't want to see negative things in their feed, get rid of the people saying the negative things. They should have control over what they see.</li>
<li>P3090: Too invasive.</li>
<li>P3094: If the participants are willing to participate then yes.</li>
<li>P3095: I think it is important to understand the implications of social media and this study would benefit humankind.</li>
<li>P3096: I don't think people at Facebook should be monitoring users' posts, nor tampering with what posts the user sees.</li>
<li>P3099: facebook already tried this. leave the individuals alone</li>
<li>P3100: Researchers must be cautious not to reveal identities or identifying information to people who may receive the results. </li>
<li>P3102: They'd be playing with people's emotions and that can cause a huge ripple effect</li>
<li>P3103: There are some ethical issues with experimenting on people without their knowledge, even if it is certain no harm will be done.</li>
<li>P3110: I view a person's account on Facebook as being quite personal and dislike the idea of others manipulating it.</li>
<li>P3117: It sounds like an interesting study and it poses no risk to those involved.</li>
<li>P3126: I can't imagine why not.</li>
<li>P3130: For the reasons stated above.</li>
<li>P3132: Again, this could hurt Facebook by not letting people know and also people finding out that some posts are not being posted, which wouldn't be hard to find out.</li>
<li>P3136: I think this is too much like censoring.  If people don't see the negative(or positive) they may miss out on important news</li>
<li>P3145: candidates need to be informed and agree to the research</li>
<li>P3148: Way too intrusive.</li>
<li>P3155: People may get upset about the process</li>
<li>P3159: Yes, but only to consenting participants.</li>
<li>P3161: Messing with people's emotions can be dangerous.</li>
<li>P3166: Again, it comes down to whether the time could be better spent doing other stuff instead.</li>
<li>P3168: I'm not sure it is up to Facebook to censor information. I don't believe that anything should be censored.</li>
<li>P3170: no harm</li>
<li>P3176: It needs to be careful because you are censoring some peoples lives.</li>
<li>P3177: They should have to tell the participants of the involvement in the study, even if it's only afterwards, and give them the option to withdraw their info.</li>
<li>P3183: because I am not sure</li>
<li>P3185: I'd need to read more about it. Maybe see a sample trial.</li>
<li>P3197: We don't want people overly sad here.</li>
<li>P3202: It is a good study topic, however I think it just needs some other safety protocols or other way to measure. (although many people these days don't seem to care who gets access to their Facebook info).</li>
<li>P3207: I feel it's pointless</li>
<li>P3208: I do not think researchers should be allowed to proceed because adding random positive posts is deceptive and invasive to the participant's private social life.</li>
<li>P3209: The person is not giving any information but there is slight manipulation</li>
<li>P3217: Only if it's university researchers, not Facebook researchers.  Facebook has too much of an agenda.</li>
<li>P3223: facebook should not hide any of my friends statues</li>
<li>P3225: The only way they should be allowed to continue is find a way for group consent.</li>
<li>P3227: Just have to be careful because some people can be very sensitive. </li>
<li>P3228: It would provide a good deal of data.</li>
<li>P3236: It sure would be nice to have someone trying to protect my well-being</li>
<li>P3240: Only if I was asked to go into my page. and if I ok it. Otherwise I would have to say, 'No'.</li>
<li>P3243: Selectively removing posts without first telling people of the experiment is wrong in my opinion</li>
<li>P3245: I'm not sure because I wonder if the participants would know they have tweets hidden from them? </li>
<li>P3246: this experiment could have some negative results</li>
<li>P3247: Seems mostly harmless</li>
<li>P3258: It seems like no subject's data will be used directly.  And, there is an algorithm in place to automate positive/negative posts.</li>
<li>P3259: Social media has become one of the main sources of communication today, people tend to inform each other of important things, tragedies, weddings, asking for help, etc.. this way a large percent of the time. omitting posts could cause negative strain on personal relationships.</li>
<li>P3260: The study interferes with people's ability to use Twitter.  If I use a social media outlet, I want to see every post from the people I follow.</li>
<li>P3269: This would alter the expectations of the user by "hiding" posts against their wishes.</li>
<li>P3274: I don't know how it will change the outcome</li>
<li>P3275: I do not like the idea of researchers purposefully seeing if they can make people's mood negative.  I would be much more apt to the experiment if they would only show positive feeds and see if people became more positive as an outcome.</li>
<li>P3276: You don't want it so scary that they will back out.</li>
<li>P3279: I do not feel like the researchers should be able to determine what the facebook users will see and not see on their newsfeed. On the other hand, it is ok for experimental purposes to see how social media actually affects us.</li>
<li>P3281: There can be repercussions in the experiment.</li>
<li>P3289: I think we all have a free mind and we will post or not post what we're feeling regardless of what others have been posting.</li>
<li>P3296: Yes, I just feel like their results won't be represented. </li>
<li>P3299: Negative thought sharing could have impact on research gathering</li>
<li>P3301: I don't see a benefit to this study, and I don't care for the fact that they are messing with communication lines for it.</li>
<li>P3302: It is worthy of studying our online behavior</li>
<li>P3306: If the data is publicly available to the researchers then there is not reason they should not be able to study it.</li>
<li>P3311: I would be on board if the user knew they were participating, but altering someone's mood can affect relationships and other aspects of their life.</li>
<li>P3313: Once again, they say nothing of informing anyone and that's alot of control.</li>
<li>P3314: It doesn't seem that important</li>
<li>P3315: The experiment is not potentially harmful and should be very safe for the participants.</li>
<li>P3316: This experiment seems to be rather frivolous. Just studying positive or negative mood.</li>
<li>P3319: They would need to be careful not to remove information that was vital to participants. For example, if a loved one dies and you don't find out because it was "negative" then there could be some backlash.</li>
<li>P3320: Again, the deleting posts is what is hanging me up on this one. </li>
<li>P3326: These companies are profiting off of peoples interaction, they should not manipulate it.</li>
<li>P3328: the person shouldnt be lead into posting negative things</li>
<li>P3333: I don't believe people should be manipulated in this way.</li>
<li>P3338: This feels wrong to me. </li>
<li>P3340: Same answer</li>
<li>P3341: I see no ill effects</li>
<li>P3343: The study sounds fabulous. I myself would like to know if others comments reflect the way I will feel.</li>
<li>P3346: Two reasons why not: 1. If the negative postings do cause negativity,it is possible that the false predominance of negative postings will affect the recipient psychologically and 2. The user assumes that all comments will come through a Twitter account.</li>
<li>P3354: It runs the risk of interfering with personal relationships that are unaware of the study.</li>
<li>P3359: Many people would want to know the findings of this type of study.</li>
<li>P3360: messing with another's posts is not good.  i do not now what facebook has to say about this.  if they find it unlawful, then i would say no.</li>
<li>P3363: I think researcher should let user have the option to view the other posts if they wanted, but other than that it seems to be okay. </li>
<li>P3367: It is a silly idea.</li>
<li>P3371: I don't see anything harmful or negative in this experiment so I think they should go for it</li>
<li>P3378: Why not? I think people love hearing about Facebook good or not.</li>
<li>P3379: This experiment seems like too much of a privacy violation.</li>
<li>P3387: Manipulating social media can make some people very upset, it has the potential to be unpopular. </li>
<li>P3389: It's an interesting question, but I don't know if producing a feature to protect one's mood is a good idea. It's good for us to experience empathy. </li>
<li>P3393: This kind of research could cause family and friend problems due to lack or misrepresentation of information. As a result this kind of research is dangerous and should instead be done in a way that allows the user to report how they feel about each post at the moment and compare it with their current mood throughout the day instead.</li>
<li>P3397: will help prevent it from actually happening</li>
<li>P3403: There is no debriefing at the end, which is required</li>
<li>P3408: N/A.</li>
<li>P3412: Researchers shouldn't be able to manipulate facebook for their own research.</li>
<li>P3413: So they'll be able to produce features that might protect the moods of psychologically-vulnerable users</li>
<li>P3416: I feel that this is a relatively safe experiment, and the information it would glean is pertinent to nearly everyone.</li>
<li>P3426: I don't think facebook should be filtered to spare people's feelings. They can either use it or not. I don't think this needs to be researched.</li>
<li>P3427: I think it is an interesting study in social media to see how emotion is tied between people. The cause and effect factor of emotion tied to what the participant is seeing is an interesting concept.</li>
<li>P3428: If it cannot produce valid scientific results it should not be conducted.</li>
<li>P3431: As stated, I don't see how harm could come from this.</li>
<li>P3434: There may be some who become more upset by having negative posts, which might actually harm some people.</li>
<li>P3438: They should keep the user information as private as possible.</li>
<li>P3440: I do not see any negatives.</li>
<li>P3442: It seems unethical (not to mention irritating to the user) to mess with somebody's Facebook feed like that. Also, it just seems like a bad experiment. How is an automated algorithm supposed to determine the mood of a post?</li>
<li>P3445: Some people use facebook as a way to keep up-to-date with the happenings of their friends. If someone posts that they just got married, people will likely want to know, but they won't know if that post is hidden because it's too "positive."</li>
<li>P3447: Sounds like a harmless enough study</li>
<li>P3451: They may miss important updates from friends or family.</li>
<li>P3453: A straight forward expierment that could be conducted with ease.</li>
<li>P3456: Personal social networks are being manipulated in this experiment.</li>
<li>P3462: Excluding posts without people's knowledge could exclude important things that they would normally be expected to notice or want to know, such as the frustrations of a significant other or trouble among family</li>
<li>P3463: The worst thing that could happen would be someone not being in a great mood after seeing other happy posts.</li>
<li>P3466: You can't let this experiment become too invasive.</li>
<li>P3467: Sure, I don't see any harm in it. </li>
<li>P3472: I know I would like to see how it turns out.</li>
<li>P3475: This is an invasion of privacy. I would not want my Facebook friends' post taken away from the feed I look at for an experiment like this.</li>
<li>P3482: Once again, you have no business making someone a subject of your experiment without their consent or permission.  It's morally unacceptable.  There has to be another, better, less reprehensible way to collect this data.</li>
<li>P3483: You are limiting the contact the person has with people.</li>
<li>P3487: I'm not really sure what the purpose of this would be or what the researchers are trying to explain but I'm not sure that I like the platform ie facebook</li>
<li>P3491: I don't really think this experiment would put anyone at risk, but I don't think the matter being studied is even necessary. It seems fairly unnecessary to develop a feature like this on Facebook.</li>
<li>P3492: It's an invasion of privacy.</li>
<li>P3495: Seem like this might not be legal</li>
<li>P3498: This seems like a good topic for research.</li>
<li>P3499: As long as what is published isn't deleted or altered permanently, I don't see a problem with the experiment.</li>
<li>P3503: Because this research doesn't seem necessary or well founded especially for the company Facebook to do, it also seems like they could find out this information with some effort without blocking or altering a persons facebook. </li>
<li>P3510: no harm can come from it.</li>
<li>P3516: This is a personal decision and should not be disrupted or studied.</li>
<li>P3518: I don't think the experiment would be harmful</li>
<li>P3523: it will help people in the end</li>
<li>P3525: The experiment doesn't sound very worthwhile, but if they want to do it then they should be able to.</li>
<li>P3526: As we don't always know how people will react, caution is key.</li>
<li>P3532: Should make sure that participants are in good mental health.</li>
<li>P3534: I really don't know on this. Torn in both directions...interesting research. but dealing with real people's lives.</li>
<li>P3536: I'm not completely sold on Facebook being a truthful entity. But that depends on whether or not they are in fact not going to this information to better themselves, not just that they say so.</li></ul>	</div>
</div>

<div class='cap' style='max-width:30%;'>
	<div class='header closed'>OSCredentialSpoofing study, answers to Proceed question</div>
	<div class='body'>
<ul><li>P6: Everyone needs to have their online identity safe from breaches.</li>
<li>P11: it may be of some use</li>
<li>P12: The researchers should be able to continue with the experiment, but should be cautious not to store any passwords or put any participants at risk. </li>
<li>P15: I feel that some aspects are slightly unsafe or can lead to some damage towards participants of the experiment.</li>
<li>P16: It will benefit and educate both parties.</li>
<li>P20: It is a research experiment so as long as researchers are conducting it within the established rules of ethics then they should be allowed.</li>
<li>P21: See above comment.</li>
<li>P25: RESEARCHERS WOULDN't be able to measure how users become victims of hackers</li>
<li>P27: In addition, the researchers should tel participants how to better protect their passwords and to change them if they feel they have been compromised.</li>
<li>P33: If its for research then I guess it would be ok but its risky to hurt a persons feelings.</li>
<li>P43: They will be getting confidential information. They need to dispose of it and let people know they disposed of it. </li>
<li>P45: See above.</li>
<li>P52: It's interesting and not hurting anyone.</li>
<li>P54: The researchers seem to be doing everything ethically.</li>
<li>P55: This experiment does not involve such obvious risks as the other two about phishing and spamming. I think people do not consider this risk quite as much as the others. It is important to gain this insight to help the community overall. They will have to be careful in that every website logs things, and there will have to be a method in place of securely scrubbing the passwords, lest the researchers get hacked themselves and inadvertently leak the information.</li>
<li>P56: Researchers could use this information to help people avoid being hacking victims. Security is an important issue these days and the more educated people are the better.</li>
<li>P59: they need to do the experiment to show us what we can do to not fall in the hands of hackers.</li>
<li>P61: the person hacked would have gained a valuable life lesson re. computers</li>
<li>P69: I THINK THIS IS A GOOD IDEA AS LONG AS PEOPLE ARE NOT AT RISK</li>
<li>P75: makes since</li>
<li>P77: See above.</li>
<li>P79: I see no harm so long as the passwords are not recorded.</li>
<li>P80: It seems beneficial.</li>
<li>P84: Yes to educate people of how easily they can be hacked and give some preventative measures.</li>
<li>P89: I don't think this is a trustworthy experiment. Although it's just testing out hackers strategies ornwhatever passwords will still be seen so this is illegal.</li>
<li>P94: It only makes sense that they do. People need to be aware of this.</li>
<li>P96: It will help to protect online users, especially newer or inexperienced users and does not pose any real threats to the participants.</li>
<li>P97: Users have passwords for various accounts. The researchers now have a responsibility to destroy the password evidence and secure their own systems.</li>
<li>P100: Again, not that the participants have to know the content of the study, their participation should be voluntary.</li>
<li>P101: Yes, because the answers will be helpful but care needs to be taken so that no one's information is jeopardized.</li>
<li>P106: Since no one would be harmed and the research yielded would be valuable.</li>
<li>P116: It seems like all the bases are covered. If there are no passwords actually been saved or stolen, but I feel like participants would need a lot of reassurance of this fact. </li>
<li>P117: Not enough information is given to decide.</li>
<li>P121: We already know some people fall for this in the real world. What is the point of measuring it?</li>
<li>P122: One of the researchers might use the information for their own personal gain.</li>
<li>P124: Sooner or later, hackers will present themselves as researchers and use the same trick to steal user passwords.</li>
<li>P132: Same as above. </li>
<li>P135: It doesn't seem as if any good will come of it. They won't be able to tell people how to recognize these attacks.</li>
<li>P136: They shouldn't even have users input real passwords.</li>
<li>P143: Security to ensure the passwords are not used for nefarious purposes is vitally important.</li>
<li>P152: It would need to be monitored closely to make sure no passwords were recorded or collected.</li>
<li>P155: It's a valuable thing to research.</li>
<li>P156: It is violating our rights.</li>
<li>P159: I think the researchers should advise the subjects to change their passwords, just in case.  This will also serve to teach the subjects about the dangers of trusting anything anybody does or says on the Internet (which they should have know, but obviously didn't, if they provided their passwords).</li>
<li>P166: No real harm will be done and it should open up some people's eyes as to the dangers of internet piracy. </li>
<li>P167: They are not taking actual passwords, participants have agreed to be in a study</li>
<li>P169: Because researchers do not plan to store password data, and also inform participants about predatory techniques, the research seems responsible. Participants will also gain an understanding of ways to protect themselves in the future.</li>
<li>P170: I would probably need more information regarding the experiment to decide one way or another. </li>
<li>P171: beneficial for many </li>
<li>P181: Why don't you just deceive the hackers and monitor what they do instead of monitoring the victims?</li>
<li>P182: Same as above</li>
<li>P183: Regardless of what you're doing with the information collected, it's not like the demographic information usually collected, which is out there on the net already.</li>
<li>P184: The researchers have the ability to collect actual passwords, so the procedure for handling and disposing of these passwords would need to be examined and approved beforehand.</li>
<li>P185: It could help people to be more careful.</li>
<li>P188: I think that it might be necessary to enable more secure password safety in the future.</li>
<li>P190: I think studies involving passwords should not be done.</li>
<li>P191: yes if the proper liability forms are signed</li>
<li>P192: Not sure if it's ethical.</li>
<li>P194: you have to be careful when tricking people or getting access to sensitive information</li>
<li>P200: This is pointless.  People should not give out their passwords.  It does not matter to what extent some do.</li>
<li>P202: After revealing the deception to the participants, it would be a good idea to ask them if they still want their responses used.</li>
<li>P203: To help.\r\n</li>
<li>P204: Researchers should make all users aware that changing their passwords would be beneficial.</li>
<li>P211: important to stop people from hacking passwords</li>
<li>P215: The risk of privacy violations appears to have been averted by not actually collecting or storing data but I still do not feel comfortable with this study's proposal</li>
<li>P218: yeah there is no harm done at the end.</li>
<li>P220: It's too risky.</li>
<li>P228: Since the study states that it will not be recording or saving any passwords obtained, I think it is a good way to both learn about hacking behavior and ultimately slow the rate of identity theft</li>
<li>P231: The participants should be told the whole truth about the nature of the experiment beforehand.  If not this experiment should not be allowed to proceed.</li>
<li>P232: Even though you're revealing the true purpose, how do people know for sure that their information is safe</li>
<li>P239: The users are informed</li>
<li>P248: Yes, but not using the "deception." Deception should not be made part of this study at all. The study's "integrity" should run throughout the vein of the entire process of the study.</li>
<li>P253: It's risky to proceed.</li>
<li>P257: Research could be beneficial to help preventing hackers and security threats.</li>
<li>P258: Raising awareness is necessary, but the temptation to steal someone's password, even for a prank, is high.</li>
<li>P270: There is an actual threat of a password being breached, even if it's not from the researchers.</li>
<li>P271: It would not be difficult (if you use your imagination) to obtain the passwords obtained by the "researchers".</li>
<li>P272: Yes, they should do it, just be sure to include that passwords were not actually taken.</li>
<li>P273: I'm not sure I'd trust my financial info in the hands of people I don't initially authorize to have it.</li>
<li>P275: I like that no information is actually being recorded. That should make this experiment interesting but not particularly dangerous.</li>
<li>P284: I understand the need for the experiment, to help with password or identity theft, but some people may not be very happy if the found out what kind of study they were involved in.</li>
<li>P289: Again, at least the participants will be told at the end the true nature of the experiment.</li>
<li>P297: I think its ok, but its still somewhat deceptive and could cause some anxiety, but i can see the usefulness.</li>
<li>P309: This experiment is moral and does not seem to pose any problems.</li>
<li>P313: Many studies require that the participants not know what exactly is being tested or observed.</li>
<li>P314: It would be a good teaching lesson about being careful on the internet. </li>
<li>P316: Again maybe in a computer lab</li>
<li>P317: As I have mentioned before, at least one person will use a password they use for other important accounts</li>
<li>P322: i don't think that murk is representative of the internet population, and sharing information is dangerous</li>
<li>P325: Some people might become upset over something like this</li>
<li>P326: just due to personal information that can be gathered</li>
<li>P333: some statement of informed consent should be drafted that meets the study requirement of being uniformed, while still asking participants if they are tolerant of deception </li>
<li>P334: Same as for pfishing, need to check the legalities.</li>
<li>P335: no</li>
<li>P347: encoding the provided passwords or using another method to prevent the actual view of the passwords from everyone including researchers should be developed.</li>
<li>P350: As long as it's very moderated and passwords are extremely protected, I don't see any harm in this.</li>
<li>P370: Research will help internet users.</li>
<li>P371: They would really need to give an option at the end of the survey telling them of the deception and allowing them to choose if they want their info to still be used.</li>
<li>P374: Some people might feel their privacy was invaded.</li>
<li>P383: If the rewarchers continued with the experiment it would show how you can avoid being hacked. But some researchers might not be honest.</li>
<li>P386: Its a terrible idea</li>
<li>P388: does not matter to me</li>
<li>P391: No identifying information or passwords are actually collected and it can help the public.</li>
<li>P393: its stealing</li>
<li>P402: You never know the intentions of the the study givers even if they are labeled as "researchers".</li>
<li>P406: They must make the post-study description one which will be read so that all participants have the opportunity to really know what went on AND give the participants an opt-out if they do not wish to contribute their data.</li>
<li>P409: Provided that the researchers provide full disclosure at the completion of the hit, they should be allowed to go forward.</li>
<li>P412: Again, they must be able to ensure extreme caution and security so that no one else is able to access the information they obtained.</li>
<li>P415: is important to determine how people are tricked</li>
<li>P417: I don't think researchers should have access to other's passwords at any point, too much security risk</li>
<li>P418: In the efforts of research I think it is important to teach the importance of protecting ones identity.</li>
<li>P419: There may be some hesitation or people being mad that they gave their passwords away.</li>
<li>P422: I think this experiment would help raise awareness of hackers' methods and equip users with knowledge to better protect themselves. </li>
<li>P423: How good are the researcher's security measures that hackers couldn't just steal their research to see what works best?</li>
<li>P425: otherwise how would we be able to ward off attackers. So yes i support it.</li>
<li>P427: No, it should be against the law, even if the purpose is for the greater good.</li>
<li>P428: All it takes is one bad researcher to steal the passwords</li>
<li>P429: invasion of privacy</li>
<li>P437: Yes they should be as long as they follow the guidelines they say and the law.</li>
<li>P439: Further research is needed in the area of password security.</li>
<li>P446: I had my password stolen once on paypal, and this needs to be stopped</li>
<li>P447: Is everyone on the research team a trustworthy person?</li>
<li>P449: again, it doesn't seem to violate any ethics and seems pretty safe</li>
<li>P450: I think it's for a good cause that can help prevent future hacks</li>
<li>P453: to test human behavior</li>
<li>P454: Yes, but there needs to be certainty that no passwords are logged.</li>
<li>P458: To show people to go on the internet with caution.</li>
<li>P462: A review board to ensure ethical standards is necessary. </li>
<li>P463: I think this is set up to be a legit experiment, but it's still worrysome that they have actual passwords.</li>
<li>P467: Making a user believe that their password has been stolen is very serious.</li>
<li>P470: I think they should be allowed to proceed with the experiment cautiously because it would be beneficial in helping prevent people from these kind of attacks. However it could also be possible for a crooked researcher to steal the data.</li>
<li>P472: Ensure nothing shady happens</li>
<li>P473: If it's for the common good than it should be allowed. </li>
<li>P476: outcome would be valuable</li>
<li>P480: oh my yes </li>
<li>P485: Because, as long as no worker/researcher actually does take one or ten, you are definitely helping others. </li>
<li>P486: Because "the researchers will not actually steal, collect, or store the passwords that users type."</li>
<li>P488: People could get mad over a study like this. I would advise caution.</li>
<li>P491: Data recovered may not be useful to goal. Experiment does not account for false information provided. Such responses are unlikely to be statistically relevant, but more information on method is required to make objective assessment. </li>
<li>P494: It seems a bit wrong but it is for the greater good.</li>
<li>P505: I think it is fine as they arent keeping the passwords but I can still see it upsetting people. </li>
<li>P513: They need to help people out there. </li>
<li>P515: Passwords are an important line of defense against keeping people out of your accounts.  I think that everyone needs to be well aware of how important it is to safeguard their passwords.  I believe that this is a worthwhile study.</li>
<li>P517: No one should be a victim of computer crime even if they are not very bright. </li>
<li>P519: So long as personal information really isn't stolen, then I think the researchers should proceed. After all, the goal is to help people better recognize and learn about such attacks.</li>
<li>P528: I think it is an important statistic for research and a way to raise awareness. </li>
<li>P531: As long as the participants passwords are not compromised, I am in favor of the study.</li>
<li>P532: The experiment seems harmless. Just make sure to encourage participants to change any passwords used after the experiment is over.</li>
<li>P533: Yes, but with caution</li>
<li>P535: I would need to see more about how the user's passwords would be protected.</li>
<li>P538: They would warn about potential dangers of giving your password to unauthorized users.</li>
<li>P539: The only thing this one has going for it is that a detailed description of the experiment will be given to the participants.  It is important that this step happens immediately after the experiment, so participants can change passwords if they feel uncomfortable with the process of the study.</li>
<li>P541: If 'hit' refers to mTurk hits and the like, and the 'survey' or 'task' is such that researchers can accomplish their task in some way, then it may be okay.  However, if it's asking for workers to tap into personal things, that's against mturk policy anyway and I would be against that.  In other words, I think there is a way this could be done that isn't personally invasive ... but it all depends on the methodology.</li>
<li>P548: I think it would be very helpful when the results come out. </li>
<li>P553: Yes I do as I feel it is imperative to ones safety online to conduct these studies</li>
<li>P555: The researchers could learn what tricks work to deceive an individual by hackers and while the person or persons involved are initially deceived they will be told later what tricks hackers used ,how they were deceived guarding against any harm occuring as a result of the experiment. With what the individual learns from the experiment they would be more knowledgeable about hackers and more cautious in the future using their passwords and computer use. </li>
<li>P557: If it can prevent hackers from continuing or at least make it harder, it should be carried out.</li>
<li>P558: I don't know how you aggregate data on passwords without retaining the passwords, so that's a concern.</li>
<li>P561: It would be important for everyone's security</li>
<li>P573: As with the other experiments, raising awareness about potential security risks is always a good thing.</li>
<li>P578: I might be OK with it if it were on total strangers.  I wouldn't want it done to someone I cared about.</li>
<li>P579: Not many people will take it seriously.</li>
<li>P583: People need to be aware</li>
<li>P585: Researchers would need the information in order to inform others of password security.</li>
<li>P590: again.  Information they gather shouldn't actually have a participants information.</li>
<li>P594: I feel that the researchers can already provide people with recommendations to secure their passwords, if they already know how to trick people into disclosing their passwords. </li>
<li>P599: It wouldn't be a good idea to show a step by step detailed way of how to hack someone's computer</li>
<li>P603: There is just too much risk here for this study.  While I participate as an mTurker, I've seen the quality and ethical nature of other workers and as a result I wouldn't trust workers to do the right thing.</li>
<li>P606: It's too risky. </li>
<li>P608: It needs to be studied.</li>
<li>P609: only if there is safty measures that the passwords are not seen</li>
<li>P612: I don't think it should be allowed to proceed because we already know people fall victim to these types of attacks. Why not do research that helps stop hackers.</li>
<li>P622: with caution so that the passwords dont really get stole.</li>
<li>P628: the information could be useful.</li>
<li>P629: It seems even better than the previous experiment as they inform the participant.</li>
<li>P631: See above.</li>
<li>P633: It looks like people are being debriefed and I think they would appreciate ultimately learning more about hacking attempts by being in the study.</li>
<li>P634: Confidential information is always a sensitive matter when included in research studies for improvements.</li>
<li>P646: It goes along the same lines as the phishing thing. This is a major thing and a scary thing for a lot of people. I think it would cause quite distress for people and for what a 40 cent survey. I know that we are as Mturkers just workers filling out things behind a screen but we are affected by these things. And we work very hard for very little money some of the time. This seems very inappropriate.</li>
<li>P652: I think if they were able to publish the information it would be somewhat beneficial but I am not sure if it is with while since they can not publish it. </li>
<li>P656: Learning about these things is important. </li>
<li>P657: nothing is being stolen</li>
<li>P660: I think the participants should be told to change passwords after the study for security purposes.</li>
<li>P672: Research like this can help fight against hackers. </li>
<li>P678: thief is real anything to stop that and produce a safe environment for users will be highly appreciated</li>
<li>P681: Yes, it will be beneficial to the community. </li>
<li>P682: The participants are not honestly advised of the intention</li>
<li>P685: I think this is safe but I don't like that they are trying to deceive people.</li>
<li>P688: As long as they're positive no one can or will use this password information to steal someone's personal information</li>
<li>P689: Even if the researchers won't collect the passwords, some participants might be skeptical.</li>
<li>P692: Yes, no issues here. </li>
<li>P694: this study will be very benificial</li>
<li>P696: This would seem like a waste of time because the data would be difficult to use and there would be serious doubt to it's validity.  Also, if a person were to be involved with this study without informed consent and they typed their real passwords into a computer with monitoring/key logging software which resulted in compromised accounts/identity, the researchers would likely be held liable for the damages.</li>
<li>P702: This is a great learning experiment that will teach people how to protect themselves!</li>
<li>P705: Planned deception</li>
<li>P707: It would be beneficial overall.</li>
<li>P708: They should do this to figure out how to prevent real people from doing it.</li>
<li>P717: The information gathered from such an experiment could be used to prevent the real hackers from doing it in the future, thus saving people from real threats in the future.</li>
<li>P722: Although I believe they have the potential to do this, it in itself is very tricky business, and can be turned against them.</li>
<li>P726: If no harm is going to come to the users, then why not?</li>
<li>P729: It seems like a good idea, just should give people a choice.</li>
<li>P732: There should be safeguards to protect any sensitive information from getting into the wrong hands.</li>
<li>P735: If deception is purposely used I would tell people to opt out.</li>
<li>P737: Its a serious issue and needs to be addressed in the proper way.</li>
<li>P740: Who is going to guarantee  where this info  goes</li>
<li>P748: The caution would be that everything is fully explained to and understood by the participants.</li>
<li>P761: It is unethical.</li>
<li>P763: See above.</li>
<li>P772: There is potential for abuse</li>
<li>P776: The risks to the research and to the participant of the information getting out is too great.</li>
<li>P780: I think its good to make people aware </li>
<li>P787: Maybe, if there were ways of assuring that passwords were completely protected. </li>
<li>P792: I would be weary of the repercussions of using deception. However, I think this study is not harmful and for academic purposes and therefore justified.</li>
<li>P794: Hackers should be taken seriously, and I don't think any study that runs the risk of making me believe I'm in danger of identity theft should be done. </li>
<li>P797: They would really have to make sure the passwords are not kept under any circumstance.</li>
<li>P800: Seems important as hacking seems to be a big problem.</li>
<li>P803: Keep the information secure and don't abuse the information.</li>
<li>P811: It will help users from falling prey to this stealing of passwords and to recognize when it is happening to them so they can prevent it.</li>
<li>P812: This one offers no harm to the individual, but it is gathering sensitive information such as passwords. So extra care needs to be taken to ensure the passwords aren't stored.</li>
<li>P820: hopefully it doesn't fall into the wrong hands.</li>
<li>P821: This is helpful in the long run.</li>
<li>P824: it would be beneficial to learn more about hackers this can improve future security  </li>
<li>P828: See above, passwords are sensitive data.</li>
<li>P833: I would be much more trusting of this research than the phishing experiment.  Since the passwords/user info aren't stored, and since you won't be logging into someone's account, I think privacy is still protected.</li>
<li>P834: There is no sensitive information collected.</li>
<li>P835: No risk</li>
<li>P836: I think that the passwords should be encrypted so no one can access them</li>
<li>P837: The scenario could cause less savvy technical users to have a lot of concern. The context for the tests would need to be constrained just to a web browser -- which makes implementation of the test very challenging.</li>
<li>P841: This is only helpful and it brings awareness of internet safety to the public once the results are published.</li>
<li>P847: If one or more of the users were unscrupulous, the participants data might be stolen and it could have disastrous consequences for the research organization.</li>
<li>P850: I think it would be a good idea, and very eyeopening, to see how many people fall for it and if there are ways to protect ourselves from it</li>
<li>P851: Make sure the information isnt shared.</li>
<li>P861: It could help improve security.</li>
<li>P865: when dealing with people's passwords, it's a tricky and potentially dangerous thing</li>
<li>P866: Affect privacy.</li>
<li>P868: I think this is a good idea for research, but it could be tricky since password information can be personal.</li>
<li>P870: Yes, but general information about the research should be given to participants before the experiment.</li>
<li>P874: I think that the researchers have a great study here and there are many benefits for those who participate</li>
<li>P882: It violates the subjects privacy to a great degree.</li>
<li>P884: I would still be worried that my password would get out. And I wou7ld be worried that it would be a trick form a hacker aslo and if that information does get out, that could be devastating.</li>
<li>P886: Participants could become very apprehensive when it is revealed to them the nature of the study and that they were being hacked during it.  Although no passwords were saved, some participants may have been using normal personal information and may feel threatened.</li>
<li>P890: There is not informed consent, so this study should not proceed.</li>
<li>P898: depending on who it is, there might be too much information given out by the participants</li>
<li>P901: As long as it can be guaranteed that passwords cannot be maliciously recorded by a third party during the experiment, then it seems fine to conduct.</li>
<li>P903: This experiment would help to education individuals who are not aware of hacker threats.</li>
<li>P904: It's not morally right</li>
<li>P906: can't learn to stop them till you know how to protect </li>
<li>P908: I think it could help make things safer for all</li>
<li>P912: could open people up to more risk</li>
<li>P913: You could teach people how to steal passwords.</li>
<li>P914: I believe researchers should be allowed to help learn how to stop hackers.</li>
<li>P921: The study could be helpful about teaching others how to avoid hackers.</li>
<li>P925: I would need more information about the specifics of the HIT and how they would get people to give up their passwords</li>
<li>P926: I think this study will reveal important information. </li>
<li>P927: they should not be allowed to proceed with this concept, if they want to conduct this experiment to get the actual result than they should do this in a real time and real world scenario. if this done in real world than only actual result would come out</li>
<li>P928: This is a severe violation of privacy and could be exploited</li>
<li>P929: Many mTurkers are familiar with such techniques, and would return the HIT if it's not done very, very well.</li>
<li>P938: Depending on what password they're thinking is being stolen, they might feel compelled to change things unnecessarily.</li>
<li>P939: Just make sure that participants 100% trust that no passwords were saved in any way.</li>
<li>P940: Researchers should be careful to make sure data is kept anonymous and only necessary data is recorded.</li>
<li>P942: the more we know about how hackers work, the better we can protect ourselves from becoming a victim</li>
<li>P948: How do you replicate the techniques without actually stealing</li>
<li>P949: steal peoples passwords no way</li>
<li>P951: they should be careful with the possible passwords</li>
<li>P953: It is more ethical than the last experiment.</li>
<li>P955: I don't like the wording:  deceive participants. I feel like there's a better way to phrase this. Also, as opposed to the previous proposed study, this one states that the subjects will be informed of the research afterwards. I feel like this is more ethical. The findings from this could benefit society. This study sounds like it could actually help prevent crimes from occurring, and it isn't just about marketing practices (as the previous study). </li>
<li>P957: As long as no passwords are store anywhere, and all information revealed to participants, I do not think this is an outright violation of a person's rights.</li>
<li>P959: It's best to us much caution when deceiving someone like this study would require</li>
<li>P963: Caution should be used, as always, but this is an effective tool for research.</li>
<li>P972: The information might be useful but it is a shady was of going about it.</li>
<li>P976: they need to make sure info is secure</li>
<li>P984: It's unethical to trick people into giving passwords - even for testing situations.</li>
<li>P989: It sounds very interesting. </li>
<li>P1004: No real risk to participants.</li>
<li>P1005: I think this would be a great experiment as long as the behaviors/logic the participants used to leak their passwords were addressed. </li>
<li>P1010: I feel as if there is more risk involved than noted.</li>
<li>P1016: This seems like an interesting study.</li>
<li>P1017: as long as they dont record the pw's and notify the participants its ok</li>
<li>P1026: Since there is no actual harm occurring to the individuals, I think it is okay, but it is important that the debriefing period be thorough and enough to put participants at ease. </li>
<li>P1031: It goes against the strict instructions we are all given in this day and age to never give out ANY personal information. </li>
<li>P1039: It's an important research question, and the deception doesn't hurt anyone.</li>
<li>P1051: Something needs to be done to help protect people from hackers.</li>
<li>P1054: They're not hurting anyone.</li>
<li>P1055: I think the biggest problem would be that MTurk seems to have an awful lot of people who have access to the HITs.  I'm not sure peoples passwords would be safe, and many of us would be uncomfortable sharing passwords.  This would most likely cause a lot of us to be up very late tonight to be changing passwords.</li>
<li>P1057: As long as they are not actually stealing information, then yes.</li>
<li>P1058: I think this is for a great cause because so many people become a victim to this nowadays. I don't think anyone will be harmed or have any hard feelings. </li>
<li>P1059: There will be no harm done.</li>
<li>P1062: There is nothing ethically wrong with this scenario, but strong security measures should be taken</li>
<li>P1083: More people need to learn about how there are so many scammers out there and to be cautious when giving away their info or logging on to websites.</li>
<li>P1084: I think it will benefit many people.</li>
<li>P1089: There are better ways to get this information than to conduct this experiment, questionnaires would be safer and get you the same information.</li>
<li>P1090: i think people could get very angry about being tricked into giving their passwords</li>
<li>P1108: People could get mad if they are lied to. They might feel that their privacy was invaded.</li>
<li>P1109: It is important to examine this issue.</li>
<li>P1110: I cannot foresee how this would create complications or lead participants to put themselves in the way of real risk.</li>
<li>P1111: The more we can tighten computer security, the better!</li>
<li>P1112: It is deceptive and will cause people stress</li>
<li>P1113: There is no actual risk to participants, and they will learn more about security.</li>
<li>P1116: No one will be harmed and they will be able to measure how often users fall victim to attacks that target user's passwords.</li>
<li>P1119: It is critical that this experiment proceed unhindered in order to further the cause of informing others of how to prevent being phished by hackers and thieves.</li>
<li>P1123: It's important to do experiments to find such data, but proceed with caution just because they are experimenting with people's private passwords.</li>
<li>P1130: As long as researchers take every precaution.</li>
<li>P1131: People may be uncomfortable with possibly believing that their password may have been stolen.</li>
<li>P1140: They should be extremely careful in explaining to others that it is just an experiment and nothing more.</li>
<li>P1147: If participants type actual passwords, they need to be assured that they are not being collected.</li>
<li>P1157: This proposed research utilizes fraud and possibly exposes participants' passwords to scrutiny if the researchers are careless or ignorant.</li>
<li>P1158: Their reasoning is valid, and the research is worthwhile.</li>
<li>P1162: The more people know about a problem like this, the more likely it is to eliminate the problem</li>
<li>P1163: While the intentions of this study may be good, it is still borderline very personally intrusive.  </li>
<li>P1165: I just feel that it is nasty to put a bunch of bad mood posts in a row on someone's Home page.  Why put someone through that?  They might quit Facebook because of the test!</li>
<li>P1168: I would be wary of a study like this because of the potential of the passwords actually getting stolen. The researches should provide as much information about their study to the participants so they know where this information is going and being used for.</li>
<li>P1169: It is an important study.</li>
<li>P1174: it s not good</li>
<li>P1176: There is no harm adn this kind of research is necessary for better security</li>
<li>P1177: It will be more of a lesson to both the participant and the researchers.</li>
<li>P1178: Yes, it's important to have the research done so we can become more knowledgeable about hackers attempts to steal passwords. </li>
<li>P1179: Yes, but make sure the passwords obtained are permanently deleted or securely stored. </li>
<li>P1181: People could be really upset about the deception and feel like their still being deceived after about their information being stolen.</li>
<li>P1186: It is a bit unfair to trick people like this, even for research. It could be misinterpreted. </li>
<li>P1191: There is no risk involved with this particular study. Their information isn't in danger of being used by those performing the research.</li>
<li>P1192: It would help computer users be safer.</li>
<li>P1195: Again caution when dealing with personal information. Must take a lot of caution with this.</li>
<li>P1196: The potential to misuse the information collected is high and needs to be closely monitored.</li>
<li>P1197: This would cause a lot of anxiety and mistrust about whether the passwords were recorded or not, even if they were actually not recorded.</li>
<li>P1199: as long as these researchers are legit and don't use the passwords for harm than yes.</li>
<li>P1203: Sounds risky. </li>
<li>P1206: They should make sure the experiment is controlled enough to make sure nothing bad happens as a result, </li>
<li>P1211: Again, people will be doubtful. Especially using hacker techniques, it will seem particularly shady. </li>
<li>P1216: No, I consider the experiment unethical.</li>
<li>P1220: It is too risky and can jeopardize someones security even if the data isnt being stored.</li>
<li>P1227: Mturk users are generally quite a bit more technologically advanced than your average group of people who would normally fall for a "hacking attempt." You would receive unreliable results. Also, users do anything asked of them to complete the hit. If there was no way to avoid diverging a password to complete the hit, the study would be void.</li>
<li>P1229: to help people keep there password secure.</li>
<li>P1230: All it takes is one person abusing the power during the study to actually steal somebody's information. The data/passwords collected after should be destroyed.</li>
<li>P1233: Checks should be in place to protect user information and passwords.</li>
<li>P1234: It's valuable data.</li>
<li>P1244: It's not ethical.</li>
<li>P1245: You want to make sure you don't violate any ethical codes. </li>
<li>P1247: I am not sure this is the best solution for studying password hacking.</li>
<li>P1248: I think it would be a worthy experiment, I'm just not sure I'd want someone I know participating.</li>
<li>P1253: I think this within the range of allowed research, but there must be safeguards.</li>
<li>P1260: They could be using the info they are retrieving to better hack individuals passwords</li>
<li>P1261: They have to make sure that the passwords gotten from people will not be stored anywhere. </li>
<li>P1262: Depends on the integrity of the researchers, if they see an opportunity to steal a password.. would they?</li>
<li>P1264: To soften the blow, perhaps researchers could offer a small incentive to participants afterward. For example, along with a thorough debriefing, participants could be given a $10 gift card to Walmart.</li>
<li>P1265: The debriefing in this experiment would need to be strong to assure participants that their passwords and account security are not in any danger.</li>
<li>P1266: I think it would be valuable for helping people not be fooled.</li>
<li>P1267: If their research can eventually lead to significantly better security then the experiment should be done.</li>
<li>P1270: i think it is a good idea but very risky because of the trust with important information being given out</li>
<li>P1272: Only if after their password has been input they are prompted to immediately change that password on any site they have it set.</li>
<li>P1273: The fact that it says that "The researchers thus plan to DECEIVE participants" makes the whole study unwelcoming.</li>
<li>P1274: All experiments should be performed with caution.  </li>
<li>P1278: I know this can be important but dont like deception.</li>
<li>P1279: They can manipulate the twitter feed.\r\n</li>
<li>P1286: Any time you steal or attempt to steal someones password it becomes an invasion of privacy.</li>
<li>P1288: As long as the passwords are not stored or in any way tracked or linked to the participants, I don't see a problem, but again, don't see it happening often.\r\n</li>
<li>P1289: this research has value because we need to learn the tricks used by the hackers in order to stop them or prevent them from stealing passwords</li>
<li>P1296: If they posted the results of this experiment it might help others learn how to steal other peoples information.</li>
<li>P1297: Make sure that whoever is a part of this study signs an agreement and understand that personal information does not leave the study or is not kept.</li>
<li>P1300: People need to be informed on how vulnerable they are.</li>
<li>P1301: Doing white hat hacking with the pretext of "research" is fine, but share your results and help make better policies.</li>
<li>P1302: It can help a lot of people if they get enough data. </li>
<li>P1310: This topic needs to be studied.</li>
<li>P1311: I think it is an invasion of privacy.</li>
<li>P1316: I always feel a bit uneasy when passwords are involved.</li>
<li>P1318: self esteem would be effected nobody wants to feel vulnerable like that. </li>
<li>P1321: As long as they're watched carefully.</li>
<li>P1326: The passwords are not collected or stored, and the participants are made aware of the experiment afterwards.</li>
<li>P1330: This seems fine to me.</li>
<li>P1331: I think that it may be more beneficial to learn the results and I don't see any real risk with this experiment.</li>
<li>P1340: Yes they should since it will teach people a lesson about not giving out their passwords so easily.</li>
<li>P1343: It seems very well thought out. </li>
<li>P1344: For the same reason's as stated above.</li>
<li>P1346: The experiment would be very beneficial to a lot of people.</li>
<li>P1356: its all a trust issue for me. I wouldn't want it to happen to me. and how do i know that they really won't use my info for other purposes</li>
<li>P1357: Cautious with the information divulged</li>
<li>P1360: I think that it could help determine ways to thwart these types of attacks.</li>
<li>P1367: The experiment seems a bit risky and may alarm the candidates</li>
<li>P1371: Participants are debriefed at the end of the study, so I see no ethical problems with the study</li>
<li>P1373: are we sure that the passwords won't be accessible at a later date by the researchers?</li>
<li>P1374: As long as the experiment is conducted as described I see no problem with it.</li>
<li>P1389: As long as the information is not used for malicious purposes and all participants are informed in due time, the researchers should be allowed to proceed.</li>
<li>P1406: It helps that the participants will be informed, and the results will be published. </li>
<li>P1410: I have no idea how yes but with caution could possibly be different from yes.</li>
<li>P1419: Plans should always be put forth to make sure we all are protected as much as possible to prevent hacker's attacks.  </li>
<li>P1423: Nothing is wrong with this experiment.</li>
<li>P1426: Could become illegal if they save anything.</li>
<li>P1427: Same reasons as above. This questions is bit repetitive. </li>
<li>P1432: Educating people about how to protect themselves on the internet is important</li>
<li>P1433: I think there's some ethical issues with enticing people to type their passwords.</li>
<li>P1438: Same as with the other similar studies, I don't see a purpose to finding out how successful certain methods of scams are. It would only increase potential scammers.</li>
<li>P1446: The more info they have the better programs they can develop to protect us.</li>
<li>P1456: Its not needed</li>
<li>P1466: It could go either way. There definitely should be independent oversight.</li>
<li>P1470: For the reasons above, but if participants were notified, that would be fine.  I think that people are already hyper vigilant on the internet.</li>
<li>P1471: The researchers would have to be eminently trustworthy and/or the experiment would have to somehow be conducted with fake passwords, otherwise this would be password theft and not simply an experiment.</li>
<li>P1472: In a monitored environment</li>
<li>P1479: Not many people would believe that their data was really not stolen and may disagree with the necessity of the study.</li>
<li>P1482: I believe they should be allowed to proceed, but no passwords shall be stored in any manner, encrypted or plain text. The page that participants type into should not send any of the information to anywhere.</li>
<li>P1487: Several measures need to be put in place to protect the passwords collected.</li>
<li>P1488: YOU HAVE TO BE CAREFUL WITH PEOPLES INFORMATION</li>
<li>P1489: It would be good to expose stuff like that this.</li>
<li>P1492: I'm not sure how I feel about this one. On one hand if they are volunteering for the study (even if they are being lied to about the actual purpose) I could see this being ok. On the other hand I could see how such a study could get out of control and leave some data vulnerable. </li>
<li>P1497: I don't think it's right to collect people's actual passwords, even if the data isn't stored.</li>
<li>P1503: They would get useful information</li>
<li>P1507: Some researchers could be dishonest and then use this information for unrelated matters.</li>
<li>P1508: the user always has to know they are part of an experiment so they can choose to opt out</li>
<li>P1510: Yes, subject to the constraints in my prior response.  </li>
<li>P1513: Too dangerous in my opinion.</li>
<li>P1514: it might offend some people...never know.</li>
<li>P1517: While it would be a good idea to perform this experiment, participants might learn how to steal passwords from others.</li>
<li>P1522: They aren't hurting anyone or taking any passwords and it could be beneficial</li>
<li>P1523: I don't think its fair for the participants, it has the potential to cause mental harm with people who are sensitive with "trust issues"</li>
<li>P1524: Again, this is the type of experiment that has validity/serves an eventual purpose for the participants.</li>
<li>P1528: There are those who learn and those who won't. Some will complain about being deceived, others will probably try to sue because their computer is already contaminated and the blame will be placed on the researcher.</li>
<li>P1534: Just be careful and make sure everyone knows whats going on.</li>
<li>P1538: It's important that the passwords not be cached, viewed, or stored in any way.</li>
<li>P1540: They are performing a study without imposing actual risk. </li>
<li>P1542: They must make sure that the passwords are not recorded or compromised.</li>
<li>P1546: It should help them learn about what not to do.</li>
<li>P1552: too many people fall prey to this sort of behavior, research needs to be done to identify triggers</li>
<li>P1553: As stated about I believe this could only end up benefitting the participant as long as the information that is entered is immediately and securely deleted.</li>
<li>P1554: k</li>
<li>P1556: It is absolutely vital to prevent hackers from receiving user password information in this digital age.</li>
<li>P1558: I like that they will not steal, collect, or store the passwords - they need to be sure they treat all other information with the same discretion.</li>
<li>P1563: Not to access any pii information</li>
<li>P1572: I would be wondering if we could trust that the passwords wouldn't be really collected or destroyed.</li>
<li>P1582: The next time the person I cared about got something like the research task they may just think it is the researchers again and complete the task when it is really a hacker.</li>
<li>P1584: Many people fall victim to ID scams over the internet. If this experiment is something that can reduce the number,I'm all for it.</li>
<li>P1593: Passwords are still being obtained.  They have to be extremely ethical in how they proceed.</li>
<li>P1597: This is still stepping on people's privacy. Caution is required.</li>
<li>P1598: I wouldn't like it, but there is some value here.</li>
<li>P1610: even though they aren't storing the passwords it could be possible for them to be stolen they need to make sure there is good security to do this.</li>
<li>P1612: I trust them</li>
<li>P1616: They are not actually stealing any passwords</li>
<li>P1617: As long as data is not stored, its fine.</li>
<li>P1618: I see the benefits as well as the risks.  Personally, I would not like to be a participant in this type of experiment, but I can see where it could help others to use more caution in the future.</li>
<li>P1620: People could easily get upset over this.</li>
<li>P1630: Yes, because if it is a legit study, the results can be beneficial. It should be heavily monitored though.</li>
<li>P1631: it would open peoples eyes to how people steal your information so easy.</li>
<li>P1633: The researchers must take care that none of the personal information gets out. </li>
<li>P1643: This experiment is not as harmful as the Facebook method, but still holds dishonest practice for possible positive data.</li>
<li>P1646: yes, but be careful since they're dealing with people's personal information</li>
<li>P1650: always with caution</li>
<li>P1651: Just make sure there is no way for the passwords to be retrieved. </li>
<li>P1655: Its a good study to see how likely people fall for hackers methods.</li>
<li>P1657: There is too much potential for sensitive data to be leaked.</li>
<li>P1668: It would be beneficial in learning how hackers and the people they hack operate.</li>
<li>P1671: Ensure that no data is stored, and the web forms are properly secured.</li>
<li>P1674: This is another one that assumes the researchers are infallible morally and ethically.</li>
<li>P1677: User education is paramount to successful cyber security.</li>
<li>P1678: If it is done responsibly, I suppose. I wouldn't participate. </li>
<li>P1680: Since the passwords will remain private, the researchers should be allowed to proceed with this experiment.</li>
<li>P1681: They may actually upset some of the test subjects after the experiment is done, even though they aren't collecting the information, the subjects may not believe them</li>
<li>P1683: peoples passwords are personal and no one should have access to them.</li>
<li>P1686: It seems like it could help people be more secure.</li>
<li>P1693: It to help protect people for getting their passwords stolen</li>
<li>P1704: any access to anther's passwords needs to be carefully safeguarded.</li>
<li>P1705: password security is getting to be amuch larger issue</li>
<li>P1709: I believe that the researchers should screen their candidates before the experiment is conducted.</li>
<li>P1721: I believe it's a thin line to have anyone with the power to steal users passwords, without their consent.</li>
<li>P1724: I think it is too dangerous for a security breach</li>
<li>P1733: It would be beneficial in helping to stop hackers</li>
<li>P1738: Absolutely but again with the caveat that banking and medical and other really sensitive information should not be asked for. I think that's too dangerous to play with.</li>
<li>P1740: It will help show people how they are tricked as well as giving the researches some data on the subject.</li>
<li>P1741: It is not possible to guarantee that confidentiality will be remained. Someone could get their hands on the study results and compromise the participants.</li>
<li>P1742: It would help many people to be more careful. </li>
<li>P1744: As long as not storing password</li>
<li>P1745: The people seeing the passwords should be trustworthy enough to not steal them</li>
<li>P1746: This could turn out to be very valuable. Researchers could figure out how many people fall for these tricks and what to do about them.</li>
<li>P1753: they are not hurting anybody and there research and finding can help prevent predatory hackers from hurting people in the future</li>
<li>P1758: Perhaps some way of getting people to sign up for a similar task where they wouldn't know the actual reasoning behind it but where they would be giving permission to the researchers to be a part of the study</li>
<li>P1766: as it is for good cause</li>
<li>P1770: Passwords are personal and that is just like hacking</li>
<li>P1774: As listed above, I would like to see the procedure for how the participants will type their passwords and how that information would be protected and hidden from those conducting the study. </li>
<li>P1775: Is this a real study?</li>
<li>P1783: Care needs to be taken over privacy concerns.</li>
<li>P1785: They should let people know ahead of time that nothing is really going to be stored.</li>
<li>P1788: Because they would gain passwords that could be used for malicious things. </li>
<li>P1793: As long as the passwords are not collected</li>
<li>P1806: Yes they should be allowed to perform this study. However, they have to tread with care. They have to make sure that all the researchers have gone through extensive background checking and other forms to make sure they are not a risk to steal information that is easily accessible to them. </li>
<li>P1808: The ethics are VERY questionable</li>
<li>P1814: Invasion of privacy.</li>
<li>P1821: because people should know how they might have given away their info and will be more cautious next time</li>
<li>P1825: They might give ideas to hackers</li>
<li>P1835: It could be useful as an end result but overall it is an experiment that would violate those involved</li>
<li>P1837: Research is important, as long as it is safe</li>
<li>P1839: People may be upset after being told what has happened</li>
<li>P1841: Yes, as long as they provide a full disclosure to participants.  </li>
<li>P1848: I'm all for safeguarding users.</li>
<li>P1850: Seems like a good experiment.</li>
<li>P1851: Anything involving passwords should always be used with caution. </li>
<li>P1853: It seems like it will help both users and researchers. </li>
<li>P1857: I don't know whether or not this is an ethical way to study how often people give up their password information. It seems like there is a chance something could go wrong and someone's password could be compromised. </li>
<li>P1865: I don't really approve of a research study using deception, but I can't really think of another way to conduct the study.</li>
<li>P1866: It is information that can stop a crime and it will help stop peoples lives from being ruined. </li>
<li>P1870: The researchers tell the participants about the deception, making this okay.</li>
<li>P1871: I believe it will educate the common public similar to this one ==> http://www.sophos.com/en-us/support/knowledgebase/37179.aspx </li>
<li>P1873: It seems like a good idea.  Deceiving people is a necessary part of the experiment.</li>
<li>P1874: This is a wonderful study, and if it were real, I would endorse it as much as I could.</li>
<li>P1876: After explaining the study to the participants, some participants may form trust issues.</li>
<li>P1877: Potentially sensitive date (such as passwords) needs to be handled with care. An experiment can claim to not store passwords, while storing passwords.</li>
<li>P1878: looks like only good could come of it</li>
<li>P1884: A lot of caution that is for sure!  Make sure all rules are written and decided on before the study is even started. </li>
<li>P1890: All participants should change their passwords after the experiment.</li>
<li>P1892: I feel that it is unfair to conduct an experiment with no benefit for society.</li>
<li>P1893: Yes, same as above.</li>
<li>P1894: Workers doing HITS assume all tasks they perform are secure and safe.  Your data might be skewed by this fact.</li>
<li>P1897: All experiments must have some degree of caution.</li>
<li>P1901: Why would you do this experiment without looking for recommendations?</li>
<li>P1906: Deception is common in research and no harm can come from being tricked to type your password somewhere where it won't be saved or stolen.</li>
<li>P1913: Yes, it is a valuable study with no harm </li>
<li>P1916: By having this experiment, try to also bring out ways to protect yourself from hackers.</li>
<li>P1917: Yes, people should be aware of the risks. </li>
<li>P1918: It might be important to learn how to protect passwords better.</li>
<li>P1920: Stolen passwords cause a lot of problems for a lot of people, and anything that can help people avoid having it happen to them is a good thing.</li>
<li>P1930: With caution is key, if the results get in the wrong hands the participants could be compromised</li>
<li>P1934: All private materials must be destroyed at the end of the research.</li>
<li>P1936: There should be safeguards and oversight to ensure that no passwords are actually collected and stored.</li>
<li>P1938: I guess it's okay.</li>
<li>P1942: The password CANNOT be stored at any point.</li>
<li>P1953: The research seems very important and valuable, but there should be caution that no real information is collected, stored, or distributed. </li>
<li>P1955: I simply see no reason why not. No actual passwords were harmed in the making of this research.</li>
<li>P1960: Deception is tricky, however, the experiment may help participants learn to be more cautious with their passwords.</li>
<li>P1963: If it will help increase security then I think it is worth it.</li>
<li>P1977: See above. Sounds super creepy. Seems like it should be illegal. I don't like duplicity. Sounds unethical.</li>
<li>P1978: For the same reasons as above.</li>
<li>P1979: I don't think they should be asking for real passwords that people use.</li>
<li>P1982: I think the premise is deceitful but I understand the point.</li>
<li>P1989: The researchers need to make sure that no passwords are actually collected or stored.</li>
<li>P1991: The more information they have condensed about the kind of people fall for hacks, the more easily that information is accessible by hackers. </li>
<li>P1998: The data this experiment hopes to gather, isn't even necessary. One does not need to know how often people stub their toes to educate as to how they can better avoid such a thing. The same is true of hacking and phishing.</li>
<li>P2002: Yes, it will help them understand how passwords can be stolen.</li>
<li>P2003: Hackers could turn around and use the information to find out what methods are the best and start actually using those. </li>
<li>P2004: Yes, because it is an informative study, although you have to have caution because passwords can be dangerous in the wrong hands.</li>
<li>P2025: There's plenty of information out there to prevent this.</li>
<li>P2026: There seems to be no real threat. The results of the study would help people in the future.</li>
<li>P2027: it should be encouraged and i think there should be more of this type of research</li>
<li>P2032: No tampering with the computers please.</li>
<li>P2040: If no passwords are collected, participants will not question the legitimacy of the study.</li>
<li>P2048: Not enough information about time frame, accounts creation and password.</li>
<li>P2051: I think studies designed to cause no harm to the subject, and end result in either better security or more well made designs for recognizing attacks via the internet. Then I'm all for it. As long as the study is conducted well, and uses at least one computer expert to make sure that no one is at risk, nothing is being sent out over the internet, and that the results aren't tainted.</li>
<li>P2053: I think it would be useful in preventing further password stealing as long as participants are informed after</li>
<li>P2060: This is research that needs to be done.</li>
<li>P2061: we need data to acknowledge that this things do exist</li>
<li>P2065: Need to make sure there is no way for the passwords to be stored</li>
<li>P2070: Seems fine but being cautious is always good</li>
<li>P2072: They can find another way.</li>
<li>P2082: The people are consenting to participate.</li>
<li>P2084: because in the long run it will help people </li>
<li>P2094: I'd want to be absolutely sure the researchers were not saving the information they received. It would be easy for it to be abused if anyone in the research team was manipulated to leak that info to real hackers or their associates.</li>
<li>P2097: No.  The researchers want to know the percentage of internet users who are deceived by hackers into typing their passwords, and they want to use AMT workers to measure how often internet users are victims of hackers who use internet users passwords.  The researchers say they they would not be able to produce and publish recommendations to help internet users better recognize such "such attacks", but the reality is, the researchers could produce and publish recommendations based on data gained from reports made by internet users who have had passwords stolen by hackers. Surely, there is plenty of data already available, freely and knowingly given by people who have had their passwords stolen at hacked websites and spoofed websites. </li>
<li>P2100: There should be a warning in the beginning that it could cause distress.</li>
<li>P2103: It should be independently verified that no passwords have been stored. </li>
<li>P2114: There's no harm to the participant and it's a worthwhile topic.</li>
<li>P2117: Provide participants the option of having their data withdrawn in case they are offended by the deception.</li>
<li>P2119: I think it's important to maintain people's privacy.</li>
<li>P2123: to measure how much people fall victim to hacking attacks</li>
<li>P2125: There weren't very many details as to the procedure but if it could help raise security, then I'm for it.</li>
<li>P2126: As long as the information is not used or stored, I see no harm in this experiment</li>
<li>P2132: Depends on what questions are next.</li>
<li>P2134: Regardless of the bona fide intent of the researchers, participants will still be giving their personal information.  I would expect some participants to be unhappy with this and they could argue that they cannot trust the researchers to keep their word of confidentiality after they have already been deceived.  </li>
<li>P2135: If the experiment is legit, then I believe they should be allowed to proceed because the research could be quite helpful. I say with caution because it's still a risky experiment to conduct.</li>
<li>P2152: This could scare people</li>
<li>P2155: Yes, but with caution tricking people can cause anger.</li>
<li>P2160: As long as the researchers are not actually storing the passwords, I believe that this experiment would be fine.</li>
<li>P2172: As long as the study does not have harmful results. </li>
<li>P2175: Maybe the researchers can be trusted, but how would they know someone wouldn't later use their research for nefarious purposes?</li>
<li>P2179: If the participant follows the instructions but doesn't read the debrief, they have now become more vulnerable to an attack in the future, as they are willing to supply that kind of information in a survey. </li>
<li>P2183: Again, this could be beneficial in stopping a real threat (identity theft).  The guidelines say no real data will actually be stolen.</li>
<li>P2191: As long as the researhers are not collecting any real passwords this should be ok. </li>
<li>P2194: To prevent any more of what happened to Target in the future. yes research on.</li>
<li>P2208: It'd be good to inform people how to protect from these attacks but it should be done carefully and securely.</li>
<li>P2212: This type of information in the wrong hands can be potentially devastating to an individual.</li>
<li>P2213: The results would be interesting to see, but only if they keep the promise of not saving the passwords.</li>
<li>P2216: This type of deception will make certain people feel like they actually did have their password stolen</li>
<li>P2218: This experiment demands personal trust be violated. It also is fundamentally flawed, in that if the researchers already know the most common means of soliciting internet users passwords, they should already know the basics on how to defend themselves against such attacks, namely admins informing users to "never give away your password to anyone, for ANY REASON" this is also a potential PR disaster for the research group considering it's use, as it indicates that the are willing to compromise end-user's trust, and personal safety for statistics of morally dubious necessity. There may also be legal consequences if the study is discovered, and a scandal ensues.</li>
<li>P2219: They should take every precaution for anonymity very seriously. </li>
<li>P2221: It is harmless and unfortunately, in a case such as this, the participant cannot know the truth until the end. This differs however from the first experiment I read, where it seemed their privacy was indeed violated as part of the experiment.</li>
<li>P2226: Even if anonymized and aggregated, the results may still be harmful to the survey participants.</li>
<li>P2227: For the reasons I stated above, even science must take a back seat to individual liberty. </li>
<li>P2231: They have consent and are not holding on to passwords.</li>
<li>P2233: As long as no information is stored.</li>
<li>P2237: Take steps to ensure participants are aware.</li>
<li>P2238: As above.</li>
<li>P2244: We need to understand this process and develop changes to increase the security of consumers information.  People are conducting interactions world wide this is a large scale problem that needs to be addressed.  The internet is not going to go away but changes need to be made as it continues to grow and become an even greater hunting ground for thieves. </li>
<li>P2245: In this day and age people should already be aware of the dangers that the internet poses. It's not like we live in the beginning of the internet stages. </li>
<li>P2253: It is harmless.</li>
<li>P2254: hacking of people's password is a real issue and needs to be addressed</li>
<li>P2260: Somehow code the passwords so the researchers dont know them. </li>
<li>P2261: This is something that especially makes people angry. </li>
<li>P2264: M ore than likely their research will be skewed because a savvy turker will see this hit for what it is and simply not do it or return it, in either case they wont get their data.  The people that do fall for it might only be doing iut because they would not expect a hit to try to collect their data.</li>
<li>P2273: I do not think  MTurk could   say they could not post it. It  could be on the up and up.  I  personally would not do it.</li>
<li>P2275: seems like a good cause</li>
<li>P2276: Only if the research team was carefully monitored themselves as I bet many wouldn't even change their passwords after this study.</li>
<li>P2280: It seems like a frivolous exercise.The problem is a serious one, efforts could be conducted to eliminate it entirely</li>
<li>P2281: I think researchers would be using a participants time and efforts without their consent.</li>
<li>P2284: They are helping people.</li>
<li>P2285: I think this is a good idea if security measures are generated because of it</li>
<li>P2286: There are too many ways this set-up could be abused in the form of a large scale scam. </li>
<li>P2289: This really is a good experiment to learn how to stop password stealing.</li>
<li>P2296: Not as currently described.</li>
<li>P2301: I think this experiment is useless and wouldn't prove anything</li>
<li>P2302: This study has important results and the participants are later informed about the study.</li>
<li>P2305: I believe they should be able, but that their studies should be overseen by an independent body, and there should be checks to ensure that private passwords are not being collected.</li>
<li>P2306: This research is not important. It has been done before by many academic researchers. Why reinvent the wheel.</li>
<li>P2307: This could easily be used for malign reasons, so caution is needed to continue on with the experiment.</li>
<li>P2308: It's important to know this information and learn from these types of studies. </li>
<li>P2309: No, for the reason stated above. I also think that if I were to find out I was included in such a study after the fact, I would be unwilling to participate in further HITs in the future for fear that I was unknowingly being included in a study that was capturing my information without my consent.</li>
<li>P2314: I think there could be a slight concern for security risks.</li>
<li>P2316: Yes, so they could invent a web extension, or add-on to stop that from happening.</li>
<li>P2321: I believe there is a better way to find results for a question such as this one. Many people have been in the situation and would probably be willing to just tell you about their experience. </li>
<li>P2323: It is important to know how people fall victim to prevent such an occurrence.</li>
<li>P2324: You would have to totally guarantee that no information was stolen by the researchers and I for one would feel uneasy not knowing if they actually stored the passwords or not (regardless of what they said)</li>
<li>P2325: Should always err on the side of caution.</li>
<li>P2326: It may be a little embarrassing for the persons who are tricked but because there is no actual theft of passwords and the participants are made aware of the fact, there is no problem and the researchers should proceed.</li>
<li>P2328: Ideally people should at least be told such a thing might happen.  Tell them a month before hand, that it will start eventually.  In that amount of time, they will relax their guard.  At least this way they were warned.</li>
<li>P2329: does not store passwords- minimally invasive</li>
<li>P2337: because it would be a violation</li>
<li>P2339: This may be shaky ground and get flagged for phishing.</li>
<li>P2340: I think the participants should be informed of what is going on.</li>
<li>P2348: It depends on how it would affect the situation</li>
<li>P2349: if it improves password security I don't see why not. </li>
<li>P2350: I think it is a good experiment and could prove to be very helpful to prevent hackers from stealing peoples' passwords.</li>
<li>P2354: This information can be obtained "after the fact" by people who were actually hacked.</li>
<li>P2357: Make sure there's no way any of those passwords could be stolen from the researchers</li>
<li>P2361: 0</li>
<li>P2368: I'm not sure the experiment would yield accurate results. How would they account for people who exit the questionnaire when they suspect it's a trick? Or if they have to complete it, how will they successfully get to the end of the survey without falling into the trick?</li>
<li>P2369: The study would provide valuable data that can be analyzed</li>
<li>P2370: for scientific purposes this should be allowed. if someone doesnt want to open it then they dont have to.</li>
<li>P2372: They should develop proactive ways of avoiding the problem.  </li>
<li>P2378: If the passwords aren't being collected or stored, then I see no risk.</li>
<li>P2382: There needs to be specific handles in place that mitigate the chance of anonymity being compromised. </li>
<li>P2386: I believe this experiment would help people with awareness about online theft.</li>
<li>P2392: They may think the HIT is a scam and return it, thus maybe ruining their hit score. Run the study if there is an option to complete it without entering your password, and there seems to have to be to even do it, so I guess it's not a problem.</li>
<li>P2396: It seems like the sort of thing that could go wrong easily. I would only be in favor if this was heavily monitored.</li>
<li>P2397: Absolutely, I don't see any real reasons why this experiment shouldn't happen. </li>
<li>P2403: yes, but only after being verified as true researchers by a third party </li>
<li>P2409: It does not seem like much could go wrong with this (unlike in the spam study). But I would still be nervous about the password being intercepted.</li>
<li>P2432: Yes, they should continue it and make sure that no one's information is not stolen from this study.</li>
<li>P2433: There may be some one or some people who will always find something to blame the researchers for.</li>
<li>P2435: I think it's a great idea but we always have to be careful when doing anything like this so that the hackers do not get this information. </li>
<li>P2445: Yes, but the researchers should do everything they can to make sure the data they collect is as secure as possible.</li>
<li>P2450:  So they might learn something then teach others how to avoid them</li>
<li>P2451: The value of the research</li>
<li>P2452: Taking people's personal information, even for the good of doing research, is still wrong.  The experiment would have to be carefully conducted so people do not feel violated and deceived.</li>
<li>P2456: Because all it takes is for one bad person on the team to steal all that info for profit.</li>
<li>P2457: violates privacy</li>
<li>P2463: I think the participant should be notified and make the attacks random from a few days to months when not expecting it. </li>
<li>P2466: Same reason as #1.</li>
<li>P2475: It would be helpful information and wouldn't hurt anyone at all</li>
<li>P2478: This study might help understand what people think when they are being tricked. </li>
<li>P2480: Password theft is rampant and it needs to be stopped. This sounds like it could help. </li>
<li>P2483: I feel as though this type of research could provide a better standard for individuals to guard against illegal practices of obtaining information.</li>
<li>P2488: Again, the whole password issue makes me nervous.  Despite the reassurances, I would still be afraid that my/another's password(s) were being stolen.</li>
<li>P2491: so people may react poorly to being the target of fake phishing scams.</li>
<li>P2494: I think that this research could help develop internet security protocols and make all of our information safer. </li>
<li>P2495: this is an important aspect of daily life there will always be someone trying to get someones information it is up to us to make it harder for them</li>
<li>P2496: Just be careful to not steal peoples information. </li>
<li>P2501: I see no risks to this study so I feel the experiment should proceed.</li>
<li>P2511: If they really wanted too, I guess they could. They would be hard pressed to find people who would be willing to do that.</li>
<li>P2516: Deception should not be the central focus of any study</li>
<li>P2518: The data is useful, keeping the real purpose of the study a secret is necessary to the integrity of the data. </li>
<li>P2522: I think that there is a lot of information that researchers could learn from such an experiment so they should be allowed to do such a study.</li>
<li>P2530: Just like with the phishing thing, I cannot condone hacking. Criminal hackers think their actions are as just as these researchers you're talking about. It's all a scam.</li>
<li>P2532: Since they aren't actually pulling passwords, the experiment seems trustworthy.</li>
<li>P2539: I think there are better ways to study this issue. I don't like that private information would be compromised.</li>
<li>P2542: See previous answer. This could lead to a reduction in identity theft.</li>
<li>P2543: Spreading the message about hacker tactics should be enough. There is little to gain by knowing how people react.</li>
<li>P2545: If one of the researchers decided that they wanted to use the passwords obtained for their own personal gain they have the power to do it. Not to mention, important information has been taken from these people without their knowledge.</li>
<li>P2546: Passwords can be a sensitive issue, but the way it is described seems good. you might find some way to prove passwords were not stolen</li>
<li>P2547: Because they are not actually stealing the password, just asking what techniques are used. </li>
<li>P2549: Make sure whoever is conducting the experiment properly disposes of the passwords afterwards.</li>
<li>P2550: Again, this information should be kept safe</li>
<li>P2555: hard to judge without knowing the actual methods that will be used</li>
<li>P2556: to inform us</li>
<li>P2561: There is no harm done to the participants.</li>
<li>P2563: I don't like experiments where the subject is unaware & has not given consent to be a participant in such an experiment, but I think the outcome outweighs the risk.</li>
<li>P2565: It may help someone to not be taken advantage of in the future</li>
<li>P2571: If they have a lot of time on their hands</li>
<li>P2572: I think that it is good to research things</li>
<li>P2574: The true purpose of the study gets revealed in the end. </li>
<li>P2575: This is far too intrusive particularly with heightened awareness of identity theft.</li>
<li>P2576: As stated above, as long as it is a reputable company. </li>
<li>P2578: The experiment could produce useful security data</li>
<li>P2579: We need to know how to recognize these attacks and prevent it</li>
<li>P2581: I think its important to know how people fall for attacks, that way we can prevent it in the future. </li>
<li>P2584: They just need to make sure to prove to people that no information was compromised.</li>
<li>P2586: The expirment setup could be a double-edged sword of sorts. On one hand, the findings would help thwart some hack attempts and other security concerns. But on the other hand, clever hackers could copy the process and steal actual passwords under the guise of an experiment.</li>
<li>P2588: Somebody might blame the NSA</li>
<li>P2589: Yes, as long as no harm is done</li>
<li>P2590: Same reason as above. I would want more information first. This doesn't really describe how they will act like criminal hackers and know if they are successful if no information is collected or stored.</li>
<li>P2595: I think it would be really helpful.</li>
<li>P2599: It will raise hacker awareness & make people realize it's a real threat.</li>
<li>P2605: Yes. The benefits from this study would be very useful in the field of security</li>
<li>P2610: It's invasive, unfair, and just reeks of skullduggery</li>
<li>P2612: Again... no real passwords should be sought.  If someone is given a password in a single location that they are told ... as with all passwords... that they must protect, than and only then do I feel this is alright. </li>
<li>P2613: Thinking about it, you never know who is trustworthy and who isn't. The experiment may come from a great complany, doesn't mean there isn't a bad apple working for them.</li>
<li>P2618: Stealing passwords is always a bad idea. They're supposed to be private for a reason.</li>
<li>P2619: I think the research is needed. However I have reservations about people revealing true passwords. Although the researchers may not use/steal this info, there could be other security issues involved. </li>
<li>P2623: I feel this would be a good way for people to understand the risk of password theft</li>
<li>P2626: Researchers need to make sure that the person taking the study is well informed of the situation that their passwords would not be stolen.</li>
<li>P2628: If people want to do it and it cause no harm why not.</li>
<li>P2638: Useful. </li>
<li>P2669: passwords are private information.  Period</li>
<li>P2674: Would want participants to believe was done by researchers </li>
<li>P2676: It's a good thing to test it out so we can learn how to prevent it but we need to make sure that people are employed that are trustworthy and have good intentions.</li>
<li>P2678: Tricking people like this is really shady and will probably get you in trouble really fast.</li>
<li>P2682: It sounds reasonable but must be handled well.</li>
<li>P2685: It will help us learn more about security.</li>
<li>P2686: The experiment is certainly valuable but the lack of consent is a huge sticking point.</li>
<li>P2689: Again, I think it's harmless.  But I think participants should be debriefed with the details of the experiment after it's over.</li>
<li>P2690: that way we will know how many people fall prey to hackers.</li>
<li>P2692: Hacking for science--no way</li>
<li>P2699: The participants should be instructed to change their passwords immediately. </li>
<li>P2713: The researchers need another way to get their data.</li>
<li>P2715: You have to be really careful about collecting people's passwords. Some people use the same password for everything. Also, some people won't appreciate being deceived this way.</li>
<li>P2717: I believe the research would be helpful, but is somewhat intrusive. </li>
<li>P2723: they are just trying to see if people will fall for tricks but with no harm involved</li>
<li>P2727: I've done HITs where I've been manipulated or the true purpose of the HIT was not revealed until later.  I feel okay with this because I'm getting paid, eventually disclosure does happen, and I'm voluntarily doing these HITs.</li>
<li>P2729: While I don't like the idea of someone being tricked into giving up their password, I suppose it wouldn't cause too much harm if the passwords were not collected or stored.</li>
<li>P2732: People may not find it correct to trick other people. </li>
<li>P2735: The disclosure makes this experiment easy to accept and no storage of the actual passwords or personnel information is assuring. I wish the researchers would ask for consent first but I understand why this might not be desirable. </li>
<li>P2736: You have to be careful because you could upset people and there really is no proof except your word that you didn't keep their passwords. </li>
<li>P2740: In the chance that the passwords were mistakenly kept and leaked you could have a major issue.</li>
<li>P2747: messing with passwords can put people at risk </li>
<li>P2771: They should have to be open about their methods of not storing the passwords and make sure the participants are given good info on how to avoid such schemes. </li>
<li>P2777: I don't see why not.</li>
<li>P2781: This experiment could lead to a rise in hacking activities.</li>
<li>P2786: I feel there's some room for something to go wrong.</li>
<li>P2787: Participants should be encouraged to change their passwords following the experiment anyway</li>
<li>P2792: I think the research is useful and it would provide interesting information as well as lead to better education about protecting passwords.</li>
<li>P2793: There has to be other ways for this type of research to be done, rather than having real people hack into real people's accounts.</li>
<li>P2794: I think they should, but they should do it cautiously because they are dealing with the persons personal information.</li>
<li>P2795: Maybe should give users a choice to exclude their hit at the end of the survey.</li>
<li>P2797: i think they should find a different way to do it</li>
<li>P2800: Why not, they're not keeping any information.</li>
<li>P2802: Anytime you are trying to trick someone you run a risk of upsetting someone.</li>
<li>P2807: The results would be somewhat unreliable since Mech Turk and the HIT's on its website are thought to be reliable, and therefore, Turkers will consider the HIT credible and there will be less usable data.</li>
<li>P2813: This may be a good thing to study but I wouldn't want any of my friends doing it or taking the risk.</li>
<li>P2818: Could provent future security problems</li>
<li>P2820: Yes, it's okay for the researchers to go ahead with the experiment because the outcome could be beneficial to the population at large in helping to reduce fraud in future. </li>
<li>P2823: I think that it is important for people to know the techniques used by hackers to steal their passwords. But at the same time, the researchers shouldn't go as far as actually having the participants type in their actual password.</li>
<li>P2827: This would help reduce the amount of hacked accounts greatly.</li>
<li>P2828: As we all know the biggest security threat lies between the keyboard and the chair, any thing that will lessen this should be tried.</li>
<li>P2829: The more people are educated about the methods of hackers to steal from people the better.</li>
<li>P2830: It is a beneficial study. Hackers stealing passwords is a a threat to everyone, that can cause financial hardship, stealing personnel information and sometimes destroying someones life. </li>
<li>P2834: Unless there are some pre and post safe guards that are in place, it seems awful risky.</li>
<li>P2837: Must obtain informed consent for any psychology study.</li>
<li>P2838: Informing users of the tricks would be better than the experiment. </li>
<li>P2841: As long as they carefully do this it should be okay.</li>
<li>P2844: Yes they should do all they can to make the internet safer </li>
<li>P2848: This could be used by malicious researchers.</li>
<li>P2850: This could be a very helpful data set to have. Often people do not know when they are at risk or when they should not trust the websites they are on. Instead they simply follow directions blindly without thinking. Knowledge of these techniques, and which ones are most effective, will help people be more aware in the future.</li>
<li>P2853: There does not seem to be any risks with confidentiality or invasion of privacy.</li>
<li>P2856: See above. use the information to eliminate password stealers</li>
<li>P2857: This one sounds a bit iffy. And there will be some who wont accept that no pw data was stored and/or used, which could cause problems for the researcher. </li>
<li>P2861: IT COULD HELP A LOT OF PEOPLE IN THE LONGRUN </li>
<li>P2872: If some one in the research team misuses the password, the effects could be disastrous.</li>
<li>P2874: This would teach people to be more cautious with their passwords.</li>
<li>P2875: Just because they say they won't steal passwords doesn't mean they won't.</li>
<li>P2879: Participants will not be identified and will remain anonymous? I don't believe it.</li>
<li>P2880: I especially like that they will inform the participants after the study the true intent.</li>
<li>P2882: Because of the deception involved.</li>
<li>P2886: Again I think that as long as it's a hit and the user already agreed to some form of study then go ahead and do it!</li>
<li>P2888: n/a</li>
<li>P2892: i dont know how i feel about them keeping it secret till the end but i know it would be necessary they would need to set up securities</li>
<li>P2893: No actual passwords are being taken, so I don't think there are any risks.</li>
<li>P2896: There is no reason why they cant help people not be victims anymore. </li>
<li>P2905: think EDUCATION...not infringing on rights of the individual (for a good reason, of course...one person's good reason is another person's catastrophe!)</li>
<li>P2916: It would be interesting to see how likely people are to fall for these tricks.</li>
<li>P2920: It should be very clear that there is no hacking or stealing of personal information involved.</li>
<li>P2924: people's security has to be the most important thing</li>
<li>P2929: Many people that I know would be very upset they were deceived.  This deception and the fact it would be so easy to get information from them would likely have a very negative effect on them and their internet behavior.  They would probably not adopt more secure habits and learn to properly protect their system, they would more than likely cut down what they do online thus limiting their experience with properly using the internet.</li>
<li>P2933: They would have to have a very high level of supervision. A single researcher could decide to store the user's data. There are too many potential risks that rely on every single researcher not committing theft. </li>
<li>P2934:  Ever seen "To Catch a Thief"? It was a show that simulated fake break-ins on an unsuspecting family while they were gone from their house. You can bet they really amped up security after it happened. Perhaps that could help in this situation too.</li>
<li>P2939: Again,I think that one's privacy is being compromised.Almost breaking the law, research or not.</li>
<li>P2941: Experiments like this can get out of hand if real hackers somehow manage to get in.</li>
<li>P2944: Make sure that it is absolutely known that the passwords were not stored, otherwise it could cause a problem.</li>
<li>P2945: I do think this sort of research needs to be done but it needs to be handled in a very secure and highly monitored way to make sure hackers do not gain access via the research itself.</li>
<li>P2946: I think some people will feel violated.</li>
<li>P2955: Yes, assuming the research is worthwhile and stands a good chance of providing information leading to improved security, and is undertaken in a cautious manner.</li>
<li>P2956: To help people learn how to stay protected from password theft.</li>
<li>P2959: Find another performance measure besides passwords.</li>
<li>P2964: No you don't have a pass word to give it away</li>
<li>P2966: They should be allowed but in a way that makes people know they arent stealing passwords</li>
<li>P2972: every step of the method should be mindful of no harm and it would be interesting to know where the sample and what group is being sought. </li>
<li>P2979: Seems like they are taking care of their data</li>
<li>P2984: There needs to be accountability to be sure that the researchers do not really steal passwords.</li>
<li>P3003: As long as no passwords were stored and/or needed to be changed, I think this experiment could really be of use.</li>
<li>P3009: Due to sensitive nature of personal data it may cause a very (-) reaction among some participants after being told of the truth of the experiment.</li>
<li>P3013: Yes so that they could find out more about hackers and their techniques used.</li>
<li>P3016: yes, but with caution</li>
<li>P3019: Care must be taken that they really do discard passwords and other info.</li>
<li>P3024: Researchers need to take care to protect the information.</li>
<li>P3028: so that they can educate people and computer users alike how to manage their password properly.</li>
<li>P3034: During the course of this experiment they will naturally see passwords, so they must be monitored and the participants must change their passwords afterwards.</li>
<li>P3036: No trust here. Someone could go rogue</li>
<li>P3039: It could just be scam.</li>
<li>P3043: See above-I also feel like there are statistics from people who have actually had this happen to them that would be able to help.</li>
<li>P3044: Although the passwords are not going to be stored, I would worry about someone getting in to the researchers system.</li>
<li>P3045: Yes, plus they can make public aware of tactics hackers use to get peoples information.</li>
<li>P3046: yes , it would help with computer security.</li>
<li>P3047: To teach those how not to become victims.  </li>
<li>P3061: I think this seems safe and fine. They are not actually allowing other hackers to steal the passwords; the researchers are just using the hackers means to steal them and would present the data to the participants of the conditions. It could help them learn more on how to keep safer passwords.</li>
<li>P3063: Computer security is extremely important in this day and age.</li>
<li>P3064: I think researchers should include asking participants to change their current passwords when they get home, or make them more secure.</li>
<li>P3065: Why do they care?  This is ridiculous.</li>
<li>P3066: so they can help prevent idiots from giving up their passwords</li>
<li>P3068: It is a wise decision</li>
<li>P3077: risk is low</li>
<li>P3079: They should as long as they stand by their stringent guidelines. </li>
<li>P3081: The research should be done so long as any and all password information is immediately destroyed and everyone on the team is vetted.</li>
<li>P3082: I believe that it is good that the participants will be told that what they have done is actually the ways in which their passwords can be stolen, so it will provide a direct benefit for them.</li>
<li>P3084: Sure,I think the study is worthwhile.</li>
<li>P3086: See above.</li>
<li>P3092: It may lead some to be paranoid about HITS after the study concludes.</li>
<li>P3094: While the researchers are not collecting the information they could be hacked themselves or spied upon by a third party that would collect the passwords.</li>
<li>P3095: This research will help prevent future password theft.</li>
<li>P3096: I don't think anyone should be allowed to collect people's passwords for any purpose.</li>
<li>P3099: dissemination risk</li>
<li>P3103: There are ethical issues with this. It involves violation of privacy, as well as possibly illegal activity on the part of the researchers.</li>
<li>P3105: As long as it is legal</li>
<li>P3110: It is a HIT which means the individual can choose to participate and it is to discover helpful data.</li>
<li>P3117: I think it is worthwhile; however, there has to be some safeguards in place so that the researchers involved don't succumb to temptation and steal passwords.</li>
<li>P3121: The study seems unnecessary.  Just publish the tricks you would use instead of duping people and freaking them out.</li>
<li>P3124: As long as they use the data for that purpose. </li>
<li>P3125: Seems unethical.</li>
<li>P3130: Such deception, while potentially understandable, is still deception.</li>
<li>P3132: People get very sensitive when it comes to information like this.  I think as long as they assure the person none of their passwords were actually saved and that they actually helped this person from someone would could of done this with harm, then I think they would be okay with it.</li>
<li>P3136: While the experiment may be helpful to help prevent such attacks I think it would make the participants more nervous online</li>
<li>P3139: Due to the deception</li>
<li>P3145: I think if the candidate was well informed it would be ok.</li>
<li>P3148: There are so many hackers out there we need to teach the novice and beginners as well as the experts more than basic fundamentals and how to defend themselves.</li>
<li>P3152: Prompt disclosure of the deception is extremely important.</li>
<li>P3159: They could learn valuable information.</li>
<li>P3161: It would really benefit society as a whole by raising awareness of hacking.</li>
<li>P3166: I say with caution because it is still a thin line for a person to have to deal with. It would be good to have them prepared in some way.</li>
<li>P3168: Again, I don't like the idea of someone having a password-regardless of their stated purposes. </li>
<li>P3170: Hacking is getting out of hand.</li>
<li>P3177: Same reason as above, there is nothing wrong with what they're doing.</li>
<li>P3183: it is a good way to teach people the dangers of these scams.</li>
<li>P3185: As long as they live up to their promise, then the researchers are not doing anything wrong.</li>
<li>P3186: This experiment would be beneficial in showing how many people are victims of hackers. I think this would open peoples' eyes, showing them just how often it happens, and hopefully raise awareness.</li>
<li>P3202: I don't believe it is a secure system to allow strangers to enter personal information.  I am sure there is a certain amount of possibility that even the AMTURK site could be hacked and information stolen.</li>
<li>P3207: It's necessary information needed</li>
<li>P3208: The researchers may be able to help inform the public in the future about password theft, which will help society. Thus they should be able to proceed.</li>
<li>P3209: They can not overstep their bounds</li>
<li>P3217: I would prefer if they collected hypothetical passwords (passwords developed specially for the study) rather than their own true passwords.  It would seem to risky otherwise.</li>
<li>P3223: I feel it may be needed but i don't like the lying </li>
<li>P3228: Of course if everything is done with the law and Amazon TOS in mind.</li>
<li>P3236: those passwords entered may be passwords used for bank account etc.  how is this information going to be protected going forward?  are the participants going to be advised to change these passwords?</li>
<li>P3240: We all should be aware of ways and how hackers get our passwords. If this research is not harming the person or the computer performing the HIT please do it.</li>
<li>P3243: Anything to improve the security savvy of users is good</li>
<li>P3245: Just as long as no actual passwords or personal information is recorded. </li>
<li>P3246: again, this is a matter of personal invasion. people tend to only have a few passwords they use constantly</li>
<li>P3247: No messing with passwords</li>
<li>P3258: After the experiment is over, the subject may have trouble believing that this was only an experiment.</li>
<li>P3259: while fraudulent activities are a high possibility its wise to use caution while performing a study, it could ultimately lead to lawsuits.</li>
<li>P3260: Assuming the participants winningly participate, this study seems harmless.</li>
<li>P3274: it does not matter</li>
<li>P3275: I see no harm in this experiment. </li>
<li>P3276: Ensure that all information is kept completely private</li>
<li>P3289: I don't agree with publishing all of the details of the scenario. Criminals learn from criminals and if they learn of a new tactic to use that they didn't know of before, they've just helped that criminal potentially target more victims.</li>
<li>P3301: This is another experiment that would aid in the research of cyber security. Password hacking is a huge issue that can cause massive problems for families.</li>
<li>P3311: This is deceiving, but not in a way that violates the persons trust in my opinion.</li>
<li>P3314: This experiment could educate a lot of people</li>
<li>P3316: The results of this experiment are very important and the study should proceed. No damage is done to the participants.</li>
<li>P3319: The same fear of important passwords getting out is inherent in this study.</li>
<li>P3320: It is a slippery slope, and I would want there to be absolutely no chance of any of the researchers being tempted to use that information later. </li>
<li>P3325: Some may think they the researchers are a scam to get people's information and this may ruin their reputation.</li>
<li>P3326: if done reasonably, ok</li>
<li>P3333: I don't think that one can predict how much damage this experiment might do to the subjects.</li>
<li>P3338: This is a huge threat to online security, and a lot of people do not realize all the risks they take with their information. This would really help the issue.</li>
<li>P3340: Again, a valuable lesson.</li>
<li>P3341: No risks, good benefits to society by knowing this security info</li>
<li>P3343: It would be very beneficial for people to be aware of how vulnerable they really are.</li>
<li>P3346: This is a good topic for research but it needs to be done carefully to protect the victims.</li>
<li>P3347: Yes, in order to help educate the common folk. However, as long as passwords/information aren't recorded I see no harm.</li>
<li>P3354: It's OK as long as passwords are not really shared.</li>
<li>P3359: I don't want to be hacked.</li>
<li>P3360: knowing what fraction is not necessary.  the plan will generate a deceptive and complex work which is not needed, except to pay the salaries of those making it up</li>
<li>P3373: I feel that this experiment is doing important work.</li>
<li>P3378: There's not logical reason to stop them.</li>
<li>P3379: Since people would be sharing personal information they may feel extremely violated after finding out it was an experiment.  Precautions would need to be taken so that this is not a negative experience for participants.</li>
<li>P3389: They aren't harming anyone. </li>
<li>P3391: The researcher is not doing anything illegal</li>
<li>P3393: Without research like this we will continue to give hackers the advantage over us, but if universities continue to do research like this we will be able to not only better protect ourselves from such attacks, but also help internet security companies and businesses to implement things that will help prevent it before it occurs.</li>
<li>P3397: provides knowledge</li>
<li>P3403: Yes, you will debrief the participants which is good and it seems like it would provide interesting results</li>
<li>P3408: N/A.</li>
<li>P3413: Because then they will be able to produce or publish recommendations that help users better learn to recognize such attacks.</li>
<li>P3416: The experiment must be conducted with 100% security.</li>
<li>P3426: Yes, there are no real risks and participants might gain knowledge about protecting themselves in the future.</li>
<li>P3427: The more knowledge we can gain on criminal hackers, the better. The participants also are educated by knowing what has occurred and how.</li>
<li>P3428: See above, this is too dangerous.</li>
<li>P3431: It seems like it might be beneficial and anyone with MTurk experience shouldn't be surprised.</li>
<li>P3434: They may continue, but have to be wary of people who may be upset after the experiment.</li>
<li>P3438: It seems relatively harmless.</li>
<li>P3440: It could be harmful to have other people personal data.</li>
<li>P3442: It's probably a harmless experiment but I feel like you could piss a lot of people off by tricking them into divulging their passwords in that way, even if their passwords are not actually stored.</li>
<li>P3445: As long as the passwords are not stored, there is no risk to the participants.</li>
<li>P3447: This is actually a very important thing that should be studied in my opinion.</li>
<li>P3453: Some people may not have an issue with this.</li>
<li>P3456: As long as it goes through the IRB process and participants are not harmed or identified it should go forward.</li>
<li>P3460: TO HELP WITH THIS FRAUD</li>
<li>P3462: Researches are gaining personal information through dishonest means, which seems like legal territory and does expose vulnerable information</li>
<li>P3463: People who already know it would (hypothetically) steal their information would close out of it, and people who didn't know would be informed after they do so.</li>
<li>P3464: I believe it is a valid experiment to curb theft on the internet.</li>
<li>P3467: I think that is a bit mean and deceptive. You don't have to stoop to the bad guy's level to tell people to be cautious.</li>
<li>P3472: I would like to see how it turns out.</li>
<li>P3482: Turkers are volunteering to be lab rats, yes, but anything that tricks us into giving up information like passwords violates the mturk terms of service.  You can lie to us and trick us, and we're fine with that as long as the money is good, but only up to a point.  And this crosses it.</li>
<li>P3483: As long as they don't have access to the passwords I think it's okay.</li>
<li>P3487: I think that the results could be used to help people better protect themselves form this type of threat</li>
<li>P3491: I think there is no harm done in this experiment because no personal information is being obtained and the participants are briefed afterwards.</li>
<li>P3495: Seems like stealing to me, if I steal somebody's car and bring it right back I still stole it!</li>
<li>P3498: The research may later be exploited by malicious hackers who will use the information to their benefit.</li>
<li>P3503: Finding ways to increase internet security is good and telling people about such things would probably make them more cautious and telling them at the end would make it better however when taking peoples passwords I believe much caution should be taken. </li>
<li>P3508: This is probably illegal and violates privacy.</li>
<li>P3510: Only if they are not really asking for passwords and personal information that could be used for identity theft etc.</li>
<li>P3516: This research is necessary.</li>
<li>P3518: This experiment could be harmful for users since they won't know what is going on</li>
<li>P3520: no because they will have access to passwords</li>
<li>P3523: it will help people in the long run</li>
<li>P3524: I think the research is a good idea, but they need to come up with an alternative way of going about it.</li>
<li>P3525: The experiment sounds benign so I think it should be allowed to proceed</li>
<li>P3532: I feel like this is beneficial for both researchers and participants as the participants learn to not engage in those behaviors again and the researchers get their data.</li>
<li>P3534: I see this as being a valid, safe study.</li>
<li>P3536: As long as the researchers are upfront and debrief them afterward, seems like a good experiment.</li></ul>	</div>
</div>

<div class='cap' style='max-width:30%;'>
	<div class='header closed'>SocialPhishing study, answers to Proceed question</div>
	<div class='body'>
<ul><li>P6: Yes they bring it up to them, but the researchers to get all that info on the students to trick them seems really intrusive without them knowing.</li>
<li>P11: it seems unnecessary</li>
<li>P12: I would support the experiment if the researchers were unable to see the passwords that were entered.</li>
<li>P15: I feel as if some aspects of this experiment are unethical or unsafe to participants.  </li>
<li>P16: It will benefit everyone as a learning experience.</li>
<li>P20: I'm not sure that tricking people into unwitting participation is ethical. Attempting to fool someone who is already agreeing to participate in a study is one thing but tricking people who do not know they are even participating is a bit too sneaky.</li>
<li>P27: I think this is a bad research project. In my opinion it is hacking.</li>
<li>P33: no, I think its invasion of privacy.</li>
<li>P43: They're compromising a person's identity. This could cause a lot of issues. </li>
<li>P45: University passwords are confidential as student information and should not be able to be shared with anyone other than IT in the event that a new password needs to be initiated.</li>
<li>P46: The researchers need to make sure the passwords are secure and not keep them on file after the experiment.</li>
<li>P52: It's interesting enough, and not at all harmful.</li>
<li>P54: I'm not sure if this experiment is ethical or not. I can't decide if they should be allowed to see students' passwords or not.</li>
<li>P55: It is one thing to send an email to see if people go to the fake site and enter their password. It is quite another to peruse all of their facebook profiles for the specific purpose of targeting them. That is mean and completely unethical.</li>
<li>P56: Phishing attacks are tricky to spot and can prey on people who are not careful. Researchers can use the information collected to help people learn more about phishing and detect it in the future.</li>
<li>P59: they should be allowed because they are doing research that will benefit people.</li>
<li>P61: see above</li>
<li>P65: As I said above, it's unethical and dangerous.</li>
<li>P69: I THINK THIS IS A GOOD IDEA</li>
<li>P77: The researchers must in my opinion find a way to obtain the consent of its participants prior to proceeding with this experiment.</li>
<li>P79: Should not bring unsuspecting friends into studies in my opinion.</li>
<li>P80: There would seem to need to be more safeguards in place with real passwords and no consent on the part of the individual.</li>
<li>P84: too invasive</li>
<li>P89: No because it will invade someones privacy and spam others u which I think is wrong.</li>
<li>P93: Researchers are looking up personal information about their participants without their consent.</li>
<li>P94: There ought to be a resolution.</li>
<li>P96: It is necessary to help protect users' information but I believe some users would feel violated and may direct their dissatisfaction at the university.</li>
<li>P97: The researchers shouldn't use the personal passwords to get into the student's facebooks. </li>
<li>P100: I don't believe it is fair to include someone in an experiment unless they volunteer as a subject. Not that they would have to know what the content of the study was, but their participation should at least be voluntary.</li>
<li>P101: Yes, I believe they should be allowed to proceed but with caution because a lot of information could potentially be taken and it could cause a lot of damage.</li>
<li>P106: Yes, for the same reasons above.</li>
<li>P117: No. Not unless they also get permission from the facebook friend who supposedly sent the phishing e-mail.  I have no other objections.</li>
<li>P119: If they fully explain things to the participants and use it as a warning tool</li>
<li>P122: I don't think the information obtained would be beneficial to anyone except people who would profit from it somehow.</li>
<li>P132: Yes, but with caution. Like I stated above, the party involved in the research should have to be accountable to someone, and have their work checked out. </li>
<li>P136: It seems fairly unethical.</li>
<li>P143: Too much exposure to highly sensitive data, with little concern expressed for security concerns of the study itself.</li>
<li>P145: This seems pointless and stupid. The results wouldn't amtter. </li>
<li>P149: People, students especially, need to be aware of these things and the harm they can do. </li>
<li>P152: It would help to be able to stop the attacks if the general consumer could learn about their nature through the universities experiment.</li>
<li>P155: There are so many ethical breaches here. So many.</li>
<li>P156: Violation of our privacy rights</li>
<li>P159: There are other ways to teach people how to protect themselves fro phishing or spoof attacks, without tricking them into divulging their passwords.</li>
<li>P166: It happens too often at my school. Some tips would be nice so people stop falling for it.</li>
<li>P167: Not sure because the students didn't agree to the study before it happened to them</li>
<li>P169: It seems that all parties are given reasonable information about the study, either before or after, permission is requested, participants can learn from their experiences, etc.</li>
<li>P171: Be cool but teach us better, safer ways. </li>
<li>P179: Involves using personal information deceptively. </li>
<li>P181: There is no need for this study. Obviously people would be more likely to fall prey to this if they thought it was from someone they trusted. </li>
<li>P183: Does not seem ethical. Too many opportunities for something to go wrong.</li>
<li>P184: The procedures for the handling and use of the passwords collected would need to be thoroughly examined beforehand, and checks and balances enforced to ensure the safety of the password information.</li>
<li>P185: I think it is a violation of privacy laws</li>
<li>P186: n/a</li>
<li>P188: I do not think the actions of this particular experiment justifies its conduct toward the participants.</li>
<li>P190: No consent can be given prior.</li>
<li>P194: need to be careful with sensitive info</li>
<li>P198: This is a breach of the subjects confidence and privacy.  There is also a potential breach of privacy if the school provides any confidential info.</li>
<li>P200: No.  Do not verify passwords.  If the study just counted how many actually tried, then no matter what they put in, they receive a thing to say this was research, then fine.  The actual verification makes this terrible.</li>
<li>P204: The passwords used will most likely be the students' real passwords, so the researchers should proceed with caution.</li>
<li>P211: still need to be respectful of peoples personal info</li>
<li>P215: Privacy issues</li>
<li>P218: yeah doesn't, have any harm</li>
<li>P220: I'm not sure why they need to validate passwords entered. Also examining someones facebook page is going too far. </li>
<li>P228: While this one seems to be similar to the previous experiment, I feel like it is an invasion of privacy to access a participant's personal facebook page and collect information. Also, testing the passwords to see if they are valid would indicate that the survey team intends on actually gaining access to participants' accounts.</li>
<li>P231: The student are only being sent to a university website, so I do see a problem here.</li>
<li>P232: Have to be careful with protecting data</li>
<li>P242: they need to securely store and destroy the passwords. </li>
<li>P248: I do not see any significance of this part of this study.</li>
<li>P253: I feel it is unsecure.</li>
<li>P254: This can lead to some privacy issues.</li>
<li>P256: Only because I believe the passwords will never actually be seen by the researchers.</li>
<li>P258: Same reasons as last study</li>
<li>P270: privacy  issue</li>
<li>P271: Intent is irrelevant. If "researchers" start robbing banks under the guise of "research", I foresee long prison sentences.</li>
<li>P272: Just make sure to be completely truthful in the end.</li>
<li>P275: As long as they secure the dataset, I see nothing wrong with this.</li>
<li>P282: They should be careful with the information they achieve.</li>
<li>P284: I think the people should agree to the experiment before it happens.</li>
<li>P286: Most research experiments are done on a voluntary basis. By having this experiment set up so that the participants are initially unaware of the experiment, while crucial to the setup, is a violation of their rights.</li>
<li>P291: Phishing is a serious problem. Better for a person to find out how serious through a controlled experiment.</li>
<li>P297: Again being careful of any anxiety it can cause.</li>
<li>P302: password privacy</li>
<li>P303: The use of real passwords proves tricky; while information gathered can be made anonymous, the participants would need to be informed to change their passwords.</li>
<li>P308: I don't see any problems with this test and it is indeed a good way to test phising</li>
<li>P309: In this scenario, the experiment will only help individuals and will not cause real harm.</li>
<li>P313: At least in this one they are being informed afterward, but it would still be ideal to inform students beforehand that a study is occurring.</li>
<li>P314: nice teaching lesson about the dangers of trusting on the internet. </li>
<li>P317: Yes proceed, but do not steal information.  Just mislead to educate people on how unsafe they are.</li>
<li>P323: Yes</li>
<li>P326: I am not sure if there is not another way to find this information out. </li>
<li>P327: this is terrible and can hurt someone and feel violated </li>
<li>P334: I'm not personally aware if studies like this are legal,  The researchers should consult lawyers on the legal aspects of this.</li>
<li>P340: There is very little risk to my friend, and they can help with research.</li>
<li>P344: n/a</li>
<li>P347: I feel the chance of improper use of passwords is too great</li>
<li>P350: If nothing else this could be a good lesson for people to learn how to tell when a website is safe or not.</li>
<li>P354: This is becoming grey area</li>
<li>P369: With univercities permission and security. </li>
<li>P370: Should help reduce the amount of phishing that goes on daily.</li>
<li>P371: I am on the fence about this one.  I think it is because they will be getting the friend info by looking up facebook (social media) sites.  I'm not sure how I feel about this.</li>
<li>P386: Its a terrible trick/experiment to play on people</li>
<li>P391: Other people who have not consented to the study are being involved.</li>
<li>P402: This experiment will make people aware of the dangers of phishing. It may even help people from preventing future cases of phishing.</li>
<li>P403: Researchers shouldn't be going through university information stores to look at student's passwords</li>
<li>P406: Privacy invasion and using non-consenting friends as pawns....not ethical.</li>
<li>P409: There is too much room for something to go wrong and not enough benefit to the users.</li>
<li>P412: Yes, as long as they are reputable, secure, and promise not to disclose personally identifying information, including the passwords.</li>
<li>P415: seems like important information can be gained</li>
<li>P417: No, I think there's ways to recreate these conditions in a survey without resorting to consent-free guerrilla research</li>
<li>P418: Only in a contained experiment. With some information released beforehand.</li>
<li>P419: People would not want to give out their passwords unknowingly, even if it is an experiment.</li>
<li>P422: Phishing scams are serious and very common. I think any study that help users avoid falling victim to these scams is a good thing. </li>
<li>P423: How does the researcher guarantee account information to be secure?</li>
<li>P424: Ensure that no data gets beyond their control</li>
<li>P425: sure, to help ward off attacks, I'm all for it.</li>
<li>P427: I think they could do this with a small sample size.</li>
<li>P428: If they just record that a password was entered and not what the password was</li>
<li>P429: Yes, it should be ok</li>
<li>P437: There going through your bank account.</li>
<li>P439: Yes, with caution, because users are very susceptible to quickly clicking on links in emails from what appears to be trusted sources.</li>
<li>P444: The results could make user aware of being cautious</li>
<li>P446: phishing should be stopped</li>
<li>P447: I think that in order to do this, they would have access to too much information.</li>
<li>P449: I would say with caution, but it would probably go against the experiment to inform the involved about the details</li>
<li>P450: I don't think its a good idea to "expose" the passwords of all the students especially since the researchers are not encrypting the passwords back,  so if something goes wrong, the passwords could fall in the wrong hands. </li>
<li>P451: The students password is being recorded and the validity tested without their knowledge; a lot of personal information could be accessible through a student's university login. I would be upset if my password was recorded by a researcher and the university agreed to confirm the validity of the password without my consent. I understand that my consent could change the results, but that's a sensitive account in my opinion.</li>
<li>P453: becaue no one is identify in the paper</li>
<li>P454: No passwords should be stored. No one should have knowledge of the passwords. </li>
<li>P458: Identify reasons why people are so willing and fix it</li>
<li>P462: A review board should be in place to ensure ethical standards are met.</li>
<li>P463: Same as above</li>
<li>P464: This is an important study and will help people to be more careful with divulging their passwords.</li>
<li>P467: Seems like this needs to be studied.</li>
<li>P470: The researchers should be allowed to proceed with caution because the research is needed but the opportunity for a dishonest researcher stealing there password is there.</li>
<li>P472: It could be harmful to a person's real relationships</li>
<li>P473: With caution and the right intention it can be done. </li>
<li>P475: Stop the phishers too.</li>
<li>P476: the outcome of the experiment would be valuable information for the public</li>
<li>P479: The benefits outweigh the risks involved.</li>
<li>P480: I think the more we know the better we are</li>
<li>P485: It raises awareness. nothing illegal.</li>
<li>P486: The reach into a  person's personal life without consent it too much.</li>
<li>P491: If phishing site which collects passwords is not accessible by researchers or any person not affiliated with the university resources requiring this password, proceed. Anonymity is moot point once password has been compromised.   </li>
<li>P496: They will have access to the student's actual real passwords to use the University systems. How will these passwords be safeguarded?</li>
<li>P498: I think it would do good</li>
<li>P502: Based on what I read above, the experiment seems unethical, and I don't feel it would contribute anything meaningful to scientific research.</li>
<li>P505: It does seem a bit sketchy. I am not sure how I feel about the deceit. </li>
<li>P513: Its never good to trick people into giving out their information. </li>
<li>P517: It is educational to teach students safety online. What better place to learn than a school.</li>
<li>P519: Again, it seems to be for a good cause. </li>
<li>P531: I understand the need to study phishing in order to curb it, but at the same time think there might be a better way to do so.</li>
<li>P532: This study doesn't seem to serve a useful purpose. Banks aren't friends, and shouldn't be confused as such. Completing this experiment wouldn't yield accurate results in phishing protection, since people are far more likely to trust an e-mail from a friend than they are from a business. If everyone falls for it, it skews the results. There's also the problem that the best solution to this, which is calling up your friend to ask them about it, wouldn't work normally.</li>
<li>P535: Too much potential for a data breach with this one.</li>
<li>P538: they could help a lot of students but they could potentially face backlash as far as ethics are concerned</li>
<li>P539: I think this one is really unethical, especailly when "friend impersonation" is involved.</li>
<li>P541: There are other ways.  This is breaking the law for research and I don't condone that.</li>
<li>P548: I think it could potentially be beneficial. </li>
<li>P553: Some persons would be upset about this one so I would proceed with cautionary measures in this experiment.</li>
<li>P555: I believe the benefits of what is learned by this research is greater than not doing it</li>
<li>P557: As long as they ask the students if they want to be included in the final study, then I think it's fine.</li>
<li>P558: It's a ridiculous invasion of multiple people's privacy.</li>
<li>P561: I hate phishing and I think it should be illegal</li>
<li>P573: I think the data provided and the lessons learned can be valuable, particularly to college students, as they either have, or will soon have, online financial or other important accounts that online criminals will try to gain access to.  This study may help spread valuable knowledge.</li>
<li>P576: This also would waste peoples time, which is still and will always be rude.</li>
<li>P578: Please see the above answer.</li>
<li>P583: Awareness</li>
<li>P585: You need to recognize the harm in it happening to people</li>
<li>P590: Why should we trust researchers? They are people too.</li>
<li>P591: important lesson</li>
<li>P594: Researchers should not be allowed to violate people's privacy in these ways. They should only be allowed to collect this data with the participants' prior knowledge and agreement to participate. </li>
<li>P599: It's an invasion of privacy and the participants are being lied to</li>
<li>P603: Same reason as above.</li>
<li>P606: It is very risky. </li>
<li>P608: Needs a more controlled group. </li>
<li>P612: They should absolutely not proceed with this. They are not only involving one person, but also their friends which is just wrong. This could ruin friendships.</li>
<li>P622: Sure as long as the university is totally in control of the phishing site.</li>
<li>P628: This experiment would offer important results.</li>
<li>P631: I don't know that this is an ethical action on the part of the University to confirm students' passwords.</li>
<li>P633: As long as the study is approved and participants are debriefed (and passwords are protected), it's OK.</li>
<li>P646: This will also bring someone who is in this study another level of distrust when it comes to phishing. In thinking, well is this real, could this be a study. Do we want people to completely distrust everyone? Nope don't think this is a moral one to do.</li>
<li>P647: They should proceed but be completely open about it to the participants in the end. </li>
<li>P652: I think since the researchers are letting the particapants know what is going on it is okay. </li>
<li>P656: I think its important for people to know how easy it is to be taken advantage of so they can protect themselves.</li>
<li>P658: Maybe if there was a way to gain consent of a group of students.</li>
<li>P660: They should tell the participants to change their passwords after the study.</li>
<li>P672: It is important to study these things. </li>
<li>P676: Passwords should remain private always. No one, not even researchers, should be allowed access.</li>
<li>P678: help students learn to be aware of phishing</li>
<li>P682: I believe that it is deceitful.</li>
<li>P685: You shouldn't be able to force people to participate in a survey without their consent.</li>
<li>P692: I don't see why the reserachers need to gain access to Facebook profiles of friends.  Just stick to replicating banks.  </li>
<li>P694: this is a beneficiary study</li>
<li>P696: This research would be an invasion of privacy and security for most of the participants, and even if the collected data showed something interesting, it would not likely apply to real world scenarios.</li>
<li>P702: I dont know that it is safe for anyone. I dont know how much damage it will cause so I am not sure it would be a good idea.</li>
<li>P705: Some may get upset.</li>
<li>P708: They should not be able to access security information that easily.</li>
<li>P709: You would have to be very careful that no one would be able to see the actual passwords at any time during the study, only confirmation of whether or not they are correct</li>
<li>P717: As long as the people the attempt to phish remain anonymous and they don't do anything but verify the passwords, I feel that this can only help.</li>
<li>P726: I'm a little weary of the fact that the passwords will be checked for accuracy. I feel like that is too much access.</li>
<li>P729: As long as they have a choice its ok.</li>
<li>P732: The fact that they would test the passwords makes me uneasy.</li>
<li>P735: Only if everyone wants to be a part of the study.</li>
<li>P737: Again- it certainly would be beneficial and I perfectly understand why it would have to be conducted this way in order to be more effective?  but cyber attacks and fraud can really cause anxiety and a lot of fear and confusion.</li>
<li>P740: It's undercover collecting of private info.   </li>
<li>P748: I think this could be educational for the students, there should be discussion as to the danger of providing passwords to anybody, even friends.</li>
<li>P749: They will have passwords from other people's accounts. That's wring</li>
<li>P761: Its unethical</li>
<li>P763: Needs to be done right.  Description of the experiment seemsfair.</li>
<li>P765: They should just so they know different methods on helping people with this scenrio,</li>
<li>P772: Real passwords are given out. </li>
<li>P776: If the researchers asked the students' permission to verify their University passwords prior to doing so ,..OK </li>
<li>P780: I think its a good eye opener to help people understand the nature of scams like this and why they should not arbitrarily divulge their passwords </li>
<li>P787: I can't really see a way in which this would work without breaking privacy rules. </li>
<li>P792: This study seems ethical to me. No one is being harmed and no data is being abused. This is for academic purposes and the benefit gained will outweigh the con.</li>
<li>P794: I don't open anything from anyone I don't know, and I certainly don't open links in any email regardless of who sent it. I'm not sure this experiment will produce what they want; personally, it'd make me more wary of email than I already am.</li>
<li>P800: Again, I don't believe it follows the typical standards because participants wouldn't be aware of risks.</li>
<li>P801: Ensure that all researchers are ethical. </li>
<li>P802: Even though the end might justify the mean, It's a dangerous road to go down by saying that it's all done for the better good.</li>
<li>P803: Keep the information safe. </li>
<li>P810: Doing something unethical and then asking for forgiveness isnt a great idea. </li>
<li>P811: This is important research that will help students and other young people to recognize phishing and prevent from giving out their passwords to these emails.</li>
<li>P812: On one hand, it would be great information to have, but on the other hand it seems like it's going a little too far.</li>
<li>P820: could make some people angry. </li>
<li>P821: Tests like this are necessary to build internet security. </li>
<li>P824: the study will make future emails safer from phishing </li>
<li>P828: See above, passwords are off limits to me.</li>
<li>P833: It seems like the participants would have to put a lot of trust in the researchers' hands.  Part of me says yes because it seems like it could have some interesting findings, but the other part of me worries about password privacy.  I'll say yes, with caution, because I think the potential pros outweigh the potential cons.</li>
<li>P834: They seem to have the proper safegaurds in place to protect the participants.</li>
<li>P835: Again, no risk is involved.</li>
<li>P836: i dont believe they should try to actually access peoples  accounts if people are foolish enough to answer a phishing email they should be notifiyed instead of info bei g taken</li>
<li>P837: The methodology should be revised because the research question is important. Consider using a different organization or entity that isn't the university itself.</li>
<li>P841: This would not be putting the users' information at risk since the company doing the research would be reputable and would not abuse the information.</li>
<li>P847: Although the students will be informed subsequent to the study as to the nature thereof, and have the option to exclude their results, they would have been tricked into submitting their valid passwords.</li>
<li>P858: Too much of a security risk for those entering their passwords.</li>
<li>P865: i think it might be helpful to stop people from being robbed on the internet if this study was performed. </li>
<li>P866: It is an invasive action.</li>
<li>P868: I find it way too personal to access information from someone's Facebook for a study without permission from the person.</li>
<li>P870: Yes, but again, the participant needs to be warned and asked in a very general way. The participant needs to consent. People already know about phishing therefore warning them before hand will not compromise the study.</li>
<li>P874: People could get angry and blame the people who they thought's profiles they were clicking on since they don't know its a study, but most risks are minimal for this</li>
<li>P882: i just feel that it's going to have a negative impact on those who participate.</li>
<li>P884: For the overall safty issus with banking and password protection and internet use</li>
<li>P886: See above.</li>
<li>P890: No informed consent and faking information from a friend; this is unprofessional.</li>
<li>P898: yes, it is something that needs to be looked into to see how many people would submit data to an unsecured link like this to make ways to secure data for everyone</li>
<li>P901: I don't see a point in the abstract where participants agree to participate in research before they are actually involved.</li>
<li>P903: The researchers should be allowed to proceed with this experiment to educate individuals to be aware of phishing scams.</li>
<li>P904: No one wants to receive spam</li>
<li>P906: see above</li>
<li>P914: I think it would be interesting to see how many students enter passwords into phishing websites.</li>
<li>P921: To much invasion of privacy (looking at facebook and impersonating a friend- getting personal password) is involved.</li>
<li>P922: Research like this can be good but not with the confirming of passwords.</li>
<li>P925: there is a danger of identify theft</li>
<li>P926: I think this study will reveal important information. I do think the researchers have to be careful on how this is approached.</li>
<li>P927: by doing this student would be panic and even there is good result in this type of experiment in a university website</li>
<li>P928: Another major privacy violation</li>
<li>P930: I don't like it. It's getting too much info from unwilling participants</li>
<li>P934: because it has access to people's personal information and that might cause problems.</li>
<li>P939: You don't want to lose a students trust with the University, and you don't want the University reputation to go down.</li>
<li>P940: I don't think it is right to check for the validity of the passwords. I think they should make it so that the passwords aren't actually recorded.</li>
<li>P942: to be certain they are not setting the stage for impersonators to more easily phish the participants</li>
<li>P948: It's phishing</li>
<li>P951: the passwords could be misused</li>
<li>P953: Again, not very ethical, but would be valuable.</li>
<li>P955: It is not acceptable, in my opinion, for a university to get involved in a research like this by allowing the research team access to the knowledge of internet passwords. I think there could be some potential lawsuits against the college for participating in this. Also, the students will have to go through the time and energy to change their internet passwords, since now another party has been made aware of that information. This is unfairly involving students in something they have no choice but to exclude themselves form the beginning. They are not given the option before entering their passwords to participate or not. I think that is very unethical.</li>
<li>P957: I think this experiment violates personal privacy and should not be allowed.</li>
<li>P958: Some people might feel overly deceived here, so caution should be taken.</li>
<li>P963: Caution should be used to prevent accidental negative results.</li>
<li>P967: I don't understand why anyone would input a password into a link their friend sent them unless it was like a link to facebook or something.</li>
<li>P984: It's unethical.</li>
<li>P991: It is just an experiment... you have to find the holes in the security to fix them.</li>
<li>P1004: They have no right to the students' passwords.</li>
<li>P1005: I believe it would help teach young adults the importance of verifying sources.</li>
<li>P1012: They shouldn't be allowed to get their passwords at all.</li>
<li>P1016: It seems like an interesting study.</li>
<li>P1017: its unethical and i dont see the point...</li>
<li>P1019: Although mostly harmless, the part about pretending to be the participant's friend is a little out there</li>
<li>P1026: Once passwords are obtained, there should be far more security in place to maintain that they will not be shared or stolen. </li>
<li>P1028: It will encourage people to do the same thing.</li>
<li>P1031: There does not seem to be enough of a benefit to justify hacking the students. </li>
<li>P1039: Phishing is a real problem, and identifying possible reasons for giving out your password is important.</li>
<li>P1041: More people should be informed of phishing scams, but the researchers MUST be proven to be trustworthy and not use acquired passwords for their personal gain.</li>
<li>P1055: It sounds as if the researchers are looking for ways to solve problems.  I think you have to be careful who sees the information, even how many researchers have access to the information.  The more people that have access, the harder it could be to keep the information confidential.</li>
<li>P1056: It's for a helpful and preventative cause</li>
<li>P1059: No harm will come to anyone.</li>
<li>P1062: People fall for phishing attacks all the time. The percentage of people who actually get suckered into them really doesn't matter. Preventative measures being taught to people are a much better utilization of dollars and time  than a study measuring the percentage of people who fall for these attacks.</li>
<li>P1072: Why not?</li>
<li>P1076: I have been a victim of phishing and I know how serious it is or can be, so the research should be allowed.</li>
<li>P1083: It is very important people are aware that there are scammers out there and they need to be careful.</li>
<li>P1084: I believe it will benefit people in the future and make them more cautious.</li>
<li>P1089: I think that the results of this study will be used against individuals and cause more harm, there are better ways to find that information.</li>
<li>P1109: It's a useful study.</li>
<li>P1110: I believe that it would be wrong and intrusive to snoop on participant's Facebook feeds and Facebook friends and then impersonate one.</li>
<li>P1111: The more we learn about how to prevent phishing, the better!</li>
<li>P1112: This is deceptive and not a good experiment</li>
<li>P1113: Actively impersonating real, immediately relevant institutions and people could negatively impact participants actual well-being.</li>
<li>P1116: I think the idea of the research is good, but I'm not comfortable with sending emails from the subjects' Facebook account.</li>
<li>P1119: The researchers should make sure that all of their information on the passwords collected must be deleted in order to ensure that it does not fall into the wrong hands.</li>
<li>P1123: I believe this is a great experiment, but should be cautious in order to prevent any lawsuits. It's great to get that kind of research out there, but being careful is very important!</li>
<li>P1131: It would be beneficial for people to be aware of vulnerabilities, but they must also learn to change passwords, etc. Don't want the usernames and passwords to be stored without consent or anything.</li>
<li>P1133: The researchers need to be very careful about protecting participants' account information.</li>
<li>P1140: It just sounds to risky to me. I don't think its a good idea.</li>
<li>P1147: Lots of deception. Could cause relationship harm for participants.</li>
<li>P1157: I hate to be so blunt, but this is a stupid idea.  The 'researchers' who concocted this devious strategy are immature, unprofessional, uneducated, cynical and devious.</li>
<li>P1158: This is an abuse of Facebook and more importantly, the university's system. Passwords in the university system should not be compromised for any reason, including research, unless everyone was aware and consented prior to using the system.</li>
<li>P1162: The experiment may end up reducing unwanted emails in the long run</li>
<li>P1163: There are going to be people who try to obtain this information no matter what kind of security is put in place. By trying to outsmart the bad guy you are really just as guilty of privacy violations as the "hackers or phishers" </li>
<li>P1165: It seems very deceitful and you can get all sorts of personal information.  I also think a university could be sued for giving out private information and would never agree to do this, so you should try something else.</li>
<li>P1174: its wrong</li>
<li>P1178: It crosses a fine line between research and taking advantage of people's willingness to earn $1</li>
<li>P1179: I feel it would be more effective to simply send an email to educate people about phishing. </li>
<li>P1180: Unless the issues raised in my last answer are addressed, then no, the researchers should not be allowed to proceed.</li>
<li>P1181: I think it's important for results. </li>
<li>P1183: same reasons as abobe</li>
<li>P1186: It seems too tricky. </li>
<li>P1187: They will be dealing with actual passwords.</li>
<li>P1191: It's a control group - why not?</li>
<li>P1192: I see no benefit of this experiment.</li>
<li>P1195: I'm for the good of studies but very cautious about gaining people's real passwords. Really undecided about this.</li>
<li>P1196: Not as structured, they should not be given access to the university's system to verify the passwords.</li>
<li>P1197: It seems a little bit shady to manipulate and deceive students, as well as impersonate.</li>
<li>P1203: Ensure that the data they collect doesn't get into the wrong hands. </li>
<li>P1206: They should make sure no one is at risk</li>
<li>P1209: I don't think they should be allowed access to anyone's passwords. </li>
<li>P1211: Again, confidential information is password protected on university systems. </li>
<li>P1216: I think the deception crosses the line ethically.</li>
<li>P1217: You wouldn't want to upset the people participating</li>
<li>P1218: passwords are personal.</li>
<li>P1220: The experiment is risky but should be permitted with caution and awareness.</li>
<li>P1229: yes to help get the word out to not trust thing you get in your email.</li>
<li>P1230: The study has good intentions but studies should be opt-in.</li>
<li>P1233: An independent auditor should confirm the security of the information that students enter. Researchers should never learn the students' passwords. Only confirmation that the one that was entered was valid. Use Md5 encryption to protect student input.</li>
<li>P1235: The researchers need to be careful with the passwords and delete them</li>
<li>P1238: doesn't hurt anyone</li>
<li>P1239: The researchers are purposely trying to do something morally wrong to students, which I don't feel is right.</li>
<li>P1242: I think it would be a prime example as to why students should be much more careful with their information.</li>
<li>P1244: It's not ethical.</li>
<li>P1245: This could possibly be violation of privacy </li>
<li>P1247: This study's aim is to measure how often people fall for phishing, not to try to stop phishing.</li>
<li>P1248: As I mentioned above, I believe this experiment could double as a good teaching moment for students.</li>
<li>P1253: This breaks the security of the student and the university computing system. It should not be allowed on security reasons alone.</li>
<li>P1260: I can't see the good in the experiement</li>
<li>P1261: As with passwords this can lead to very sensitive information being given so making sure none of it is stored is crucial. </li>
<li>P1262: Gives more awareness than harm.</li>
<li>P1264: Phishing activity is illegal, whether conducted for 'research purposes' or not.</li>
<li>P1265: The participants in this study are being lied to big time in order for the researchers to get their results so I feel like it's too big of risk to take on.</li>
<li>P1266: No, this is too risky and invasive. </li>
<li>P1267: The research can only help.</li>
<li>P1269: As long as it helps the user know what they did wrong.</li>
<li>P1270: im not sure how any number figure of how many people would fall for phishing will actually change the people who actually became victims</li>
<li>P1272: I think they should be allowed to do this but only if there are checks & balances in place that fully delete the information as soon as it's received and notify the user to change their password anyway.</li>
<li>P1273: I don't know how ethical this is. Since its after the fact that participants will know what is going on, I think it might be unethical. The participant has to willfully agree beforehand, not after.</li>
<li>P1274: People need to know about phishing attacks.</li>
<li>P1278: I think it might be valid information for preventing phishing.</li>
<li>P1286: This is treading a mighty fine line of invading privacy. Although it is a study that could help, some people may be offended by it.</li>
<li>P1288: Maybe it will make people more aware of tricks used to scam them.</li>
<li>P1289: Phishing is dangerous and needs to be stopped</li>
<li>P1295: I see nothing wrong with this.</li>
<li>P1296: This would help people understand how easy it is to accidentally give out personal information on the web or being tricked into doing that. Researchers should take caution as to not help other people figure out how to steal others information in this manner.</li>
<li>P1297: Depending on how that information gets linked out and when most likely that university will actually get attacked.</li>
<li>P1299: I think its wrong to trick people about these things.</li>
<li>P1300: It would help raise awareness about security.</li>
<li>P1301: I know with human subjects there are a lot of rules and ethics, I'm not sure what they all are, but it sounds harmless to me</li>
<li>P1310: I believe this is something we need to educate people on and this study will reveal how susceptible people are to this type of scam.</li>
<li>P1311: You want to be careful not to infringe on someone's privacy unknowningly.</li>
<li>P1316: Again, too much infiltration of personal information.</li>
<li>P1320: Acquiring students university passwords (for comparison) seems wrong even for an experiment.</li>
<li>P1326: The deliberate act of acquiring passwords to private accounts is a gross invasion of privacy.</li>
<li>P1327: Just so long as everybody is trustworthy involved in conducting the research and there are precautions taken.</li>
<li>P1328: It isn't fair but the info would be worth it</li>
<li>P1331: I think the results of such an experiment would help and I don't see how it can harm anyone.</li>
<li>P1338: I am a bit iffy about this research because a hack of this sort has happened to me before.</li>
<li>P1340: Yes they should but I believe it's best to be careful using the student's password. </li>
<li>P1346: The results could be very beneficial to future internet security.</li>
<li>P1356: Trust. I don't trust that the researchers wouldn't use my or my friend's info for other things.</li>
<li>P1360: Yes, this is the only way that they will be able to attempt to resolve this problem.</li>
<li>P1363: I don't want independent people from the University being able to see someone's password</li>
<li>P1371: Use of Facebook profiles may count as an invasion of privacy</li>
<li>P1374: This experiment could very easily offend a lot of people, it allows the experimenters to access a profile and collect data on friends as well as checking to see if an entered password is correct. I think the net positive out weighs the negative possibilities but recognize that others would disagree.</li>
<li>P1386: I'm not a fan of the idea, to be honest.</li>
<li>P1389: As long as it is done in correlation with the University and as long as they are aware, the researchers should be able to proceed.</li>
<li>P1404: Definitely...it would be eye opening</li>
<li>P1406: This experiment seems ethical, transparent, with accountability.</li>
<li>P1419: On going research will always be needing to fight against phishing attacks.  Anyone working against a person's security will always find ways to continue to be successful in causing mass destruction.  </li>
<li>P1420: Much too intrusive.</li>
<li>P1427: Again, another example of how information about people's habits on the internet may help future attacks to happen. The information gained would be helpful. </li>
<li>P1430: They're using the participant's Facebook friends, which I feel is unethical.</li>
<li>P1432: This also seems like it might be an invasion of privacy and if done should be done with caution</li>
<li>P1433: I think this violates students privacy by checking their Facebook friends, having them enter their passwords, and by having the university confirm if passwords are correct. Too many ethical issues to proceed.</li>
<li>P1436: too unethical for my tastes</li>
<li>P1446: Important data for them, wake up call for the participants</li>
<li>P1456: Again its redundant as its always the mentally vague and stupid people who fall for this stuff sic!,.</li>
<li>P1465: It could be really beneficial.</li>
<li>P1466: Seems less invasive than other potential experiments.</li>
<li>P1470: I do not see how an experiment such as this benefits mankind.  It is not really a science experiment.</li>
<li>P1472: Monitored for deletion of actual sensitive information</li>
<li>P1482: Passwords should not be gathered in anyway. The fake page should just tell whether something was entered or not. It should not "use the university's systems to verify that the passwords entered were valid passwords."</li>
<li>P1486: They aren't doing anything risky and the information found will be helpful</li>
<li>P1487: Careful to not abuse passwords/university systems.</li>
<li>P1488: because this will help computer users and give them helpful information</li>
<li>P1489: I like this one very much.  So many people think that email is really from a friend or someone else they trust.</li>
<li>P1492: I don't think its right to trick someone into being part of an experiment even if the results may be helpful.</li>
<li>P1503: they will gain useful information</li>
<li>P1507: Its a serious breach of someone's privacy.</li>
<li>P1508: they shouldn't be tricking people with real email accounts</li>
<li>P1510: Tests like this, IMO, should be more controlled.  They should specifically involve passwords that aren't real using resources that aren't real.  And if the passwords absolutely had to be real, they should never be stored or used in any way, even if to verify legitimacy.  </li>
<li>P1513: I'm not sure, it could be dangerous.</li>
<li>P1514: if it helps better the safety then who am i to stop them?</li>
<li>P1517: This experiment could raise awareness about phishing scams so that students could be more aware of this type of attack in the future.</li>
<li>P1522: As long as no information is being shared I see no reason why this shouldn't be allowed.</li>
<li>P1523: Again, I think that all we need to do is have our email companies provide phishing protection built in to the browser; Also, I can't imagine that it will be approved by a irb board, however i don't know!</li>
<li>P1524: I see no real risk based on the above explanation, and I understand the validity of such and experiment, so I think it should be allowed.</li>
<li>P1528: Again, people can be extremely dumb.</li>
<li>P1538: The researchers would be given access to numerous student accounts so if they were to continue with the study there should be safeguards in place to prompt students to change their passwords as soon as the researchers have verified the validity of the entered passwords.</li>
<li>P1540: I can't decide on whether or not this is safe enough to go through with. </li>
<li>P1546: Because it can help educate people about what they're doing wrong.</li>
<li>P1552: in the digital day and age, everyone should be made away of schemes that could harm them or their personal information</li>
<li>P1553: I believe that the aspect involving sending a fake email from a friend is where the ethical line is crossed.  This could cause change to a social relationship.</li>
<li>P1556: It is important but some may not like the deception at first.</li>
<li>P1558: The risk of privacy loss or data compromise is too great with this study.</li>
<li>P1563: No access to pii</li>
<li>P1572: It will be a good learning experience for the people involved and will warn them or make them more careful.</li>
<li>P1582: Younger people are very social and very trusting of their friends.  Maybe this would help them be more careful.</li>
<li>P1583: While the researchers intend to publish the results of the study with the intentions of helping to protect others from phishing scams, I do not think that it is morally correct to subject these students to a study that they have not consented to.</li>
<li>P1584: I see no harm in the experiment.</li>
<li>P1597: Before research is conducted, permission should always be obtained. This is especially true when dealing with details such as passwords and personal information.</li>
<li>P1598: While we already know the answer, people tend not to believe without proof.</li>
<li>P1604: I think the ressearchers should be allowed to perform this experiment, but I also think that there should be a faculty member supervising this whole experiment.</li>
<li>P1610: it is still stealing passwords but notifying the people about it afterwards they need to be very careful if they proceed that the information is not available to others.</li>
<li>P1615: If their system is compromised, all the information could be used by someone else</li>
<li>P1617: Again, dealing with data and passwords always seems ripe for abuse.</li>
<li>P1618: Although the experiment may have the best of intentions, it seems a bit too personal.  If I were a part of it, I would feel like my privacy had been violated.  </li>
<li>P1620: They are actually having people's passwords and checking them with the real thing.  a bit sketchy.</li>
<li>P1624: Research projects should be opt in, not opt out.</li>
<li>P1633: As long as the researchers were careful and watched each other carefully then the research would be safe. </li>
<li>P1643: Even though it technically does not harm anyone, and the experiment is used for purposes to collect data to help prevent phishing, the very act infringes on others.</li>
<li>P1646: As long as they have the university's permission. </li>
<li>P1650: If there is a scientific reason for the study then yes</li>
<li>P1651: It doesn't seem very ethical. </li>
<li>P1655: It's invading people privacy a bit even if for a good cause.</li>
<li>P1657: It could be helpful to try to learn to recognize phishing attacks, but I am concerned about the deception used.</li>
<li>P1662: It gets the word out and makes us aware.</li>
<li>P1671: The process should be modified, the study should be incorporated to allow the testing of logins without human interaction or access, and the stored data should be properly hashed.</li>
<li>P1674: See above - a little too dangerous - how do we know the researchers can be trusted?</li>
<li>P1680: They have to make sure they don't invade people's privacy.</li>
<li>P1686: Would decrease the chance of people being victimized by phishing</li>
<li>P1696: For instance, the link to the phishing site should have a disclaimer after the participant has been "fooled", carefully explaining that their info has not been stored, then on that page ask if their info may be used in the study</li>
<li>P1704: see above</li>
<li>P1705: the ends justifies the means</li>
<li>P1707: They should proceed with the study only if they ask permission for the passwords before they are used, but after the need exists.  Invasion of privacy concerns.</li>
<li>P1709: I feel like the university students should not have access to the personal information of the candidate. They should only be able to know if the phishing attack was successful or not.</li>
<li>P1721: Anything of this personal nature must be agreed upon by all participants, unless it's unethical.</li>
<li>P1724: I think it is too dangerous for a security breach</li>
<li>P1729: i'm sure this is the best way to get the results, but i'm sure there is other ways to get this information</li>
<li>P1730: Its too invasive and could worry people that their privacy has been compromised once they get an email like that. </li>
<li>P1733: I don't like the fact people would have to give out personal information.  Too much chance for something to go wrong and that persons account to be hacked. </li>
<li>P1738: As long as they take reasonable precautions and they don't use the information they get in an unethical way then yes. They should ensure that they don't ask for banking or medical or other very sensitive information just as an added precaution.</li>
<li>P1740: If someone found out about this and there data was accessed without consent it could cause problems.</li>
<li>P1741: This is crossing a line in my opinion. Although anyone who is stupid enough to put in their password after clicking on a link deserves to be scammed.</li>
<li>P1744: Wouldn't feel comfortable researchers having real passwords</li>
<li>P1745: Make sure those seeing the information are trustworthy.  </li>
<li>P1746: A lot of people are still oblivious to the dangers phishing holds. This experiment needs to take place.</li>
<li>P1748: Any kind of experiment should always proceed with caution.</li>
<li>P1751: Studies are a great way to learn.</li>
<li>P1753: in the long run they are not hiding anything and are going to help people. </li>
<li>P1758: Privacy issues</li>
<li>P1761: The experiment will give the researchers access to a tom of passwords. The intention is good, but what if those passwords are leaked? It's a risk. </li>
<li>P1770: I don't know if there are any long term negative effects, but Im leaning toward no</li>
<li>P1775: I think I already answered that no student should have their private info used this way.</li>
<li>P1777: While it may be a benefit to security, I think that people have a right to their privacy as well.</li>
<li>P1783: I think it should be re-worked so that people's privacy isn't violated as much.</li>
<li>P1784: Using people without their knowledge before hand does not sound like a great idea.</li>
<li>P1785: No harm done from study.</li>
<li>P1786: I believe this experiment would make a lot of the participants angry. In addition, I know that there is not a university or school in existence that would provide any one - even for a study/experiment - passwords to their students accounts. The school would be in HUGE trouble for doing so, students would be very angry, and I could see lawyers coming into play.</li>
<li>P1788: because of the answer I gave above</li>
<li>P1800: It doesn't seem safe.</li>
<li>P1802: It should be ok as long as they are very careful with the password data they get.</li>
<li>P1806: Whenever it comes to peoples passwords you have to have to be careful. </li>
<li>P1808: Make sure they're school authorized and that it wouldn't cause any students to freak out.</li>
<li>P1814: It's fraudulent to do something like that.</li>
<li>P1825: They are looking at people's passwords and Facebook pages and impersonating friends.... there are some ethical issues here... may need to get permission from friends</li>
<li>P1827: They should make people aware that they are sending emails as student's friends.</li>
<li>P1835: They could wind up using the information they obtain in a bad way and it could make students distrust the university</li>
<li>P1837: I think it should be done in a controlled environment</li>
<li>P1839: They must be able to tread the line where the participant does not feel his privacy was violated.</li>
<li>P1842: They are accessing sensitive information and the participants have no way to give informed consent.</li>
<li>P1850: The researchers have to use a bit too much personal info for it too work.</li>
<li>P1851: I think if it was the school's website, it would be safer</li>
<li>P1853: Passwords are private. The study sounds like it would be helpful, but now students might not feel secure. </li>
<li>P1857: I feel like the participants privacy is being violated in a way. I think it is wrong to stalk them on Facebook to determine who their friends are. The whole feel of the study is creepy. </li>
<li>P1864: In the end it is harmless, and it also does the user a service in a way.</li>
<li>P1865: I would think they can find ways to help users better learn to recognize attacks of phishing without conducting this study.</li>
<li>P1870: Students are not made aware that the researchers have their passwords. The researchers should not be able to compare passwords until after the student gives permission and then they should have the ability to change the password.</li>
<li>P1871: Sure</li>
<li>P1873: If the experiment were allowed, I believe that all students should be encouraged and reminded to change their password after the results were collected.</li>
<li>P1874: It seems really risky and deceitful, which I understand it's inherent to the study, but it still seems sketchy.</li>
<li>P1876: Some of the students may form some kind of trust issues over this.</li>
<li>P1877: This feels like something that opens up way too much latitude to researchers. Digging around in people's private lives without their consent in order to mess with them in ways they don't anticipate, in the name of "science," is too much a slippery slope.</li>
<li>P1878: I don't see much downside</li>
<li>P1884: Just make sure they people that are involved are well informed it goes no further. </li>
<li>P1890: Yes but there should be s foolproof way where the passwords won't leak out into the wrong hands.</li>
<li>P1892: It oversteps their boundaries by performing an experiment on people who do not know that they are involved.</li>
<li>P1893: No way. Passwords are way too important for anyone else to see.</li>
<li>P1894: Complete invasion of privacy</li>
<li>P1897: They must be sure there are no leaks to allow private information to escape. Not sure about the using of facebook to get friends, but that's where it can come from anyway.</li>
<li>P1901: Same as before, we need to do these types of experiments to understand how people get duped by emails.</li>
<li>P1906: There's no harm in what they're doing as long as they keep the passwords safe.</li>
<li>P1913: They need to make sure everyone involved does not keep the passwords that people enter, as those are personal.</li>
<li>P1916: IF you do this, ensure that you have the intent of helping to eliminate the means of Phishing and also send out an email or something that lets the victim know that this was an experiment rather than them realizing they were hacked.</li>
<li>P1918: Participants must agree before being in an experiment.</li>
<li>P1920: It is slightly better that the students would be able to opt out of having their data included, but it is still not ethical to obtain the data without permission in the first place.</li>
<li>P1934: It doesn't seem ethical. </li>
<li>P1938: I'm torn over it.  I don't like the idea of deceiving the students, but it's important that research be done so that actual malicious phishing can be curbed.  </li>
<li>P1942: If the passwords are protected, or destroyed immediately, students will not be in danger.</li>
<li>P1945: You have to securely (even temporarily) store the passwords for checking.  You would also have to be transparent in your whole process to ensure there are no security holes.</li>
<li>P1951: It would help educate people about how phishing works and teach people to be more cautious.</li>
<li>P1953: This research appears valuable and could help learn more about phishing attacks and how to prevent them better.  They should just make sure not to compromise anyone's privacy while conducting the research.</li>
<li>P1955: Dear god, no. This seems like a disaster. All it would take is one leak of any of the information anywhere, not to mention that a bunch of people would be getting access to other people;s /actual passwords/. Terrible idea for all kinds of reasons I haven't even STARTED to get into here.</li>
<li>P1956: I would be leery that the data may become readily available to hackers and then used for real crimes.</li>
<li>P1960: Tricking students without their knowledge seems risky, but if they are notified in the end, and no real information about them is identified, I think it would be ok. </li>
<li>P1963: So long as they were confident that the results of the study and the info they get from it will be able to be put to use.</li>
<li>P1967: I could damage friendships.</li>
<li>P1971: The access to real passwords, even if they're purged later, is troubling.</li>
<li>P1977: It is deceitful. This experiment is creepy and weird. </li>
<li>P1978: Once again it is against the law!</li>
<li>P1979: I don't think the researchers should be asking for real passwords of the people taking the survey.</li>
<li>P1982: I say no unless it is in a very controlled environment with people.  I think everyone participating should know the experiment beforehand.</li>
<li>P1989: The caution being that all passwords recovered during the experiment be destroyed once the experiment is completed.</li>
<li>P1991: My one hesitation is "researching" participants' friends via Facebook. It seems like a violation of privacy and trust. </li>
<li>P1994: I think this is a great idea to gain insight</li>
<li>P1998: As I stated above, something about this just feels wrong, and because of that, I do not believe this should experiment should be carried out in this manner.</li>
<li>P2002: Yes, but with extreme care to the passwords.</li>
<li>P2003: They are causing no trouble and are helping people potentially learn a valuable lesson in online security, they should proceed.</li>
<li>P2007: They need to be careful and make sure people are aware of the fact it was a survey once it was finished, which it seems they would do.</li>
<li>P2025: It's already been researched.</li>
<li>P2026: Yes. I also think they should offer some compensation to the people involved.</li>
<li>P2027: i think they should be encouraged to do this, i can see only good results</li>
<li>P2032: Its fine as long as it is the property of the university and no harm comes to study participants.</li>
<li>P2036: Extra care should be used to make sure that all the risk has been examined and eliminated</li>
<li>P2037: It will give them a good idea of how liberal people really are with their personal info</li>
<li>P2040: Some people may not like having their passwords known by the researchers, so the researchers should be sure to explain to students that their accounts will not be compromised and that they can change their passwords if they wish.</li>
<li>P2043: I believe results of this experiment could help prevent phishing</li>
<li>P2048: It is, objectively speaking, a privacy violation.  If students signed a consent prior to the experiment, then I would advocate it.</li>
<li>P2051: For the same reasons I gave to the question previous to this one.</li>
<li>P2053: As long as participants are made aware of the findings I think it could help users learn about phisihng and teach researchers ways that could help people become less susceptible.</li>
<li>P2060: This type of activity needs to be tracked to better understand how to warn against it.</li>
<li>P2061: phishing is so new today that we dont have any data to confirm the extent damage it has given to individuals and to private corporations</li>
<li>P2063: I suppose it would be ok if the participants agreed to it.</li>
<li>P2065: I would not trust my university with my passwords to banks or other accounts / websites.  Especially not without my permission. </li>
<li>P2072: You don't know what's research and what's harmful.</li>
<li>P2076: The fact that these are students, and that fake use of their friends is involved seems a little risky. Students might get upset. </li>
<li>P2082: They are working on behalf of the university, there shouldn't be any problem</li>
<li>P2094: The researchers should be supervised in such a way as to make impossible their using the students' correct password info to view or alter anything within the students' university accounts. The students involved in the study should also be walked through the process of changing their password after the study to protect them in the future and further ensure the researchers could not abuse the intel gained.</li>
<li>P2097: One thing I would want the researchers to do is debrief the AMT workers who attempt to exit when they see the security warnings (rather than just debrief at the end of the experiment, which I assume would require the AMT worker to continue through the study, in spite of what appear to be security warnings.</li>
<li>P2100: Same as above.</li>
<li>P2103: I think that given the researchers access to the university's stored passwords even if it is just to verify them is too much information to disclose. </li>
<li>P2114: There's no real risk and it's a worthwhile issue to review.</li>
<li>P2117: As above, This is just unethical. Unless they signed up as a participant and had given some form of consent for researchers to go snooping through social media and personal information, this is unethical.  </li>
<li>P2119: It is much too invasive.</li>
<li>P2123: any experiment should be done with caution</li>
<li>P2125: Using "friends" as the bait is close to crossing the line of privacy.</li>
<li>P2126: I think its too risky to put participants in this type of situation. They may not appreciate the deception.</li>
<li>P2132: It's also phishing</li>
<li>P2134: This would be the worst kind of research out of all these.  Too deceptive and fraudulent. </li>
<li>P2135: Doesn't seem like a legit experiment. </li>
<li>P2137: with experiments only we would be able to solve problem</li>
<li>P2156: We should never access peoples stuff without their knowledge. There should be some caution and awareness that the persons stuff maybe accessed. </li>
<li>P2159: they are helping not harming</li>
<li>P2164: It is helpful to understand how these attacks occur so the public can be informed.</li>
<li>P2172: It would show how much of the population is inclined to go forward in a phishing scam.</li>
<li>P2175: Not only should they not proceed, they should be sanctioned for considering doing something like this to their students.</li>
<li>P2177: Yes - I think it is good to work on this.  I would participate in such a study.</li>
<li>P2183: If you notified the students whose email account you were using what you were doing, then that may work.  Otherwise, it's trickery.  </li>
<li>P2189: As long as they protect any sensitive information and only use it for research purposes.</li>
<li>P2191: This is a big invasion of privacy. The researchers would have passwords for real accounts belonging to real people. </li>
<li>P2193: It can be useful one day in identifying legitimate friend e-mail messages too.</li>
<li>P2194: If the goal is to stop phishing then yes for any other reason I would say no to it.</li>
<li>P2204: I'm not sure about actually using the passwords. </li>
<li>P2205: There are possibilities that this could go wrong and people should be able to consent and agree to a study like this.</li>
<li>P2208: There's always a chance the personal info could get out even from the experiment.</li>
<li>P2212: This is an ethical dilemma to which I feel that arguments presented from those who approve and those who don't approve could sway my opinion.</li>
<li>P2213: It would be different if they told people ahead of time that they would be doing an experiment in the area, maybe.</li>
<li>P2218: I fail to see how learning and quantifying how to better victimize people by abuse of trust, will ensure better responses to such attacks. The techniques that allow one to avoid being taken in by such techniques already exist. Researching how Vulnerable people are to abuses of trust, by abusing their trust and the publishing it, may have the OPPOSITE effect, it might embolden scamsters who would then know, which techniques of security circumvention were the moste effective. One cannot assume that this knowledge would be limited to only the "morally responsible" who would not abuse such knowledge, nor can one assume that knowing which techniques were most effective would result in better education/countermeasures against actual attacks. The benefits are dubious, the risks are disproportionately high. It is also a potential PR disaster for the university involved, as it demands that student trust be abused by faculty members.</li>
<li>P2219: I don't see the benefits of this deceptive study. </li>
<li>P2221: It violates their privacy without them knowing until the end, at which they can decline and have their data excluded.</li>
<li>P2226: Even if results are anonymized and aggregated, the results still may be harmful to survey participants.</li>
<li>P2227: Science should not be an excuse to invade people's privacy. </li>
<li>P2231: I feel like there are numerous violations of privacy.</li>
<li>P2233: I think it helps not harms</li>
<li>P2237: It is important for research, and someone has to be a participant.</li>
<li>P2238: Unethical to get people to divulge passwords.</li>
<li>P2244: As i said it is needed information that will help to educate and protect the public.</li>
<li>P2245: This is talking about trying to trick someone into giving a password. Frankly when the students find out, I'm sure they will be extremely upset.</li>
<li>P2253: I am curious about how careless people are with emails from people they know.  Email from friends are faked all the time.</li>
<li>P2254: this is a big problem in internet use and needs to be researched and addressed</li>
<li>P2260: Maybe with a change of rules. It seems odd to do for the amount of risk. </li>
<li>P2261: This could make alot of people mad, but honestly it would be a good experiment. I would like to see the results. </li>
<li>P2273: I just think it  needs to be   overlooked   carefully but  others at the universary.</li>
<li>P2275: passwords should be secure</li>
<li>P2276: Helping people learn from such attacks is an extremely important endeavor.</li>
<li>P2280: It opens  a pandoras' box of issues about privacy</li>
<li>P2281: I think they would be using sneaky tactics to gather data.</li>
<li>P2284: Seems like using deception in this case is wrong.</li>
<li>P2285: the verifying password part scares me.  </li>
<li>P2286: Natural caution must be taken to insure not only that useful data is collected but that the students rights of privacy are not infringed. </li>
<li>P2289: This seems like a slight invasion of privacy, although this is a very likely phishing tactic.</li>
<li>P2302: The results are important, but they should have access to their real passwords.</li>
<li>P2307: Knowledge is a good thing, but the potential misuse is a high risk.</li>
<li>P2308: It's important information</li>
<li>P2309: It is an invasion of privacy to go through someone's address book and use their information in an attempt to trick them, even if the intent of the research is good.</li>
<li>P2314: Some useful results may be produced.</li>
<li>P2315: I don't like the idea that information on facebook and university websites could be used like that without consent.</li>
<li>P2316: Yes, if they develope an add-on, or extension phishing block script. </li>
<li>P2323: Make sure their personal information is kept private. </li>
<li>P2324: Yes, but with caution. It doesn't say anything about them deleting information about the passwords the students enter or giving them a change to change their password afterwards which seems like a security issue.</li>
<li>P2326: It may seem like a breech of privacy to go looking in a person's facebook in order to phis better, but if the participants can opt out of the study afterwards I see no real harm being done.</li>
<li>P2328: Again, i do not like the idea of testing people without their consent.</li>
<li>P2337: It would be a good idea to show students that they have to be careful but it is still a violation of privacy and they would be giving passwords out that could end up who knows where</li>
<li>P2339: Identifying how phishing works is a great step toward combating it.</li>
<li>P2340: I don't think it will do any good.</li>
<li>P2348: It should be perfectly fine and work fine</li>
<li>P2349: Anything to stop phishing and thieft.</li>
<li>P2350: I would say yes that they should be allowed to proceed with this experiment as long as the don't use any of the data that they collect against any of the students.</li>
<li>P2351: This just seems very wrong.</li>
<li>P2353: The researchers should make sure all participants are contacted to have their data excluded - and also to be advised to change their passwords.</li>
<li>P2354: This same info could be obtained "after the fact" from real victims consenting to be surveyed.</li>
<li>P2357: We don't need to learn how to steal better.</li>
<li>P2368: I'm not sure the test group is ideal for the answer they seek. University students are a small part of the demographic. They are constantly interacting with "strangers" who are in their same classes, so they might be more likely to respond to the emails. On the other hand, they are allegedly the smarter portion of the population because they are in college, so they might be wise enough to avoid it. </li>
<li>P2370: for scientific purposes i believe researchers should be allowed to conduct such experiments.</li>
<li>P2372: Trust and empowerment should be promoted.  This will undermine both.</li>
<li>P2378: I believe you have to have the right people conducting the experiment, in order to not take advantage of the students participatin.</li>
<li>P2382: There's a big opening to exploit the participants in the study by confirming passwords with email accounts. That confirmation makes it a bit of an invasion of privacy and can compromise someone's identity.</li>
<li>P2386: I wouldn't want to participate but I do see the point of this experiment being conducted.</li>
<li>P2390: The way researchers want to check Facebook profiles to identify a student's friends, and getting a hold of their passwords are just two more examples of phishing</li>
<li>P2396: This could possibly harm the relationship between the student and the person the scientist pretends to be. I think some sort of tweaks to the basis need to be done before proceeding.</li>
<li>P2397: This experiment targets an actual problem and may help find solutions.</li>
<li>P2401: The ending result of this experiment is a positive one but the method is slightly troubling. The fact that the people that are selected to do this are being researched on their personal Facebook's makes me a little uneasy. But the reasoning behind it makes sense. Telling them afterwards and giving them the option to back out or not is very important though.</li>
<li>P2403: This seems like a disaster waiting to happen - the system testing passwords could be hacked, passwords could be sold, etc</li>
<li>P2406: Researchers should always use caution and take measures to protect their subjects.</li>
<li>P2408: I think there needs to be justification for why the study needs doing, and a better thought out system to debrief.</li>
<li>P2409: Going to their facebook page to find their friends names and then impersonating them seems to be going a bit too far on the deception scale.</li>
<li>P2416: I don't know about letting the researchers verify passwords.  That might be going a little too far. </li>
<li>P2425: All of this research must be done in a lawful and ethical way.</li>
<li>P2432: Yes,because learning how to recognize hackers trying to get your information can help improve people's awareness of the dangers of opening anything that you may think is from someone you know.</li>
<li>P2433: There can be backlash from the students who were used for this experiment.</li>
<li>P2435: A great idea to make sure that people are not falling prey to these emails but as always proceed with caution.</li>
<li>P2441: More rules should be put into place, as researchers are dealing with a lot of sensitive information and have access to things such as facebook profiles.</li>
<li>P2445: The data the researchers collect could be sensitive, so it's important that the researchers take extra steps in securing their data.</li>
<li>P2449: without the consent of the participant, an experiment shouldn't be performed</li>
<li>P2450: I am sure that it will be in a controlled setting and they won't lose anything and it will help researchers better understand people on how and why we do things.</li>
<li>P2451: Because of the value of the research </li>
<li>P2452: I believe this experiment is too deceptive and also a violation of people's privacy and should not be conducted.</li>
<li>P2453: This could be a dangerous experement if not closely monitorted.</li>
<li>P2456: Just because criminals use these methods I don't think they should also be used by researchers to study them.</li>
<li>P2457: violates privacy</li>
<li>P2463: Phishing does not seem as bad as hacking. the participant is willingly tricked into giving the password.</li>
<li>P2473: Obviously, the researchers must be very trusted.</li>
<li>P2475: They need to make sure that it is not other students seeing the passwords. Only instructors who would have little interest in logging into young people's facebook accounts to start trouble</li>
<li>P2480: So many people especially old folks get scammed - this needs to stop. Research is a step in the right direction. </li>
<li>P2488: This experiment violates people's privacy, and is mean-spirited as well (i.e. sending fake e-mails from friends).</li>
<li>P2491: It's rather uncouth. </li>
<li>P2495: people need to know how to protect themselves from this because it happens every day maybe even every minute</li>
<li>P2496: I don't think phishing is legal, this shouldn't be either.</li>
<li>P2499: This is important research being done.</li>
<li>P2501: I think the experiment should proceed but the researchers must be careful not to expose any of the students' passwords to anyone outside the study.</li>
<li>P2505: It may be for research but the researches could still use the passwords to actually steal information.</li>
<li>P2514: I think this would be a useful study and should proceed.</li>
<li>P2516: If the researchers are just sending emails to students without their knowledge of any experiment being conducted I feel that is morally wrong</li>
<li>P2522: I think that there is a lot of info to be gained from such a study so it should be allowed to be carried out.</li>
<li>P2530: Phishing is still phishing, and just because you say it's legitimate doesn't make it so. Criminals think their activity is just, too, and a crime is a crime. </li>
<li>P2532: It would be a good lesson to teach the students but I would be leery about how trustworthy the researchers are. </li>
<li>P2536: Seems to be baiting</li>
<li>P2539: Yes I think it would be worthwhile and is an academic setting. The password information is for University websites.</li>
<li>P2542: See my reasoning above.</li>
<li>P2543: The information is not going to help anybody and the methods are experimenting with personal information and trust.</li>
<li>P2545: Again, I am having issues with how much personal information is being obtained by the researchers. </li>
<li>P2547: Because there is some risk in actually intentionally gaining the password of some people. This is what "phishers" do, and it is kind of the same thing- tricking someone in to giving you their password. </li>
<li>P2549: Notify anyone who may be used as the identity for the friendly email so they can opt out.</li>
<li>P2550: Because you are collecting passwords you must be very careful in keeping that information safe. </li>
<li>P2555: they are actually using the passwords, that is unethical</li>
<li>P2556: do not like this experiment</li>
<li>P2558: It's for a good cause.</li>
<li>P2561: There is intrusion of privacy. Using someone else's Facebook information should not be allowed for any purpose. </li>
<li>P2563: Knowledge & consent should always be given for any experiment or survey.</li>
<li>P2565: Could do more harm than good</li>
<li>P2571: ok</li>
<li>P2572: I think it would be good information to study</li>
<li>P2574: This is a hard one. I feel like the end result would be helpful, but it could really stress people out. </li>
<li>P2575: Too much confidential information to obtain for study.</li>
<li>P2578: I think it is unethical to send fake communication to people from friends without the friends' permission. It is also unethical to trick people into giving out their passwords.</li>
<li>P2579: We need to learn how to know how to recognize what these websites are.</li>
<li>P2581: Seems like a good experiment, but I worry about the risk to the participants. </li>
<li>P2584: I feel like it would be better if when people clicked on a fraudulent link, if it would just say that it was a fraudulent link and that in a real situation their info could be at risk.. Otherwise people could get really angry</li>
<li>P2586: It seems straightforward enough and limited in sample size to the University. With the caveat that the Students are told about the study after their incidental participation.</li>
<li>P2590: Same reason as stated above. It seems dangerous for the researchers to be allowed to verify that the password obtained is valid. I don't trust them. They shouldn't have access to actual passwords.</li>
<li>P2595: I think the researcher would have to completely explain in the debriefing that the  participant is completely safe. </li>
<li>P2596: how can any victim of this phishing be sure that some researcher wont use their passwords? they cant.</li>
<li>P2599: Phishing is a real threat--most people don't realize it.  This study would bring awareness</li>
<li>P2605: Many students may not want to participate and wouldn't appreciate being automatically opted-in</li>
<li>P2610: You can't guarantee that someone will not take the information and run with it for nefarious purposes.  To even consider doing that sort of collection of information is wrong.</li>
<li>P2612: No no no!!  I consider it stalking to go into Facebook or other social media for such personal information. Even if you belatedly tell someone its for research, you have still given them an actual experience of stalking... meaning that they can and likely will feel violated and suspicious in the future. </li>
<li>P2618: Too much could go wrong. Security and trust would have to be through the roof to pull this off.</li>
<li>P2619: Because the participants are not agreeing to be part of a study, I think this should not be allowed. </li>
<li>P2623: some people may be upset by this experiment</li>
<li>P2638: Seems like a good idea. </li>
<li>P2654: Only if not verifying passwords.</li>
<li>P2674: Would request the participants to change passwords afterwards</li>
<li>P2677: for it's deceptive and represents an invasion of privacy   </li>
<li>P2678: It might be alright if you were collecting trivial information about the test subjects, but not real passwords that you actually check the validity of.</li>
<li>P2684: Because this experiment deals with actually recording the students' private data (passwords) and trying them to see if they actually work, many students could feel violated and, therefore, become upset. I believe this to be an important study, but one where they should tread lightly with the password recordings.</li>
<li>P2686: This seems like a legitimate experiment but I would like to know a bit more before declaring it proceed-worthy or not.</li>
<li>P2688: It is almost certain that the experiment will upset a lot of people, and it should.  Those that are wise enough to see the purpose of the study will eventually benefit from it.</li>
<li>P2689: As above</li>
<li>P2690: so companies can know  where they are when it comes to security</li>
<li>P2691: This is an experiment that harms no one but helps many. </li>
<li>P2692: Come up with a scientific process that does not violate privacy</li>
<li>P2699: To raise awareness of the problem</li>
<li>P2713: The needs to be another way to do this experiment.</li>
<li>P2716: I could also see this being done as a public service to educate the public in regards to phishing/</li>
<li>P2717: I believe it is a great experiment. However, I believe the experimenters should proceed with caution since personal/ protected information will be revealed. </li>
<li>P2723: its not going to cause any harm to anyone</li>
<li>P2727: It is important to get an idea of the likelihood a person is to fall victim to a phishing scheme, however people might be emotionally damaged if they are put through this event during the experiment.  </li>
<li>P2729: I think that this experiment would cause a lot more harm than good. </li>
<li>P2732: Some people may not be happy to learn that they just been used for this experiment. </li>
<li>P2735: This is beneficial and the risk can be easily managed. Participants can opt out if they wish.</li>
<li>P2747: This experiment is putting peoples real passwords at risk who is to say they researchers computer is not stolen or hacked into it happens all the time to credit card companies.</li>
<li>P2750: it sounds dangerous and if anything bad happen they do not want to br responsible</li>
<li>P2757: It seems a little "phishy" (haha, puns) if the researchers have to verify real passwords to real accounts through the University's systems.</li>
<li>P2762: Just not save any personal information (passwords) from the participants.</li>
<li>P2771: There have to be other ways to obtain the info (i.e. asking the person if they've ever fallen victim to phishing, imperfect a method as that may be) without engaging in the deceitful behavior. Also, I think more focus should be put on actually informing people how not to fall for these scams than obtaining a stat for a research paper. </li>
<li>P2777: Why wouldn't they?</li>
<li>P2781: The experiment could be potentially dangerous because it could lead to cyberstalking, bullying etc.</li>
<li>P2787: Im not sure the university will be ok with providing access to passwords, study or not</li>
<li>P2792: I think this is a valid experiment with potentially powerful results and it would cause little to no problems.  Also those that participated and did enter passwords would learn a valuable lesson.</li>
<li>P2793: Only if the participants were made aware first.</li>
<li>P2795: It seems to be very helpful thing to protect people later on down the line.</li>
<li>P2802: Again tricking someone can lead to them doing things that they normally wouldnt and might upset some people.</li>
<li>P2807: Phishing is serious, and there are plenty of opportunities to lose money.</li>
<li>P2811: This is a really good study to help create ways to combat this type of problem.</li>
<li>P2812: invasion of privacy</li>
<li>P2813: this would be a waste of money because what are you trying to prove? obviously if your friend sends you an email you wouldn't expect it to be phishing.</li>
<li>P2818: this could help people</li>
<li>P2819: Because i would like to know the results as well.</li>
<li>P2821: you don't need to study this. they are as old as time. just educate.</li>
<li>P2822: it is not required </li>
<li>P2823: I have received emails supposedly from people on my contact list, but the content of the email was clearly not from the actual person. So it is important for people to know that this technique is being used by phishers. At the same time, I don't think the university students' passwords should actually be taken. That is a security breach. And I don't think the students will trust the statement that the password is not being stored by the researchers. </li>
<li>P2827: It would be great to help raise awareness about fraudulent activity on the internet.</li>
<li>P2828: Again as above, researchers will gain more knowledge about how phishing attacks succeed so they can be prevented - this assumes that all necessary precautions, as outlined in the description about the experiment, are followed</li>
<li>P2829: Who is to say how secure the researchers are?  Giving passwords to a 3rd party is not a good idea.  What if someone stole the researchers computers or hacked into them?  Then someone else would have all the information.</li>
<li>P2830: As long as the email didn't contain any controversial issues and the participant was notified that it was a research study in a timely manner.</li>
<li>P2834: As above.</li>
<li>P2837: This study has too much potential for abuse.  In addition, failure to gain informed consent is dangerous for any psychology study and has the potential to cause psychological harm to participants.</li>
<li>P2838: I do not believe universities would agree to this.  </li>
<li>P2841: I think it's okay to use Facebook info for research</li>
<li>P2844: This research would be very useful to keep students and others from making a mistake and giving out valuable information to a stranger who wants to steal from them.</li>
<li>P2845: Impersonating someone's friends is unethical</li>
<li>P2848: They should be cautious of using personal information</li>
<li>P2850: The participants do not know that they are participating and the use of their own personal information (facebook friends) in this is a little too far. Exploiting people and their information without their consent is too far to justify the good of the experiment. </li>
<li>P2853: I do not think the researchers should go through the facebook account of the person they are researching.</li>
<li>P2856: If there was a well developed pool of people to send the email to. I think it may want to extend beyond students because they are usually more knowledgeable about computer security than say, older computer users.</li>
<li>P2857: Provided they have no direct access to student accounts, then yes. For example, passwords are encrypted and the researchers cant actually see them - only verify thru the university if they were accurate.</li>
<li>P2861: GOOD LEARNING EXPERIENCE</li>
<li>P2869: The results seem like they would be obvious.  </li>
<li>P2874: It is an important condition to explore.</li>
<li>P2875: Seems too dangerous</li>
<li>P2879: They are going to have to invade privacy one way or another in order to assemble a list of likely friends.</li>
<li>P2880: Should be revised.</li>
<li>P2882: I feel like they need to redesign their experiment first.</li>
<li>P2886: This seems unethical to me since you do not have the consent of the people you are studying.</li>
<li>P2888: I think that this experiment could cause a lot of people to become angry. </li>
<li>P2892: they should be careful about who they include</li>
<li>P2893: I don't like the idea of them going through Facebook profiles.</li>
<li>P2896: You cant make people give out their info. </li>
<li>P2905: teach people about phishing and then let the individual TAKE RESPONSIBILITY...something we seem to have forgotten as a culture</li>
<li>P2910: See above.</li>
<li>P2916: I understand they would have to log into there accounts to check the validity of the passwords there phishing collects but I still don't think it should be allowed.</li>
<li>P2920: I suppose the students could change their password afterwards, but many people use the same password for numerous websites so that seems risky.</li>
<li>P2923: I'd want to be careful how you publish the results.  </li>
<li>P2924: this needs to be stopped so it seems important to do</li>
<li>P2929: The information students would be entering would be their real passwords, and on top of that they are actually going to be checked to make sure they are real.  This is very deceptive and should NOT be allowed.  </li>
<li>P2930: You may get some very upset people with this one</li>
<li>P2934: I believe that this is really for the greater good of all the people that will be using the system. Far too many people fall victim to these scams and it would be good to try to do something to fight it.</li>
<li>P2941: This is a bad experiment to conduct as a whole</li>
<li>P2944: Use caution when impersonating people. It might almost be worth it to take a group of students and ask their permission to impersonate them for research and have them sign a non-disclosure.</li>
<li>P2945: The research done could be helpful in making people realize that this problem is easier to fall prey to than they may think.</li>
<li>P2946: Some might get very upset and feel as if they were really decived and the info was used maliciously.</li>
<li>P2948: they're not doing anything bad with it and it's hard to research otherwise</li>
<li>P2955: The procedure used to verify that the passwords entered were valid is worrisome and violates expectations of privacy.</li>
<li>P2956: It could be beneficial.</li>
<li>P2959: Find another way to analyze phishing attacks.  They should be able to find another performance measure.</li>
<li>P2964: Passwords should we ours only</li>
<li>P2979: Data is being protected but I dont know about the ethics</li>
<li>P2982: Ethical and possible legal reasons</li>
<li>P2983: Yes. However, passwords are personal and private property of the users of said account. (This is my personal interpretation. It may not hold legally.) If the information isn't handle carefully, it could compromise many people's financial security.</li>
<li>P2986: phishing is a very bad problem </li>
<li>P3003: It's hard because it's kind of an invasion of privacy.</li>
<li>P3004: I think its dangerous to conduct research without consent.  </li>
<li>P3009: Due to the sensitive nature of the experiment may cause a very (-) reaction among some users.</li>
<li>P3012: It's worth it to learn something</li>
<li>P3028: yes so that students and other who can learn much about this experiment will know how to react and protect them selves.</li>
<li>P3032: It doesn't sound like there is any real risk of harming anyone.</li>
<li>P3034: The researchers will again be exposed to passwords, no record should be kept and then later they should be changed.</li>
<li>P3039: This is too deceiving.</li>
<li>P3043: As long as the student has the option to not participate at some point, I think it's for a good cause. I would like to add I would feel more comfortable if the emails that came from friends were actually from their friends-ie, people were recruited to join the study and were asked to email their friends the phishing link.</li>
<li>P3045: So they can educate people to be careful not to give out important information.</li>
<li>P3046: i think the study is wrong , however , i believe in freedom of research.</li>
<li>P3047: The researchers would be getting passwords.  </li>
<li>P3048: I do not think they should be able to get access to students passwords without permission, or to use students as participants without getting their consent</li>
<li>P3061: They are having it in a controlled setting, and they are going to let them participants know about the research study and conditions of the experiment. I think it could be helpful for the future so more people can be careful and aware of websites and phishers.</li>
<li>P3062: It's a deceitful practice, even if it's a university. For example, evem if you call the branch of your bank, they can't ask for your online banking password.</li>
<li>P3063: As I wrote above, most people fall for phishing e-mails and having subjects that fall right into the hackers "hands" might offer a bit of a wake-up call for those who don't pay attention to shady emails.</li>
<li>P3064: I almost think it would be better to have preventative education on not falling for phishy e-mails.</li>
<li>P3066: actually taking passwords is kind of sketchy</li>
<li>P3068: It will be helpful in the future</li>
<li>P3076: illegal, fuck these guys. they're borderline crackers</li>
<li>P3077: security risk too high</li>
<li>P3079: Although privacy has become less of a priority in this day and age, such a phishing experiment would not be enjoyable to the public. </li>
<li>P3082: It could provide useful physiological information about how the phishing is successful and prevent people's banking information from getting stolen.</li>
<li>P3084: Not harming anyone</li>
<li>P3086: This borders on privacy infringement, and a lot of people could be angry not understanding the point of the research.</li>
<li>P3094: The passwords should not be collected and verified.</li>
<li>P3095: This research will help prevent phishing attacks in the future and is beneficial to society.</li>
<li>P3096: It is far too invasive--with the researchers looking at students' Facebook friends lists and collecting passwords.</li>
<li>P3103: This is flatly unethical, and possibly illegal.</li>
<li>P3110: It seems straightforward, helpful, and noninvasive.</li>
<li>P3117: Any time someone is releasing their password is a risk on both sides but I think the benefit of the study outweighs the risk.</li>
<li>P3121: you shouldn't mess with some one's passwords</li>
<li>P3123: I foresee many University students having an issue with researchers accessing their passwords, but I think this is an important study.</li>
<li>P3125: This seems unethical.</li>
<li>P3126: It's a little more risky than the last, but it doesn't seem like it has a high potential for problems.</li>
<li>P3130: While I can't think of an alternative methodology that doesn't include at least some subterfuge, I still don't like the unseemly nature of the study.</li>
<li>P3132: I think this could benefit everyone. A lot of people fall victim to this phishing scams all the time.</li>
<li>P3148: These jokers need to be put in jail. I realize the high percentage of them don't reside in this country, but the ones that do, hard time.</li>
<li>P3152: This is illegal.</li>
<li>P3155: Unfavorable deception </li>
<li>P3159: It could raise awareness to a problem if necessary.</li>
<li>P3161: Some people may be offended. They should be careful.</li>
<li>P3166: This experiment would be seeking quite a bit of information not normally needed but it could indeed help people become more aware and help improve against phishing.</li>
<li>P3168: Some people may not be upset by it, but I wouldn't be pleased.</li>
<li>P3175: They would have the students' passwords. This idea makes me uncomfortable.</li>
<li>P3177: Yes it is a valid experiment giving the students to opt out after.</li>
<li>P3183: people need to learn not to fall for these scams</li>
<li>P3185: As long as they live up to their word.</li>
<li>P3186: I think this experiment would definitely help to measure how often phishing is performed, and it would help, eventually, to educate people about how to avoid it. But, I think it should definitely be done with caution.</li>
<li>P3193: feels like the students are being taken advantage of by the university</li>
<li>P3196: There is too high a level of deception that comes from not only using a fake website but impersonating a friend.</li>
<li>P3197: be careful with the passwords, make sure no one else gets to them.</li>
<li>P3202: It is a controlled experiment with no known harm to the participants.  IT is a much better venue for a lesson than a real life phishing mistake.</li>
<li>P3208: This seems very invasive. Plus real password information will be captured and potentially stored, which is a security issue all it's own.</li>
<li>P3209: This seems unethical</li>
<li>P3217: It could be tricky if the person truly believes the link is from their friend.  But it would also be interesting to see how people responded to the links.</li>
<li>P3225: Same as above.</li>
<li>P3228: Of course while still following all applicable laws.</li>
<li>P3236: How many people are ignorant to the schemes of people?  Some people are both ignorant and overly trusting.</li>
<li>P3238: It is just too unethical of an experiment even if it is for a good cause.</li>
<li>P3240: They need to find how better to control phishing. This is a good way to do it since technically noone or their computer is harmed.</li>
<li>P3243: Yes provided a warning was published in advance</li>
<li>P3245: I don't see any disclaimer that passwords won't be actually recorded. </li>
<li>P3246: some passwords are multifunctional, and they could violate the privacy of the participants</li>
<li>P3247: No way should you impersonate anyone</li>
<li>P3258: It has to be a closely monitored experiment, as people's information is being used.</li>
<li>P3259: its a well contained and safe study</li>
<li>P3260: Researches should not be given confidential information without permission like passwords.</li>
<li>P3269: While the overall experiment would be insightful, I don't think that validating passwords with the university system is ethical.</li>
<li>P3274: it does not matter</li>
<li>P3275: This experiment does no harm to any participants and would be helpful in the study on phishing.   </li>
<li>P3276: Doing so will mean that the researchers truly have access to personal information.</li>
<li>P3289: It may give some of the participants a wake up call!</li>
<li>P3296: Obviously, it is important they respect privacy.</li>
<li>P3301: While phishing is a problem, I feel this is a very intrusive experiment. I cannot decide if the good outweighs the bad.</li>
<li>P3306: The researchers are committing fraud</li>
<li>P3311: The only issue I have is the invasion of using someone's Facebook profile.  I know it's public knowledge, but knowingly pretending to be someone that person knows feels like it crosses a line.</li>
<li>P3313: They don't say anything about them not collecting the passwords or informing anyone.</li>
<li>P3314: The results could help many people</li>
<li>P3316: The experiment is important and any results might be important.</li>
<li>P3319: I think there would need to be an incredible amount of effort put into keeping the information confidential. </li>
<li>P3320: There are checks, balances and informed consent on this one, so I think it would be okay to do. </li>
<li>P3325: Some people may think the researchers are just a scam and trying to get people's information. This may ruin their reputation.</li>
<li>P3326: Could be considered fraud.</li>
<li>P3328: once again I believe a password should remain only with the individual</li>
<li>P3331: It would let people know what type of scams are out there.</li>
<li>P3333: Who knows what damage this experiment might cause? It might destroy friendships.</li>
<li>P3338: This is a huge invasion of personal privacy.</li>
<li>P3340: A valuable lesson.</li>
<li>P3341: Since no prior informed consent</li>
<li>P3343: It's a valid study that could be beneficial in the long run.</li>
<li>P3346: Precautions need to be taken to ensure no one else can get the passwords. For instance, the passwords should not be kept.</li>
<li>P3347: While I agree it can be an important study, I feel it's just too much of an invasion of privacy. Tracking the success of the link from a friend and a stranger is one thing, but to extract their password and validate it is another. I feel the latter is crossing the line.</li>
<li>P3354: I don't think it's ethical for the university to collaborate with the researchers to confirm the passwords.</li>
<li>P3358: Full disclosure with participant in clear terms</li>
<li>P3359: Make sure people involved in the study know whats going on afterwards.</li>
<li>P3360: as i stated before, i feel facebook is a 2 way screen.  one should give up privacy if one wants to interact with facebook.  it is naive to think everything is as it appears to be </li>
<li>P3367: It will help defeat theives.</li>
<li>P3373: I am convinced that this research is important in reducing the prevalence of phishing.</li>
<li>P3378: If it comes out in a scientific paper or just out to the community, they may feel like their privacy isn't sealed</li>
<li>P3379: My concern about this experiment is that people's privacy will be violated.  At the some time, I think the research could be very beneficial.</li>
<li>P3387: See above</li>
<li>P3389: Impersonating people is not okay. </li>
<li>P3391: This sounds unethical and the passwords could be missued</li>
<li>P3393: I think that an experiment like this will not only bring attention to such a scam, but also better prepare people to be aware of it at no real cost to them.</li>
<li>P3397: phishing can result in major dollar loss, also bad credit ratings</li>
<li>P3402: yes, they should be allowed to continue with the experiment</li>
<li>P3403: I feel like it is a little sketchy looking at someones facebook account to find their friends without their permission</li>
<li>P3408: N/A.</li>
<li>P3411: with caution to ensure the risk is totally minimized or eliminated.</li>
<li>P3413: So they would be able to publish recommendations to help users better learn to recognize such phishing attacks.</li>
<li>P3416: I would not trust this experiment.</li>
<li>P3426: Yes, there are no real risks involved and it's a good chance to educate people.</li>
<li>P3427: Phishing is a huge problem and it is often hard to tell you are being targeted. A study that links a relationship between a person being more apt to respond to a trusted party can help build education on phishing attempts.</li>
<li>P3428:  Again, no scientific or useful results means it should not be conducted.</li>
<li>P3431: It's still a good idea that I could see being used for the benefit of potential phishing targets.  Which is pretty much everyone with an e-mail account.</li>
<li>P3434: Passwords can be sensitive information, so students may be upset if they figure out their password was accessed by someone other than the university.</li>
<li>P3438: They should be sure not to give away any information about the candidates.</li>
<li>P3440: It could put the participants at risk.</li>
<li>P3442: It's a potential useful experiment and will not result in harm to the subjects. </li>
<li>P3445: If this study takes place, the researcher must ensure that all of the participants' passwords and private information are deleted and they remain private.</li>
<li>P3447: This is an important thing to study, and there is no danger</li>
<li>P3451: As long as students have the option to opt out if desired</li>
<li>P3453: Liability issues could make this a rough one.</li>
<li>P3456: These students did not sign up for this experiment.</li>
<li>P3460: TO HELP </li>
<li>P3462: Verifying the passwords means that they do have personal information of value gained through dishonest means</li>
<li>P3463: I would be worried that a friend who received a fake email from another "friend" would take the study the wrong way and confront them about an email they did not send.</li>
<li>P3467: As stated in the previous answer, it is an invasion of privacy. Just tell people not to give out their passwords. I have never been asked to and think it would be weird if a website asked for it. It already has it, I am usually the one asking for it because I forgot it.</li>
<li>P3469: I appreciate the participants will have the opportunity to have their information taken out of the study.</li>
<li>P3472: Just not with my name on it.</li>
<li>P3482: You have no business making someone a subject of your experiment without their consent or permission.  It's morally unacceptable.  There has to be another, better, less reprehensible way to collect this data.</li>
<li>P3483: I question the ethics of it.</li>
<li>P3487: The context of this project is already something of a no-brainer. People should know NOT to divulge password info. Writing a warning for this scenerio would not require this sort of experiment if it was worded well.</li>
<li>P3489: I would not want to be a participant</li>
<li>P3491: I am sure that there would likely be no real information compromised, but it just seems too risky. </li>
<li>P3495: I believe it will help people in the long run.</li>
<li>P3498: Giving out the personal information of students/participants in the research as well as their friends through Facebook is an invasion of privacy.</li>
<li>P3503: Because I feel that this is somewhat invasive and probably wont show how often users fall victim to phishing attacks because phishing attacks are usually from large organizations and very rarely personalized I don't see how impersonating a friend could get information that anyone performing a phishing scam could want.  </li>
<li>P3508: They would need to find out if it is illegal for them to do this first.</li>
<li>P3510: Do not trust them even for the study.</li>
<li>P3516: Most people will probably delete the e-mail thinking it a scam to begin with so the research will be inconclusive.</li>
<li>P3518: Must be careful with how much information you take from the users</li>
<li>P3520: they will have the students' passwords</li>
<li>P3525: As long as they don't use the information for ill purposes, they should be able to collect and keep the data they receive.</li>
<li>P3529: finding someones friends on Facebook for the purpose of research (although it is public information) just seems unethical to me.  You are targeting the audience of the research too much.</li>
<li>P3532: I believe such a thing could ruin friendships.</li>
<li>P3534: Given university approval and extra care for privacy, and perhaps compensation for the participants, it seems that this experiment would provide useful information to the public at large.</li>
<li>P3536: Seems well within the bounds of an experiment. Furthermore, I think this would be useful knowledge for the general public--people should know how to protect themselves.</li></ul>	</div>
</div>

<div class='cap' style='max-width:30%;'>
	<div class='header closed'>WarningsDeception study, answers to Proceed question</div>
	<div class='body'>
<ul><li>P3: I believe the reasons for it are necessary.</li>
<li>P6: Because they disclose all of what happened and is not intended to keep it from them.</li>
<li>P11: it seems unnecessary</li>
<li>P12: The researchers need to exercise extreme caution in protecting the participants, if that is done then they should be allowed to proceed.</li>
<li>P15: Because I believe the experimenters were careful when designing all aspects of the experiment so that participants would not come to any harm.</li>
<li>P16: I think it will benefit people in the long run but I dont want my security to be compromised any.</li>
<li>P20: As long as the researchers followed established guidelines and rules of ethics then there is no issue.</li>
<li>P21: See comments above.</li>
<li>P27: This seems fine to me, I see no issues with the manner in which the research is to be done.</li>
<li>P33: seems ok</li>
<li>P43: As lose as they disclose that nothing is wrong at the end of the experiment, this seems safe. </li>
<li>P52: It's interesting and not hurting anyone.</li>
<li>P54: I don't think that this experiment would cause any harm, and the participants are shown the true purpose of the study afterward. This seems to be an ethical experiment.</li>
<li>P55: I think the study is sound as given by the answers above, but I don't know who the computer security researchers are and who they are with. Maybe if I knew who they were representing, it might make or break the determination.</li>
<li>P56: Researchers will gain valuable information about how to present security warnings. They can use this information to make effective warnings that help people avoid real security risks.</li>
<li>P59: The research will actually provide better security warnings and that can save people from damaging their computers and software.</li>
<li>P61: yes, as it would produce a more effective security warning system</li>
<li>P65: I would want to know what they are doing with people's financial information that is being used to purchase things, is this webpage encrypted?</li>
<li>P69: AS LONG AS NOT LAWS ARE BROKEN</li>
<li>P75: no harm is caused and I agree that if people knew the real reason of the test there answers will change</li>
<li>P77: See above.</li>
<li>P80: It's ethical and helpful.</li>
<li>P84: getting too much information</li>
<li>P96: It would be beneficial and there are no real security risks.</li>
<li>P97: It's good that they are keeping it anonymous.</li>
<li>P101: Yes, I believe they should be allowed to proceed because no one is at risk and neither is their information.</li>
<li>P106: Yes, for the same reasons above.</li>
<li>P117: I don't know enough about the "false warning" to decide.  If I got a security warning on my computer there is a good chance I would try to do something about it.  Doing that when there is no real problem could harm my computer.</li>
<li>P119: It's misleading</li>
<li>P122: I would like to see this helping with internet security.</li>
<li>P132: I know that it would be hard to conduct a proper scientific experiment otherwise. </li>
<li>P135: Improving security warnings is important. This seems like a good way for researchers to find ways to improve them.</li>
<li>P136: It seems like many participants would just return the HIT with the present security risk.</li>
<li>P143: I don't see any harm. Although, I think most MTurk participants will ditch any HIT where they encounter a security warning of any kind.</li>
<li>P152: It shows the participants the benefits and risks of using/not using proper online security.</li>
<li>P156: Once again this is a violating of our privacy and rights.</li>
<li>P159: Warning subjects that their Online behavior (and computer security measures) are inadequate could give them the information they need to browse the Internet more safely.</li>
<li>P161: They will have to be aware that many people are just going to discontinue the study when presented with that warning screen so they may not get the results they are searching for</li>
<li>P166: Allow people to see true danger of internet.</li>
<li>P169: At the end of the experiment, researchers should provide participants with an explanation of why their choice of action facing a security risk was either helpful or harmful. This will help them learn about best practices going forward.</li>
<li>P171: Good learning tool for everyone </li>
<li>P179: It's useful research</li>
<li>P181: Exposing these reasons will give hackers and criminals important data for deceiving people in the future. </li>
<li>P183: Procedure unclear, most turkers are okay with being guinea pigs.</li>
<li>P184: The deception used is necessary and relatively harmless, apart from the anxiety provoked. The ends justify the means in this case.</li>
<li>P185: They just need to make sure no one hacks them and infects their stuff</li>
<li>P188: It helps advance technology and no harm is done.</li>
<li>P190: Consent can be given.</li>
<li>P200: This is a harmless information gathering endeavor that puts no one at risk.</li>
<li>P205: There is no risk involved.</li>
<li>P211: it is inportant so that we can keep up with the hackers</li>
<li>P215: You don't want to cause unnecessary stress to the participant</li>
<li>P218: nothing wrong with it.</li>
<li>P220: Everyone isn't interested in participating in a study.</li>
<li>P228: The deception seems a tad wrong and may cause users to return the HIT out of fear, cheating them out of payment, but I think if handled properly this study could be done</li>
<li>P231: The study isn't stealing any information or anything from the participants.  I believe this study is harmless, and should be allowed to continue. </li>
<li>P232: Does not seem to cause any harm</li>
<li>P239: It is only a warnibg if security risk, and nothing actually happens</li>
<li>P242: their research could improve security warnings</li>
<li>P248: This might result to people using MTurk and Amazon doubting the security of the site.  </li>
<li>P253: Ensure they give follow up answers should the reveal incite questions.</li>
<li>P258: Getting people to pay closer attention to security warnings is a good thing.</li>
<li>P270: Participants should at least be informed at the outset that they might be exposed to material that some people might find somewhat frightening.</li>
<li>P271: Why not? I don't know what results they will get, other than commonsensible ones.</li>
<li>P272: Yes, they should proceed, but make sure they tell people it was fake all along.</li>
<li>P275: This actually sounds a responsible way to test something important.</li>
<li>P279: paranoia can manifest in worse ways</li>
<li>P284: i think it will help.</li>
<li>P289: The structure is the same as a lot of surveys that I've taken, though I never took one that involved a security warning.</li>
<li>P291: I think there is validity to the experiment.</li>
<li>P292: I think that there is nothing illegal about it. But the researchers need to be careful in regards to the psychological effect it might have.</li>
<li>P297: I think you'd have to be very careful in doing it</li>
<li>P302: same reasons as above</li>
<li>P308: again because no one is at risk or will be harmed, I think it is ok to proceed</li>
<li>P309: This experiment does not pose any issues.</li>
<li>P313: Once again, the subjects are willing participants in a study.</li>
<li>P314: seems like an interesting study. don't see any problems.</li>
<li>P316: isn't there another way to do it in a more controlled setting, like not on a users personal computer but maybe a computer lab?</li>
<li>P317: I don't want to participate although I wouldn't mind if others participated.</li>
<li>P326: Again, just due to personal information gathered</li>
<li>P327: they are conducting research for further knowledge. if it was going to hurt someone, then the board would not allow the experiment to occur</li>
<li>P334: See above.</li>
<li>P347: It seems to be a worthwhile study which does not appear to present any real problem for the participants.</li>
<li>P350: As said above, I can't think of any negative side effects from this experiment.</li>
<li>P370: I believe it will provide a valuable service to internet users.</li>
<li>P371: I don't see any problem with this experiment.  It might help participants as well as researchers.</li>
<li>P376: I believe that the researchers need to thoughtfully plan this experiment out so it won't anger any students. </li>
<li>P386: Its not a bad idea, but the participants might close out the page and not get paid for their hit, which would be deceptive and wrong.</li>
<li>P391: Everyone has consented and there seems to be no obvious downside.</li>
<li>P402: In order to not compromise the purpose of the study, it would be necessary to give an unrelated task to get accurate results.</li>
<li>P403: The study seems straightforward and beneficial.</li>
<li>P409: What will be learned could be very useful for other internet users.  Obtaining this information is from users who are aware that they are part of a study.  Thus, they will have given their permission to be part of the study without knowing fully how the study works until the end.</li>
<li>P411: I think it will be good </li>
<li>P412: Again, no real threat means that I would support this research.</li>
<li>P415: sometimes people can get in the habit of overlooking security warnings after time has gone by and the need to make them more effective is important</li>
<li>P417: I'd like to know how researchers could immediately inform people who try to withdraw that the threat wasn't real</li>
<li>P418: For research purpose in a contained test yes.</li>
<li>P422: If researchers need this information to make security warnings more effective, than this experiment seems necessary. </li>
<li>P425: I believe that security is a moving target and we need to keep up with it.</li>
<li>P427: Yes, I do.  They are not digging up passwords or personal information by doing this experiment.</li>
<li>P428: Ensure that no security risk is being transfered</li>
<li>P429: seems pretty safe</li>
<li>P437: As long as they follow their guidelines and the laws.</li>
<li>P439: The described scenario is an effective way to accurately measure user response in a realistic manner.</li>
<li>P444: It´s the only way he can get results</li>
<li>P446: it would be nice to have stronger security warnings</li>
<li>P449: doesn't cause any damage</li>
<li>P450: Might be okay if the participants signed for this type of experiment otherwise it can be a bad idea. </li>
<li>P453: yes no one gets hurt.</li>
<li>P462: An ethical review board is necessary.</li>
<li>P467: This seems harmless to the person being tested.</li>
<li>P470: I believe that they should push forward with the experiment because the research is highly needed.</li>
<li>P472: Caution so that some users don't go too far trying to face the threat</li>
<li>P473: I believe that with caution the experiment can happen. </li>
<li>P475: I know people who ignore security warnings if they're not "stern" enough and frankly, anything to force them to be smarter is a-ok by me.</li>
<li>P480: the more we know the better</li>
<li>P485: I'm just really not sure if there is any invasion of privacy here. otherwise, go for it!</li>
<li>P486: Safeguards are in place and there is no actual security risk. </li>
<li>P488: This experiment would have real value. I believe people don't take threats seriously these days.</li>
<li>P496: As long as they're not exposing people to actual security risks, it sounds fine. </li>
<li>P505: This doesnt seem too harmful but I can see it upsetting some people.</li>
<li>P513: There is nothing but good things that will come out of this. </li>
<li>P515: It's important for computer users to read and understand security warning messages.  I believe that this experiment could help researches find the type of warnings that will work best for users.</li>
<li>P517: This could help future potential computer users avoid computer viruses. All computer virus research should be monitored closely including this in case errors are made.</li>
<li>P519: I have no preference really.</li>
<li>P525: Again if there is no real risk I see no harm in the deception.</li>
<li>P528: Important statistic that is difficult to achieve without deception. </li>
<li>P531: The experiment doesn't harm anyone.  The outcome is important to all computer users.</li>
<li>P532: It's just showing people a security warning and seeing how they react to it, right? I don't see any issue.</li>
<li>P538: It doesn't really have too much potential to do a lot of harm.</li>
<li>P539: Nothing personal here to get anyone upset.</li>
<li>P548: I think it would be very helpful. Security is a major issue. </li>
<li>P553: Yes indeed if it helps users online to be warned of a security issue I think by all means to allow this to happen.</li>
<li>P554: A security warning will scare a few people. These people may not be willing to take the risk.</li>
<li>P555: There would nbot be a security risk to any of the participants. The information gained by this research could help to determine the most effective warnings that would be most effective in users avoiding a real security risk</li>
<li>P558: It sounds like there's no harm done at any point.</li>
<li>P561: Security is very important</li>
<li>P569: They should assure that participants are anonymous.</li>
<li>P573: As stated before, raising awareness is always a good thing, and to quantify what typically happens to present it in real-world terms, would do a lot of good.</li>
<li>P576: This wastes peoples time, which is just rude.</li>
<li>P578: I might be OK with it if it were on total strangers.  I wouldn't want it done to someone I cared about.</li>
<li>P583: Awareness</li>
<li>P590: I don't see any issues with this one.</li>
<li>P591: don't see any harm</li>
<li>P594: I believe that researchers can improve the effectiveness of future security warnings in ways other than deceiving people in an experiment. </li>
<li>P599: This one seems less intrusive and more helpful</li>
<li>P603: I see this as completely harmless to the participants and a good source of material to make security warnings more meaningful and/or approachable to end users.</li>
<li>P606: Again, as long as there is no real risk and there is a way to end the task after believing a security risk is occurring, then I see no problem with it. </li>
<li>P608: It needs to be done. Too many risks out there right now. This will help reduce the number of victims from cyber attacks. </li>
<li>P610: by disclosing it was an experment</li>
<li>P612: I think it is a good experiment but they need to use another method that doesn't involve deceiving people.</li>
<li>P622: yes I don't really see too much risk.</li>
<li>P628: No harm in the experiment, information is useful.</li>
<li>P629: As explained above, no risk with great data.</li>
<li>P631: I'm not sure I understand. After being presented a warning will they measure if people go ahead with the task? If that's the case, and they aren't actually in any danger, I suppose that would be ok.</li>
<li>P633: See above. </li>
<li>P634: Confidential information is always a sensitive matter.</li>
<li>P643: yes, I do not think the experiment is unethical</li>
<li>P646: I wouldn't want to do it but I am curious to see the results of this finding. More that perhaps different types of "warnings" have different effects in general.</li>
<li>P647: Seems like a safe experiment. No collection of personal data. In psychological surveys, there are deceptions but the true nature of the test is revealed in the end. I don't see this experiment being too different from a psychological survey.</li>
<li>P652: It allows them to see how people typically react to different security behavior which can be beneficial.</li>
<li>P657: yes, It's just the illusion of danger and you;ll get unbiased results </li>
<li>P658: If there is no threat then there isn't a problem. Some studies require people to be deceived. </li>
<li>P660: No personal information is being given so I think this is ok.</li>
<li>P668: yes there is no risk</li>
<li>P672: Wouldn't be worthwhile. </li>
<li>P678: some people act differently to these sort of situations, a lot of things to factor in, health issues, panic attacks, ect</li>
<li>P682: This practice is deceptive.</li>
<li>P684: It isn't unethical and could be useful for future development</li>
<li>P685: The people are at least agreeing to be part of a survey so I think this is fair.</li>
<li>P688: I think that this information they gather from study will help people be more safe on computers in the future</li>
<li>P689: This would have beneficial results.</li>
<li>P691: It can be very helpful</li>
<li>P692: I could see some participants turning off their computers or unplugging desktops from the wall.  Potential is there to lose other vital information the participant may have been working on.  </li>
<li>P694: its a good study that will help us all</li>
<li>P696: Useful information might come out of this study, so why not?</li>
<li>P702: Maybe this would be better with randon people but I think they need to be cautious because someone may sue them.</li>
<li>P704: I don't believe they will get any data due to participants shutting down the program as soon as they get the security warning.</li>
<li>P705: I don't believe that it is okay to be deceptive of turkers in such a manner.</li>
<li>P708: it is good for people to understand how to deal with different security threats and how the public reacts to them.</li>
<li>P717: Basically for the same reason I stated on the first question, people wasting time when they could have been making money.</li>
<li>P722: People run into this situation and handle it very often, so it wouldn't seem atypical. I see the experiment running smooth, with little or no trouble from participants.</li>
<li>P729: I suppose if it were handled the correct way.</li>
<li>P732: no harm done</li>
<li>P735: Deception is not ethical.</li>
<li>P737: The information collected can be extremely valuable in protecting users in the future</li>
<li>P761: Its unethical, its a gray area.  You cant measure the behavior you want, ethically.</li>
<li>P763: Not knowing the particulars, I believe this experiment could be unethical in the impact it might have on the subjects/participants due to a possible (albeit mild) psychological trauma.  It is possible that it would be benign, but I would have to see the specific messages and context.</li>
<li>P776: I do not see any real problem with a fake security warning.</li>
<li>P780: Awareness </li>
<li>P787: Since there is no risk, they are no doing anything unethical. </li>
<li>P792: Although deception is utilized, it is not harming the participant and the participant is made aware of the deception at the conclusion of the experiment.</li>
<li>P793: I understand why this research is a good idea, but it seems like there should be other ways to do it, maybe...</li>
<li>P794: Although the experiment is a good one, there is a slight ethical problem stating that participants need to be informed of the experiment and any deception they might go through.</li>
<li>P800: Seems like a fair experiment without risk.</li>
<li>P803: There is no risk involved.</li>
<li>P811: This will help the researchers to know which warnings are effective and which ones are not.  This will help them to know which ones to use in the future.</li>
<li>P812: Some people may report them or be unlikely to finish the research because they're worried about a breech in their computer.</li>
<li>P817: I could not trust them with my privacy.</li>
<li>P821: I don't see a problem as long as they are careful and nothing malicious occurs.</li>
<li>P824: yes because it will improve future warnings </li>
<li>P833: This seems pretty safe, and since no actual harm will be done to the participants, I think it can be a good tool for security studies.</li>
<li>P835: No risk.</li>
<li>P836: seems liker they have already thought of the precautions to keep surveyors safe</li>
<li>P837: Care has to be given as to how the potential security risk warning is presented -- if it causes enough concern then the subject may not complete the task (closing all browsers, shutting down software).</li>
<li>P841: This experiment also brings awareness to internet safety and does not harm the participants.</li>
<li>P842: Sometimes you have to be secretive to get results in studies. </li>
<li>P847: As already stated, this experiment poses no risk to the participants. There is no actual threat involved, just a perception thereof.</li>
<li>P861: Because new information can be learned.</li>
<li>P865: i think it could help with security warnings being taken more seriously. </li>
<li>P866: Being carefull.</li>
<li>P870: I believe the researchers should be allowed to proceed with this experiment as long as at the end of the project the participants are told what actually was going on.</li>
<li>P874: Could be a good way to find data about how people make decisions about computer security, which could benefit those who sell online security software</li>
<li>P881: It seems ethically dubious. I don't care for the level of deception.</li>
<li>P882: As I stated above, finding effective security warnings is a worthwhile goal.</li>
<li>P884: I think the more informed we are about this behavior that safer millions of people will be with there private information.</li>
<li>P890: People give their consent to participate in a study. While I think it is OK to use deception in this study, the experimenter needs to handle this in a professional manner and ensure that participants are accurately debriefed. Additionally, they should ask if participants are still OK with their results being used (now that they know the true nature of the study).</li>
<li>P898: the data needed for these experiments outweighs the negative risks</li>
<li>P900: It's ethical.</li>
<li>P901: I don't see any real risk to potential participants, and the study does propose a plan to study a concrete security feature.</li>
<li>P903: The experiment should be allowed to see what is the best way to present security warnings to individuals. </li>
<li>P906: Yes, it allows them to create safer/better products</li>
<li>P912: Be aware that most people will either completly stop b/c of warning or ignore the warnings anyways</li>
<li>P914: I think they should be allowed to continue because there are always security risks when you use your computer.</li>
<li>P921: It is important to gather data in order to adjust security system warnings in the future.</li>
<li>P922: This test has no personal info being drawn from computer and this can help people avoid a bad website.</li>
<li>P925: the only issue I have is stated above - since there is no security risk the only risk is the well-being of the subject</li>
<li>P926: I think this study will reveal important information. </li>
<li>P927: this type of experiment can be conducted in HITs as it would allow the participant to react according to the situation and result would be proper</li>
<li>P934: because it may go too far and somebody will feel offended.</li>
<li>P938: I'd be worried that someone might panic and do something unnecessary/harmful to react to a non-existent threat.</li>
<li>P939: Like I stated above, the experiment for the most part is harmless. But if one is not used to see warnings like this, it may cause stress.</li>
<li>P942: anything that can lead to improved security is worthwhile</li>
<li>P948: Don't actually commit a crime</li>
<li>P951: they should make it very clear there is no risk</li>
<li>P953: This could have very informative results.</li>
<li>P955: I need more information before I would support this study. I am not sure what a "security warning" refers to...someone potentially entering financial info or passwords online that could be compromised by a hacker or party with foul intentions? I do think that revealing the nature of the study to participants following the study is an ethical thing to do. </li>
<li>P957: I do not think researchers should deceive participants in order to participate.</li>
<li>P958: It seems harmless enough and might help to make security more effective on computers.</li>
<li>P960: WIthout any emotional trauma.</li>
<li>P963: Care and established security should be used, with regard to privacy.</li>
<li>P972: It is a security warning. People see them all the time on their browsers and the research seems important.</li>
<li>P984: I don't see any issues with the study.</li>
<li>P989: Old people who use the computer and are not tech savvy may be alarmed by this security warning. </li>
<li>P1004: They are not putting participants at risk.</li>
<li>P1005: You have to understand human behavior to create the programs that can help keep the online environment as safe as possible.</li>
<li>P1016: The research could be interesting..</li>
<li>P1017: as long as its harmless its a good learning experience</li>
<li>P1018: People might get upset if they took this hit.</li>
<li>P1019: The experiment causes no more harm than any other every day activity would.</li>
<li>P1026: There seems minimal risk involved with this experiment. </li>
<li>P1028: Correcting or understand a behavior is necessary work.</li>
<li>P1031: I believe that the results from this experiment are worthwhile. The more effective that a security warning is than the better for computer users. I say go for it, but all experiments should be done with caution. </li>
<li>P1039: It's an important research question and deception is required.</li>
<li>P1041: People should be made more aware of security warnings in order to protect themselves. </li>
<li>P1050: There is no risk of significant harm to the participants.</li>
<li>P1055: This test seems safe,  They will be as controlling as any other test, but they will not be taking other peoples exams, it will just look as if tjey did.</li>
<li>P1056: Yes, it's causing no harm</li>
<li>P1058: Any researcher should proceed with caution. You never know what could happen to people when they feel like they are under duress. </li>
<li>P1059: Again, it doesn't appear to have any real benefits or detriments.</li>
<li>P1062: There are great benefits that could come from this study and the set up seems very straight forward.</li>
<li>P1063: Again, since people would be willing participants it seems ok to me</li>
<li>P1076: It's kind of dishonest...</li>
<li>P1081: I like that the researchers will let the participants know about the research and assure them that their security was not at risk.</li>
<li>P1083: It is important for people to learn that security warnings aren't just some optional message, they are actually warning you for potential scammers.</li>
<li>P1084: It will benefit people in the future if better and more effective warnings are used.</li>
<li>P1088: How else is the data that is needed to be collected?</li>
<li>P1089: I think it offers valuable information, however I feel that there should be some controls with this study to ensure no harms comes to the participants.</li>
<li>P1108: People could get really angry because this isn't what they agreed to. It's a trick. They aren't really in harms way but it might still make them angry.</li>
<li>P1109: It is necessary to explore the topic.</li>
<li>P1110: While the outcome of the research is important, I believe that there are other ways to go about researching the effectiveness of a displayed warning without imitating a security risk. I think too many people would mistakenly believe that they are at risk, abandon the experiment, and download or use programs that are security risks to remedy the false security risk.</li>
<li>P1111: It is important to strengthen computer security.</li>
<li>P1112: It sounds like this could results in better ways to provide security warnings in the future.</li>
<li>P1113: This seems ethically OK, but it'd be bad if a participant ended up get finishing the HIT because of perceived but non-real risk.</li>
<li>P1116: It is good information and no one will be harmed.</li>
<li>P1119: I give full permission for the researchers to proceed with this experiment because they are furthering the cause of science by gathering more data, and without any risk of real danger too. There is nothing to loss, but everything to gain.</li>
<li>P1123: Once again, I think this is an interesting and great experiment, but the researchers should be cautious to make sure that they do not step on any toes. </li>
<li>P1131: No real harm is done and no sensitive information is taken</li>
<li>P1140: It seems very reasonable to me.</li>
<li>P1147: Minimal stress for the participant and any concerns of the participant will be alleviated at the end of the study.</li>
<li>P1157: The risk of inducing potentially life-threatening reactions is too high.</li>
<li>P1158: Participants are willing, and no harm is being done. Rather, it will help them as well as others.</li>
<li>P1162: It is a good idea to study how to make computers safer for people</li>
<li>P1163: I believe the researchers should be allowed to go through with this experiment. The results will be very beneficial in progression of security. </li>
<li>P1165: I really don't know.  I don't want them to, but perhaps this is the only way they can test the different types.  I think you should ask us Turkers which security warning we think will be the best instead!</li>
<li>P1174: i dunno</li>
<li>P1177: As long as there is no real danger.</li>
<li>P1178: I think that researchers should be very careful how they approach this task because people are very wary of computer security.</li>
<li>P1179: It would give valuable real world information that would be helpful. </li>
<li>P1191: So long as there is absolutely no risk to the subjects, this can definitely shed some light on how those unaware use the internet and how compromised their security might be.</li>
<li>P1192: I doubt there's any beneficial information to be learned from this experiment.</li>
<li>P1196: This test does not put the users at risk.</li>
<li>P1197: I see no problem with this.</li>
<li>P1203: The data would be useful. </li>
<li>P1206: Sounds like a reasonable experiment. </li>
<li>P1209: This seems much more acceptable than the previous scenarios. </li>
<li>P1211: No one is ever fully trusting of those types of messages. Moreover, people are wary of security risks on their computers. </li>
<li>P1214: It is deceitful and could cause mental trauma to one who receives a message.</li>
<li>P1216: The research is useful and the experiment describe is not ethically problematic.</li>
<li>P1217: The warning has to be presented in such a way that participants don't immediately shut down the program and think their computers are bugged</li>
<li>P1220: This task is dangerous and complicated. I believe that the study should be permitted with caution.</li>
<li>P1227: This would have to be done very carefully. I know if I personally ran across a hit that led me to a security warning I would return the hit immediately and close the web page. Again, Mturk users also tend to be more technologically advanced than your average person as well, potentially skewing the results of this study. </li>
<li>P1229: is a good way to see how people act in a computer threat situation</li>
<li>P1230: As long as there is no real threat I don't see the problem.</li>
<li>P1231: The only way researchers will find out anything is do experiments.</li>
<li>P1233: This study could open users' eyes to the dangers on the internet.</li>
<li>P1238: It doesn't really hurt anyone</li>
<li>P1242: I think researchers should be allowed to proceed, but let somebody close to the participant know what is going on, just in case it goes too far, because I would not want anybody to get themselves in real danger.</li>
<li>P1245: Again, make sure there is no violation of ethical codes</li>
<li>P1247: The risks seem minimal.</li>
<li>P1248: I don't see any real risk involved to any of the participants in this type of study.</li>
<li>P1253: I see no problem as the participants are not being lied to.</li>
<li>P1260: I am not sure. I can see the benefits but I can also see the risk. I don't like experiments that aren't upfront about what the purpose is. </li>
<li>P1261: I see no problem at all with this experiment. </li>
<li>P1264: Please see previous response.</li>
<li>P1266: It could be educational and would be within a controlled environment and system of the hits.</li>
<li>P1267: As long as they notify the participants. </li>
<li>P1269: This is a valuable research project.</li>
<li>P1270: no information is being used that could really cause harm</li>
<li>P1272: As always there needs to be severe checks & balances in place for something like this to prevent the "researchers" from putting cryptocurrency mining software on the users computer.</li>
<li>P1288: I would likely return the hit and warn people via Turk Opticon that there was a security risk.  </li>
<li>P1289: computer security warnings need to be as effective as possible and this is one way to make them better</li>
<li>P1295: Bad idea overall.</li>
<li>P1296: More people need to learn computer/web safety.</li>
<li>P1300: To increase security awareness.</li>
<li>P1301: It will raise people's awareness.</li>
<li>P1309: Completely ethical and debriefs participants</li>
<li>P1316: Seems safe.</li>
<li>P1318: It is in the name of science.</li>
<li>P1326: The participants are informed afterwards.</li>
<li>P1328: It seems fair</li>
<li>P1330: This seems like an interesting experiment.</li>
<li>P1331: I don't see how it is any harm so I think it's okay to have this type of experiment.</li>
<li>P1332: It seems mostly safe, and I can't think of any problems. But they have to agree to being tricked like that.</li>
<li>P1340: Yes but the researchers should not contact people about viewing their security preferences. </li>
<li>P1343: It seems to be a reasonable study. </li>
<li>P1346: I trust the researchers and think that the experiment is needed to help further insure internet security for everyone.</li>
<li>P1357: Potential psychological harm</li>
<li>P1360: I think that this is important because it will help users become more aware of warnings that they should be paying attention to.</li>
<li>P1371: Participants are debriefed, no ethical problems</li>
<li>P1374: I see this as a net positive, both in data gained and in informing the public.</li>
<li>P1386: People don't like getting security warnings in HITS, so they will most likely abandon the hit, and then the researcher(s) may not be able to collect their data.</li>
<li>P1389: As long as the security threat is only perceived and not real, I see no reason the researchers should not be able to proceed.</li>
<li>P1400: I would be concerned that someone would exit the survey before learning that the threat really wasn't a threat. They may decide to purchase software or shut down their computer.</li>
<li>P1406: It helps that the truth is revealed, and the results published though it is uncomfortable to be deceived.</li>
<li>P1419: After the research is done the participant would be advised of the deception and the purpose of not disclosing the reason for the deception.  The participant would definitely perform differently if they had any ideas of being under review.  </li>
<li>P1421: I think it is a good study and has some positive benefits to it.  I hope it leads to helping people be more aware of security risks</li>
<li>P1427: I usually ignore a lot of those security warning. Its be interesting to know which warning actually get a response. </li>
<li>P1432: Educating people about issues like computer security is important, especially since there are lots of viruses that can act like security software</li>
<li>P1433: I don't see any problems with it.</li>
<li>P1438: Seems like it would provide useful information.</li>
<li>P1446: Our security is important.</li>
<li>P1452: Good learning experience</li>
<li>P1456: Surely but only as long as no "Real Penetration" of the Computer or Violations of the firewall and security software take place sic!,.</li>
<li>P1462: The results can lead to security warning changes that can benefit all computer users.</li>
<li>P1465: It could be extremely beneficial.</li>
<li>P1470: I am beginning to suspect that this is such an exercise, but if it is, then I am giving my permission to be used by continuing to participate.  I believe that the experiment is unnecessary.</li>
<li>P1472: Educate the public!</li>
<li>P1479: No harm can really be done as long as the researchers make sure the health and stability of the participants are okay.</li>
<li>P1486: This research will be beneficial in the future </li>
<li>P1487: As long as participants sign a contract that covers all of these potential issues.</li>
<li>P1488: you have to be careful with the information you are collecting</li>
<li>P1489: Yea it would be good to show people that don't know what one looks like.</li>
<li>P1492: I could see this not working out well. If I were to see a security risk warning pop up during a HIT I would most likely close my browser, flush my cache, and run a malware/virus scan then return the HIT not finishing it. This would have to be designed in such a way so that doesn't happen but that would probably invalidate the results. </li>
<li>P1503: It isn't dangerous and the results will be helpful</li>
<li>P1507: Thats how they can only test out their hypothesis.</li>
<li>P1508: there needs to be stringent protocols in place to make sure that users don't do anything unwarranted in connection to the security warning</li>
<li>P1510: I participated in something remotely similar.  It was a "game" study that involved a fake Silverlight installation popup.  It was quite clearly fake.  But the deception here was terribly unfair.  The HIT paid terribly and only did it because someone said it was just playing games for fun.  It was not.  If you're going to proceed with this, please make sure the compensation is more than fair given the deception.</li>
<li>P1513: It could be beneficial but I would be cautious.</li>
<li>P1514: never know what might happen.</li>
<li>P1517: I believe that people might act drastically and completely reset their Operating System when it is not necessary.</li>
<li>P1522: I think this experiment would be absolutely fine for researches to conduct.</li>
<li>P1525: A bit deceptive, but it still teaches us to be aware</li>
<li>P1528: Some people will believe it's real and will exit the survey/study without a proper return and that could affect their account rates.</li>
<li>P1538: There's no harm in completing an experiment of this type.</li>
<li>P1540: I believe that it is okay to do this to collect data.</li>
<li>P1546: It will help people learn how to manage security risks.</li>
<li>P1550: 0</li>
<li>P1552: there are too many different messages to identify risk situation online now, it would be helpful for researchers to identify one that is effective</li>
<li>P1553: Yes, there will be no real harm. </li>
<li>P1554: same</li>
<li>P1556: The full disclosure at the end should go over we'll with the participants.</li>
<li>P1563: Caution not to expose anyone to threats.</li>
<li>P1572: I would wonder if it would make me less trusting on researchers because I would trust that a university HIT would be safe to use.</li>
<li>P1582: You need to be careful as the people may think it is a research type thing in the future when it is not.  But overall most people know not to click on something with a warning so it would be nice to see what is most effective.</li>
<li>P1597: Due to the nature of research sometimes it is necessary to deceive individuals who participate. However, as with any research that requires participates to perform tasks, it is best to be cautious and to make certain that all actions that can be taken by the participants are covered thoroughly during debrief.</li>
<li>P1598: The need to have plans in place to protect the targets' PCs and data and a plan for what to do if they can't. </li>
<li>P1616: I</li>
<li>P1617: I don't think there is anything wrong with it.</li>
<li>P1633: The study seems very safe. I can't imagine anything bad arising from the study coming about. </li>
<li>P1650: always with caution</li>
<li>P1651: There doesn't seem to be any repercussions. </li>
<li>P1655: I see no reason for this study not to be tried as long as there is no real risk to people.</li>
<li>P1657: I like the idea, but again I don't like deception being used.</li>
<li>P1664: The researcher should wight the emotional consequences that the experiment may have.</li>
<li>P1665: should be careful </li>
<li>P1671: I see no reason not to, the study is seeking to measure specific responses under certain conditions, not harmful in any way.</li>
<li>P1674: There doesn't seem to be much possibility of the study going too far wrong, so I think the positives outweigh any negatives</li>
<li>P1680: This experiment is ethical as it eventually reveal to the participants the truth behind the purpose of the study. There's no harm in it either. So researchers should be allowed to proceed, but make sure they abide by the ethical laws.</li>
<li>P1681: Sometimes when it comes to experiments the best way to find answers is to deceive subjects</li>
<li>P1682: When you accept a hit you read over an agreement and then proceed so yes, I think so.</li>
<li>P1683: many people can benefit from this study.</li>
<li>P1704: INCREASING AWA\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nIncreasing awareness of security warnings seems like a good idea and there don't seem to be any down sides.</li>
<li>P1705: it may prevent people from just clicking away</li>
<li>P1707: Scientific experiments are there to increase positive life theories.</li>
<li>P1708: because it's dealing with security risks.</li>
<li>P1709: The researchers should choose their candidates after reviewing them with a screening process.</li>
<li>P1723: It seems like they are pushing antivirus software sales. I function better without antivirus on my computer, but I know some people need to have it.</li>
<li>P1724: Invasion of privacy</li>
<li>P1733: It would be good to know what kinds of security warnings are the most effective. </li>
<li>P1738: I don't know. The problem I see is that the only person I know who does HITs is myself and I know I would respond by immediately terminating the task and so you would have no way of knowing that I took part and quit and I would have no way of being compensated so I would become a bit annoyed so nobody would really benefit.</li>
<li>P1740: Will help uninformed users for there future computer use</li>
<li>P1741: Because anyone who is cautious of security warnings will not continue. </li>
<li>P1744: Its just a warning of a security risk. Not an Actual risk will happen</li>
<li>P1746: This could lead to some really good developments including better ways to warn people of a security threat.</li>
<li>P1751: It's an interesting but risky experiment.</li>
<li>P1753: they are not hurting anyone but in the end may end up helping people. </li>
<li>P1758: It sounds like a fine idea. </li>
<li>P1770: Doesn't seem like it will hurt anything and can gather useful info</li>
<li>P1771: They need to be careful. Some people can get very upset if they feel they have been manipulated.</li>
<li>P1774: I think the study is alright as long as the study takes place as described and the participants are not put in any unnecessarily stressful situations. </li>
<li>P1775: Seems to me the best way to is to be upfront. Tell them it is a security breach test and teach them how to proceed if it were to really happen to them.</li>
<li>P1777: I think it is important to make sure that participants are properly debriefed about the nature of the survey so as to alleviate any possible anxieties they may have about their online privacy.</li>
<li>P1783: People should be briefed accordingly on the details.</li>
<li>P1785: This is too serious an issue to mess around with without telling someone.  You don't know what they may need to keep secure on their computer.</li>
<li>P1786: For the above reason as well as I don't think it is needed to see how other react to security warnings. Most people now have software such as McAfee or other software to warn them and they will always take that seriously. </li>
<li>P1806: Yes because the people know they are there for some for of a experiment just not the one they think they are going to be doing and there are no damaging results to the person or outcome for doing it. </li>
<li>P1808: Make sure the security warning wont make users freak out, exit from the survey, and be unaware of not being at risk</li>
<li>P1811: Yes if the deception is later explained to the participants. </li>
<li>P1814: I think that the panic involved from this experiment would exceed the benefits.</li>
<li>P1821: I think it would be good to know how people react to different security warnings. To see if they will take them seriously or not. </li>
<li>P1835: There is no harm in this experiment and I don't see any reason to be bothered by it</li>
<li>P1837: Research is important as long as there is no real threat of any kind</li>
<li>P1839: There seems to be no personal risk for the subjects</li>
<li>P1848: To provide better security warnings to keep people safe I believe this is a valuable experiment.</li>
<li>P1850: I don't think the experiment would be that deceptive or harming and be beneficial in the end. </li>
<li>P1851: Same as above, and its probably easier to make a fake security warning than a fake spam or password stealing account.</li>
<li>P1853: The people will remain anonymous and there was never a real threat. </li>
<li>P1857: There doesn't seem like there is much actual risk involved in the experiment. The misdirection is explained to the participants and their personal information isn't being compromised, so I don't have any objections to the conduction of the experiment. </li>
<li>P1870: They reveal the deceit at the end of the study, making the deceit okay.</li>
<li>P1871: Again, education is key to practicing safe surfing while online.</li>
<li>P1874: Security is a huge deal, and anything that we can do to improve security, especially while not taking away liberties, is an amazing thing and should be done.</li>
<li>P1876: If they are found out they might be sued.</li>
<li>P1877: I see no harm in it.</li>
<li>P1878: yes because there is no risk and it will be explained to the participants at the end</li>
<li>P1884: Just make sure they are clear about what is happening. </li>
<li>P1890: Yes as long as there would be no risk to participants</li>
<li>P1897: All research should be done with caution.</li>
<li>P1901: understanding how people view security warnings would interesting.</li>
<li>P1904: Online Security is extremely important and most individuals do not realize how their actions online can affect their lives. This would be an excellent way to make people understand.</li>
<li>P1906: You would likely need to screen out the computer-literate. People who know what they're doing with computers will recognize that the security warning doesn't look normal and will think the security warning is a security breach in itself, like malware that disguises itself as an antivirus program. </li>
<li>P1913: Presenting a fake security risk to someone could cause some health issues</li>
<li>P1916: yes they should proceed but with caution in the event that any information that is presented to the participant is not emotionally or mentally dehabilitating in that they experience some type of harm from the deception.</li>
<li>P1917: As long as they let the participant know this is just an experiment I think it is beneficial. </li>
<li>P1920: Developing new and more effective security warnings could be very beneficial to people who are not very computer savvy.</li>
<li>P1934: It seems safe and is therefore okay with me. </li>
<li>P1938: The deception in this case is not quite as unethical, I think, because the stakes are lower.</li>
<li>P1942: There is no danger.</li>
<li>P1951: The researchers are not actually posing a real threat to the user, so I think it would be ok.</li>
<li>P1953: The research seems valuable for learning more about the effectiveness of security warnings, so I would support it.</li>
<li>P1955: I don't think it's a problem, but obviously, people can get pretty worked up about security and security risks of any kind. We don't want people getting TOO worried. :) </li>
<li>P1960: Participants would not be facing any real threat of any kind. </li>
<li>P1963: The sensitive data that is being used is extremely minimal and the possible positive results from this research seem to be very high. I would support this research.</li>
<li>P1977: It is deceitful. I think these types of deceitful experiments are unethical.</li>
<li>P1979: I don't think the researchers should be asking for people's real passwords</li>
<li>P1986: With participants not knowing about it ahead of time, the study has a lower chance of having skewed results, but it could be upsetting to some of the participants, particularly ones who are most likely good candidates for the study.</li>
<li>P1989: I see no moral or ethical dilemmas involved with the experiment.</li>
<li>P1991: I think it's a very interesting and useful survey, but I think it's a very sensitive one that needs to have extra care that there is no real security risk and needs to really fully truly reassure participants that there was no security risk.</li>
<li>P1998: I don't see any major ethical concerns here, so I support this research.</li>
<li>P2001: It's necessary to deceive the participants, but every decision should be scrutinized in creating the study. </li>
<li>P2002: I do not see how this study will provide any useful information.</li>
<li>P2003: The more HITs, the better.</li>
<li>P2025: It is a valid request.</li>
<li>P2026: There is no real risk to this experiment so I think it should be performed. </li>
<li>P2027: i think it would be a good way to test out security procedures</li>
<li>P2032: This could cause someone to tweak a computer that does not need tweaking, possible loss of data and such.</li>
<li>P2040: There is nothing compromising about this study.</li>
<li>P2043: Yes I believe the results are noteworthy</li>
<li>P2048: Increased security it important to me. I am not giving out any personal or valuable information, just information that will protect those things.</li>
<li>P2053: As long as participants are made aware after, I think it would be useful to see what security warnings work and what ones dont work</li>
<li>P2060: They need to know how best to use effective security warnings.</li>
<li>P2061: it help us secure our computer more and make recommendations to avoid this kind of security warnings</li>
<li>P2070: Be cautious about anonymity, otherwise seems harmless</li>
<li>P2072: People tend to lie so they have to do this at times for authenticity.</li>
<li>P2074: Some people may feel violated.</li>
<li>P2082: People are consenting to be a participant.</li>
<li>P2083: There is no harm to come of it.</li>
<li>P2094: This seems beneficial and minimally risky for participants.</li>
<li>P2097: Provided the researchers debrief workers who attempt to exit due to the security warnings, rather than just those who complete the study, which assume requires continuing in spite of the security warnings.</li>
<li>P2100: They do need to be sure to clearly explain the purpose at the conclusion, as indicated in the text above.</li>
<li>P2105: seems okay</li>
<li>P2114: While it is important to study the effectiveness of these warnings, I know people get very anxious over those warnings.</li>
<li>P2117: I see no ethical violation, but people are sensitive and get offended easily. The deception may set someone into nerd-rage. </li>
<li>P2119: Be careful with people's privacy. :-)</li>
<li>P2121: This experiment could have interesting results, that have positive impacts.</li>
<li>P2123: so that no person will feel used and unhappy they should be careful</li>
<li>P2125: No risk is being posed to participants and there will be benefits from conducting the experiment.</li>
<li>P2126: Like I said there is no harm done so I see no reason not to proceed with the experiment</li>
<li>P2130: So that they can obtain what they have been looking for.</li>
<li>P2132: Depends on what they ask.</li>
<li>P2134: It should not be foreseeable that a participant might conduct himself adversely to their normal day or cause stress. </li>
<li>P2135: It's not very risky, and it would be productive.</li>
<li>P2144: It might be psychologically damaging if people truly believe the risks are real. However, it's a simulation so it's not real. </li>
<li>P2149: It seems like it could cause people to panic</li>
<li>P2172: It could only lead to positive results. </li>
<li>P2181: Be careful of how it will affect the participants later in life</li>
<li>P2183: I would worry that the security alert may cause many participants to quit the HIT before completing it or being extremely worried before being reassured by the researchers.</li>
<li>P2189: As long as no real risk is involved.</li>
<li>P2191: This kind of research is harmless and should be allowed in my opinion. </li>
<li>P2194: I don't want to do anything on my computer that might damage it so I would want something done to prevent it.Liek going to a site that may be infected with a virus</li>
<li>P2208: I don't see anything wrong with it.</li>
<li>P2209: It's an invasion of someone's privacy.</li>
<li>P2212: I understand that in some cases the ends justify the means, but I'm not too sure about how i feel regarding this situation. I would honestly say I would be extremely upset if I found out after the fact that i was an candid participant in this type of experiment, and would be potentially upset at the researchers.</li>
<li>P2213: I think it would be interesting to see how people react to security warnings under the guise of an experiment. </li>
<li>P2216: The deception seems harmless</li>
<li>P2218: No. It involves an abuse of trust, and may violate the terms of service or contractual agreements that the Hit is based on.</li>
<li>P2219: This study has the potential to cause alarms for many people. </li>
<li>P2221: It is harmless, with no security threat being present, only a warning of a security threat for the purpose of research. No privacy is violated and the research method sounds viable.</li>
<li>P2227: Science is not a good enough excuse for invading people's privacy. </li>
<li>P2231: This seems to be a very thought out experiment with low risk.</li>
<li>P2233: I don't think this would cause any harm</li>
<li>P2237: They should take all measures that participants are informed.</li>
<li>P2238: Sounds fine.</li>
<li>P2244: If consumers in many cases are not avidly avoiding those warning which can do harm they should be changed in order to adequately convey the seriousness of those warnings. So this research would be helpful.</li>
<li>P2245: People do not like to be deceived.</li>
<li>P2253: It is a good idea for people to know that maybe in general they are not being as cautious as they should be online.</li>
<li>P2254: security is a critical part of safe computer use and should be researched and studied</li>
<li>P2260: Again there is no risk. The only problem would be not telling people the truth. </li>
<li>P2261: It is good to see what type of warnings people will and will not respond to. </li>
<li>P2273: I do not see any harm in this  study.</li>
<li>P2275: make sure participants haven't had panic attacks in past</li>
<li>P2276: The potential gain of this study outweighs the in reality non-existent security risk.</li>
<li>P2280: Again, I think its inherently redundant</li>
<li>P2281: I think a candidate needs to provide their consent.</li>
<li>P2284: Seems harmless even though deception is used.</li>
<li>P2285: I don't see any harm in the experiment so yes</li>
<li>P2286: This should be performed only with a great many checks in place so that it cannot be abused by the researchers. </li>
<li>P2289: This would help realize which warnings actually work with people.</li>
<li>P2302: The results of this are very important.</li>
<li>P2305: I believe it is necessary to deceive people to gather accurate data. No harm will come to people and the situation of receiving a security warning online is fairly common.</li>
<li>P2306: I would be afraid users would return the hit thinking there was an actual security risk. I believe this would be deceiving to users not knowing they are fictitious security warnings. I believe this has not been done in the past because of the misleading nature of it.</li>
<li>P2307: With no real risk, it is a good prompt to expose people to possible risks and reactions.</li>
<li>P2308: I think it's a good experiment. </li>
<li>P2309: Researchers should be certain that the participants have agreed to participate in their study, and during the study, be sure not to intercept personal or private information that the participant may not have agreed to share.</li>
<li>P2314: Security is a big issue these days so the study would be beneficial.</li>
<li>P2316: yes, as long as teach the participants on how to avoid these security warnings. </li>
<li>P2321: It is true the results would be skewed if people knew about the study they would be apart of but it is still deception if they don't know before hand. It is good to tell them at the end but you may lose their trust. </li>
<li>P2324: I don't even see any safety issues with this one. </li>
<li>P2325: Always whenever dealing with security, tread with caution.</li>
<li>P2326: Same as above. No harm no foul.</li>
<li>P2328: There is too much potential for causing harm to participants.  This falls under the provisio that testing people without their consent is wrong.</li>
<li>P2329: no risk, non-invasive</li>
<li>P2330: The experiment does no harm to the participant other than the anxiety potentially created by the faux situation.</li>
<li>P2339: Be aware that many users may just return the hit upon seeing the warning</li>
<li>P2340: I think people should always be informing of what the real purpose of their task.</li>
<li>P2348: It seems well thought out and could be done</li>
<li>P2349: If it improves the security I don't see why not. </li>
<li>P2350: I believe that this study could benefit in the help to design future computer security warnings.</li>
<li>P2351: It seems harmless.</li>
<li>P2354: Yes, the results will be interesting and no one will be identified.</li>
<li>P2357: Make sure the researchers don't steal anyone's personal information.</li>
<li>P2368: I think this is a valid concern, a well thought out process and an effective way of finding answers to solve a real issue.</li>
<li>P2372: To close to institutional behaviour management.</li>
<li>P2378: I don't think there is any risk not to conduct this.</li>
<li>P2382: There's no risk at all to the participants. There is only perceived risk on their end, which is the point of the experiment.</li>
<li>P2386: I think there are other ways to test security measures that do not involve human participants.</li>
<li>P2391: It is harmless</li>
<li>P2392: I would assume they wouldn't say the experiment was stealing your social security number or anything really scary. But as long as the experiment isn't drawn out over multiple days, just half an hour or something, and they tell them at the end that they weren't in danger, it seems fine. I have been in "tricked" experiments before, just not with security. The tester may assume the warning is fake anyway.</li>
<li>P2396: Not being truthful in experiments can be a fine line. However the goals for this seem well meant and could leave to improvements most people will benefit from.</li>
<li>P2397: It is the only way to remove the Reactivity factor from the test and see how people will truly react.</li>
<li>P2401: Since this is done without the knowledge of the participants I believe that full disclosure at the end of the experiment is very important. The caution option was selected because the people in the study may believe that something is legitimately wrong just to find out that it was false. </li>
<li>P2403: Software and things need to be tested by a third party first.</li>
<li>P2408: They have a quality debriefing planned, and deception seems necessary.</li>
<li>P2409: The people will not be exposed to real security risks anyway.</li>
<li>P2411: researchers could be arrested for hacking</li>
<li>P2419: If no one is actually affected I don't see any reason why they shouldn't be allowed to do the experiment. </li>
<li>P2432: Yes the experiment should continue because the participants were never in any harm;So the experiment was all an illusion given that they could receive realistic reactions to a security risk. </li>
<li>P2435: As always we need to be careful about what we put out there and whose hands this fall into.</li>
<li>P2445: The researchers aren't exposing participants to any real risk, so I don't see any harm in it.</li>
<li>P2449: testing for something without the participants knowledge is always risky but in this case i would proceed with it</li>
<li>P2450: Its then only why that we can learn what to watch out for and the researchers can pass it along to us</li>
<li>P2451: The research is important and should be allowed, so long as there is no personal injury.</li>
<li>P2452: The should plan carefully how to execute this research so they don't cause people to panic due to security risk concerns.</li>
<li>P2453: This could lead to more productive ways of warning of risk.</li>
<li>P2456: As long as they are honest at what they did I'm fine with it.</li>
<li>P2457: this seems like a useful experiment it could help people in the future</li>
<li>P2463: As long as personal data is not stored.</li>
<li>P2466: It seems that the information is important to gather, but again, I don't agree with the deception.</li>
<li>P2478: If nobody is going to be hurt by this then why not? </li>
<li>P2480: We need all the research we can get to help us learn more about this topic. In the end consumers will benefit. </li>
<li>P2483: Many people do not understand the risks associated with such computer activity.</li>
<li>P2488: Some people will ignore security warnings at any rate, regardless of the amount of danger involved.  The researchers can't control that.  I do understand that some degree of deception is involved in many experiments; most of the time, this deception does not harm participants in any way.</li>
<li>P2495: it is not really exposing them it is a simulation so yes it should be allowed to show people how things work</li>
<li>P2496: as long as there is no danger for the people taking the survey I think it's fine. </li>
<li>P2501: I think this is a valuable study with no risks, so therefore the experiment should proceed.</li>
<li>P2513: The risk is too great that it could result in stolen information.</li>
<li>P2516: Using deception in a scientific experiment can cause participants to be less trustworthy with future experiments</li>
<li>P2522: I think it's a great experiment and would give lots of good information on the subject so it should be allowed.</li>
<li>P2528: It is important to understand how people react to security issues.</li>
<li>P2530: As long as the researchers aren't trying to harm the participants (like they were doing in the first four scenarios you presented to me), and the participants agree to do this type of study, even under false pretenses, then yes, I would condone it. </li>
<li>P2532: As with any experiment, caution should be used. </li>
<li>P2536: It should be a long term experiment so that people forget they're being monitored.</li>
<li>P2539: I don't think it is necessary to study this issue, it should be obvious how an effective security warning can be presented.</li>
<li>P2542: Identity theft is a huge crime, and if they can find ways to better improve security, I'm all for it.</li>
<li>P2545: I think that after they explain the experiment then they should give the participants the option to have their reaction included. Otherwise I think it is not appropriate to include them if they do not wish to be included. </li>
<li>P2547: Because it can help make people more aware of the risks they take with their computer everyday. </li>
<li>P2549: Make sure that it is clear no damage has been done afterwards. Novice computer users may become alarmed at the security warning.</li>
<li>P2551: I don't see anything wrong with it.</li>
<li>P2555: little bit of deception but not a big deal</li>
<li>P2556: seems harmless</li>
<li>P2561: It does not lead to any harm of the potential participants.</li>
<li>P2563: Knowledge & consent should be given for any experiment or survey.</li>
<li>P2565: People are agreeing to participate in a study when they accept the HIT</li>
<li>P2571: By all means,to test their hypotheses</li>
<li>P2572: I think that this would be an interesting study</li>
<li>P2574: I feel this is an okay experiment and there are really no risks involved. </li>
<li>P2575: How effective is this study?</li>
<li>P2578: Yes, this experiment can be used to learn how to improve security of users.</li>
<li>P2579: I'm not sure if it would be good to do a study when the participants don't know what is really going on</li>
<li>P2581: I don't see any real harm mentally that could come from this. </li>
<li>P2586: It seems like a benign enough experiment, and security warnings often require consent before activating.</li>
<li>P2588: Yes because that would make this decently meta</li>
<li>P2590: With no real security risks, the experiment seems harmless to the participants. It will provide useful information on security warnings.</li>
<li>P2595: I would make sure that the debriefing explains that the participant had to be manipulated in order to get the results that they were looking for.</li>
<li>P2599: Some people might freak out over it--it might be a good idea to ask the participants beforehand if they experience anxiety & whatnot.</li>
<li>P2601: Obviously there is a bit of deception here which may cause some stress for a survey taker concerned about security. But there is no real danger here, so I don't see any problem with the experiment given that there may be no other viable alternatives.</li>
<li>P2605: I don't foresee any risks with this study and the benefits seem good</li>
<li>P2610: I don't think this is invasive, it doesn't retain personal information. and there's a detailed explanation given afterward.</li>
<li>P2612: QUOTE... "If the researchers are not allowed to perform this experiment, they will not be able to measure the effectiveness of different designs for computer security warnings." \r\n\r\nI disagree.  Security breaches happen all the time. Software can be created to record what people actually do... which is much more REAL than any staged situation.  Why not gather real data instead?  </li>
<li>P2617: They should use caution so they don't get their information stolen.</li>
<li>P2618: I think it's fine as long as they take into account how people will react if they do get a security warning. As long as no damage is done it's all good.</li>
<li>P2619: The only drawback I can see is Turkers returning a HIT because of the security warning, rather than continuing to the end. </li>
<li>P2623: I do not feel anyone would be put in any harm</li>
<li>P2626: Reseachers need to be careful that people would not overreact by giving a powerful security risk that could cause them to believe that they are at risk.</li>
<li>P2627: yes i believe they should its the reason being it</li>
<li>P2638: Seems like a good idea. </li>
<li>P2674: yes it would be the only way for accurate results</li>
<li>P2677: because it take a way consent </li>
<li>P2678: A simple and fake security warning probably won't cause a lot of trouble.</li>
<li>P2681: IN THIS EXPERIMENT PEOPLE WILL LESS LIKELY TAKE THE SECURITY RISK IN MY OPINION, IT MAY IMPROVE HOW ONE WILL ACT WHEN A SECURITY WARNING COMES UP  </li>
<li>P2682: Sounds reasonable but needs caution.</li>
<li>P2686: The precautions are very good. There is no harm to the participants of the study.</li>
<li>P2688: This experiment seems quite harmless and could provide some important data to researchers.</li>
<li>P2689: Harmless and will allow collection of data that may be important</li>
<li>P2691: There is no actual risk and it has a lot of potential benefit. </li>
<li>P2692: Why not</li>
<li>P2713: It's important to them. But I don't want to participate.</li>
<li>P2716: Although the users are completing what they think is an unrelated HIT, they are still being compensated for their time.</li>
<li>P2723: its fine with me - it would be interesting to see the results</li>
<li>P2725: no harm is done </li>
<li>P2727: I've done HITs where I was deceived as to the actual nature of the HIT, and maybe on occasion I've felt a little peeved that I was taken in, but mostly I enjoy HITs that manage to trick me a little.  Especially if they disclose the nature of the trick at the end, and it serves a useful purpose.</li>
<li>P2735: Minimal to no risk. Full disclosure at the conclusion.</li>
<li>P2747: this experiment serves a great purpose trying to show how security warnings can grab your attention instead of just clicking on random windows is a very important idea </li>
<li>P2771: They're not actually exposing them to a security risk or obtaining private info (passwords, etc.), so sure. </li>
<li>P2777: I don't see why they shouldn't.</li>
<li>P2781: People might panic when they see the security risk alerts. </li>
<li>P2786: See above.</li>
<li>P2787: Safety measures should be in place in case one of the participants panics and becomes violent</li>
<li>P2792: I think the end result of the research could provide useful information that would enable others to more effectively raise security warnings.</li>
<li>P2793: As with any research it should be with caution, especially one that deals with security issues.  You don't want to alarm people to the point of panic.</li>
<li>P2795: Same thing, let participant withdraw hit if they choose to.</li>
<li>P2802: I think that this experiment could lead to some people being quite upset and distraught over the warnings.</li>
<li>P2804: Of course they should be able to do so as they please.</li>
<li>P2813: The only reason I say with caution is because you cant trust anybody in this world.</li>
<li>P2821: i don't see why not, but you'll be surprised by the results i bet</li>
<li>P2822: i think we should allow</li>
<li>P2823: I worry about the discomfort a security risk message would cause others. At the same time, I like the fact that it can help develop more effective security warnings that will cause users to immediately take the necessary step to eliminate the risk.</li>
<li>P2825: I'm not sure how the researchers will explain the reason for the study if one of the possible reactions to a security threat is to return the HIT uncompleted. Seems like it needs more thought.</li>
<li>P2827: this is a great way to warn someone who would normally ignore warnings.</li>
<li>P2828: Again this will increase knowledge in a dangerous situation and help to make it less dangerous.</li>
<li>P2829: It is stated that there are no real risk.  So what would be the harm?</li>
<li>P2830: I understand the importance of being able to test the security warning, but I believe the researchers need to listen if there are concerns along the way by the participants.</li>
<li>P2834: Seems we get this kind of deception frequently in HIT's. I don't mind I understand the need to not disclose til after task/study is done.</li>
<li>P2837: Researchers must obtain informed consent to avoid causing harm.</li>
<li>P2838: Convincing users to avoid risk can be valuable. </li>
<li>P2844: I think the only way to gain knowledge is to preform these kinds of experiments.</li>
<li>P2850: It is an interesting subject and something that can really have a positive effect for people. I know I personally ignore some warnings that seem like they are fake, and understanding the psychology of that would be helpful. This could cause a person undue stress, so it might be a better option to have them do it on a public computer and not their own personal one.</li>
<li>P2856: no one will be harmed and they will all receive conformation that it was just a study.</li>
<li>P2861: GOOD LEARNING EXPERIENCE FOR SOME PEOPLE</li>
<li>P2865: Seems harmless.</li>
<li>P2874: Helps with computer security messages.</li>
<li>P2882: Participation should be by willingness not deception.</li>
<li>P2886: Yes, because if it is a hit, then the participant has already agreed to participate in some kind of study.</li>
<li>P2888: Seems logical. </li>
<li>P2892: they need to be aware of people trying to hack them or something in retailiation before knowing the truth</li>
<li>P2893: I don't think there are any risks, and any deception will be explained to participants.</li>
<li>P2896: This will help people pay more attention to such warnings </li>
<li>P2910: There's no harm in the experiment and they are only being "deceptive" in the interest of getting valid results.</li>
<li>P2920: I think it's important to have appropriate warnings so people do not fall for such tricks.</li>
<li>P2923: Personally I assume all those pop ups are tricks so I usually shut down the browser when they pop up.  So might not work for some people. </li>
<li>P2929: As long as caution is used and NO REAL INFORMATION/PASSWORDS ARE BEING INPUT then it is possible this will benefit people who may not know about computer security.</li>
<li>P2930: Research is very important and therefor necessary</li>
<li>P2934: It would be unwise to have older participants that have a risk of cardiac arrest. The security warning could startle or frighten them and cause a health issue. Also, if one of the participants starts to panic, other people in the experiment could get hurt. Just a few things to keep in mind.</li>
<li>P2941: This experiment doesn't seem to be too good</li>
<li>P2946: No harm can come of it.</li>
<li>P2956: It could be beneficial.</li>
<li>P2959: I would give them an example of the human factor with pc's.</li>
<li>P2964: Helping them will help us</li>
<li>P2966: It sounds like it might scare people</li>
<li>P2979: No real risk and anonymous data</li>
<li>P3001: Just to be sure nothing bad happens</li>
<li>P3003: This study has great potential to be helpful to protect computer users.</li>
<li>P3008: If done incorrectly, it could cause a fair amount of emotional distress.</li>
<li>P3009: As long as experiment is not too long. There may be possible panic among users if experiment goes on too long & users may end up doing something very drastic to the PC to resolve the "security issue".</li>
<li>P3016: yes, but with caution. they should not make it very risky</li>
<li>P3023: I feel this is less deceiving because the participant's are told at the end of the study the true purposes.</li>
<li>P3028: it can help others to be able to know the difference. now in real life situations they know how to react in that kind of situation.</li>
<li>P3032: Should be made explicitly clear that there is in fact no risk.</li>
<li>P3034: I see nothing wrong with this sort of deception as no one is truly at risk.</li>
<li>P3036: See no danger in this one</li>
<li>P3039: To deceiving.</li>
<li>P3043: Since there is not any personal information being given away, I feel more comfortable with this study.</li>
<li>P3045: It's the only true way they can get the most honest actions from the participants.  Just be careful how they react.  Might need to end study and let them know there's no true risk if they react badly.</li>
<li>P3046: yes , it seems like a valid study.</li>
<li>P3047: To improve the effectiveness of future security warnings. </li>
<li>P3061: They are not allowing the subjects to be harmed, and they are informing them afterwards about the experiment and conditions, so I think it is okay.</li>
<li>P3062: Some people may feel offended that they were deceived, even if they were disclosed all of the information.</li>
<li>P3063: If the average knowledge of the average user were to increase then, in my opinion, the overall need for tech support, at the most basic level, would lessen.</li>
<li>P3066: no true danger</li>
<li>P3068: People might be more cautious on the internet</li>
<li>P3076: Definitely this is useful for studying how people react to warnings. Because a lot of dumb fucks tend to ignore the warnings and bypass their own anti-malware programs.</li>
<li>P3077: this seems to be a safe procedure</li>
<li>P3079: I think it is important information to attain and would benefit the end user. </li>
<li>P3082: If it will help to design better security warnings it seems very useful.</li>
<li>P3084: Again, no one is getting hurt, so yes, they should proceed.</li>
<li>P3095: This research would help improve future security.</li>
<li>P3096: If the researchers are not exposing users to risks or collecting information, they could proceed.</li>
<li>P3099: go ahead. your purpose is not to harm</li>
<li>P3103: Again, ethics issues. The study could cause subjects to take unanticipated actions which might be detrimental to their property, personal security and safety.</li>
<li>P3110: See my answer to the previous question.</li>
<li>P3117: I think that this experiment presents little risk. The security of the participant is not really being breached so a little deception will not be harmful.</li>
<li>P3126: It doesn't seem harmful in any way.</li>
<li>P3130: The stress of thinking your computer is at risk is great.</li>
<li>P3132: I see no harm in this at all.</li>
<li>P3148: Pretty much harmless study. However, I can imagine getting participants that are totally oblivious to the circumstance regarding the study. Almost impossible. So I have the same numbers would be askew</li>
<li>P3152: It is extremely important that they are promptly told that there was a ruse.</li>
<li>P3155: Seems like this could help the general populace</li>
<li>P3159: It could lead to good data.</li>
<li>P3161: It's for the benefit of society.</li>
<li>P3166: When you deal with anyone's personal behavior it is always a good idea to practice safety and smart responding to the security risks</li>
<li>P3170: No long term harms</li>
<li>P3171: There is no danger to the individual.</li>
<li>P3177: Same reason as above, there is nothing wrong with what they are doing.</li>
<li>P3183: so they can teach people about computer security</li>
<li>P3185: I see no reason why not.</li>
<li>P3193: does not feel as invasive since there is no real risk or information gathered</li>
<li>P3202: The study needs to be safe in that it will not actually collect any personal passwords or banking info, etc.</li>
<li>P3208: The research is meant to ultimately help consumers in the future by helping them avoid security risks. There will be no harm to participants and they will likely learn something by participating, which is all good.</li>
<li>P3209: The results need to monitor what the person does after to insure no harm is done</li>
<li>P3217: I'm very curious to see how people would respond.</li>
<li>P3225: See above.</li>
<li>P3228: Considering nothing harmful would actually happen, I do.</li>
<li>P3236: I hope that the people who accept the HIT will be compensated the same</li>
<li>P3240: Otherwise, they wouldn't be able to find which system affects people more. Which system would work betteraccorrding to how peopel eract to it.</li>
<li>P3243: Anything to improve the education of users is a good thing</li>
<li>P3245: I think this would be interesting survey. But I wonder if participant would just return the hit and close the survey if they were "informed" there was a security risk. </li>
<li>P3246: There is no harm that would come to the participants</li>
<li>P3247: The risk is minimal</li>
<li>P3258: To the unsuspecting subject this can be intimidating. After the experiment is over, the subjects need to be assured that this was only an experiment.</li>
<li>P3260: It seems harmless as the security risk isn't real.</li>
<li>P3273: No harm will be done. </li>
<li>P3274: it will not affect me</li>
<li>P3275: This experiment seems to do no harm to the participant and would help in the study of security.  </li>
<li>P3276: Just really need to ensure that there is no risk and that the risk does not appear so great that the participants will back out of the study.</li>
<li>P3289: This is just a touchy situation. If you've ever encountered a warning of this manner, it can be frightening, depending on the severity. </li>
<li>P3299: Learning about security behavior could minimize risk.</li>
<li>P3301: This will aid research in cyber security, which is a huge problem nowadays.</li>
<li>P3306: The participants are not placed at any risk.</li>
<li>P3311: It follows the same answer as before, we need to be aware of the dangers of online.</li>
<li>P3314: People would learn more about security risks, which is beneficial.</li>
<li>P3316: This experiment is important and should be allowed to proceed.</li>
<li>P3319: I think the research is important and presents no threats.</li>
<li>P3320: I think this would be an interesting experiment, actually. </li>
<li>P3322: I see no ethical issues</li>
<li>P3326: If there is no risk, then it would be fine to move on.</li>
<li>P3333: The information about the effectiveness of different security warnings could be of significant value.</li>
<li>P3338: It is ok because it benefits the researcher and the participants. It is not one-sided like the facebook study.</li>
<li>P3340: No harm done.</li>
<li>P3341: No risks beneficial info</li>
<li>P3343: I don't see a problem with it. Again, it would be informative for people.</li>
<li>P3354: It's something that doesn't jeopardize anyone and can improve security for all.</li>
<li>P3358: I see no real concerns here</li>
<li>P3359: Proceed with research but be very careful not to freak people out.</li>
<li>P3360: if researchers want to find out what they want to find out about security warnings, they shoujld be allowed to do it this way</li>
<li>P3373: I am convinced that this type of research is of considerable importance.  If more people were to take warning messages more seriously, computer viruses and account phishing would be less prevalent.</li>
<li>P3378: It shows how people are knowledgable and using that knowledge as they're on the computer</li>
<li>P3379: I think this would be a beneficial experiment and I like that no one's personal information would be violated and that there would be no real threat.</li>
<li>P3387: Unlike the previous two studies mentioned, this one is at least under the framework of a hit, so the participants would be aware of being studied and that makes it acceptable to me. </li>
<li>P3389: It seems that they won't have accurate information about how many people chose not to participate because of the security warnings. Also, it would waste those people's time because they would attempt the task and change their minds and so not get paid. </li>
<li>P3391: It could cause some stress on people that do not have a lot of information about computer security</li>
<li>P3393: This research is important, not just for security overall, but for drawing attention to the issue at hand. This research will allow companies to implement things that prevent such instances and create new dialogs that hackers can't duplicate easily.</li>
<li>P3397: important</li>
<li>P3402: though some deceiving is needed, it is not harmful and should be able to proceed with the study</li>
<li>P3403: It seems like there is no reason not to!</li>
<li>P3408: N/A.</li>
<li>P3412: I don't see any truly negative impacts from a test like this, nor do I see the deceit as anything wrong, given that it's explained at the end.</li>
<li>P3413: Because I support the idea of measuring the effectiveness of different designs for presenting computer security warnings </li>
<li>P3415: I'm all for research, but of course, with the proper caution taken. </li>
<li>P3416: They need to be 100% secure in the warnings they use.</li>
<li>P3426: Yes, there is no real risk to participating.</li>
<li>P3427: Security risks when in an online environment can cause several issues and many people are not aware of just how scary and time consuming a breach in security can be. Any study that can create better warning systems is great.</li>
<li>P3428: Might scare some people, but a useful study.</li>
<li>P3431: I could see people potentially screwing up their computer trying to take immediate measures to counteract the fake security risk.</li>
<li>P3434: There may be some people who become very upset even if there was no risk.</li>
<li>P3438: They aren't exposing any threats. This is a safe and informational study.</li>
<li>P3440: I think it is good that there is no breach of privacy to the participants.</li>
<li>P3442: The experiment is totally ethical and may provide useful results.</li>
<li>P3445: No harm comes to the patients, and the deception is for the greater good.</li>
<li>P3447: Again, there is no danger, there is no reason why they should not do this experiment</li>
<li>P3453: This looks like a simple straight forward experiment where no extra data is needed.</li>
<li>P3456: I also do not see any violation of privacy in this experiment.</li>
<li>P3462: Many users are aware of spam "security risks" that are not from their machine or security and can check</li>
<li>P3463: There is no danger, which participants would read at the end of the HIT, so there is not risk to anyone involved.</li>
<li>P3467: It doesn't sound like anything is compromised. You are just studying reactions and that is all they are giving you.</li>
<li>P3472: i would like to see the results.</li>
<li>P3482: Turkers accepting a hit understand full well that they are being used as lab rats, and are agreeing to serve as such for a fee.  We are often told than an experiment is about one thing when it is really about something else.  We accept this, so long as we're being paid enough to make it worth the aggravation.  </li>
<li>P3483: It is beneficial and no one is in any real harm</li>
<li>P3487: I consider the deception in thi instance to be 'soft' and will not impact the subject at the conclusion of the test.</li>
<li>P3489: Yes, I can't think of a reason why not.</li>
<li>P3491: Again, as long as participants are being briefed afterwards and no personal information is being collected, I see no harm.</li>
<li>P3495: Because it will help people in the long run.</li>
<li>P3498: Yes, so long as people are reassured at the end that the security risk is not real.</li>
<li>P3503: This seems somewhat important to find out and the fact that they will tell people at the end makes it somewhat better.</li>
<li>P3508: It is a harmless experiment and will help improve security.</li>
<li>P3510: Good way to teach with no real harm being done.</li>
<li>P3516: This experiment is interesting.</li>
<li>P3525: The experiment sounds safe, so they should keep the data.</li>
<li>P3526: With all experiments, there are variables that cannot be predicted, so caution is always warranted.</li>
<li>P3532: I believe experiments like this have been done before, and I think they're interesting so why wouldn't they be allowed to proceed?</li>
<li>P3534: see above</li>
<li>P3536: This seems like a very standard experiment so I don't see why not.</li></ul>	</div>
</div>




<hr style='clear:both;'/>

<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<div class='cap' style='max-width:30%;'>
	<div class='header closed'>BotnetSpam study, answers to Surrogate question</div>
	<div class='body'>
<ul><li>P6: I do not like this type of study could really turn people away.</li>
<li>P11: I believe spam is an invasion of privacy</li>
<li>P12: As long as researchers are not collecting any personal information from the participants, I would support the experiment. </li>
<li>P15: I feel as if this experiment is entirely unsafe for participants.</li>
<li>P16: It will help to control SPAM</li>
<li>P20: On the fence on this one but if no payment information is collected then I might say yes. Maybe.</li>
<li>P21: The researchers need to obtain informed consent from the participants.</li>
<li>P27: I don;t see any harm in this research.</li>
<li>P33: Would not want to see them get hurt</li>
<li>P38: While the research would be interesting to see, I wouldn't want any of my friends or family to be messed with like that.  When you start being funny with peoples money, they might get mad.</li>
<li>P43: I feel that this would make people anxious. </li>
<li>P45: This crosses the line by actually infecting someone's computer.  I would not feel confident in others' being able to control the behavior of hackers.</li>
<li>P48: Because they believe they are purchasing something and won't be told otherwise.</li>
<li>P52: Doesn't matter if it's someone I care about.</li>
<li>P54: They haven't given their consent to be a part of the experiment.</li>
<li>P55: This data will not impact the person financially or physically and should be allowed to be carried out.</li>
<li>P56: This does not seem to provide much benefit to the person I care about.</li>
<li>P59: i think that it would not affect the person.</li>
<li>P61: Wouldn't want any loved one to get caught up in any form of spam, whether for research or not. The ones mostly like to do so would be the computer "naïve" ones like older parents or really young ones (teens)</li>
<li>P69: I REALLY DONT UNDERSTAND THIS SCENERIO</li>
<li>P77: I believe it is unethical to conduct any study without the consent of the participants of the study.</li>
<li>P80: Even with researcher control, letting spammers in is not a good idea.</li>
<li>P84: Hopefully people do not respond to spam</li>
<li>P94: Because it would shed some like on something people are not even aware of.</li>
<li>P96: I would not mind them being included as it will benefit the online community as a whole and won't affect them negatively in any way.</li>
<li>P97: I wouldn't want a person I cared about dealing with a spammer because they could easily take their personal information and the researchers wouldn't know because they aren't experts at computer science.</li>
<li>P100: Absolutely not, no explanation should be needed. That is insane.</li>
<li>P101: No, I think there is too much that could go wrong with the experiment.</li>
<li>P102: I don't want them to get a computer virus.</li>
<li>P105: My wife has been the victim of identity theft and the experience was emotionally taxing on her.</li>
<li>P106: Even though it would pain me to see someone I cared about (like my grandmother, for example) duped by scammers, at least it would be in the context of a "safe" spam site and in the pursuit of knowledge that would help develop anti-spam measures in the future.</li>
<li>P117: Will this allow that person's e-mail to become infected?  I don't understand how they will infect only one computer yet the result will be spam in the e-mail of multiple users.  I also have a problem with people believing they have bought something when they really haven't.  What if they have a genuine need for the item "purchased"?  This could cause harm to the participant.</li>
<li>P119: I don't agree with it.</li>
<li>P121: Spam mail sucks</li>
<li>P122: I would not want their private purchasing seen by others.</li>
<li>P124: I would prefer someone I don't know, to take part in such experiments.</li>
<li>P136: There seems to be no process for consent.</li>
<li>P143: The description of the survey is not clear in what will or will not be retained. Specifically, "The researchers will NOT inform users who visit the store to make a purchase that the store has been disabled or that their choice to make a purchase is being recorded" appears to state that that the data will be collected on the purchase (double negative).</li>
<li>P156: If they consent to a study such as this it is there choice.</li>
<li>P157: participants will not be identified and will remain anonymous</li>
<li>P159: Even though the researchers aren't actively collecting participants' information, it's impossible to insure that such information is not collected or used for nefarious purposes (especially if the researcher's computer is compromised).</li>
<li>P161: I wouldn't want someone I know to have to be in a situation like this even if it was in an experiment.</li>
<li>P166: No harm will come to them or their bank account</li>
<li>P169: Even though researchers may not want to send spam, they would still be sending spam. This would be an annoyance.</li>
<li>P171: I'd like to present the finding to elderly family. Especially if they fell for it. </li>
<li>P181: This would open them up to possible hacking of their computers</li>
<li>P183: They are their own person, it's their choice.</li>
<li>P184: The study does not concern me a great deal, although it does result in some inconvenience to the user. I would have no strong opinion.</li>
<li>P185: It does not seem legal.</li>
<li>P188: I do not think it is right in any circumstance to allow an infection regardless if it is controlled or not.</li>
<li>P191: I wouldn't want info getting into the wrong hands</li>
<li>P192: This is completely unethical, and who is to say the researchers really wouldn't keep that information. Do you think that has never happened? 99 percent safe isn't 100.</li>
<li>P198: This could compromise the subjects private information.</li>
<li>P200: This is stupid in total.  No one should do this.</li>
<li>P206: Presumably, these participants are criminals, so...</li>
<li>P211: too stressful</li>
<li>P215: No informed consent</li>
<li>P218: I think there may be problems</li>
<li>P219: I have no problem with this</li>
<li>P220: It's not necessary.</li>
<li>P231: I believe the researchers should just disable the spam entirely from the infected computer.  Allowing unsuspecting participants to try to buy stuff on a store that doesn't work is not really ethical.  I would not want someone I cared for participating in this experiment.</li>
<li>P235: As long as no harm is done, I would not be against it.</li>
<li>P242: to increase the researcher's ability 'empirically measure the effectiveness of spam emails'</li>
<li>P248: In the situation described above, the results of the study will be helpful in understanding the impact of spams, and perhaps, also, result to studies on how people can prevent and protect themselves better against spammers. However, what is the SAFETY NET - OR THE DETERRENT - FOR THE RESEARCHER/S OR ANYONE OF THE researchers becoming a spammer...and take advantage of the information.....if one finds out the benefits that it brings?</li>
<li>P253: IT seems like a scam.</li>
<li>P258: One way or another, they are being scammed. And spammers can outsmart research scientists.</li>
<li>P270: This is a huge privacy issue and an interference with interstate commerce. It's also a total infringement on the 4th Amendment against the right to unreasonable searches and seizures by the government. If your school or program is funded by the government, you could be in violation.  </li>
<li>P271: Their computer is at risk and I can perceive of countless types of mischief that could be created.</li>
<li>P272: The researchers won't inform the users, and no awareness is being raised until the research is published.</li>
<li>P282: Potentially risky. People shouldn't be encouraged to follow spam. </li>
<li>P284: i don't see anything wrong with this experiment.</li>
<li>P289: No, because the participants are not really aware of what is actually taking place. If they did know, then they may decide to decline. It's not fair to the participants, even if the researchers actually learn something useful with this project.</li>
<li>P308: again a very worthwhile study that can help with spammers - and infected computers so I think it would be well worthwhile</li>
<li>P309: The participants need to be notified.</li>
<li>P314: seems like an interesting study. </li>
<li>P316: If this was in a controlled computer lab with the participants un aware of the study prior sound like a good idea. if on personal computer no.</li>
<li>P317: These people are more than likely hackers so it is good to discover how they go about their business</li>
<li>P326: Think that is pushing a bit too far</li>
<li>P334: Hijacking is also illegal, the researchers are actually behaving worse than the spammers.</li>
<li>P335: hmm</li>
<li>P347: I hate spam. any legitimate study that may reduce the amount is welcome</li>
<li>P348: I don't think not informing the users (participants of the experiments) is right.</li>
<li>P350: Since they aren't collecting personal info, I don't see the harm in testing this.</li>
<li>P369: The user should be notified immediately after any purchases of the experiment. They might get angry regardless, however.</li>
<li>P370: I would want them to receive less spam.</li>
<li>P371: They would have no choice as to weather or not they participated.</li>
<li>P376: I think this is a valuable experiment.  I think the researchers need to be careful about infecting a computer though and if there is any repercussions that come with that. </li>
<li>P384: Spam should be illegal.</li>
<li>P388: n/a</li>
<li>P390: They should be informed of what is going on. </li>
<li>P402: I don't see any harms in this experiment. </li>
<li>P403: I think there is some risk involved to them or their fininacial information. I would not encourage them to click on spam links either, it is a dangerous habit.</li>
<li>P406: This is a very one-sided study where the participant is deceived yet doesn't learn anything useful (only the researchers benefit from the info gained) AND the participant isn't informed or given an opt-out at the end.</li>
<li>P409: I do not see how this benefits the user.  Researchers need to find another way to assuage their curiosity</li>
<li>P412: This sounds like a very risky experiment.</li>
<li>P415: seems a little risky at first</li>
<li>P417: I don't think is legal or ethical.</li>
<li>P418: Not sure how I feel about this. I keep my accounts and computer quite protected, so I would prefer it not to be on my computer.</li>
<li>P422: I disagree with the fact that these users believe they are purchasing something that they actually are not. </li>
<li>P425: Yes, If it is for research i can see it. As long as it does no harm. We might even learn something from this.</li>
<li>P427: It's an invasion of privacy so I am against it.</li>
<li>P428: They are not taking any person information and are collecting marketing data.</li>
<li>P429: seems too risky</li>
<li>P437: Sending any virus to a computer can be detrimental, and the survey monitor has too much control.</li>
<li>P442: I guess it would depend on the compensation. </li>
<li>P444: I think it is risky</li>
<li>P446: yes, it is not harming them since this is not a real store</li>
<li>P449: spam email is just annoying</li>
<li>P450: Not worth the risk to get email spams</li>
<li>P453: I think you may save people some money.. because I wonder how many of those are fake anyway.. </li>
<li>P458: Open emails with caution, especially nowadays.</li>
<li>P464: This study is different because it is interfering with the computer user's freedom of movement on the web and is defrauding users to purchase items. </li>
<li>P467: I have to draw the line when someone thinks they are actually buying something.</li>
<li>P470: I wouldnt want someone I cared about to be a candidate for this experiment because it sound as if one little mistake by the researchers and there data would still go to the spammers.</li>
<li>P472: Don't see how it hurts anyone</li>
<li>P473: I said no because that might mess up someone's computer in the process of conducting the research.</li>
<li>P475: Anything to stop spammers.</li>
<li>P480: I would recommend it, so they gain knowledge</li>
<li>P485: sounds sketchy.</li>
<li>P486: The researchers are not actively doing anything to a person. They are simply monitoring what is happening. </li>
<li>P487: Time is valuable to people</li>
<li>P488: I wouldn't want anything bad to happen. Something could go wrong and they could be the victim of identity theft.</li>
<li>P494: No harm, would be done, just wasted time.</li>
<li>P496: This seems like a useless experiment. What qualifies as spam? What about emails from actual legitimate stores? Wouldn't it be just as effective to study how often people purchase from emails that they didn't sign up for but receive from legitimate businesses? </li>
<li>P505: I would be fine with someone I care about being part of this experiment. It doesnt hurt them in any way. </li>
<li>P513: I think that it would be all up to them to be honest. </li>
<li>P515: Spam is annoying and can cause problems for your computer/smartphones.  </li>
<li>P517: It is a choice of the other person's free will that may help improve future computer security and anti-virus software.</li>
<li>P519: I would still be hesitant about the other person's safety.</li>
<li>P525: I think stopping email spam is important for everyone</li>
<li>P529: I wouldn't want them to take the risk with thier computer.</li>
<li>P531: As long as the person's computer will not get infected, I see no risk involved.</li>
<li>P532: I'm not sure I want to know which of my friends or relatives actually follows through on spam mail.</li>
<li>P533: As long as the password data can be assured to be secure and data not retained and as long as the password isn't sensitive like bank password and the data is anonymized</li>
<li>P535: I see this as a data security risk.  If they attempt to purchase and divulge any personal information, this could be a problem.</li>
<li>P538: Cause there is always potential for the researchers to be vulnerable to other security risk and I would not want someone I cared about to experience that.</li>
<li>P539: I would be concerned that receiving spam from an "infected" site could cause further problems down the line.  I would hope that the spammers wouldn't catch on and then totally inundate that person's email with tons of spam.  Privacy problems here?</li>
<li>P541: This is a bit too manipulative and abusive of privacy rights.</li>
<li>P548: I lean towards no on this one because it doesn't seem entirely right for a person to participant in a study without them knowing. However, I don't think it would be harmful for them to participate. It's just the idea of them being involved without knowing that is a bit concerning. </li>
<li>P554: I see nothing wrong with this experiment</li>
<li>P555: I would be concerned that allowing the spammers to infect their computer and then be controlled by the spammers would be result in an inability or difficulity in getting rid of the spammers after the experiment and could do damage to their computer</li>
<li>P558: Because you're still invading someone's privacy!</li>
<li>P562: Although it would be pretty annoying no harm could come from this</li>
<li>P573: I don't believe that this study can help prevent or decrease spam or increase awareness about the dangers of it.  Rather, due to the nature of spam, I would be concerned about the possibility of infecting the computer of someone I care about and possibly increasing the number of REAL spam coming through.</li>
<li>P576: This could damage their personal property. </li>
<li>P578: It seems unethical.  What happens when the person never gets the merchandise they ordered?</li>
<li>P583: Awareness</li>
<li>P590: It seems like the researchers have a lot of confidence in redirecting people to the fake sites.  Seems like this could go wrong.</li>
<li>P591: Wouldn't want them to be taken advantage of</li>
<li>P594: I would not want someone I care about to be a participant because they are being a participant without the knowledge that they are even in an experiment. It violates their rights. </li>
<li>P606: Spam is a dangerous thing and I know how annoying it is to have an email full of it. </li>
<li>P608: No risk involved.</li>
<li>P610: i dont see any harm being done</li>
<li>P612: It's totally up to them. I see no harm in them participating since they will remain anonymous. </li>
<li>P622: computers can get ruined by the spammers.</li>
<li>P626: If they don't give consent, they shouldn't be a part of an experiment.</li>
<li>P628: Would not feel to comfortable with having someones computer infected.</li>
<li>P629: I would have no problem with it. If someone I know falls for a spam site or email I feel they don't deserve any protection or warning from the researchers.</li>
<li>P631: This seems really deceptive.</li>
<li>P633: This seems convoluted but again it's an important issue. </li>
<li>P646: Sounds like a good plan. And the researchers are the ones in the midst of it rather than my friends or myself.</li>
<li>P647: Even today, there are people who are not tech savvy, including many people I know and care about. A research like this will definitely be beneficial, even if it is a little bit deceiving. I trust that a group of computer scientists and or academics will be able to ensure safety of its research participants. </li>
<li>P652: I think it is a little to risky and messing with others computers a little to much. </li>
<li>P656: It won't be of any harm to them or their electronics.</li>
<li>P657: It's intrusive</li>
<li>P660: People could be expecting purchases that will never come or giving out credit card info.</li>
<li>P667: Just that the concept is interesting.</li>
<li>P672: I don't want them clicking on spam links of any kind. </li>
<li>P678: expose these cheap tricks to them</li>
<li>P682: I am leery about data being collected on the internet when it regards possible personal information. I would advise the individual I cared about to not put their personal information out there via spam.</li>
<li>P689: It doesn't seem like it would cause any kind of negative results to the participants.</li>
<li>P691: Sounds risky</li>
<li>P692: I have some concerns with how much total control of those computers the experimenters would have.</li>
<li>P694: very helpful study</li>
<li>P696: The data they seek to collect is not very important, and would open up the researchers to any number of problems if the deception was ever discovered.  Also, no IRB would approve the use of research property to enable spammers to interact with users and collect person data without a disclaimer, the liability would be too great.</li>
<li>P704: Too many variables that could go badly wrong.</li>
<li>P708: I would not want someone I care about to have to deal with Spam at all.</li>
<li>P710: personal choice</li>
<li>P717: I hate spam and wouldnt want them to choose me or anyone I care about.</li>
<li>P721: I think that spam is dumb and that people should have a legitimate job rather than trying to con other people out of their money. </li>
<li>P722: Seems risky.</li>
<li>P729: Seems like it could be helpful in spam detection.</li>
<li>P732: So they can learn to be safe</li>
<li>P735: This is a waste of time for a "participant". They don't know that they are part of the experiment and would most likely opt out.</li>
<li>P737: Again the benefits out weight any risks. Finding a solution to cyber attacks of this nature requires thinking outside the box.</li>
<li>P741: I would be afraid for them that somehow they would be jeopardized</li>
<li>P748: This seems too deceptive, user behavior is monitored without their knowledge.</li>
<li>P749: I don't like the fact that data from their computer is bing used without them knowing about it.</li>
<li>P750: I know someone who would be interested in this research so I would recommend that they be included. </li>
<li>P761: I personally wouldnt want them to be a participant in this sort of study. I believe it borders on ethics.</li>
<li>P763: I just would prefer someone that I care about to be subjected to this experiment. Also, not informing someone who has attempted to make a purchase may lead them to be concerned that their identity or credit information has been stolen.  Research recording a purchase prior to an actual credit card, paypal, or other legitimate payment process would not be a valid attempt to purchase (I put things in a 'shopping cart' all the time, to check shipping rates, etc.).</li>
<li>P765: I would want them to take part but to to be careful on giving out to much information. </li>
<li>P772: Absolutely not. It's deception that can cause real life issues for the victim. The false belief they purchased something can be damaging.</li>
<li>P776: Yes, I would want a persona I care for to participate, as it does not appear to be a large danger since the online store has been disabled and only the researchers wold have access to his/her info.  Perhaps this study could help eliminate Spammers for others.</li>
<li>P780: Its research but its not really important </li>
<li>P784: Since that person would not get hurt, possibly disappointed by not being able to actually buy a product, I think this experiment could be helpful in regards to spamming</li>
<li>P787: I don't like the the people making purchases and getting emails don't know what is happening, nor does it seem like the stores sending spam more. So the whole research seems a little too sneaky. </li>
<li>P794: I would not trust any link in an email unless I could verify that it was legitimate.</li>
<li>P796: To much risk</li>
<li>P797: Doesn't seem to hurt them</li>
<li>P800: Doesn't seem honest, especially the fact that the researchers will not inform users who are trying to make a purchase that store has been disabled.</li>
<li>P803: It would stop them from getting real spam email. </li>
<li>P810: I dislike like the idea of someone else being able to use a personal cmputer that is not theirs.  Allowing ones computer to be infected by spam is another disturbing thought. </li>
<li>P811: It would help them to understand spam and to recognize when someone is trying to steal from them while trying to make you believe they are legitimate.</li>
<li>P812: This one definitely seems to be going too far. The users don't even seem to find out they're taking part in the research.</li>
<li>P816: I think it's a good experiment</li>
<li>P819: Does not matter to me, if they want to be part of it then they can</li>
<li>P820: I would not want someone I cared about to be part of a scamming experiment.</li>
<li>P821: I think it's necessary to test out how hazardous spam is. As long as the participant doesn't lose any valuable information, I see no problem with it.</li>
<li>P824: I wouldn't want someone I care about to be used and cheated for someone else's benefit </li>
<li>P827: so he could be informed</li>
<li>P834: This study could cause problems and inconveniences for its participants.</li>
<li>P835: No risk, learning experience for participants</li>
<li>P836: seems risky for some that are not tech savvy</li>
<li>P837: This model allows collection of data and observations of malware in a safe environment.</li>
<li>P842: This seems risky to me and I wouldn't want them to be part of it. </li>
<li>P845: I don't see any harm in it.</li>
<li>P847: This seems like a safer experiment than the previous one.</li>
<li>P851: Spam email are easy to delete or block if they decide they no longer want to participate. It does not hurt anyone.</li>
<li>P858: I'd rather them get sent to a fake store if they were foolish enough to follow a spam link than the real thing.</li>
<li>P861: This could be misused</li>
<li>P865: it sounds a little risky. i don't like it. </li>
<li>P866: It is not appropiated.</li>
<li>P870: I don't mind being a subject of research or my close ones being the same as far as this is going to be beneficial for helping to reduce spam. </li>
<li>P874: Since participants don't have to risk the health of their own computer in this experiment it seems safe</li>
<li>P882: People would be divulging personal financial information that they might feel required to change after participating in the experiment.</li>
<li>P884: This is an expierement that can only help people, and help using the internet become a safer place.</li>
<li>P886: This seems illegal.</li>
<li>P890: I don't see how this could impact someone (neither positively nor negatively), so it wouldn't matter to me.</li>
<li>P898: most friends i know would not even open the email let alone try to buy something</li>
<li>P899: Sounds benign and shouldn't be harmful</li>
<li>P900: I would rather not but the data that could be obtained from such an experiment could be useful.</li>
<li>P908: I can't see that it would hurt them.</li>
<li>P912: risk for spamming is still there</li>
<li>P914: I would want to the person to be included because I know they would be unbiased.</li>
<li>P925: I would not want someone I know to give out their credit card to someone who is not a valid store - my friend would not receive the merchandise he ordered and would not know why and his credit card informaiton would be out there and could conceivably be compromised</li>
<li>P926: I think that it would be interesting to see the results of this experiment. </li>
<li>P927: as per the whole concept of the experiment, it would be better is this experiment is conducted, and i would not stop my cared on to participate in this experiment. instead i would help in this, i think the concept is good </li>
<li>P930: because if they were the target of span i would rather it be a good group than a bad one</li>
<li>P940: It doesn't seem there are any consequences to being a participant. </li>
<li>P942: Spamming needs to be totally exposed and hopefully stopped</li>
<li>P948: Buy what you want</li>
<li>P951: it is too dangerous</li>
<li>P953: It seems unethical to do this.</li>
<li>P955: Because it sounds a little misleading. I understand the potential value from the data collected during this research (and that it could affect policies in the interest of the consumer), but to manipulate someone's computer usage without their consent doesn't sound quite ethical. Would this be done on a library or public-access computer, I'm guessing?</li>
<li>P957: I think participants in a study should know they are participating in a study and what is happening.</li>
<li>P958: I don't like spam and I wouldn't want anyone I know to receive it. It is annoying.</li>
<li>P963: This data could be effective if the participants are in fact secure (alternative website, no money being exchanged,etc.)</li>
<li>P972: I'm not entirely sure, to be honest. On one hand, it could be useful data but on the other hand, I don't like how users aren't told afterwards. However, if they were already going to a spam link, their information could be used for much worse. I'm really torn on this scenario.</li>
<li>P984: I don't think it would cause any harm, but I probably would prefer not to participate myself.</li>
<li>P986: As long as they are willing to help research move forward.</li>
<li>P989: I would not want someone I cared about to be spammed through their email. </li>
<li>P1004: I do not like the idea that the users who follow spam links are not being informed.</li>
<li>P1005: Again, by looking at data already on the net, this is knowable. </li>
<li>P1010: This research could expose many scammers.</li>
<li>P1016: I would want this person to decide for himself.  I would not want to interfere if this person wanted to participate.</li>
<li>P1017: most people in my family are not that pc-literate so i wouldnt want them to be involved in this</li>
<li>P1018: I'd rather them not be subject to allowing their computer to be infected.</li>
<li>P1019: seems a bit risky</li>
<li>P1024: sounds harsh</li>
<li>P1026: There are far too many variables, in my opinion, and I have doubts that the researchers would be able to maintain sufficient control of their computer. </li>
<li>P1031: I am much too cautious to want anyone I know to join such a study.</li>
<li>P1041: I don't think this experiment would cause any harm to them. </li>
<li>P1050: While the spammers themselves are engaging in immoral acts, tricking people into thinking they are making a purchase when they are not is unethical in my opinion.</li>
<li>P1055: If this spam was going to a computer set up by a reseracher to use as a dummy computer with the spam, it seems that the information in that computer could be very tightly controlled by one researcher, sending the information to one ocmputer.</li>
<li>P1058: This does not sound like it would require outside participants other than the researchers themselves. </li>
<li>P1059: They would not be harmed in any way and would be aiding research.</li>
<li>P1062: I'd want anyone who may be involved in this study to avoid it if possible, just for the sake of keeping their computers safe, but it seems harmless.</li>
<li>P1063: Nobody should get more spam</li>
<li>P1069: This can compromise the person's personal information.</li>
<li>P1083: I would be scared that some type of defect or accident would happen where the spammer gains control again and gets the info.</li>
<li>P1084: I do not think that it would hurt or benefit someone I cared about to take part in the study as a participant.</li>
<li>P1088: As I stated before, it is the decision of the person being asked to do it.</li>
<li>P1089: I would be really mad if my friend was involved in this project, as they were ripped off the researched knew they were getting ripped off and no one did anything about it.</li>
<li>P1090: all i can think of is my mother, who will click any link she is sent and constantly gets viruses because of it.  i would not want her doing something like this that could reinforce clicking links in spam emails</li>
<li>P1109: Again, this is solved through common sense.</li>
<li>P1110: So long as no personal information about the participants whatsoever is collected, I do not see why this would be a problem.</li>
<li>P1111: I don't see any harm being done to the participant. The researchers seemingly have everything controlled so that the participant will not be personally affected.</li>
<li>P1112: I feel it would be deceptive to send them spam and then reroute the purchases to a different website to measure consumer behavior.</li>
<li>P1116: I wouldn't want them to be hurt.</li>
<li>P1119: I would personally prefer that they did not participant in this experiment, because their PC is at risk of becoming infested with spamware.</li>
<li>P1123: I believe this is a different kind of study, but I would have no preference if someone I cared for was in this study or not. It seems rather harmless and can be effective in finding data.</li>
<li>P1130: I would think my friends are smart enough to know about spam.</li>
<li>P1131: Do not trust researchers getting infected with spam software. Could be infected with something worse than they expect.</li>
<li>P1133: This experiment seems risky and I don't like the idea that participants are never notified, not even after the experiment.</li>
<li>P1140: I am not sure if they would be willing to participate in an experiment like this.</li>
<li>P1147: There is not a likely outcome of the experiment as stated in the last line.</li>
<li>P1157: The chief purpose of this proposed study is to provide a training ground for spammers.  Otherwise, it is fraudulent, devious, and filled with risk. I have an idea for a better study: gather a group of students, tell them that as part of 'research' you are going to point a gun at them and pull the trigger.  Tell them that monitors have maintained 'sufficient control' so that the guns are unloaded.  If anyone consents to the study, point the gun and pull the trigger. The result? </li>
<li>P1158: It appears that the people responding are unaware that they are involved in a study. Consent is required. </li>
<li>P1159: I feel like this is the type of thing that is too risky and and that the people involved should be completely informed. </li>
<li>P1162: It is harmless to the participant</li>
<li>P1163: With the computer being infected with software that seems like a huge violation of privacy. Also with the redirection of websites I feel like that is very invasive and misleading. </li>
<li>P1165: My problem is, I don't understand if it will affect their own computer.  I still think it will waste their own time and their time is valuable.  </li>
<li>P1168: I would be concerned about the safety of their information and </li>
<li>P1173: I think it could help in learning more about spamming.</li>
<li>P1174: its up to  them</li>
<li>P1176: I'm afraid that the hackerrs would catch wind of this figure out how to maliciously alter this study</li>
<li>P1178: Does not sound safe!</li>
<li>P1179: I would not want to risk them giving out personal information or having personal information illegally taken from their computer. </li>
<li>P1180: I don't fully understand how this experiment works, but i don't like the idea of participants not being told that they have been part of the study and not given the opportunity to opt-out of the research. It doesn't sound entirely legal.</li>
<li>P1191: Again, it's necessary that every know and understand how phishing and scams work, and what they look like, so no one should ever avoid these types of studies.</li>
<li>P1192: This sounds like a good experiment.  Hopefully it would result in less spamming and not more!  I'd have no problem if I learned I were a participant.</li>
<li>P1195: Doesn't seem as if there is any harm being done to anyone. It's being done on the researchers computer.</li>
<li>P1196: Too much potential for misuse of credit card information and indication that the users will ever be informed that they attempted to make an invalid  purchase.</li>
<li>P1199: if the research isn't hurting anyone than I don't see a problem with it.</li>
<li>P1203: Sounds like it won't hurt anyone</li>
<li>P1211: Simply, spam mail is annoying. I don't see a purpose in the survey and I'm assuming that the person will be more of a victim than they will a pt. Moreover, there is no consent form. So, it's kind of unethical.</li>
<li>P1216: The participants didn't agree to take part in the experiment.</li>
<li>P1220: It puts security at risk and should not be permitted because of the possible dangers.</li>
<li>P1227: These people would expect an item that they never receive. I assume they would be given some kind of fake error message telling them that their order could not go through. In this case, I would be fine with someone I know participating.</li>
<li>P1230: I feel like that is dangerous and you could possibly get into a scenario where the researchers thought they had things under control but one mistake may send people to the actual spam site.</li>
<li>P1233: This experiment sounds very interesting. Having good data like your study describes could be very valuable in understanding how illegal spam operations work.</li>
<li>P1238: I wouldn't want anyones computer to be infected.</li>
<li>P1239: It feels like an invasion of privacy.</li>
<li>P1242: It can help them learn how to safeguard their computers from hackers.</li>
<li>P1246: there is no harm</li>
<li>P1247: As long as it is anonymized, I think it would be alright.</li>
<li>P1248: I don't see the problem with this as they will be visiting the spam store anyways. Since the purchase won't be allowed in the experiment, it doesn't seem like there is any harm to them.</li>
<li>P1253: The participant is being lied to and allowed to buy from a fake store that will not send them an item. This is wrong in many ways. What if the person really needs the item. Not every spam is everyone's spam.</li>
<li>P1260: I don't want anyone I care about to be involved in spam</li>
<li>P1261: I don't want them falling for these type of spam even though these wouldn't link to the real website. </li>
<li>P1262: That would mean that their computer would be infected.</li>
<li>P1264: I have read this explanation a few times over but remain a bit confused about how it would be conducted. Sorry; it just isn't laid out as clearly as the others have been. If I am understanding it correctly, this experiment does seem slightly less invasive than those previously described, as researchers would be protecting users from actually divulging personally identifying information on the spammers' 'sites.'</li>
<li>P1265: I don't know anyone that is that distraught about spam and I wouldn't want to subject anyone I know to such a strange study.</li>
<li>P1266: Because I would  not trust that the spam would be completely made harmless.</li>
<li>P1267: The idea that your action are being recording without your knowledge feels wrong.</li>
<li>P1269: This is protecting the user in a way, so I'm ok with it.</li>
<li>P1270: it seems a little safer that the other scenarios</li>
<li>P1272: I don't want anyone I know to be a target for something like this. Again, they can use their own friends.</li>
<li>P1273: Their choice, not mine.</li>
<li>P1274: Hopefully, they are tech savy.</li>
<li>P1278: I think this might be beneficial to us all.</li>
<li>P1279: It would help with spam.\r\n</li>
<li>P1283: Participants are deceived and are not made aware that they are in a study.</li>
<li>P1288: Now you're getting into the realm of people's hard-earned money.  That's pretty sensitive, and I don't know that I'd want to be part of that experiment.</li>
<li>P1289: participants will not be harmed in any way and will be anonymous</li>
<li>P1295: I don't think they can do it and be successful without cutting that computer off from the rest of the spam bot network. I can come up with other ideas they should experiment with.</li>
<li>P1296: As long as the researchers remained in control of the spam and it didn't harm other's computers, it wouldn't matter to me.</li>
<li>P1300: For one, it would help the results be more organic as well as hopefully teach them to not trust spam emails.</li>
<li>P1301: Unsure, it sounds like a honeypot to me. I wouldn't want to be involved, but if someone else was, might be interesting.</li>
<li>P1302: There is no information being sent through email. It would be nice if they were informed at a later date to prevent this from happening again to them.</li>
<li>P1303: Too much opportunity for financial abuse that would be hard to regulate and/or stop once it gets going. </li>
<li>P1309: This is unethical</li>
<li>P1310: This just seems like a sketchy way to perform a study. It may not work out as planned.</li>
<li>P1311: As long as no personal information is compromised it seems harmless.</li>
<li>P1316: I think it depends on whether he or she would receive payment. I'm not sure what the benefit would be for the participant otherwise, but there doesn't seem to be any harm in the study.</li>
<li>P1318: Yes the spam website would be a the reasearchers website and no harm would be done.</li>
<li>P1319: No one is harmed in this experiment as long as the banking information is not saved by anyone.</li>
<li>P1320: Recording information like that for a study without consent is something to be concerned about.</li>
<li>P1328: Unsure how I feel</li>
<li>P1332: I just don't want to be tricked like that, even for a good reason. I don't like feeling lied to.</li>
<li>P1338: I hate spam mails more than anything, and I definitely want this research to be published with the results.</li>
<li>P1340: No since messing with spam isn't a good idea.</li>
<li>P1343: I honestly wouldn't be concerned either way. </li>
<li>P1346: It involves the participants not being informed of the study.  </li>
<li>P1348: I wouldn't mind them being a participant in a study like this.</li>
<li>P1350: I might be useful to understand the spams better, but I do not like it really.</li>
<li>P1356: no - any spam or hacking is offensive and there really isn't any true control when it comes to the internet</li>
<li>P1357: Seems too deceptive</li>
<li>P1360: I would be concerned that the information that is downloaded will ruin my friend's computer even though it is controlled by the researchers in the experiment.</li>
<li>P1363: Spam can be dangerous for certain people.</li>
<li>P1367: This study seems safe and effective</li>
<li>P1371: This is up to them</li>
<li>P1373: There is nothing really harmful being done.</li>
<li>P1374: They are not being harmed only mildly inconvenienced. </li>
<li>P1386: I don't like the thought of anyone having to deal with spam emails in any way.</li>
<li>P1395: Choosing to answer or fail to answer spam messages/follow spam links is a personal choice that requires individual savvy. It is not my business as to whether or not my "someone" accepts the risk associated with obvious spam. Also, I would not have a preference knowing that it is not actual spam with dangerous private information dissemination consequences.</li>
<li>P1400: This seems quite shoddy. No explanation of what the experiment is about is given.</li>
<li>P1406: The way it is described makes the experiment seem too intrusive. Maybe if it were more like the double blind study model, so participants could give informed consent but not know whether their computer would be involved.</li>
<li>P1410: "Spammers are unlikely to divulge how successful their emails are in attracting purchases."  Why is this stated as fact?  Pay them more than they're making from their spamming enterprise and you'll be surprised.</li>
<li>P1419: The researcher will not collect payments that the participant would place or other personal information.  The researcher would just record the activities being place on a website that is set up by a spammer.  This would be done to find ways to protect the innocent from being used and abused.  </li>
<li>P1421: I wouldn't want them to be deceived by something like this </li>
<li>P1427: Yes, there seems to be relatively little risk for a participant. </li>
<li>P1432: The experiment seems harmless enough I dont think it would be a big deal</li>
<li>P1438: It would be a waste of their time and I don't see a point to this study. See my next response for more details.</li>
<li>P1443: Individual choice</li>
<li>P1446: They are being manipulated.</li>
<li>P1452: not sure</li>
<li>P1456: No both as it would be wrong and under current Federal Law it would be illegal as we'll tho i suppose in an attempt to gain information to turn over to Law Enforcement it might be permissible, But I'd seek a Lawyers advise first?,.</li>
<li>P1470: I would not want them to be manipulated, and then data on them to be used.</li>
<li>P1472: Spam stores need income too, even if it is through such bottom feeder means.</li>
<li>P1485: Seems like a big headache </li>
<li>P1486: It seems safe and the more results recorded would allow for a greater help of all internet users. </li>
<li>P1487: There is no risk for the participant.</li>
<li>P1488: THAT WOULD REALLY BE THE DECISION OF THAT PERSON AND NOT ME.</li>
<li>P1489: Most people I know wouldn't want to be involved.</li>
<li>P1492: I don't think its right to trick people who haven't volunteered for this study. I also think it sets a bad precedent to allow researchers to essentially become part of a spammers botnet in the name of research. </li>
<li>P1503: It wouldn't harm them or their computers.</li>
<li>P1507: Someone accessing my computer remotely is a breach of my privacy.</li>
<li>P1508: you can't use people without letting them have the choice to opt out</li>
<li>P1510: Again, I'd want to see if they fell for it so that they could improve their security habits, if possible.</li>
<li>P1514: really do not care</li>
<li>P1517: There is no threat to the candidate so I would not mind if that person were a participant in the experiment.</li>
<li>P1519: It seems harmless but it also doesn't seem like the study has a great deal of purpose.</li>
<li>P1522: I also think this would be beneficial so that people may realize the difference between real emails and spam.</li>
<li>P1525: This has a lot of implications the spammer may have a more elaborate scheme in store</li>
<li>P1528: As long as the researcher was from a trusted resource.</li>
<li>P1538: If someone wanted to participate I would not stand in their way.</li>
<li>P1540: It is anonymous and doesn't actually collect payment. </li>
<li>P1542: If everything in this experiment is well controlled, there should be no danger.</li>
<li>P1543: That could be too costly for someone especially if they work from home, or conduct any type of business on their computer.  Why not just create a spam email to see if someone goes to the site when it's been clicked on.</li>
<li>P1551: This is a bad question.  Who is the participant? The researcher, or the unnamed people who will get spammed? It sounds like you have no say in who is spammed.</li>
<li>P1552: their choice, not mine</li>
<li>P1553: I would hope that anyone I care about would be smart enough not to click on spam emails in the first place.</li>
<li>P1554: too risky</li>
<li>P1563: Too dangerous, actually letting a spammer get information in the system and then having to trust someone can control the program, someone you don't know. You won't know if they succeeded or not</li>
<li>P1580: I don't like the idea of deceiving users in this fashion; they should be informed afterwards.</li>
<li>P1582: There is way too much uncertainty with this experiment.</li>
<li>P1591: I would hope that they would be informed that the purchase could not be completed if they were trying to purchase an item.</li>
<li>P1597: There is simply too much that could go wrong.</li>
<li>P1598: I don't really see the value.</li>
<li>P1604: Would not matter to me, as they wouldnot know anyway.</li>
<li>P1612: I don't like the part about replacing the link to the spammer's store with a link to a website collecting payments etc.</li>
<li>P1614: The users do not know that their choice to make a purchase is being recorded.  This is a violation of privacy.</li>
<li>P1617: Either way is fine.</li>
<li>P1620: It wouldn't effect them poorly or positively either way</li>
<li>P1633: It seems as if the scientists were very responsible with their experiment. I don't believe it would make a difference. </li>
<li>P1649: It would be helpful to get this data and can prevent hackers.</li>
<li>P1650: Participating in an exercise like this seems kind of shady without letting the people know.</li>
<li>P1651: I could see this causing a small amount of stress but they wouldn't be harmed by the experiment. </li>
<li>P1655: This study seems more complicated and I do knot like that they users would no be informed.</li>
<li>P1657: It sounds like it would be an inconvenience.</li>
<li>P1658: I'm undecided because I wouldn't want my 'someone' to suffer spamming problems but, on the other hand, research is important.</li>
<li>P1664: The anonymity is important in this but it does seem very detailed and the researchers do have a lot of compromising information.</li>
<li>P1668: It seems sort of sketchy. I wouldn't want anyone I cared for to be involved in an experiment about spam and scams.</li>
<li>P1671: If someone I knew had fallen for this, I would want them to be notified.</li>
<li>P1674: It seems fairly harmless, except for time wasted</li>
<li>P1676: 0</li>
<li>P1680: It may be risky.</li>
<li>P1683: i hate spam email just as much as any one else and i would not wish this study on anyone.</li>
<li>P1686: It seems unethical</li>
<li>P1704: Too invasive.. there are good spam filters now if people are interested in stopping spam.... its their decision to buy or not buy a product</li>
<li>P1705: this will advance protection of common problems</li>
<li>P1708: With more information i am a bit unsure.</li>
<li>P1710: I do not really care either way.</li>
<li>P1715: The risks are too extreme.</li>
<li>P1722: Virus and malware risk not worth it</li>
<li>P1723: If it encourages ending spam I am for it.</li>
<li>P1724: Creating excess spam isnt helpful</li>
<li>P1725: There's no harm being done, however if they "fell" for this spam email then perhaps another informative email warning about spammers could be beneficial.</li>
<li>P1730: Well, its fine since they're being directed to a store that doesn't work- won't collect any information etc. </li>
<li>P1733: I feel it's safe since no personal information is actually going to the spammers.</li>
<li>P1738: I wouldn't want my friends to be scammed but if they fall for this then I'd rather they be in your experiment and thus not be actually scammed and maybe learn from this situation.</li>
<li>P1740: Something that sounds interesting and more interested in the general data itself than who participates.</li>
<li>P1742: Its for a good cause and participants will not be identified. </li>
<li>P1744: Seems to much personal info being given out </li>
<li>P1746: I'd be interested to know the results of this study. If everyone remains anonymous, I don't see the harm.</li>
<li>P1752: No  because their computer is at potential risk of others hands not their own</li>
<li>P1753: Not informing the people being used helps them in no way so they are just being used. </li>
<li>P1757: It doesn't seem harmful or beneficial to the participant, so it doesn't matter to me.</li>
<li>P1758: The people participating in this research are left clueless about it and are never debriefed, the way the researchers are going about with the spam emails seems very weird and not necessarily the safest way to do it. </li>
<li>P1764: Since it remains anonymous, there is no personal harm to the participants and provides the opportunity for the researchers to gain valuable information.</li>
<li>P1770: Still seems dangerous that others are watching your moves without you knowing</li>
<li>P1771: The researchers are not informing the customer of their deception.</li>
<li>P1773: I feel this is going to far.</li>
<li>P1774: I think it is a problem that the users will not be informed that they are being monitored about the activities of the study. I also think that allowing the computer to be infected can lead to security risks for logins required to operate the computer.  </li>
<li>P1775: Spam can carry other malware with it so no. No should be given the right to invade someones computer for any reason. This one wouldn't even let them know it happened. I hope this is a joke.</li>
<li>P1778: it sounds unfair to not allow someone to have a choice. </li>
<li>P1785: If they were trying to buy something for real they would be blocked by this and mislead.</li>
<li>P1786: I would not want myself or someone I care about (or anyone else) involved something where they put their information out there and it ends up being collected by a researcher somewhere, the researchers never even tell them they were involved in an experiment afterwards so they think they have made a purchase, never get their item(s), have no idea whats going on with their bank card, and probably end up getting into a dispute with the store, neither knowing it has been taken over by researchers doing a study. It is wrong in many ways, unethical, illegal, not good for anyone. </li>
<li>P1788: I think this would be fine as it does not appear they would be collecting any personal data. </li>
<li>P1799: it seems harmless to the participants</li>
<li>P1800: It is still being controlled by 3rd party</li>
<li>P1806: Things are getting more chancy by letting spammers into the process. </li>
<li>P1809: I think this would be a valuable study.</li>
<li>P1812: Based upon what the warning says, they have free will to participate or not</li>
<li>P1829: I feel like they were being lied to and they wouldn't know that their information was being used, so therefore they couldn't give consent. </li>
<li>P1835: This experiment seems like it could make the users who receive the experimental email feel very annoyed or unsafe</li>
<li>P1837: I wouldn't mind if they adequately compensated for their efforts </li>
<li>P1839: I would not want my friend giving payment information and being tricked by this experiment</li>
<li>P1841: No, not with the risk of their computer becoming infected due to the dissemination of spam.  </li>
<li>P1848: Personally I don't think anyone should respond to spam, but if they are going to do it anyway then the experiment is fine.</li>
<li>P1850: It depends on what candidate means. If its that the computer is already infected by the spam then yes. But if it meant infect the computer to become a candidate then no.</li>
<li>P1853: This sounds a bit like invasion of privacy but the anonymity makes me not care that much. </li>
<li>P1857: I don't think it is ethical. It feels like they are lying to the people involved and in a sense spying on them. What they are doing isn't much better than the spammers they are studying. </li>
<li>P1864: Most people I know want to actually make a purchase when they choose to, even if spam sent them their. So I would say the hassle for the subject is to much.</li>
<li>P1870: The payment information is not being collected or any other personal information that would put the person at risk for identity theft. The person would also remain anonymous.</li>
<li>P1871: SPAM SUCKS and any help is welcomed to block it.</li>
<li>P1873: I would be concerned for their security.</li>
<li>P1874: I don't want my loved ones to be hurt while trying to figure out how much spammers make from spam emails.</li>
<li>P1876: If the researchers are not collecting personal data then the participant has nothing to worry about.</li>
<li>P1878: I wouldn't want to get anymore spam even if it was for a study</li>
<li>P1884: i hate spam emails. They can spam away and catch them and stop them that would be great. </li>
<li>P1885: I would not want someone I knew to be a target for spam.</li>
<li>P1890: Participants should be informed and have their consent to be included.</li>
<li>P1892: The researchers are not informing the users of their experiment.</li>
<li>P1896: So long as no financial information or other information was kept, then I don't think that this experiment would harm anyone. However, it has the potential too, so I would like the researchers to let its subjects know that this experiment is potentially risky.</li>
<li>P1897: This needs to be done, and some friends are especially vulnerable to believing the spam is real.</li>
<li>P1901: Same as before, it would be their decision.  I see nothing wrong with completing this experiment.</li>
<li>P1902: It sounds like it is pretty legitimate and controlled enough to not be dangeroys</li>
<li>P1904: Spamming is a major problem which needs to be investigated.</li>
<li>P1913: My friend would be in a study and would never know</li>
<li>P1916: Just a way that hacker's can mimic this.</li>
<li>P1917: This just seems risky. </li>
<li>P1934: I don't have a reason to object to this. </li>
<li>P1936: If the computer is being controlled by actual spam mail propagators, then their email address is now compromised and on their future lists.  That effect will last far beyond this study.</li>
<li>P1942: This study seems safe enough if all goes as planned.</li>
<li>P1945: My father is very vulnerable to these attacks.  It would be helpful to educate him on ways to prevent it.</li>
<li>P1951: The people I know that use computers would not actually know what they where getting into.</li>
<li>P1952: It seems harmless as long as people are kept anonymous.</li>
<li>P1953: I support any research that could help stop spam, and there appear to be no risks involved, so I would recommend anyone participate.</li>
<li>P1955: I wouldn't want anyone I cared about involved  in this kind of work. It seems like bad waiting to happen.</li>
<li>P1960: Spam emails usually end badly- They might get scammed</li>
<li>P1963: This would violate their private information too much.</li>
<li>P1970: There's no harm one way or another.</li>
<li>P1971: Despite the fact the software is being monitored by the researchers and there's some limit to the damage that could be caused, they're still allowing the subject's computer to be infected by a virus.</li>
<li>P1973: Would not want someone to be part of altered software for research purposes.</li>
<li>P1978: I would participate but would not want anyone I know to do so.</li>
<li>P1982: I would not think a friend of mine would benefit participating.</li>
<li>P1989: Since this experiment involves actually infecting the participant's computer, I think that too many things could go wrong here.</li>
<li>P1991: I think it's a worthwhile experiment, and it actually saves people who fall for spam from being compromised. </li>
<li>P1998: This experiment may or may not involve breaking several laws. In the event that it does involve breaking laws, it does involve compromising peoples' security. This is wrong.</li>
<li>P2002: I would not want to be infected with spam.</li>
<li>P2003: I don't really see where this is bad, but I do see slight potential that it could not go as planned.</li>
<li>P2004: If anything, this study will annoy the person as opposed to learning anything.</li>
<li>P2006: No, there is no informed consent and the ads might be for sensitive material that the consumers may not want known. </li>
<li>P2018: No harm being done</li>
<li>P2026: It is up to the loved one.</li>
<li>P2027: again, i think its harmless and would be helpful with these spammers</li>
<li>P2032: No tampering with the computers please.</li>
<li>P2038: If the participant thinks that the link is spam they may not click</li>
<li>P2040: I wouldn't mind if they were included or if they weren't included.</li>
<li>P2044: the person involved in the experiment isn't harmed and they will remain anonymous.</li>
<li>P2046: It'd be interesting to see how the react. Seems benign enough.</li>
<li>P2048: I think this research is good and valid, but I couldn't say how others would feel</li>
<li>P2053: I wouldnt want to encourage people to respond to unsolicited emails as it could affect them down the road with regards to identity theft</li>
<li>P2060: This is an important study.</li>
<li>P2061: this will help a lot for those fall victim of this email spam</li>
<li>P2063: As long as the spam software is successfully removed from the computer after the experiment I see no reason why they shouldn't participate.</li>
<li>P2070: I don't think its that big of a deal.</li>
<li>P2072: Don't see ant harm here.</li>
<li>P2082: If I wanted a product, I would be pretty mad if I thought I ordered it when I didn't.</li>
<li>P2094: To maintain integrity to the goal of the study and to avoid influencing participants's actions, researchers can't inform participants that they're being taken advantage of - I'd prefer those I care about are not taken advantage of at all. However, if their gullibility can further science, they might as well be unaware participants.</li>
<li>P2100: A virus or spam can be inadvertently passed.</li>
<li>P2103: I would not have any problem if myself or a loved one were a part of this study. It does not collect personal information so I would not mind participating. </li>
<li>P2114: I don't think it's a big thing either way.  The person might be disappointed that they never got the thing they purchased, but that's not really much of a loss to suffer.</li>
<li>P2117: Not informing the participants at the end of the study that they were indeed participants is an ethical violation, and the IRB would not approve. This is not a field observation, nor is it secondary data. The participants need to be informed of their participation and be given the option to withdraw their data from the study. However, if anyone was actually retarded enough to click on a spammer link and tried to buy stuff from a spammer sight, well, they're too dumb to be considered human, and don't qualify for human subjects protections.  </li>
<li>P2119: I think there are some loose ends to tie up. A lot of the experiment wasn't explained. I wouldn't want anyone's debit or credit card information to be taken or seen by these researchers. The whole thing doesn't set well with me because it's very deceitful.</li>
<li>P2121: I wouldn't want someone I cared about to receive spam, and be deceived like that.</li>
<li>P2123: the researchers will not inform users that they were part of it and still use the data, its not right</li>
<li>P2125: It seems like a study worth conducting and as long as no harm is caused, I don't see a problem with it.</li>
<li>P2126: Since spam is a regular part of e-mail, I see no reason why this experiment would have any negative effects on any participant.</li>
<li>P2131: Never ok with hacking into my personal computer</li>
<li>P2132: Doesn't sound ethical to me.</li>
<li>P2134: This would result in a waste on time for the participant for the benefit of the researcher. </li>
<li>P2135: Too risky</li>
<li>P2144: Seems annoying to those who are involved.</li>
<li>P2155: I do not want anyone I cared about having their computer spammed.</li>
<li>P2156: This is encroaching a little to much on personal privacy</li>
<li>P2159: it teaches about internet security safety..</li>
<li>P2172: It gives the experiment more integrity.</li>
<li>P2175: I think this would easily get out of control and actual identify theft and fraud would occur. </li>
<li>P2176: It doesn't matter to me either way, it's just research so nothing will really happen.</li>
<li>P2177: Depends on the individual being selected.  </li>
<li>P2181: Too dangerous to test out</li>
<li>P2183: While the results could be beneficial, I don't think the researchers would be able to have complete control over the experiment.  I would worry the spammers would gain control/outwit the researchers.</li>
<li>P2188: I don't want to risk getting spammed or having my information spread. </li>
<li>P2193: Sounds very risky.</li>
<li>P2194: I would prefer that research is done to stop criminals, if the spam is apart of criminal activity then yes I would want them to be a participant to help stop crime</li>
<li>P2205: My concern is the participants handing over sensitive payment information.</li>
<li>P2208: It seems harmless.</li>
<li>P2209: The computers should not be infected with some of virus that someone could use to get your information.</li>
<li>P2212: I think it could be an interesting experiment considering that the people are buying their product as is.</li>
<li>P2213: I don't really understand this one, since someone would have to be aware that they are participating in an experiment in order to go about it, but they have to also "fall for" the spam email. Unless the software is installed on the computer without the participant's permission, because that is wrong.</li>
<li>P2216: I don't like the thought of submitting payment information on a fake page</li>
<li>P2219: This experiment seems rather dangerous, especially someone like my father, who is computer-illiterate. </li>
<li>P2221: Yes, in fact in the long run it may end up saving a friend or that someone I cared for from this kind of problem in the future.</li>
<li>P2232: I care for them, so if they want to do the experiment, then I hope they can.</li>
<li>P2233: I would want to see if they know not to fall for it</li>
<li>P2234: I think the users should be ultimately told that it is an experiment-that they were about to be spammed but were diverted.</li>
<li>P2237: It seems effective.</li>
<li>P2238: Sounds unethical.</li>
<li>P2244: This is research that needs to be conducted. As a consumer we are flooded with spam e-mails and many of us try on our own to stop the influx but have not found a viable solution.  This should be done.</li>
<li>P2245: People shouldn't be used as guinea pigs.</li>
<li>P2253: Experiment is harmless</li>
<li>P2254: all computer activity as we become more dependent on the use should be researched and studied</li>
<li>P2260: There is no major problem or risk to participate if the researchers are changing the spam. </li>
<li>P2261: This doesn't seem to serve a purpose.</li>
<li>P2267: i believe everyone should be created equal</li>
<li>P2273: Im not sure about this one. As  long as no personal information is being  gathered and   they do not acutally perchase  anything I do not see a problem with it.</li>
<li>P2276: I feel like this method could be considered to invasive for many, but it may very well be required for us to learn how to best combat spammers.</li>
<li>P2280: As long as the experiment is internally controlled , it doesn't appear to pose any issues</li>
<li>P2281: I think the researchers tactics would be invasive. They would also be wasting a participant's time by leading them to believe that they are purchasing a product.</li>
<li>P2284: I think the study is too intrusive.</li>
<li>P2285: sounds cool but I don't feel safe for people on this</li>
<li>P2286: I believe this is a worthwhile study and it is one that exposes the participants to very minimal risk</li>
<li>P2289: It would not matter to me if he or she was part of this experiment because no real damage can be done.</li>
<li>P2302: This makes me uncomfortable that researchers would allow spam to take place but not inform the victims or try to prevent it.</li>
<li>P2305: As long as they understood what they were taking part in.  If it is the researcher's computer I would hope they were smart enough to use a specifically chosen computer and not one with personal information stored on it.</li>
<li>P2307: Spam is potentially very dangerous and I don't believe in advertising in general.</li>
<li>P2308: I feel it's important to notify those involved after the experiment. </li>
<li>P2309: The study is unethical because the participants have not provided their consent to be included.</li>
<li>P2316: So they could see the world of spam, and how people are making tons of  money off there email ads using web email extractors myself. </li>
<li>P2324: On one hand, it would be good information. On the other it sounds like people are still being scammed and the researchers are just watching it?</li>
<li>P2326: Hopefully the person I cared for would not skew the results of the study. I have no preference because the person I cared for is not being harmed by the study.</li>
<li>P2328: i do have a problem with this,in that no attempt is made to later on tell people that their purchases did not go through.  They should be told later on, that it was a fake purchase.  maybe after they actually make the purchase, send them to a screen explaining this was a fake site, and that they had been protected against spam.</li>
<li>P2338: I have no preference</li>
<li>P2339: Allowing spam to be sent even for research is a little too much</li>
<li>P2340: I would not want anyone to have to have their computer infected with something that would allow spammers to control it. Even for an experiment.</li>
<li>P2341: Regardless if I knew the person or not it is a valid scientific study and they should participate, nothing is being done to them or collected that would be harmfull.</li>
<li>P2348: It wouldn't matter either way</li>
<li>P2349: Spam is invasive. It invades a persons privacy and crashes computers.</li>
<li>P2350: I think the experiment sounds kind of risky for the fact that the researchers don't let the candidates know that they are a part of a study.</li>
<li>P2351: I just dont think this experiment is a very good idea.</li>
<li>P2354: This seems to be a violation of our personal life and would interfere with our purchasing rights.</li>
<li>P2357: Seems harmless.</li>
<li>P2368: It doesn't sound like the researchers are being very responsible for the well-being of the participants. Unless they made the infected software themselves or moderated it closely by working with a phisher, there would be no way to guarantee the security of their information.</li>
<li>P2372: Good data on this type activity is needed.</li>
<li>P2378: This is too risky.  You are inviting actual scammers to participate, so the methods of security may be breached.</li>
<li>P2382: There is no chance of loss to participants, as long as the compromised accounts are recovered and no long-term damage has been done to said accounts.</li>
<li>P2386: While I don't agree with allowing access to my computer, this may help to stop scammers in the future.</li>
<li>P2392: My friends wouldn't click on spam anyway. But it's annoying to get it and may make you think your email has been hacked.</li>
<li>P2396: Seems okay, not real strong feelings on this. I would not want a friend in this situation much but if they're opening spam and getting scammed, better this than by the real scammers.</li>
<li>P2397: I do not believe that this is a real problem anymore. However if i were made a believer I would not have a problem with a loved ones participation. </li>
<li>P2398: It is a good opportunity to know and prevent spam.</li>
<li>P2403: Spammers may be smart and able to outperform the researchers.</li>
<li>P2409: There is too much that can go wrong. How will the researcher maintain this "sufficient control".</li>
<li>P2411: could be a security breach and headache if this wasn't a legitimate study</li>
<li>P2412: I dislike spam in general.</li>
<li>P2425: There is too much that can go wrong with researchers sending spam emails.</li>
<li>P2433: Spam can be tricky some times.</li>
<li>P2435: Once again I think this would be a good idea because although it seems a bit deceitful you need to be in order to get the valid information. I hate getting pop ups and links from where I have shopped come up on my computer and would love for someone to make it so that doesn't happen anymore</li>
<li>P2445: I don't see any harm in it, since there isn't any real threat.</li>
<li>P2449: i probably would not have a problem with this experiment </li>
<li>P2450: I would be worried that something could go wrong and lose there data.</li>
<li>P2451: No personal data is retained, and the data retained is valuable.</li>
<li>P2453: This sounds like as complicated and sneaky experiment.</li>
<li>P2456: Seems very shady. Lots of stupid people on the internet but they don't deserve to be used like this.</li>
<li>P2457: It seems compromising to privacy</li>
<li>P2461: I feel like this research is harmless and do have a preference one way or the other. </li>
<li>P2463: no personal information other than e-mail addresses is being stored. spam is becoming a real nuisance these days.</li>
<li>P2466: This doesn't actually stop the spammer from getting people's information, which s/he could use in the future. </li>
<li>P2473: Overall, it may help humanity as a whole.  So might as well give back and help out.</li>
<li>P2480: Again this study looks harmless</li>
<li>P2483: I believe it is important to understand the action of spammers.</li>
<li>P2485: sounds useful</li>
<li>P2488: The choice would be up to him or her.  That being said, I see no reason why this experiment would be deemed unsafe.</li>
<li>P2491: The participants are not being informed of a disabled store or recording attempted transactions.</li>
<li>P2495: people need to know how spammers work and why spam occurs</li>
<li>P2496: I wouldn't want anyone close to me subject to the kind of advertising that spam is. Plus I feel that a lot of spam emails are also used to distribute malware and other harmful software. </li>
<li>P2499: It is important reserach.</li>
<li>P2501: I would not want someone I care about to get in the habit of opening spam.</li>
<li>P2507: No harm is done.</li>
<li>P2511: That seems a little "out of the hands of researchers" if you ask me and it would be a DEF NO!</li>
<li>P2513: It's an invasion of privacy and should be divulged to users.</li>
<li>P2517: It sounds like it would be way to easy for something to go wrong.</li>
<li>P2518: Anyone I care about is typically intelligent enough not to pay attention to spam.</li>
<li>P2522: As long as the person I cared about knew that they were a participant I would not care.</li>
<li>P2528: This is not only an Internet security issue, but a privacy issue as well.</li>
<li>P2530: I don't want people I care about to be used as test subjects for the whims of others.</li>
<li>P2532: It would not bother me either way who participates.</li>
<li>P2536: this question does not apply</li>
<li>P2539: This would not be justifiable. This is too much interference in the personal affairs of the person that is being redirected to the research website.</li>
<li>P2542: Spam can be dangerous and lead to identity theft. This could help reduce it and does not harm the participants.</li>
<li>P2545: the term "sufficient control" over the infected computer bothers me...</li>
<li>P2547: Because it seems they would have been a victim of this spam regardless. At least this is working toward stopping future scams like these ones. </li>
<li>P2549: I wouldn't wish spam upon anyone, even if it was harmless</li>
<li>P2556: too deceiving</li>
<li>P2561: They'd rather end up on researcher's mock site, than the real spammer's web site because they will not complete a questionable purchase and will not expose their email for further spamming.</li>
<li>P2563: This is a very frustrating & deceiving experiment.</li>
<li>P2565: seems too risky</li>
<li>P2566: I hate spam</li>
<li>P2571: Science would be best served by passing on this one.</li>
<li>P2572: it does not matter to me what they do</li>
<li>P2574: If I knew that someone I cared about was going to be a part of this study, I would not like it because I feel like it takes away their privacy.</li>
<li>P2575: Same answer as before.  I am somewhat confident amazon MTurk screens for this security breach.</li>
<li>P2578: Seems a little rude to send participants to fake stores, but not necessarily harmful</li>
<li>P2579: If we see the effects of spam email maybe we will learn how to try to prevent them.</li>
<li>P2581: I don't like taking the fake risk.</li>
<li>P2582: There is no 100% gurantee that all spam will be redirect to the researchers'.</li>
<li>P2584: This just seems like a bad idea and I wouldn't want anyone I know to be a part of it.</li>
<li>P2589: I have no preference because there's no harm being done</li>
<li>P2590: I don't understand how this works without spamming people. I don't like that the users aren't informed that the store isn't real. They might try to make a purchase with personal information.</li>
<li>P2592: I wouldn't want their computer to become infected by a virus or something that spammers use to disable the usage of a computer.</li>
<li>P2595: I'm really not sure about this one, it just doesn't sit well with me.</li>
<li>P2596: intercepting web traffic and spoofing without consent is wrong. if a person legitimately wants to make a purchase who are you to stop them by redirecting their request?</li>
<li>P2599: Spam, like hacking and phishing, is a real threat.  It would teach the person how to detect spam & get rid of it.</li>
<li>P2605: I don't want any of my friends or family getting spam emails and then being tracked.</li>
<li>P2610: It's a fake store, there's no payment information being gathered. My only caveat is that at the end, there should be some sort of message stating what's happened as that may make the user more cautious about clicking on random links.</li>
<li>P2612: This does not sound safe from virus attacks, etc. </li>
<li>P2618: It depends if they're aware of it being spam before they put in any real personal information.</li>
<li>P2619: This is iffy. If it is a legitimate request to purchase and the store has been disabled, the customer could become upset with the store for not getting the products, when the store is not at fault. </li>
<li>P2623: I do not feel this experiment is well thought out</li>
<li>P2626: It would be a potential privacy issue.</li>
<li>P2628: Seems like it could cause trouble</li>
<li>P2639: Once again: I wouldn't trust the research group.</li>
<li>P2654: Violates privacy rights.</li>
<li>P2669: no fooling around with someone's computer information</li>
<li>P2674: Causes no direct harm</li>
<li>P2684: Spam is an ongoing battle in the computer world. Studies such as these that accurately calculate how many people actually believe and give in to these SPAM websites would help to increase the amount of information available to regular users of how to stay safe against them.</li>
<li>P2685: I would want to see how they respond to spam emails.</li>
<li>P2686: My friend wouldn't know so I have no preference on their inclusion in the study.</li>
<li>P2689: Harmless, but may annoy participants.  May allow collection of valuable data.</li>
<li>P2692: This is deceptive and breaks the law..noo one can redirect a buyer trying to contact a seller</li>
<li>P2699: It will not cause any financial harm.</li>
<li>P2713: Spam! We all try to avoid it. There has to be another way to do this experiment.</li>
<li>P2716: This is a worthwhile experiment and would have no negative impact on the participant aside from frustration.</li>
<li>P2717: This experiment seems to be one where the participants will not reap a benefit of any kind.</li>
<li>P2723: i think they might see this as an invasion of privacy even if it is an experiment</li>
<li>P2732: The participants may not know which malis are from the resarchers and which are not. </li>
<li>P2735: There is a slight chance that their personal information would be compromised.</li>
<li>P2737: because they are being included without informed consent</li>
<li>P2740: I don't see much of a risk involved with this type of experiment. If no personal info is being shared and no finances are being involved I don't see why an experiment shouldn't be done.</li>
<li>P2743: It seems ethically questionable.</li>
<li>P2746: This person would not be harmed or benefit in any way from their participation, so i would have no preference pertaining to their participation</li>
<li>P2747: Spam mail is very annoying and has a tendency to infect computers with viruses and I would not want to involve people I care about into this risk.</li>
<li>P2749: I do feel that the researchers should come clean to the purchaser tho' (after the fact).</li>
<li>P2750: for the inconvenience that they have to go through</li>
<li>P2753: SO they could learn safely what not to do on the internet.</li>
<li>P2768: It seems like a safe enough experiment that the benefits outweighs the risks.</li>
<li>P2771: Seems awfully spammy</li>
<li>P2777: I'd just rather not if someone was to actually be infected. </li>
<li>P2781: This experiment could lead to a breach in security for participants.</li>
<li>P2786: I don't know, something about the fake website being used...it all makes me uncomfortable for some reason.</li>
<li>P2792: There are factors outside the researchers control, like the infected computer and the spammers are actually involved.  The experiment seems too risky.</li>
<li>P2793: I don't like spam sent out at all.  All spam seems to add more than it should.</li>
<li>P2794: I don't have a preference because since they switched the link I think it would be safer.</li>
<li>P2795: As long as no real damage is done and they are informed.</li>
<li>P2800: This just sounds like a bad idea. I wouldn't want spam no matter who was sending it. </li>
<li>P2802: I think that this could end up resulting in problems to the researchers computer and the possibilty of being flooded with junk mail.</li>
<li>P2804: This honestly just sounds annoying.</li>
<li>P2807: No, unless I could guarantee that they would not lose money permanently.</li>
<li>P2813: Its a study on spam and how they're trying to fix it so sure why not.</li>
<li>P2818: seems irritating</li>
<li>P2821: the average suspicious and dubious activity such as spamming to know WHAT you are actually doing to their machine.</li>
<li>P2822: YES</li>
<li>P2823: It is a questionable experiment. I don't see how it is doing anything other than showing how effective spam is at getting people to buy what they don't need.</li>
<li>P2827: it is a violation of privacy</li>
<li>P2828: I would participate so I have no problem if someone I care about participates.</li>
<li>P2829: I see no harm in this.  So sure.</li>
<li>P2830: The computer was already infected by spam. It would actually let the participant there is spam on the computer. </li>
<li>P2834: I say I have no preference, because I wouldn't want to recommend a person for this experience, but it seems the researchers seem neutral in the spam scam and are seeking to study the process. So I would give them a pass in the name of science. We must keep in mind my family many generations ago was from Germany. So I don't trust myself in these matter. I think it is great we usually have ethics committees to give us guidance and permission to continue with certain research or not.</li>
<li>P2837: They would not have provided informed consent; I realize that this derails the ability to study them naturally, but it seems sleazy.</li>
<li>P2838: Yes, then his response will be included to measure the effectiveness of spam email.</li>
<li>P2844: For the most part it seems pretty harmless to me they would only be helping out research.</li>
<li>P2848: They should not allow users computers to be affected.</li>
<li>P2850: The participants in this study do not know that they are in a study in general. This seems to be a little unethical and I'm not sure how much I trust the methods.</li>
<li>P2856: This could get great results  but not fair to those trying to buy something and never knowing they are not going to get it.</li>
<li>P2861: IT WOULD HELP TO INFORM SOME PEOPLE.</li>
<li>P2865: Allowing computer infections is bad.</li>
<li>P2874: It would teach them to be careful with spam emails.</li>
<li>P2879: Sending spam is never safe and usually not invited.</li>
<li>P2880: Participants will not be educated.</li>
<li>P2882: I think the participants should know that they are involved in a study.</li>
<li>P2888: Well, if it's spam, is it necessarily junk, what if they ended up really wanting the purchase and can't get it. Of course they can look elsewhere, so it's fair. I wouldn't be upset if a cared one was a participant. </li>
<li>P2892: this will show people what types of ads or products are most used</li>
<li>P2893: Too much manipulation, too much time wasted.</li>
<li>P2896: I don't want my friends in such a test that is lying to them like this. </li>
<li>P2905: again this seems to take research to a more deceptive level than is necessary...what about INDIVIDUAL RESPONSIBILITY!!   spam is what it is...no need to trick folks...EDUCATION is the key!</li>
<li>P2910: As long as there's no harm to innocent peoples computers.</li>
<li>P2916: I don't like contributing to statistical data without my knowledge so I wouldn't want it to happen to anyone else regardless of whether i know them or not.</li>
<li>P2920: I don't know the exact procedure but what if there is a risk that the researchers will not be able to control the spammers' attack?</li>
<li>P2924: i don't want anyone i know to have someone messing with their computer without their knowledge</li>
<li>P2929: This is very deceptive and I would not want anyone I know to take part in this.</li>
<li>P2930: There is no harm in this</li>
<li>P2931: They wouldn't be harmed and it could be useful.</li>
<li>P2934: I just feel that this violates a certain level of privacy that needs to be maintained in a professional workplace. Even if they remain anonymous, their personal habits will have been recorded and I feel that this is invasive without consent from the subject.</li>
<li>P2941: I don't really care about this experiement whether or not the person chooses to be involved that is completely up to them</li>
<li>P2945: There are so many identity threats now that people may not realize how spam is such a dangerous tool when used wrongly and may not realize it unless it is published </li>
<li>P2946: Don't see how they can go wrong researching it</li>
<li>P2947: This experiment was of no consequence to them, no harm done. And it may be helpful to others.</li>
<li>P2948: If they were to go through to these spam sites, I'd rather them go to a fake one for research than a real one and lose money</li>
<li>P2949: I don't believe it would have much of an effect at changing anyone's behavior, gullible people will remain that way in my opinion. </li>
<li>P2955: This sounds like it would cause aggravation to the person and waste their time.  </li>
<li>P2956: It seems safe enough, but at the same time you never know what could go wrong.</li>
<li>P2959: I would be wary of any interface with an infected PC.  Just because they have supposedly made safe that spammer application does not mean the device is safe to use.</li>
<li>P2964: I don't open spam</li>
<li>P2966: It would be that persons decision</li>
<li>P2972: Because no personal information is being collected and the participants would not realize that their activities are being observed.</li>
<li>P2979: It seems that all IRB protocol are being followed</li>
<li>P2992: I feel these types of things are very intrusive even without trying to collect payment information they are still getting data that should be private.</li>
<li>P2999: Sounds like it is not a very useful experiment and there could be the possibilities of "bugs"</li>
<li>P3002: I would not want someone I know or care about to be included as a participant mainly because I would hope that they would not even respond to the spam as this only encourages the spammers to continue their practices.</li>
<li>P3003: Seems harmless enough and could really be useful.</li>
<li>P3004: Its kind of a shady area.  Who's holding the researchers accountable?</li>
<li>P3008: This actually seems illegal.  I can actually think of a few types of fraud this might fall under.</li>
<li>P3009: I don't like spam on my PC & I'm sure others would agree.</li>
<li>P3012: I think the learning experience would be worthwhile.</li>
<li>P3016: no</li>
<li>P3022: While I have a problem with the experiment in general, I must concede that the whole thing is very unlikely to affect participants negatively. </li>
<li>P3028: because it will help my friend to deal with this kind of situation where in some sort of hackers got into his files and downloaded so much stuff that he was forced to turn off the computer and smash his hard drive.</li>
<li>P3032: I'd rather not because it could encourage them to actively try and make purchases from future spam e-mails.</li>
<li>P3034: This experiment is important enough in terms of magnitude for me to overcome the potential moral issues that arise.</li>
<li>P3036: This is too risky. Too much could go wrong</li>
<li>P3039: This is also very deceiving.</li>
<li>P3042: I usually dont make unsolicited purchases</li>
<li>P3043: This does not seem to be an important issue-if people want to buy something from spam, they should be allowed to.</li>
<li>P3045: Doesn't seem to be risk to anyone since no real unexpected people are getting there computers infected with spam.</li>
<li>P3046: this research is good , however , i would prefer for a friend of mine to not be included so to be safe.</li>
<li>P3047: I don't see any benefit or the participant really but it could help to stop spam.  </li>
<li>P3061: I would not want them to get spam. Spam is annoying and can lead to attacks on one's computer.</li>
<li>P3063: Everybody gets spam, it's not so important, in my opinion.</li>
<li>P3064: I would personally be annoyed if I wanted to purchase something and could not, so I would not want someone I cared about to go through the same annoyance.</li>
<li>P3066: it does not matter because anyone who would be a participant in this experiment was negligent.  </li>
<li>P3068: That person may not want their computer to be infected </li>
<li>P3069: I would feel uncomfortable having someone being able to access my computer.</li>
<li>P3076: Wasting their time and deceiving them</li>
<li>P3077: absolutely not ... risk is too high</li>
<li>P3079: I absolutely despise spam email.</li>
<li>P3082: I don't click on links from an email and provide secure information to make purchases. I advise people I care about not to do this as well. I see no direct benefit for the individual to proceed in the experiment and people should be warned against clicking on email links more instead of not telling them.</li>
<li>P3084: The words "infected computer" scare me, even if there is link replacement.  One never knows, and I've had one too many computer viruses in my day.</li>
<li>P3086: I wouldn't really want anyone I care about to be involved with spammers.</li>
<li>P3090: Again, this is really invasive, and I don't like it!</li>
<li>P3094: This could adversely affect their ability to successfully judge an attack and make them vulnerable to other attacks from spammers.</li>
<li>P3095: Yes, I'd want to help prevent spam in the future.</li>
<li>P3100: I would not want someone to be tricked into thinking they're buying something, and not receive it, with no explanation. </li>
<li>P3103: Most of my loved ones wouldn't fall for this, and if they did, it might be a good lesson for them.</li>
<li>P3117: I think the person's participation will be helpful for others and his/her personal information is not collected.</li>
<li>P3124: I hate spam.</li>
<li>P3126: It seems like an awful potential security risk for the participants involved.</li>
<li>P3130: Given the prevalent usage of spam filters, I think the methodology is antiquated and unnecessary.</li>
<li>P3132: If someone thinks they are buying something and never gets it, that would be frustrating; however, I would also be curious as to how many people click on these also.</li>
<li>P3136: It doesn't seem to be harming the participants in any way.  The only downside is they're never made aware so they may get confused thinking they purchased goods but receive none.</li>
<li>P3145: I can only envision my old grandmother getting spammed.</li>
<li>P3148: I would encourage anyone to participate in this experiment. I just want to know who is stupid enough to click on these gimmicky things on the Internet. Please I'll participate!</li>
<li>P3152: This is messed up. In fact, every one of these "experiments" are messed up and unethical.</li>
<li>P3159: It seems to go too far.  Going so far as to order from a fake store and not receive the product or service.</li>
<li>P3161: Spam email awareness is important.</li>
<li>P3165: I wouldn't want them to be part of this experiment because he might get hurt</li>
<li>P3166: The easier way to solve the problem is the base assumption that spam is trash and should be illegal anyway</li>
<li>P3170: I hate spam</li>
<li>P3177: They will not ever be told they took part in the study.</li>
<li>P3183: I don't care either way</li>
<li>P3184: I don't think it matters who is involved, all they want to know is is about the spam and if it leads to sales. They don't want super personal information on people </li>
<li>P3202: It is being performed in a controlled environment with monitoring and blocks from actual purchases being made.  </li>
<li>P3208: I would not want someone I cared about to be deceived in this way. Plus they may get frustrated by the fake store front and would not appreciate that.</li>
<li>P3209: the people in the survey should be aware</li>
<li>P3217: It sounds like important research, and I think there are enough safeguards, and the planning is intelligent enough that it would be appropriate.</li>
<li>P3223: it doesn't sound to bad but it's a bit confusing so i would need more info </li>
<li>P3224: Not ethical.</li>
<li>P3228: I think that it is a neat experiment that could open many doors.</li>
<li>P3236: don't know if it really matters</li>
<li>P3240: Any research that looks at controlling spam is importasnt and nneds people to participate in the study. There is no harm to that person. But I think it would be really difficult to get that person on the computer with the spam and relealize that there isn't something strange going on.</li>
<li>P3245: This seems too messy and complicated to get right without having personal information accidentally getting out.</li>
<li>P3246: Most people can recognize spam nowadays</li>
<li>P3258: Spam is scam! With that, it is important for people to know that spam sites and emails are just as malicious as phishing and other web based "dangers".</li>
<li>P3260: Because the experiment enables spamming, and there's no guarantee something couldn't go wrong.</li>
<li>P3261: It seems safe enough.</li>
<li>P3262: It is dishonest</li>
<li>P3268: There's no harm in anyway</li>
<li>P3274: it does not affect me</li>
<li>P3275: I would not like it if a friend was not warned of spam on the computer they were using or a false website where they are not going to get the product they thought they bought.  </li>
<li>P3276: There is no real threat and it will provide more research material.</li>
<li>P3279: I think this is a good experiment, but i do not know if i would want someone i know involved in the experiment.</li>
<li>P3289: It sounds a bit dangerous, because a purchase could potentially be made, making credit card/bank info vulnerable. But, I would think they would regulate this properly to make it a learning tool.</li>
<li>P3296: I hate spam, anyways we can reduce it, is good in my book!</li>
<li>P3299: An economic infrastructure that enables email spam. There is already spam everywhere, are current economic infrastructure enables spam.</li>
<li>P3300: Doesnt seem harmful or dangerous or even potentially beneficial</li>
<li>P3301: It's not very harmful in this case, but it also is an inconvenience. I have no preference as it's not harmful.</li>
<li>P3306: No, I would still feel like their computer and identity were at risk.</li>
<li>P3311: I don't have a different way to conduct this, but I don't feel that the need justifies the mean.</li>
<li>P3313: Something about the researcher not being informed irks me.</li>
<li>P3314: It would be safe because researchers are conducting an experiment</li>
<li>P3315: I don't care either way.</li>
<li>P3316: There are too many variables for the experimenters to try to control. They might not be able to properly protect participants.</li>
<li>P3319: There will be no disadvantage to participating. It would be their decision to make. </li>
<li>P3320: None of my friends or family should be even thinking about hitting a spam site, after all the lectures I have given them. However, if they did, I would rather they not be further deceived. </li>
<li>P3321: It just seems like an invasion of privacy. They shouldn't have access to the purchase history of anyone without their consent.</li>
<li>P3322: i support any research that could help thwart spammers</li>
<li>P3326: somewhat uncomfortable, as this could lead to negatively affected future  use of computers</li>
<li>P3331: I wouldn't want them use someone I cared about because they would not be able to purchase what they were looking for.</li>
<li>P3333: The experiment requires that the subjects be made fools of.</li>
<li>P3338: I am not sure about this experiment, it is confusing to me. </li>
<li>P3340: I don't think any harm could come from it.</li>
<li>P3341: If you allow spammers onto the computer, they may get more info than you intend and compromise security</li>
<li>P3343: I don't see how it would pose a problem.</li>
<li>P3351: No one wants to receive spam. </li>
<li>P3354: I don't like that it is using financial information and that the victims are not aware of it.</li>
<li>P3358: Concerns whether researchers will have total control or hackers will </li>
<li>P3359: I don't want someone I cared about to be naive enough to purchase something from a spam site.</li>
<li>P3360: the research is not that important to find out how much spammers actually sell.  there are many ambiguous areas.  is one reads the buys the email, is it spam to them?  the so called research needs high tech which often goes wrong.  mostly, the secretiveness of it is not ethical.  i would not like to try to buy something on line to find out i was in a secret study and actuallydid not make the purchase</li>
<li>P3373: There are two pieces of this experiment that seem unethical to me: 1) altering the code of the so-called spammers and broadcasting it, seemingly in their name, without their knowledge and 2) by not informing either the so-called spammers or the participants that research is being conducted  it is possible that misunderstandings could develop between those two parties which would be problematic to reconcile.</li>
<li>P3376: Anybody can be part of the study group me included</li>
<li>P3378: I don't like that the computer used by researchers is infected by spam. </li>
<li>P3389: No one I know would make a purchase from a public computer. </li>
<li>P3391: It does not sound ethical</li>
<li>P3397: information on what they are doing wrong can help prevent this from happening</li>
<li>P3403: I don't think there is any psychological risk involved so I don't see the problem with it.</li>
<li>P3406: It is not harmful</li>
<li>P3408: N/A.</li>
<li>P3412: It seems there must be other ways than spamming people, to determine how often people respond to spam. It seems a needless experiment, and questionable ethically.</li>
<li>P3416: We get spam every day, there is almost no stopping it, so I would be ok with this experiment.</li>
<li>P3426: I think there is too much risk with this one. </li>
<li>P3427: Although I understand the need of the survey, it seems a little unfair to the participant who has zero knowledge they are being duped. The participant believes they are contacting a store where they have an actual interest and may want to buy, but then will never receive a product. The inability to inform users seems a tad unfair to the users.</li>
<li>P3428:  I don't see this research as a bad thing per se, but it would be somewhat undesirable to have someone I care about receiving spam emails.</li>
<li>P3431: It wouldn't harm someone I care about but I don't have a reason to want them to do it.</li>
<li>P3438: The researchers would be releasing private information about the users to the spammers.</li>
<li>P3440: I feel you could do this study without having people go through the risk of buying from a spammer.</li>
<li>P3442: The experiment may involve tricking the subjects into thinking they've made a purchase when they haven't. This doesn't seem ethical.</li>
<li>P3445: Their computer is not at risk in this experiment</li>
<li>P3447: I wouldn't want someone I cared about to not know that they were making a fake purchase.</li>
<li>P3453: I wouldn't want anyone receiving my loved ones data. Collected or not.</li>
<li>P3456: I still see no major harm in this experiment.</li>
<li>P3463: There would be no harm done to the person, and it would be done without them knowing about it.</li>
<li>P3466: There seems to be a security risk, and also it would be frustrating to not be able to buy the product which could lead the consumer to the spammer.</li>
<li>P3467: I can't stand anything to do with spam.</li>
<li>P3469: I don't trust that the researchers can make this completely safe.</li>
<li>P3472: That is just not right to do that.</li>
<li>P3483: I don't think it's harmful and we get information from it.</li>
<li>P3487: I think this could provide very useful data for researchers</li>
<li>P3488: It seems to be safe, if it's just for research</li>
<li>P3491: I think that the experiment will lead to helpful information, but I think that most people would not like to find out that they were being "watched" or studied without their consent.</li>
<li>P3495: I think this could help them in the long run and if not them then others.</li>
<li>P3498: This research study seems misleading if they do not tell the participants after the fact that it was not a real store.</li>
<li>P3503: Because I wouldn't want someone I cared about being studied without their knowledge or permission.</li>
<li>P3508: I think this experiment may be illegal.</li>
<li>P3510: good way to show someone how it is done.</li>
<li>P3516: As long as not harm would come to the individual or their equipment then I would say the decision to participate would be up to them.</li>
<li>P3518: They would be deceiving the users</li>
<li>P3522: There seems to be a slight risk involved in participating.</li>
<li>P3523: it would teach them not to fall for hackers tricks</li>
<li>P3524: I think it could be psychologically harmful to do that to someone without their knowledge.</li>
<li>P3525: Allowing one of the PCs to become infested is asking for trouble</li>
<li>P3526: It could help prevent spam based cyber attacks.</li>
<li>P3532: I don't believe anyone I know would purchase something from a spam email</li>
<li>P3534: I feel that individuals should be informed if they are being scammed, even though it would compromise the research data.</li>
<li>P3536: Again, they can do whatever they want. There's no risk to taking this experiment. \r\n\r\n(Sorry if my answers are becoming redundant--a lot of these experiments seem good to me, and interesting.)</li></ul>	</div>
</div>
<div class='cap' style='max-width:30%;'>
	<div class='header closed'>Facebook study, answers to Surrogate question</div>
	<div class='body'>
<ul><li>P5: Because participants will not be identified. </li>
<li>P11: it is an invasion of privacy</li>
<li>P20: Unsure about this one.</li>
<li>P21: There is no mention of the people being informed that they are part of a study.</li>
<li>P27: I don't think it is ethical for the researchers to exclude any posts.</li>
<li>P33: dont want them to be hurt.</li>
<li>P43: These seems harmless. </li>
<li>P46: It doesn't seem like there would be any risks to the experiment. </li>
<li>P52: Doesn't matter if it's someone I care about.</li>
<li>P54: There don't seem to be any problems w</li>
<li>P55: This is facebook just cooking up another scheme to market better and improve their share price.</li>
<li>P56: This experiment seems to provide no real benefit to the person I care about.</li>
<li>P59: I see no real reason why this would be done, It's messing with peoples feeds and potentially their emotions</li>
<li>P60: Experiments like this are fun and interesting.</li>
<li>P61: it's not Fb's role to "protect he moods of psychologically-vulnerable users" to this extent</li>
<li>P65: I believe that within reason it is a decent experiment, thought it does raise questions about content and consent.</li>
<li>P69: I DONT SEE WHY NOT</li>
<li>P77: First, I believe it is unethical to conduct any study without the consent of its participants.  Second, this experiment involves gross manipulation of and intrusion into the personal and public lives of human beings.  It also involves misrepresentation of the emotions of human beings publicly, which could pose grave and far-reaching consequences in terms of disrupting or influencing the interpersonal relationships and public perceptions of human beings.  Finally, the outcome of this experiment, which is to allow Facebook to produce features that "might protect the moods of psychologically-vulnerable users" is ridiculous to begin with.</li>
<li>P80: No harm done and it seems interesting.</li>
<li>P84: If that friend thought it might benefit them then I would say go for it. I personally would not want research on my personal page.</li>
<li>P93: This seems unethical</li>
<li>P94: There is no purpose of this.</li>
<li>P96: It seems like it is invading one's privacy to me.</li>
<li>P97: It doesn't really matter what shows on a person's newsfeed.</li>
<li>P101: Yes, there does not seem to be any risk to anyone involved.</li>
<li>P106: As far as I can tell from the description, there is no real benefit to any of the candidates for participation.  Candidates should be compensated in some way if their data is going to be used by facebook to develop new features.</li>
<li>P117: They will miss out on news from their friends.  Possibly they will miss out on info I want them to know.</li>
<li>P118: If the results were to remain anonymous, I wouldn't care either way</li>
<li>P119: That would make them seem like complainers to their friends</li>
<li>P121: I dont use Facebook anymore</li>
<li>P122: It is none of anyone's business what is on anyone's facebook page if you are not invited</li>
<li>P135: It doesn't harm anyone.</li>
<li>P136: It doesn't seem dangerous, nor particularly useful.</li>
<li>P141: If they want to be a part of research that is fine, if they don't, that would also be fine with me. No preference.</li>
<li>P143: It seems silly and of little real value, but I would not be concerned for anyone participating in the survey.</li>
<li>P145: I wouldn't want to do this</li>
<li>P155: As long as they're adequately informed about the experiment's methods and parameters, it's entirely their choice.</li>
<li>P156: Why wouldn't I want someone else to take advantage of earning money.</li>
<li>P157: Participants will not be identified and will remain anonymous</li>
<li>P159: It's wrong to mess with people's minds, especially if you don't warn them, so they can protect themselves against the mind games.</li>
<li>P166: Does not seem like a terrible experiment. No real harm would be done. </li>
<li>P169: There seems to be potential harm to participants.</li>
<li>P171: The experiment doesn't seem particularly invasive but a little annoying, messing with my tweet feed. </li>
<li>P179: Subjects aren't consenting to participate in a study. </li>
<li>P180: I would not want my mood to be manipulated by an outside source without my direct consent.</li>
<li>P181: I am also curious about the result</li>
<li>P183: There does not seem to be any harm in doing it, if they want to do it, I have no objections.</li>
<li>P184: It seems to be a harmless and relatively unimportant study. I would have no strong opinion on it.</li>
<li>P185: I would not like my information accessed through someone elses facebook</li>
<li>P188: I do not think it is right to withhold posts just because they are deemed negative. I feel it is an invasion of user rights toward freedom of speech.</li>
<li>P192: It's facebook, the people who own and run it have that information on us anyways. I'm indifferent to that type of experiment.</li>
<li>P197: to help learn more</li>
<li>P200: I don't really care.  I find this kind of a stupid thing to do, but it doesn't hurt anything.</li>
<li>P211: they will not see some of their friends posts</li>
<li>P218: The experiment seems safe</li>
<li>P220: No because that's an invasion of privacy.</li>
<li>P231: I feel like people should be expose to the truth no matter what.  I do not think anyone I cared would want there twitter stream altered, and they probably would no want to be lied to.</li>
<li>P232: I believe that people should know when they are being observed in this way</li>
<li>P239: No negative environmen is created</li>
<li>P242: it's just facebook</li>
<li>P248: I think the results of this study will help  understand how sharing in social media sites influence emotions and behaviors of individuals. I hope that such a study will be useful in helping society become stronger and better with the proper use of the social media sites.</li>
<li>P253: I don't see the issue in being a participant, as the results will be posted in aggregate.</li>
<li>P254: Again this is for the greater good.</li>
<li>P258: I'd be curious to see if it works, especially on some of the bubbly people I know.</li>
<li>P270: It's not only an invasion of privacy, it's actually changing the meaning of what's been written, however slightly. It could trigger libel law suits.</li>
<li>P271: I have no sympathy for anyone foolish enough to throw their "stuff" all over the internet via Facebook</li>
<li>P272: I don't want the person that I know to be censored.</li>
<li>P284: I see nothing wrong with this experiment.</li>
<li>P289: Facebook needs to stay out of its users' lives.</li>
<li>P291: I don't think the experiment is vital.</li>
<li>P292: I would not want to subject to such an experiment.</li>
<li>P302: trying to manipulate someones feelings </li>
<li>P308: again this situation is being simultated so there is no harm that can come and something important could be learned</li>
<li>P309: I think this is an interesting experiment.</li>
<li>P313: Technically no harm.</li>
<li>P314: seems harmless</li>
<li>P316: I have a sister and a mother with diagnosed psychological issues. I feel this study would be beneficial in helping them keep a happier mood. (why my mom does not watch the news because it brings her down and she does not cope as others do)</li>
<li>P317: This is fine as long as you inform the participants beforehand that their posts will be studied for the greater good</li>
<li>P322: i think that users should be informed first, but otherwise i think it is ok</li>
<li>P326: Twitter is pretty much public anyways</li>
<li>P327: this is not harming anyone </li>
<li>P334: I'm pretty sure it's illegal to hijack someone's FB account.  They could simply ignore the negative posts and track the reactions to the positive ones.</li>
<li>P347: I think positive thoughts are a source of comfort to others and can see no harm in conducting this research</li>
<li>P350: Seems like a safe experiment</li>
<li>P354: This probably happens everyday anyway</li>
<li>P369: Don't see any harm, and seems like a useful experiment that extends beyond Facebook.</li>
<li>P370: Not really sure this is of any value.</li>
<li>P371: This research study has no real risk.</li>
<li>P376: I think that Facebook is suppose to be a private thing of one's life and shouldn't be brought into research without consent. </li>
<li>P383: I would not want to chance something going wrong and she got hacked.</li>
<li>P384: It seems like a boring study.</li>
<li>P390: I feel like this would be a good thing to know for psychological research. </li>
<li>P403: The experiment seems benign, so I would not warn anyone one way or another.</li>
<li>P406: Manipulating posts in order to manipulate mood seems unethical, especially since it doesn't appear in this description that participants are even aware of being in a study or have given consent.</li>
<li>P409: I think the experiment is stupid and would not accurately reflect social behavior or the reasons behind certain behavior</li>
<li>P411: I think is useful</li>
<li>P412: I believe that this could cause problems by altering what a person actually posts for their friends and family to see.</li>
<li>P415: seems intrusive to me</li>
<li>P417: I don't think most people I know need any more manipulative aggravation in their lives.</li>
<li>P418: Facebook fails to follow their own TOS/Community Standards. I do not support them nor their supposed research.</li>
<li>P419: No because, how does the study access their account to remove some of the posts? I would not want their account messed with.</li>
<li>P422: Why would researchers need to protect users' moods? Users don't need Facebook controlling or altering their moods. </li>
<li>P425: My experience in this has proved that negative thoughts produces negative thoughts and vice versa.</li>
<li>P427: I'm on the fence about this.  I would be annoyed to find out that my news feed was altered in this way, but it wouldn't have any major effect on anyone.</li>
<li>P428: If the twitter user is willing to allow there feed to be altered that is their desicion</li>
<li>P429: seems like invasion of personal space</li>
<li>P437: Their hacking your fb account.</li>
<li>P442: I think some people may be interested in the research.</li>
<li>P444: So he or she can become conscious of being affected by other´s comments </li>
<li>P445: I believe that this is entirely their choice and has nothing to do with me</li>
<li>P446: seems like a waste of time, who cares</li>
<li>P449: it would really be up to them. I don't see a problem with it</li>
<li>P450: people should decide on their own</li>
<li>P453: It would be interesting to see who it worked..</li>
<li>P458: It would be interesting to see how a friend or family member of mine is swayed by their friends.</li>
<li>P462: It sounds like the researchers are using some sort of manipulation in terms of potentially affecting a person's mood. </li>
<li>P464: whether facebook friends post happy or unhappy thoughts is not really that important and doesnt affect anyones day-to-day life</li>
<li>P467: This is also allowable and very testable.</li>
<li>P470: I have no preference to including a person I cared about in the experiment because I don't think the reason for the study is really important.</li>
<li>P472: Seems relatively harmless</li>
<li>P473: I don't see any issue with the experiment. </li>
<li>P475: Since the candidates will be kept anonymous, it doesn't matter what I think of them joining or not joining the study.</li>
<li>P476: As long as there is no harm there should not be any issues with participating</li>
<li>P480: I think anyone that QUAIFY'S SHOULD PARTICIPANT</li>
<li>P484: I don't think I'd want my friends to participate in a study involving social media. </li>
<li>P485: Again, nothing specifically pulls me one way or the other.</li>
<li>P486: I wouldn't want their moods to be artificially determined. </li>
<li>P491: Facebook is not an appropriate forum for such testing. "Participants" are not stated to be, at any time, notified of their participation in such a study. While Facebook has executive control over the use of the information on their website, I do not believe it is ethical to manipulate their users in such a fashion for what equates to marketing research. Automated algorithms to determine positive or negative mood are also subject to significant error. Far too many potential variables for experimental results to be valid. Did a business management undergraduate think this up?</li>
<li>P496: This seems totally useless. Also, your hiding friends' posts from users, which negates the purpose of Facebook. This sounds like it's bordering on censorship - "researchers will not be able to produce features that might protect the moods of psychologically-vulnerable users."</li>
<li>P498: I doesn't see like it would cause any harm</li>
<li>P505: This wouldnt bother me at all. I see no harm here.</li>
<li>P513: You cant let someone mess with your friends facebook. </li>
<li>P515: I hate to read unhappy post by my friends and family.</li>
<li>P517: This may lead to better social network privacy settings so it is my loved ones choice to go online and take a chance here.</li>
<li>P519: I personally am hesitant to share information on Facebook. </li>
<li>P528: I would hope the people I care about have solid enough self esteem so that there mental status would not be affected by some inane Facebook comment. </li>
<li>P529: I think it would be helpful for a lot of people and the results could help so many people avoid negative thoughts.</li>
<li>P531: I personally use Facebook to connect with friends and family.  I would not appreciate being fed untrue information, positive or negative.</li>
<li>P532: No harm that I can see.</li>
<li>P533: dont want to give you access to facebook account</li>
<li>P535: This looks like another data security issue.  How would the personal information or Facebook account of the participant be protected?</li>
<li>P538: Seems like it would likely to hurt anyone I cared about.</li>
<li>P539: I realize Facebook is public, especially if people have friended each other.  However, I don't think it is right to alter other peoples' information for the sake of research.  They have a right to see what is sent to them--good or bad.  It's really no one else's business what's on their sites.</li>
<li>P541: What people do is up to them.  This isn't a 'dangerous' thing from my perspective so have no preference.</li>
<li>P548: Either way, I don't see any harm in taking part in the experiment. </li>
<li>P554: sounds like an experiment that won't harm anyone.</li>
<li>P555: The choice would be up to them but I also would want the option to not be included because even though facebook is a social media I would want to choose what I post or have access to post</li>
<li>P558: Facebook isn't supposed to be edited, nor are users' mental states supposed to be evaluated by armchair psychologists</li>
<li>P561: People's moods may be important to study</li>
<li>P573: This seems like a fairly harmless study and I would be fine either way.</li>
<li>P576: I would hate for them to be exposed to a bunch of negative stuff.</li>
<li>P578: It's unethical to interfere with something like that.</li>
<li>P579: Facebook has enough emotions on it</li>
<li>P583: No preference </li>
<li>P590: I don't see how it would hurt.  I'm unclear if the actual posts would be included in the paper or not.  That could be an invasion of privacy.</li>
<li>P594: I would not want someone I care about to be a participant because their personal Twitter account is being monitored without their prior consent. </li>
<li>P606: A person's Facebook is a personal page where everyone shares their thoughts and feelings with each other and a way of keeping in contact with each other. </li>
<li>P608: Will the participants be notified and given an opportunity to have their data removed from the experiment? </li>
<li>P612: I think this could possibly cause people to be depressed if they read other peoples unhappy thoughts. i do not want any of my loved ones to be depressed for an experiment.</li>
<li>P622: think this would be fine not too risky.</li>
<li>P626: I think it is manipulative and a violation of their privacy.</li>
<li>P628: I don't think the user is properly given information at the end of the experiment.</li>
<li>P629: It seems difficult</li>
<li>P633: I don't feel there's any risk, but I'm not sure I think the research is that vital to understanding human nature. </li>
<li>P644: i think the experiment is for everybody</li>
<li>P646: It sounds very interesting. I would like myself or anyone I love to do it. The positive one is good. Although if they were inundated with posts on the negative side I would say no. </li>
<li>P647: This seems rather invasive personally. I don't see any security benefits or protection from hackers. This sounds more like a marketing ploy rather than protecting the psychologically vulnerable. Even if this experiment is well intentioned, moods online are a symptom of a larger problem in modern culture. You're trying to treat the symptom rather than the problem. This study is pointless and invasive. </li>
<li>P652: I do not see what it would harm the person by doing this research.</li>
<li>P656: I think it would be an interesting experiment to take part in.</li>
<li>P658: Researchers should not have access to anyone's facebook feed and what comes up on it. </li>
<li>P660: The person may miss important information about the people they keep in contact with via Facebook.</li>
<li>P667: As long as the research isn't malicious then why not. Go ahead.</li>
<li>P668: because they could decide themselves</li>
<li>P672: I think it would be cool to see the results. </li>
<li>P676: I think I would nominate this study for on IgNoble award.</li>
<li>P678: it doesnt seem to be hurting anyone</li>
<li>P682: Deceptive.</li>
<li>P685: I would be angry if someone manipulated my Facebook page without my consent.</li>
<li>P688: I don't see the harm</li>
<li>P689: Someone's Facebook is rather private, even if the method doesn't necessarily violate privacy.</li>
<li>P692: Privacy concerns</li>
<li>P694: I don't see why not, the research seems harmless to me.</li>
<li>P696: While I imagine the posts on Facebook are monitored anyway, it does not make much sense for Facebook to go out of its way to potentially harm it's image when this study is published and people find out they were involuntarily studied from an account they may have trusted.  Also it seems difficult that an automated algorithm would be able to differentiate happy thoughts from sarcasm. </li>
<li>P702: I think that seeing negative posts mostly would bring the person down and I would not want them to feel a negative emotion. </li>
<li>P704: These researchers need to get a life. If someone is affected by their friend's negative outlook on life, it is their problem and they need to see a shrink. They do not need to see a scientific research project that tells them that is why they feel bad.</li>
<li>P705: It would be interesting to see the outcome.  </li>
<li>P708: I would like them to have more positive in their life.</li>
<li>P710: Its a personal decision</li>
<li>P717: This just seems like a waste of time all around.</li>
<li>P721: I really don't care one way or another. Facebook is not a huge part of my life - and I don't think that it should be. It is a nice way to share information.</li>
<li>P722: Seemingly waste of experimental resources.</li>
<li>P729: I don't see how this would really hurt anyone so it doesn't matter.</li>
<li>P732: They might be chosen to only see unhappy posts!</li>
<li>P735: If the person wanted to be a candidate I don't see any reason that they could not be a participant. I don't see any truly negative consequences to participating.</li>
<li>P737: This just doesn't seem like a legitimate use of time to me.. Facebook is using this information to benefit themselves and it should not be allowed.</li>
<li>P740: It's matter of personal choice</li>
<li>P761: The subjects arent notified, therefore it is unethical.</li>
<li>P763: Wow. Are they doing this?  This is a very odd and specific scenario.  Let's depress random members of our community and see what happens.  </li>
<li>P769: I would not want them to be posting negative post and only reading negative posts.</li>
<li>P770: Excluding posts suggests to the "vulnerable" user that he/she is not even capable of using Facebook on his/her own. This type of monitoring seems unnecessary.  </li>
<li>P772: It seems harmless</li>
<li>P776: I don't think it is right to control which posts from X to Y are seen or not even seen by Y. It could cause problems if an important post was not seen by the receiver.</li>
<li>P780: I don't think its right to mess with anyones Facebook profile without their informed consent and the research might satisfy curiosity but it is not a matter of safety and not really necessary </li>
<li>P784: This does not seem like a necessary experiment, and going through peoples facebook accounts and changing the messages, does not seem right.</li>
<li>P787: I think it depends on how much the researchers change their facebook and if it gets changed back afterward.</li>
<li>P788: I have no strong feelings either way about this experiment. </li>
<li>P792: If the person I cared about happened to be in the group with a limited proportion of negative posts, I would worry about the effect on their happiness level.</li>
<li>P794: There's no reason not to participate. To me, the experiment is like going on facebook, just with less of a news feed.</li>
<li>P800: Don't believe it is right to include or take away friends' posts in newsfeed.</li>
<li>P802: Facebook is not the place for such manipulation. </li>
<li>P803: There is no risk involved.</li>
<li>P811: Yes, because Facebook in a place where a lot of people go to post their feelings and thoughts.  Others respond by being there for them in good and bad times.  It helps to have a lot of friends to share things with.</li>
<li>P812: They're missing valuable things if certain posts on their friends list are being withheld from them.</li>
<li>P816: I think some people really get effected by things like this</li>
<li>P820: I don't think it's a harmful experiment and might be interesting to know. </li>
<li>P821: This feels like a breach of privacy to me. I don't think any tests should be allowed through facebook.</li>
<li>P827: n/a</li>
<li>P828: There is no risk, it is just altering the items that participants are exposed to.</li>
<li>P835: No harm in this</li>
<li>P836: i think it would be good to show how others influence ones thoughts most people dont realise the dangers of facebook</li>
<li>P837: Negative impacts seem low - as long as some sort of prescreening to keep negative feedback away from participants who might be at risk for hurting themselves.</li>
<li>P841: I would be interested to see how invested they really are in their social networking accounts.</li>
<li>P845: I don't see how it could harm the person, so I would not object.  On the other hand, I don't see much value in Facebook so it would not interest me much</li>
<li>P847: Because some of the Twitter posts will be excluded from the news feed without the users consent, it infringes upon their First Amendment rights to freedom of speech.</li>
<li>P850: I don't want my newsfeed manipulated</li>
<li>P858: Emotional manipulation is not a good thing to do to your users.</li>
<li>P865: sounds harmless and interesting. i would actually like to be a part of this study too. </li>
<li>P866: If the person agree to permit that.</li>
<li>P870: Why not just collect data about how many positive thoughts are followed by friend's positive thoughts and how many negative thoughts follow as a result?</li>
<li>P874: Doesn't seem like a experiment that would cause any harm to someone who would participate</li>
<li>P880: I'd rather that researches didn't rearrange my facebook.</li>
<li>P881: I feel that a tests is being conducted with skewed results.</li>
<li>P882: While I'm doubtful that the information is really that important or that those vulnerable to negative tweets really need much protection, I feel there isn't a really potential to harm the participants.</li>
<li>P884: I find a scientific experiment like this is interesting and can teach us a lot about the way that we act. Furthermore since things like facebook is relatively new, we still have things yet to find out about it and how it affects society</li>
<li>P886: I'm not sure I understand the concept here.  If the candidate knows the researchers are controlling the account, then they could react differently anyway.  If they are unaware, then you are changing things in someone's Facebook account illegally.</li>
<li>P890: I don't see how this would have a big impact on a person, so it wouldn't matter to me either way.</li>
<li>P893: it says optional</li>
<li>P898: most of my facebook friends posts are usually just relinks to articles we read</li>
<li>P901: There's no way to protect the moods of psychologically-vulnerable users.</li>
<li>P904: I'm not interested in this kind of tracking. </li>
<li>P908: I don't see anything wrong with it.</li>
<li>P912: Cause we don't always let our moods flow over into Facebook. </li>
<li>P914: I think facebook should be off limits due to privacy issues.</li>
<li>P921: The study seems harmless but perhaps a little unnecessary. </li>
<li>P925: this is unfair to the people involved - it gives them the wrong impression of their friend</li>
<li>P926: I think that it would be interesting to see the results of this experiment. </li>
<li>P927: this experiment can be allowed, as this is a on-line experiment and would give a proper result, i would allow my cared one to be  part of this experiment</li>
<li>P929: Some of my friends struggle with depression and I wouldn't want to run the risk of exposing them to that much additional negativity.</li>
<li>P934: i think everyone would react differently.</li>
<li>P936: As long as the participants are told they will be included in the experiment and may not see some posts.</li>
<li>P938: If they're not identified, it doesn't affect them.</li>
<li>P939: I think this is digging on a too-personal level. Excluding someones 'negative' posts is really wrong. This person might be reaching out to his/her friends and the very thing they may need, is someone to talk to. This experiment is too risky, I think.</li>
<li>P940: I wouldn't feel comfortable if I were a participant myself.</li>
<li>P942: I personally do not like negative posts, but imagine they do affect some people negatively</li>
<li>P948: It's their choice.</li>
<li>P951: it seems harmless</li>
<li>P953: This seems like an interesting study.</li>
<li>P955: Facebook is used by choice and it is a very personal thing. I don't think it would be ethical for researchers to manipulate someone's Facebook without their knowledge and consent. It actually sounds quite mean. Some people place a lot of value on their Facebook experience and it seems like this study would be messing with people's emotions. </li>
<li>P957: I would not want someone I know to participate in this experiment.  I do not feel like a person's personal messages should be excluded to prove a point in an experiment.  By randomly excluding posts from friends, the participant is missing personal correspondence from their facebook account.</li>
<li>P958: I don't see how this could do a lot of harm to anyone, unless the were depressed.</li>
<li>P960: It is an invasion of free will.</li>
<li>P963: It would be interesting to know the results, but I would be concerned with the privacy of posts being read, even by an aggregator.</li>
<li>P972: Doesn't sound so bad.</li>
<li>P976: it interferes with their privacy</li>
<li>P984: It doesn't seem harmful in any way, so I think it would be interesting experiment.</li>
<li>P986: this is a form of censorship </li>
<li>P989: Reading about someone's post being negative can be a bit depressing on a participant, and would not want that on someone I cared about because they already have enough to worry about. </li>
<li>P991: I am not that person and this experiment is not really relevant to me.</li>
<li>P1004: I would be worried that the negative mood would affect them for a duration beyond what the experiment intends.  I also do not like the idea of their social information being subject to experimentation.</li>
<li>P1005: There is enough data that analyzed correctly, you would not need to perform this experiment. You can analyzed data from Facebook already. This could be potentially really bad. Especially because you are introducing a social element.</li>
<li>P1007: seems an invasion of privacy</li>
<li>P1010: I do not view any harm.</li>
<li>P1016: I would want the person to decide.  I wouldn't want to interfere if the person wanted to participate.</li>
<li>P1017: i have no problem w/this so whatever is ok</li>
<li>P1024: If it will help with scientific research and they remain anonymous then I see only a benefit. </li>
<li>P1026: I find this study to be manipulative. </li>
<li>P1031: I don't actually think this is entirely ethical, but controlling media content is nothing new. Think television programming. </li>
<li>P1041: It's not my right to determine another person's participation. </li>
<li>P1050: Modifying a users' social interactions without notifying them up front is unethical.</li>
<li>P1054: Wouldn't mind either way.</li>
<li>P1055: That is a flat our lie.  The person mighty things were great with their frieds and that might not be Fun or even healthy,  </li>
<li>P1058: I think social media has become so integrated in our lives in the past couple of years. I think both good and bad things have come from it. I think this would be a great research study and would recommend it to someone I cared about.</li>
<li>P1059: They could miss possibly important information.</li>
<li>P1061: people's feeds shouldn't be tampered with - if the experiment proceeds, participants should be informed that they will miss some items in the news feed and agree to that condition.</li>
<li>P1062: People subscribe to facebook for a reason - to keep in touch with the goings on of people they know. If certain events are taken out of their news feed, the reason for them being there in the first place is no longer being served.</li>
<li>P1063: Seems like an invasion of privacy</li>
<li>P1068: Social media should be personal and not subject to research like this. </li>
<li>P1071: I think this is too personal a level to be intruding on.</li>
<li>P1072: Fuck Facebook.</li>
<li>P1076: It would be up to that person.</li>
<li>P1077: I don't think any harm can come of this experiment.</li>
<li>P1083: I don't see the harm in participating in this experiment, it is actually fun.</li>
<li>P1084: I do not think that people should mess with other people's Facebook.</li>
<li>P1088: It is up to the person being faced with the ability to take the study.</li>
<li>P1089: I don't feel that this study would hurt the participant in anyway, however, I also don't see how this information is useful.</li>
<li>P1108: If someone wants to participate in this I don't mind. It's not effecting me.</li>
<li>P1109: I don't really see the point of this.</li>
<li>P1110: I don't see the harm in participating in such an experiment, but I do not see much benefit in it either.</li>
<li>P1111: This research will interfere with the person's personal life, which I don't find appropriate.</li>
<li>P1112: I don't like the idea of Facebook excluding posts from the news feed.</li>
<li>P1116: I think the idea of the research is good and I think the participants need to be random.  I don't think my friend would be harmed.</li>
<li>P1119: I would allow them to participate in this experiment, because they are not placed in any danger and it allows the researchers to gain more data for their research.</li>
<li>P1123: I think this is a fantastic idea for an experiment and would want anyone to be involved in it. I would be interested in participating.</li>
<li>P1130: Sounds safe for people.</li>
<li>P1131: This study may change people's emotional states without their consent. May have unintended consequences.</li>
<li>P1133: This experiment could cause personal harm to the participants as they may wonder why friends' postings are different than normal, or why a friend is posting more or less than usual. If postings are more negative than usual, a participant could mention this to a friend which may skew the experiment's results. </li>
<li>P1140: I think they would not mind being in a experiment like this.</li>
<li>P1146: I wouldn't want them to risk being exposed to more negative posts than are already on their page.</li>
<li>P1156: Because the people I know make generally happy (positive) postings. </li>
<li>P1157: A social network is a place to communicate with others, with emphasis on the word 'communicate.'  Using it for any other purpose, whether scientific, political or social, or any other type of research, is improper and should not be allowed.  There should be no analysis whatsoever of communications, with the possible exception of length.</li>
<li>P1158: This is an abuse of Facebook, and must violate the TOS. To exclude posts from a form of communication  such as Facebook is no different than deleting a persons voicemail. Wrong on so many levels.</li>
<li>P1159: No, because it is interrupting the service facebook provides, and it is not something the test subjects will know about. </li>
<li>P1162:  have no problems with this harmless experiment</li>
<li>P1165: I think anyone I know can handle some negative posts and they may even post more positive things in order to try to bring the mood up.</li>
<li>P1174: because it wont hurt them and no one will know who they are</li>
<li>P1178: Sounds like a harmless study</li>
<li>P1179: I don't see why not. Their identity will remain anonymous so there is really no risk. </li>
<li>P1180: I don't fully understand how this experiment works from the description, but it sounds really sketchy and the logic behind it is pretty stupid. If there were a more intelligent reason why this experiment is at all necessary, then maybe I'd have a different opinion. </li>
<li>P1181: If I was previously notified. </li>
<li>P1191: Facebook has no real bearing on every day life and not everyone uses the website. I wouldn't see the value in the results.</li>
<li>P1192: I don't see any value in learning the happy/sad state of twitter posters.</li>
<li>P1195: The results of the study would be interesting. I wouldn't mind because there is really no harm being done. Nothing is being changed just eliminated.</li>
<li>P1196: Because there is no indication if the excluded posts will be eventually sent to the individual or just lost forever.  If the posts where eventually delivered, then I might consider saying yes.</li>
<li>P1199: I don't see any harm in the study.</li>
<li>P1203: I want happiness to spread to others and if this easy experiment works, than great!</li>
<li>P1206: It would be their decision to make. </li>
<li>P1211: I would be supportive of them either way. If their posts are more negative, oh well. That doesn't mean that their general disposition will be more negative. Facebook is not life. </li>
<li>P1216: I don't consider it facebooks job to protect the moods of it's users.</li>
<li>P1217: If they don't know they are being studied, this could actually mess with their emotions and effect their mood in a negative way</li>
<li>P1220: I would have someone that I know participate in this project because it is useful information and is in no way harmful to the participants.</li>
<li>P1230: I don't think this is a big deal.</li>
<li>P1233: This is an interesting psychological question. It could help correlate human behavior online with that found in the offline world.</li>
<li>P1234: I don't use facebook much.</li>
<li>P1238: Doesn't really affect anybody</li>
<li>P1239: I don't use facebook so I really don't have any preference.</li>
<li>P1243: It is up to them I do not think any harm would come from it</li>
<li>P1247: It is really irritating to have your Facebook feed excluding posts randomly, so they should not be doing that for anyone.</li>
<li>P1248: I don't see the harm in this study. I would be interested in the results.</li>
<li>P1253: Editing of posts is something a person should have the right to expect to NOT happen.</li>
<li>P1260: It doesn't really matter to me if someone participates in a study about facebook. </li>
<li>P1261: No sensitive information is being taken and this seems it wouldnt have any bad consequences. </li>
<li>P1262: Their privacy would be compromised.</li>
<li>P1264: I think this study would only be fair if participants were allowed a general overview of the experiment, and had the freedom to decide whether to participate. I would be most concerned that someone having a really bad day would happen to be exposed to friends' negative content when they log into FaceBook, and they could potentially fall into a dark place in their own mind.</li>
<li>P1266: Because I cannot see how they would get into people's facebook accounts and how they would pose as friends.  And it could cause upset to people for many reasons.</li>
<li>P1267: I don't really care one way or the other about this research. Since there are no risks to the research I have no qualms against it or for it.</li>
<li>P1268: I feel like this project has the hypothesized goal of attempting to make people more negative, so I'd prefer my friends to stay positive. </li>
<li>P1269: I don't think this data is valuable.</li>
<li>P1270: i think other forms of studies can be used to determine moods besides using facebook which does have personal data</li>
<li>P1272: It's incredibly malicious to post fake facebook feeds to someone timeline. I would be furious & instantly delete my facebook(though I have already) if I found out facebook was posting fake statuses on my behalf.</li>
<li>P1274: I need to physically talk to someone face to face to be able to determine if I would like to continue speaking to them or not.</li>
<li>P1279: I do not know anyone who uses twitter.</li>
<li>P1283: It neither helps nor harms the person who is participating, so it doesn't really matter.</li>
<li>P1285: I don't think any of my friends or family post on Facebook that much.</li>
<li>P1286: Their taking out positive parts of people's days for friends to see. Ultimately it would create a negative impact on someone I care about.</li>
<li>P1288: If they wish to be a part of it, assuming they're an adult, then that's fine.  I don't think they should be included if they're unaware of the experiment or haven't agreed to it.</li>
<li>P1289: i don't see any great value or problem with this research</li>
<li>P1295: I think that we're not going to change targeted ads at all and if they're working on improving them to be suit individuals then there really shouldn't be any negative involved provided the community as a whole knows it's going to happen and there is an opt out feature to assure those who do not are not randomly selected anonymously.</li>
<li>P1296: I would like to see how easily influenced they are by other people. </li>
<li>P1297: If they signed up to be a part of it it is fine with me.</li>
<li>P1299: I think it will be interesting to see what the results are.</li>
<li>P1300: I don't really use Facebook so I don't have an informed opinion on what the side effects of such an experiment would be.</li>
<li>P1301: If my friend is dumb enough to use twitter and is not famous, let them think someone like's there dumb tweets, it may make them feel better about themselves.</li>
<li>P1302: I don't believe this will do much in the long term. I view it as a waste of time. </li>
<li>P1310: I don't think purposefully messing with someone's emotions without their knowledge is moral.</li>
<li>P1311: Doesn't affect me in any way.</li>
<li>P1318: There is no harm being harm only insights.</li>
<li>P1319: They don't ask for consent</li>
<li>P1320: I wouldn't want someone altering what I would see so I wouldn't want someone altering what a person I cared about could see.</li>
<li>P1328: It seems weird and I could miss important information</li>
<li>P1331: I don't really have an opinion on this so no preference on whether they participate.</li>
<li>P1332: It tampers with content that they may want to see, they miss important events in their friends lives if it is filtered.</li>
<li>P1338: I am curious how the automated algorithm figures out if a post is negative or positive.</li>
<li>P1340: I don't think the person I care about would appreciate their personal messages being used in this survey.</li>
<li>P1343: I don't think that toying with emotions is okay, especially when it involves hiding positive information someone's friend is sharing. </li>
<li>P1344: I simply do not like the idea of posts of friends being blocked.</li>
<li>P1346: I don't see how the study could or couldn't be harmful to anyone so if my someone wanted to participant, I wouldn't care.</li>
<li>P1350: I just do not like the idea that somebody is reading private messages and selecting the good ones and deleting the bad ones..</li>
<li>P1356: I'm tired of all the mind games and control by Facebook and I wouldn't trust them not to use this study to become even richer and more powerful than they already are</li>
<li>P1360: I'm not sure that this is an important or necessary study.  It seems to me that the researchers are just trying to test responses and not really study anything of value.</li>
<li>P1363: If they are anonymous, it doesn't seem to matter if they want to participate or not.</li>
<li>P1371: The possible benefits of the data gathered could drastically improve some people's lives</li>
<li>P1373: I wouldn't want them to miss out on potentially important things. Like my grandmother is sick right now. If negative things were excluded, I wouldn't see my Uncle's updates about her.</li>
<li>P1374: I don't think that it is necessary to perform this experiment in this way, instead just monitoring the positive versus negative rates should work.</li>
<li>P1386: I don't think my loved one's mood would fluctuate because of the experiment, and it sounds like an interesting experiment!</li>
<li>P1389: This experiment is almost an invasion of privacy.</li>
<li>P1406: I'm sure this answer is colored by my own negative opinion of Facebook, but Facebook users know the company will use anything posted in various ways and they use Facebook anyway.</li>
<li>P1410: Can't even work up a care.</li>
<li>P1411: I am really interested in this research but I feel like its already a given</li>
<li>P1419: Any time research is being done to help to explain the influence of a person's mood, this would help to continue to provide needed information about a person's decision making.</li>
<li>P1420: Too intrusive.</li>
<li>P1421: I am worried about information being used by third-parties to try to target advertising and don't trust a promise.</li>
<li>P1423: I would not mind whether or not.</li>
<li>P1426: Could be interesting to see how they would react.</li>
<li>P1427: I think this is just a interesting study about how other's mood can affect our own or what we think is appropriate to share on social media</li>
<li>P1432: This seems harmless especially since the participants will be anonymous</li>
<li>P1433: I think it could be interesting to see the effect that social media has on our moods.</li>
<li>P1443: Each person has a right to decide for themselves</li>
<li>P1446: Facebook feels like that happens anyway. Posts are manipulated and I'm not sure I'm seeing all of their posts anyway.</li>
<li>P1452: Many people uses this social network</li>
<li>P1456: Using 'Bogus Results' is always iffy at best and it would be hard to tell if the results were truly valid or not?,.</li>
<li>P1465: This experiment seems like it would make the person look depressed and such, if they are excluding a fraction of the positive posts. </li>
<li>P1470: I do not want to see my loved ones manipulated.  I believe that people should be given the option to participate or not, before the fact.</li>
<li>P1472: I would prefer the spreading of happiness at all times</li>
<li>P1479: There is no harm to the participant.</li>
<li>P1485: No risk</li>
<li>P1486: The experiment seems safe, however I wouldn't really mind if they did or didn't participate. </li>
<li>P1487: No drawbacks to having someone participate; if anything, it could improve their mood.</li>
<li>P1488: this study doesnt really mean much to me</li>
<li>P1489: I don't get this study so would be hard to say someone i know should join.</li>
<li>P1492: I don't think its right to mess with someone's social media account as part of an experiment unless they volunteer for it. I also don't think facebook should be in the business of censoring posts to "protect the moods of psychologically-vulnerable users". </li>
<li>P1503: it wouldn't harm them</li>
<li>P1507: This looks to me like a fair experiment that doesn't risk any privacy violations</li>
<li>P1508: yes, it would be interesting to see the outcome</li>
<li>P1513: I think as long as the person was willing to do the experiment that would be ok.</li>
<li>P1514: i dont really get into peoples lives.</li>
<li>P1517: This would be an interesting experiment and nobody would be harmed by the data gathered.</li>
<li>P1519: It seems like too much interference; too much tampering to have someone try to mess around with the posts. I wouldn't want to encourage negative thoughts and posts. </li>
<li>P1522: Again, I wouldn't have a preference. It wouldn't really matter to me.</li>
<li>P1524: This one seems more invasive and serves no real purpose for the participants.  With the others, increasing internet security was involved.</li>
<li>P1525: It does not do much harm</li>
<li>P1526: It is unclear whether or not the participants are aware they are a part of this study.</li>
<li>P1528: Because it's a harmless research question with an interesting outlook.</li>
<li>P1538: The information available through Facebook is already a security risk. I would not encourage someone I care about to allow researchers access to their Facebook page and, therefore, all of their Friends' Facebook information.</li>
<li>P1540: They shouldn't hide information from anyone in regards to their Facebook friends.</li>
<li>P1542: I don't see how it could hurt the person.</li>
<li>P1543: This experiment wouldn't bother me.  I'm not sure why the researchers would want to do this experiment.  If someone is posting negative comments, why would you care if someone else did it.  Sharing is not always the best, and especially not on a public forum.</li>
<li>P1552: ITS THEIR CHOICE, NOT MINE</li>
<li>P1553: I don't believe they should alter the information that would normally be coming from their friends, and this may also negatively affect their mood if they getting the increase in negative posts. </li>
<li>P1559: sure why not.</li>
<li>P1580: I think private messages should be left alone.</li>
<li>P1582: I don't see any harm in this research.  </li>
<li>P1583: I think that being subject to a study such as this could be mentally manipulative. Though the intent of the study is to "produce features that might protect the moods of psychologically-vulnerable users," the researchers who are conducting the experiment may accidentally choose a psychologically-vulnerable user, and changing their News Feed to fit their experiment could have damaging results on the person.</li>
<li>P1587: i dont care they can do what they want it is their life after all</li>
<li>P1593: This directly affects someone's life and is emotionally manipulative.  What if it sends them into a depressive state?  Why would Facebook even care to know this?</li>
<li>P1597: While studies like this are not guaranteed to produce accurate, conclusive information, there is no reason an individual should not participate.</li>
<li>P1598: One, we already know the answer is yes.  Two, I'd be very upset if my communications were purposely interfered with.</li>
<li>P1599: They should not be allowed to manipulate someones page for their own personal interests.</li>
<li>P1604: I think that if "my" moods are really affecting my "friends" moods, I really would like to know about it. You never know, if someone is contemplating suicide because of depression, seeing "happy" posts could potentially save their life. GREAT IDEA, if proven!</li>
<li>P1612: I didn't like this: the researchers will randomly exclude some fraction of friends' negative posts each time the news feed is loaded.</li>
<li>P1614: Users may want to see their entire news feeds, and not have portions of it blocked out.  They may miss posts they would have wanted to see.</li>
<li>P1617: Again, not my place to care.</li>
<li>P1618: I wouldn't want others to perceive that person as a pessimist (if chosen to have the proportion of negative posts increased).</li>
<li>P1630: Interesting study so would like to see the results.</li>
<li>P1633: Manipulating the information one can receive is bad. I wouldn't want a close one to have that done to them. </li>
<li>P1634: Their identity won't be known. </li>
<li>P1643: This sort of method of research is very deceitful and wrong. It is creating misinformation to the user. </li>
<li>P1646: I would want my best friend to participate to see if it works or not.</li>
<li>P1650: Sine the researchers are trying to increase e-secirity then yes</li>
<li>P1651: It does not seem any worse than what they already do. I stopped using facebook because of all of this information they collect. </li>
<li>P1655: I think it would be an interesting experiment.</li>
<li>P1657: I don't think the study nor its algorithm could accurately assess one's mood.</li>
<li>P1658: There would be no harm done. The experiment would not invade anyone's privacy.</li>
<li>P1660: No, because I believe it is an invasion of privacy.</li>
<li>P1664: It is a breach of privacy as twitter messages may be intended only for one person</li>
<li>P1668: I wouldn't care either way. The experiment doesn't seem too bad to participate in, but at the same time it doesn't seem all that important either.</li>
<li>P1671: People use social media to communicate, by preventing that, they're doing a disservice to their customer base.</li>
<li>P1674: The whole thing would be too annoying to them, and of little personal benefit</li>
<li>P1680: I don't have a preference because this study doesn't involve any harm. </li>
<li>P1682: I myself would not want to be in an experiment without giving permission so no.</li>
<li>P1683: it wouldnt be a drastic change so it would not be a big deal to participate.</li>
<li>P1686: I wouldn't want a friend's facebook feed tampered with like that.</li>
<li>P1687: It is a violation of the person's privacy.</li>
<li>P1693: I think this is a cool experiment to be a part of to see if it really did work</li>
<li>P1704: This is manipulation in an area that people are trusting of. Also many people use facebook to keep an eye on their friends moods and this would invalidate that information. A friend could need help and you would not know it.</li>
<li>P1705: facebook has a large impact on our lives</li>
<li>P1708: Yes because the research is harmless although it involves Facebook and tempering with users posts.</li>
<li>P1709: I feel like a study of this nature would help my piers acknowledge faults in their security preferences and make them consider changes for possible threats in the future.</li>
<li>P1710: seems fishy</li>
<li>P1715: Don't care what happens on facebook.</li>
<li>P1722: This experiment doesn't seem harmful</li>
<li>P1724: It doesnt matter to me it seems like it will do no harm or affect them in any way</li>
<li>P1725: Although not mentioned, as long as participants are made aware of the experiment afterwards I feel there is no harm.</li>
<li>P1729: it sounds like the participants are not aware that they are in the study, i wouldn't condone any one being in a test they are not aware of</li>
<li>P1733: I honestly don't see where this would hurt anyone by doing this.  Facebook doesn't let you see everyone's posts now as it is. </li>
<li>P1738: I have no real preference for this. I don't know if it would help my friend out so I can't say if I'd want him or her to participate or not.</li>
<li>P1740: No interest in what others usually post.</li>
<li>P1742: Quite interesting.</li>
<li>P1744: Not a big deal so doesn't matter to me</li>
<li>P1746: If all it took was for this person to read some positive thoughts and comments to be in a good mood, why not be included?</li>
<li>P1751: It should be up to them.</li>
<li>P1752: because it shows how others opinions affect your own</li>
<li>P1753: i dont believe that you should keep someone from seeing what there friend posts on a social network. </li>
<li>P1758: I don't think researchers should have access to people's personal accounts, this would lead them to be able to see the participants personal information, possibly also the information (name, location, etc) of the participants friends on the social network site</li>
<li>P1761: It's a good cause!</li>
<li>P1763: I don't care about Facebook</li>
<li>P1770: This is wrong to mess with someone's news feed and give them negative information</li>
<li>P1773: I feel that this study is harmless.</li>
<li>P1774: Yes. I think that studying the effects of comments on Facebook is important in understanding how we can effect others by the things we say and do on social network sites.</li>
<li>P1775: I feel that this is a form of privacy invasion and that we should never have posts removed from our friends. It is a personal choice to sit and read negative posts, no matter how it affects us. </li>
<li>P1785: To me Facebook is used to communicate with family.  If something important happens I don't want them to be excluded whether good or bad.  You may hurt someone's feeling as a result.</li>
<li>P1786: It does not state if the participants in this study will know they are participating or not. It would be unethical to mess with someones Facebook posts left by friends. By taking off some posts, you are denying the user of getting all the information left by family/friends on Facebook, some of which may be important to them. Additionally, I would not want someone having that sort of access to my Facebook account, and I don't know anyone else who would be comfortable with that either. Finally, I feel Facebook is untrustworthy to begin with and I would not trust any studies coming directly from the company itself.</li>
<li>P1788: I think this is fine as long as they are not trying to access peoples accounts. </li>
<li>P1811: There is no harm in the study.</li>
<li>P1827: Facebook is attempting to influence the reaction to posts as oppose to post happening organically.  </li>
<li>P1835: I think it would be interesting and it isnt harmful in any way</li>
<li>P1837: It doesn't matter to me as long as it is safe</li>
<li>P1839: This does not seem to have too bad of an influence on the subject</li>
<li>P1841: No, social media is intrusive enough on its own.  </li>
<li>P1848: Sure sounds like a fun social experiment.</li>
<li>P1850: Altering the mood someone emotes in a news feed is a bit too much.</li>
<li>P1851: It would be interesting to see if an outside influence would actually have an impact. </li>
<li>P1853: No threats to security and anonymity. </li>
<li>P1857: I think it is wrong to manipulate the Facebook newsfeed and to record the type of posts a person creates. It feels like an invasion of privacy, though I do know Facebook isn't really all that private and they ask for permission to use your data when you sign up. I still don't like the way this experiment is set up. </li>
<li>P1864: I would not want their posts censored for any reason.</li>
<li>P1870: I see no risk to the participants in performing this study.</li>
<li>P1871: I don't use facebook so I don't or wouldn't hear anything about facebook.  I'm anti-social.  The ONLY reason I'm on the WWW now is to use Mturk.  :-)</li>
<li>P1873: I'm concerned about the security of my loved one's Facebook feed and private messages.</li>
<li>P1874: It seems like a nice thing to do, though a little intrusive.</li>
<li>P1876: They are not collecting any personal information so this is ok.</li>
<li>P1877: The fact that they're "researchers at Facebook" implies a conflict of interest.</li>
<li>P1878: there really isn't any downside or benefit to participation, or at least it doesn't seem like it</li>
<li>P1881: This could be interesting</li>
<li>P1884: That is a personal site I don't think they should do that. </li>
<li>P1890: This is invasion of the participants privacy and participants should be informed first.</li>
<li>P1892: I feel that someone who is depressed and unstable  might do harm to themselves if they got a too many negative facebook posts.</li>
<li>P1893: People's emotional states can be very fragile, this doesn't seem right.</li>
<li>P1897:  Some of my friends are always posting positive things, so they need to be included</li>
<li>P1901: There is nothing wrong with the experiment, so they could make their own decision.  I think it would be interesting to see how they were affected.</li>
<li>P1902: There appears to be very little if no risk </li>
<li>P1904: I am interested in the outcome of this study. It sound extremely interesting and I have never considered this in the past.</li>
<li>P1913: It is not a harmful experiment, so they should go for it</li>
<li>P1916: Absolutely because people should realize that we are human's and that we have negative and positive emotions.  </li>
<li>P1917: I don't like the idea of withholding information from people. </li>
<li>P1918: They did not agree to be a participant and should have a choice.</li>
<li>P1929: information should not be manipulated</li>
<li>P1936: There are other ways to study the affect of positive or negative influences on mood that are more open.  Plus some people obtain important information via social media today, and disallowing posts from being seen can have unintended effects.</li>
<li>P1938: I wouldn't want someone I knew and cared about to be involved in some form of social manipulation by facebook.</li>
<li>P1942: It is their own choice, I don't care about this issue.</li>
<li>P1951: I don't think facebook should be handled this way. I think people should be able to see whatever anybody posts instead of hiding it or delaying the post.</li>
<li>P1953: The research could be valuable, but I don't know if I would want my Facebook page / news feed intruded upon and cluttered with artificial posts, so I am not sure I would want a person I cared about to be involved.</li>
<li>P1955: They might find the result interesting themselves. They'd clearly know something was going on, but wouldn't necessaril know what. I'd be a bit worried about a friend seeing nothing but negative news about another friend, but I don't think it'd be that long a space of time.</li>
<li>P1956: I would like them to know if they are susceptible to phishing and then be better able to protect themselves in the future</li>
<li>P1960: It is up to my friend to do what they want.</li>
<li>P1963: I would feel like Facebook was using them. I don't think it's in the person I know's best interest.</li>
<li>P1970: There are not any negative side effects of the study.</li>
<li>P1971: There aren't any real negative consequences.</li>
<li>P1977: I would just be curious to know more about the experiment from the person I care about. </li>
<li>P1978: I do not find this to be an ethical experiment it is similar to some experiments that are now shown to college freshman as a warning not do this. I also am not sure but feel that Facebook is using whomever they please and not asking permission. Lastly, facebook is not a research company.</li>
<li>P1979: I think others should decide for themselves as to whether or not to participate</li>
<li>P1982: I think it would be a good exercise to study online psychology since this allows to get inside an individual's thinking pattern.</li>
<li>P1989: It doesn't seem like a harmful experiment so the participants would only experience negligible discomfort.</li>
<li>P1998: I think it's wrong to curate another users' news feed without consent the same way it's wrong to walk into a stranger's bedroom and proceed to get undressed. Privacy is privacy. Consent is consent. These ends do not justify these means.</li>
<li>P2001: The researchers don't appear to be asking the users if they want to be in the study.</li>
<li>P2002: It is only scanning your Facebook posts, not taking passwords or any personal information.</li>
<li>P2003: DOn't really lean either way, but I'm not sure I would like not knowing if their posts are real or not ( If I understand what they are doing correctly )</li>
<li>P2006: No. Just because you don't see a negative post does not mean that you don't have negativity. This study wouldn't make sense, it would assume that your entire mood is contingent on the experiences of your friends. Posting negative posts serves a purpose. You get support from friends and then in turn show friends that support will be offered when it is needed. </li>
<li>P2009: This sounds like an invasion of privacy where Facebook has to be logged in and actively changing a user's friends posts which are not accurate.</li>
<li>P2018: Tampering with their posts and what they want people to see</li>
<li>P2025: I don't get why they would randomly exclude some posts.</li>
<li>P2026: There is no real risk to this experiment, therefore my loved one could decide for themselves whether they wanted to participate.</li>
<li>P2027: the people i know wouldn't be bothered by this, so i say do it</li>
<li>P2038: People on facebook don't want to read irrelevant post</li>
<li>P2039: dumb study...</li>
<li>P2040: I wouldn't mind if they were included or if they weren't included.</li>
<li>P2044: they may actually be less depressed as a result of the experiment.</li>
<li>P2048: I would like to know the full spectrum of my friends emotions.  I believe all are valid and legitimate and give me an accurate sense of what is going on with them and how they are feeling.</li>
<li>P2049: I would find this study interesting. I also think moods are affected by others. </li>
<li>P2053: I have no preference.  I have a pretty good group I surround myself with and I truly dont see how more negative or positive posts would affect their mood.</li>
<li>P2060: I really don't want facebook messing with the feeds.</li>
<li>P2061: this are personal interaction to your closest relationship</li>
<li>P2063: I see no harm in participating in such an experiment.</li>
<li>P2067: I don't think the experiment is harmful at all</li>
<li>P2070: It doesn't really matter</li>
<li>P2072: See no harm here.</li>
<li>P2074: I would be interested to see if their posts and mood were influenced by what he or she sees on facebook.</li>
<li>P2082: I never really check Facebook anyways.</li>
<li>P2083: It includes censorship without the participants knowledge.</li>
<li>P2094: The harm to them is minimal - a potential mood shift. This study is interesting and if the hypothesis on which it's based is proven true, it would align with broader psychological research showing we catch moods from others.</li>
<li>P2100: They are not in danger.</li>
<li>P2103: I do not think that researchers should manipulate the news feed in any way. </li>
<li>P2105: It seems harmless</li>
<li>P2109: I wouldn't want my positive posts removed from their feed nor would I want to be in an experiment like this myself so I would not want someone I cared about to do this.</li>
<li>P2114: I don't think people's friends Facebook posts should be suppressed for the sake of an experiment.</li>
<li>P2117: Twitter is going to decide which posts clients are allowed to see? That isn't ethical. Although they may own the form of social media, to decide what persons can and cannot see that their network of friends are posting is unethical. Plus, the researchers' dependent variable, negative/positive posts is not indicative of positive/negative mood. I say some snarky ass shit in my posts even when I'm in a great mood. The findings wouldn't be valid, the researchers manipulate peoples' moods without permission/consent of participants, they control flow of information that users receive without users being aware...no, this whole thing, just no. Unethical.  </li>
<li>P2119: This doesn't set well because the people in the study would have no control over their newsfeed. I think this is something that needs to remain more private.</li>
<li>P2121: This experiment doesn't seem huge to me, so it doesn't matter one way or the other.</li>
<li>P2123: it sounded like nobody was aware of any kind of experiment or if they had not given any kind of consent to being part of an experiment</li>
<li>P2125: I think it's an evasion of privacy.</li>
<li>P2126: If I have an unhappy friend I wouldn't want to make him or her unhappier by adding negative comments to his or her Facebook page. I wouldn't mind so much about the positive comments.</li>
<li>P2130: Yes because I want that friend to learn many things. I have learned many things in surveys.</li>
<li>P2131: Because I do not agree to have loved ones Facebook accounts tampered with due to privacy issues</li>
<li>P2132: Doesn't sound like a real experiment that Facebook would do.</li>
<li>P2134: I do not see the harm in having someone I care about being included in the experiment.  </li>
<li>P2135: It would be interesting, and a little funny.</li>
<li>P2144: Facebook is a comfortable place for most of the people I know. </li>
<li>P2155: The experiment does not comprise any personal information.</li>
<li>P2156: We need more positive influence in the world. </li>
<li>P2165: This experiment is not life threatening.</li>
<li>P2172: Positive people tend to have positive friends on Facebook. </li>
<li>P2175: I don't think it is right to use Facebook in this manner. It is supposed to be a website where you share things with your friends and family, not some lab experiment. </li>
<li>P2177: It depends on the experimental disclosure - it is possible to still have blinded subjects to the purpose of this experiment and them being aware that there profile is being manipulated - they don't need to know the purpose of the experiment to consent to the proposed manipulations.</li>
<li>P2183: Are you kidding?  As I read this, the researchers would be editing/using the Facebook accounts of real people.  How would this even work?</li>
<li>P2189: Because there's no point without a definite outcome.</li>
<li>P2194: Leave facebook alone.....end of story</li>
<li>P2208: I don't like the idea of anyone being manipulated like that.</li>
<li>P2212: Facebook doesn't actually help you gauge a level of happiness. It's just a veil for users to post whatever they want to think that others will think about them.</li>
<li>P2213: I feel it's wrong to use deception and block out "negativity" or even "positivity" from a news feed. People will want to see all of their friend's recent posts on a news feed, not just the ones facebook blocks. Also, someone might need help and that post might be censored, and that makes people less likely to see the call for help.</li>
<li>P2216: The experiment is harmless</li>
<li>P2218: I would be very upset to see a friend be socially punished by having their personal feed violated, against their knowledge.</li>
<li>P2219: This study seems pretty innocuous, so I would let that choice up to my loved one. </li>
<li>P2221: This is harmless, and an effective way of going about this research.</li>
<li>P2227: It is not right to edit someone's feed without them knowing. </li>
<li>P2231: I would not want a friends mood to possibly get altered because of an experiment.</li>
<li>P2233: It might cause this person to become more depressed or down.</li>
<li>P2234: It is valid research that could help overly emotional people.</li>
<li>P2237: This is manipulative.</li>
<li>P2238: I don't have a preference because it doesn't sound like there are risks.</li>
<li>P2244: However with using the platform of Facebook I believe that many people respond and post more in line with their own feelings.  Just as many happy posts can generate subsequent happy ones so can those whose moods are not so happy.  Facebook tends to almost mimic a discussion platform which all of us can relate to topics in one way or another. </li>
<li>P2245: People should be in charge of how they react to others postings and should be held responsible for their own actions and reactions. I think people who live through media have nothing else better to do with their lives and take social media way more seriously then they should.</li>
<li>P2247: I'm not an avid facebook user, but I don't believe this experiment is particularly risky or potentially harmful to participants. </li>
<li>P2254: yes, Twitter has become a part of everyday life and there should be studies to see the effect of its use.</li>
<li>P2260: Researchers are changing the actual post</li>
<li>P2261: I think this would be interesting, but I don't know to what application. </li>
<li>P2273: I see no harm in this study.  IT would be interesting to know the outcome. We all  are influenced  by those  around  us and the moods of others. </li>
<li>P2276: Facebook is pretty much an evil company at this point, and I would rather they didn't study people close to me for something they would try to manipulate for their own gain.</li>
<li>P2280: No, I would prefer fro my friends to manifest their emotions in an unbiased fashion without external input</li>
<li>P2281: I believe the candidate should have to give their consent before being included in this experiment.</li>
<li>P2284: People are not on Facebook so they can be studied.</li>
<li>P2285: see no harm and its an interesting theory</li>
<li>P2286: There is no risk involved but I do not see the point of this survey except as an act of academic research without obvious practical value.</li>
<li>P2289: This doesn't hurt anyone, only helps.</li>
<li>P2291: if they want to </li>
<li>P2296: It's not a third parties place to decide what news should or shouldn't be delivered to users.</li>
<li>P2302: I don't see how this study is harming anyone.</li>
<li>P2305: Facebook should not change people's news feeds.</li>
<li>P2307: It is their choice seeing as it is not necessarily beneficial or malignant in general.</li>
<li>P2309: It is unethical to include a person in a study without their consent.</li>
<li>P2314: I have no interest in the experiment so it would not matter to me one way or the other</li>
<li>P2316: so they know that they could get there positive or negative posts excluded from showing up on feed. </li>
<li>P2321: I believe this is a valid study for the period that we are in. Many people use social media and are exposed to both positive and negative post everyday. It would be interesting to find the results of this study. </li>
<li>P2324: It sounds interesting, but not necessarily important.</li>
<li>P2325: Honestly with the way Facebook has delt with user data its hard to say that I trust them for anything.</li>
<li>P2326: This study seems to involve messing with privacy of the participants who are then not told that they were participating in a study and also are not given the option to omit their results.</li>
<li>P2328: This is being done without their consent.  It's too much like emotional rape.</li>
<li>P2339: I like the Idea of the experiment, but seems a little big brother-esque to me.</li>
<li>P2340: I think it would be an interesting experiment. So i would be all for a friend participating.</li>
<li>P2341: Same as the prior one.</li>
<li>P2348: It would be viable to my interest</li>
<li>P2349: People have been negatively affected by post on Facebook, especially young people. If my friend were at risk or could become " psychologically-vulnerable I would want some type of fail safe in place to protect them. </li>
<li>P2350: No, because they are keeping information from the participants that they may what to know</li>
<li>P2351: It seems harmless but I just dont see the need for it.</li>
<li>P2354: Yes, they will not be identified and can make an anonymous contribution to science.</li>
<li>P2357: I see it as a harmless thing.</li>
<li>P2367: Only the account holder has the right to include or exclude their friends' posts.</li>
<li>P2368: I don't support this cause.</li>
<li>P2370: my cared ones do not use twitter.</li>
<li>P2372: This really crosses the line of ethical research.  It is not productive and is the inverse of what should be examined.  </li>
<li>P2378: I believe this intrudes on a persons privacy</li>
<li>P2382: I don't see the problem with this experiment, as long as the individual was a consenting participant.</li>
<li>P2386: I think that Facebook delves too far into people's lives as it is.</li>
<li>P2392: This sounds like an involuntary experiment. Many of my friends ARE psychologically vulnerable.</li>
<li>P2396: Might be important or relevant information in the excluded post. Also could possibly damage relationships.</li>
<li>P2397: This one seems to cross some kind of line into peoples personal space. I do not believe I would want my or my loved ones Facebook accounts to be hacked for any kind of scientific research. </li>
<li>P2398: I think it is a very interesting experiment.</li>
<li>P2403: Not fair to keep information from users, but can understand the purpose.</li>
<li>P2409: It seems fascinating.</li>
<li>P2411: no security codes exposed.</li>
<li>P2412: I would prefer that my closer friends and family not be affected or tested on.</li>
<li>P2419: I don't think it would affect their thoughts negativly just because others are sharing negative thoughts. </li>
<li>P2424: it can be beneficial to society</li>
<li>P2425: I don't believe that this research is worth spending time and money on.  What does it matter whether a post is positive or negative.  People should be free to post whatever they want as long as it is legal and ethical.</li>
<li>P2428: As long as the person knows that they could potentially be included in this study, I think it would be okay;</li>
<li>P2433: Some people just need to keep their moods/feelings to themselves and not blast it all over social media.</li>
<li>P2435: It doesn't sound like it would be harmful to anyone so I don't see why I wouldn't want someone I cared about to be a participant. Then again I'm not sure if they would want to be a participant because they might not want anyone reading personal posts.</li>
<li>P2445: I don't see how it could hurt.</li>
<li>P2449: i wouldn't mind if they were on the positive test, but if they were being negatively effected by the negative post i would be upset. disclosure needs to take place first. you don't have to tell people what your testing but you need to ask them if they want to be in a experiment</li>
<li>P2450:   I would no want my friends or familys right to free speech tampered with.</li>
<li>P2451: the research is valuable</li>
<li>P2452: This experiment seems too manipulative and also unnecessary.</li>
<li>P2453: Im not sure if the study would really help people.</li>
<li>P2456: Don't see any harm in it if it is anonymous and has the users consent.</li>
<li>P2457: seems harmless</li>
<li>P2461: It would not bother me one way or the other. </li>
<li>P2463: Sure it seems to be a harmless experiment.</li>
<li>P2466: If participants' moods are truly impacted, I would not want someone I cared about to be in a bad mood due to this.</li>
<li>P2468: No comments</li>
<li>P2473: I don't have facebook, so personally I could care less</li>
<li>P2475: I don't think this is a good idea. The researchers would need access to the setttings on someones facebook account</li>
<li>P2480: I think the research is beneficial</li>
<li>P2483: I believe that if people want to share their thoughts positive or negative on Facebook, they are already showing their willingness to participate in this type of study.</li>
<li>P2485: sounds like a waste of time</li>
<li>P2488: This experiment looks harmless; no harm is going to be done if a user misses some of his/her friends' posts.</li>
<li>P2491: I don't post often on facebook.</li>
<li>P2495: this does not affect me in one way or another so I would not know how I feel about having someone I know be included</li>
<li>P2496: I wouldn't want my social media being moderated by anyone.</li>
<li>P2501: I do not see any risks to this study so I don't see any reason why this person shouldn't participate.</li>
<li>P2513: I don't see the value of this experiment.</li>
<li>P2514: It would be up to them to participate.</li>
<li>P2517: FB is such a trusted organization.</li>
<li>P2522: I think it seems like a harmless experiment so I wouldn't care if the person I cared about was a part of the experiment or not.</li>
<li>P2528: Social media is a popular venue for staying in touch and how it influences people should be studied.</li>
<li>P2530: Because while I understand these researchers are trying to find scientific facts, using someone I cared about as a guinea pig and trying to influence their moods and way of thinking are not something I would want.</li>
<li>P2532: Many of my friends would fit right in with this experiment. </li>
<li>P2536: It's up to them.</li>
<li>P2539: I don't like that posts would be randomly excluded.</li>
<li>P2542: I don't think that a social network that someone is using should be able to determine whether or not someone is psychologically vulnerable. This sounds scary to me. </li>
<li>P2543: This is an invasion of the personal life of my friend for a pointless experiment.</li>
<li>P2545: I don't think that this experiment should be conducted.</li>
<li>P2547: Because it doesn't seem that important. It's cutting into people's private life for unnecessary research.  </li>
<li>P2549: No, I'd rather them see what they usually see in their newsfeed rather than having it altered.</li>
<li>P2550: I think this is an important study to conduct especially considering today's mental illness epidemic. </li>
<li>P2556: sounds too personal</li>
<li>P2561: Nobody would want their feed to be tampered with.</li>
<li>P2563: This is a HUGE invasion of privacy.</li>
<li>P2565: They are interferring with an individuals content</li>
<li>P2571: Just let the honest results speak for themselves</li>
<li>P2572: it would not matter to me if they participated or not</li>
<li>P2574: This takes away their privacy. </li>
<li>P2575: Too intrusive.</li>
<li>P2578: Yes. I do not see any harm in someone being a participant.</li>
<li>P2579: I think it would be good to know what percent of people post positive and negative post.</li>
<li>P2581: I think that the study is interesting and I'm curious about the results.</li>
<li>P2588: Let me see everything my friends post, not what you determine is better for me.</li>
<li>P2589: It could have an effect on their personal interrelationships</li>
<li>P2590: I don't have much of an opinion. It doesn't seem like the study would have too much of an effect either way.</li>
<li>P2592: I don't think it is useful information to be gained.</li>
<li>P2595: I think it would be an interesting experiment.</li>
<li>P2596: manipulating peoples emotions without their consent is wrong.</li>
<li>P2599: It's a bogus study--Facebook should not have the power to limit someone's voice because it's negative.  Constitutional rights are being violated.  Bad call.</li>
<li>P2605: Seems like a harmless experiment to me.</li>
<li>P2610: I don't like it because you're screwing with a person's right to information, but Facebook does it all the time by deciding who and what posts you see.</li>
<li>P2613: Facebook has turned into a platform for all subjects such as politics, which is great, but after a while it gets to where I don't even want to look on Facebook. I joined to keep in touch with friends and family and see some funny stuff on the way. </li>
<li>P2618: I really don't care. It's not too intrusive because they're already sharing those updates with many of their friends and probably acquaintances and people they barely know.</li>
<li>P2619: This sounds like an okay experiment. </li>
<li>P2623: Facebook does not have a right to alter peoples' posts without their permission</li>
<li>P2626: That person would not mind being a part of this experiment.</li>
<li>P2627: its a positive experiment that is safe and easy to do </li>
<li>P2638: No risk. </li>
<li>P2669: \r\nAgain, no one should mess with any information</li>
<li>P2674: I do not like facebook in general</li>
<li>P2678: It seems like an ultimately harmless experiment.</li>
<li>P2682: I tsounds interesting but i'm indifferent.</li>
<li>P2686: This seems highly unethical unless the person I know gives consent.</li>
<li>P2688: This seems quite harmless.</li>
<li>P2689: I don;t think a well-recognized site like Facebook should be used for that purpose.</li>
<li>P2690: It doesn't matter to me. it is for research purposes and it is nothing bad.</li>
<li>P2692: I need privacy..eyeryone needs their privacy secure and protected.  This method denies my security, the security of my friends, and our privacy</li>
<li>P2700: I don't think that that someone would be affected by this experiment. </li>
<li>P2713: Possibly this might be ok. I still don't like being deceived though.</li>
<li>P2716: I can't think of any detrimental effect to that research so long as posts were not hidden on every refresh.</li>
<li>P2717: The research seems helpful to society, but not directly to the participants. </li>
<li>P2723: its their choice </li>
<li>P2725: because youre playing with their moods on a daily level</li>
<li>P2727: I feel this is a manipulation of people's moods via a resource they trust to give them information about their friends.  I really just have a bad feeling about it.</li>
<li>P2735: The risk is minimal.</li>
<li>P2740: I don't think playing with peoples emotions is the right way to conduct research. Why not look at posts that are already written as truth and are positive and see what people do then?</li>
<li>P2743: That algorithm would likely be incredibly problematic and difficult to write.  I sincerely doubt its efficacy</li>
<li>P2747: Its facebook there are settings people can use to hide things from certain people and who really cares if it is positive or negative mood </li>
<li>P2749: They should know ahead of time that they are part of an experiment.</li>
<li>P2753: too intrusive, and information gathered almost useless.</li>
<li>P2762: I honestly don't think reading other's status would affect anyone's mood. It would mostly depend ont he mood the person was already in on how the status affected them.</li>
<li>P2768: It seems like a safe and harmless experiment.</li>
<li>P2771: As long as the Facebook owners agree to it, it's Facebook's site so I think they should be able to manipulate it however they want. </li>
<li>P2777: I'd prefer not to see my friends get potentially upset because they're seeing upsetting statuses and such.</li>
<li>P2781: I think this experiment could be useful because it reveals how people feel about the news. </li>
<li>P2792: I don't think the research is particularly useful and I don't see why I would care if someone was included or not.</li>
<li>P2793: I think the data could be manipulated by the researchers, and I wouldn't want to be a part of this.</li>
<li>P2795: Seems like a rather harmless experiment. If people are affected that much by the news feed, than it might actually help prove the hypothesis.</li>
<li>P2800: It's Facebook, if you post it they have all the information anyway.</li>
<li>P2802: I think it would be an interesting look at someone thought process and how the moods of other affect people closes to me moods.</li>
<li>P2804: This would actually be great.</li>
<li>P2811: If people think this is important, who am I to say it isn't just because it is of no interest to me.</li>
<li>P2813: This study seems like a harmless non risky study so I think it would be ok if a family member or friend of mine participated in it.</li>
<li>P2818: Does not sound interesting or relevant to me</li>
<li>P2819: It doesn't matter,it is their decision.</li>
<li>P2821: influencing someone's mood by outside artificial stimuli verges on mind control</li>
<li>P2823: I don't want anyone I care about being given a false sense of reality.</li>
<li>P2827: I don't want their mood to be manipulated because of tweets</li>
<li>P2828: I would agree to participate so I will allow others to as well.</li>
<li>P2829: I would never want anyone's private social media manipulated without their consent.</li>
<li>P2830: I think this is personal and maybe it is important for someone to know what someone is feeling on there facebook page. </li>
<li>P2834: Wouldn't want anyone to participate in this type study unless they had agreed to say some general research agreement or perhaps if this were done by positive adds that Facebook seems to foist in everyone's newsfeeds now and then.</li>
<li>P2837: Seems innocuous.  They are just recording data that is already published on the internet; there is no deception here.</li>
<li>P2838: I feel we do not have the right to alter the direction of a person's thoughts.</li>
<li>P2848: This seems like a relatively harmless experiment.</li>
<li>P2850: No, I do not believe that people should be profiled based solely upon the information they put online. Furthermore the users will not have knowledge of this experiment or research, which I find to be unethical. </li>
<li>P2853: There does not seem to be clear benefit from this study. It seems pointless. I would not want this person's facebook screened for this study.</li>
<li>P2856: It is possible they will have a negative mood but nothing drastic can happen</li>
<li>P2860: This experiment does not tell the participant that they were in a study.  Also, this is breaking privacy rules.</li>
<li>P2861: I DO NOT THINK THIS WOULD SERVE A GOOD PURPOSE.</li>
<li>P2862: If they weren't hurt in anyway, then I wouldn't have a problem with it.</li>
<li>P2865: In this scenario, I would not be involved. Therefor, I would not be concerned either way.</li>
<li>P2869: I like the idea of spreading positiveness. </li>
<li>P2874: They would learn how their mood was affected by others.</li>
<li>P2879: I don't think any poster should be edited or censored.</li>
<li>P2880: Variable; don't like the idea of some data being hidden. Participants not educated.</li>
<li>P2882: While it does not seem harmful I don't like the idea of someone taking part in this without their consent.</li>
<li>P2885: I don't know enough about it to feel safe</li>
<li>P2888: Yes, I don't think it could cause any harm.</li>
<li>P2892: it might be interesting to see the answer</li>
<li>P2895: I don't think someone should experiment on me and my friends.</li>
<li>P2896: I don't want Facebook doing anything that excludes me from the posts of my friends. </li>
<li>P2905: i feel as tho' i am already involved in this with fb...already...they have TOO MUCH CONTROL OVER WHAT I CAN READ/SEE and WHAT I CANNOT...</li>
<li>P2910: The experiment seems harmless. Why not?</li>
<li>P2913: Due to their feelings of being left out.</li>
<li>P2916: I consider this sort of research useless.</li>
<li>P2920: I think this seems safe and also very interesting.</li>
<li>P2923: This seems to pass the privacy boundary.</li>
<li>P2924: I feel like facebook shouldn't have that kind of power to protect peoples moods. the whole point of facebook is to post whatever you want</li>
<li>P2929: This is a manipulative process.  It calls for changing someone else's posts without their knowledge or permission. </li>
<li>P2930: No harm in this for research</li>
<li>P2934: Facebook is the center of all things insincere. It doesn't hurt anyone and it definitely would be interesting to see how a loved one of mine let social media influence them!</li>
<li>P2941: people's facebook should be kept private and not allowed to be in this experiment to prevent harrasment of users</li>
<li>P2946: Can't hurt anything.</li>
<li>P2947: This is silly research and it is of no consequence to me.</li>
<li>P2955: I think the exclusion of information is troublesome and could effect the well-being of the participant.</li>
<li>P2959: You are interfering with the communication between parties.</li>
<li>P2964: Just to see if it would change the way the post things on facebook</li>
<li>P2966: It would be that persons decision</li>
<li>P2972: I don not agree with nor think it is ethical to:  \r\n"randomly exclude some fraction of friends' negative posts" and " randomly exclude some fraction of friends' positive posts" I understand this may be important but those posts may require specific meaningful empathy, sympathy or feedback. I see this as unethical.\r\n</li>
<li>P2979: Facebook is kind of played out but it is important to study I guess</li>
<li>P2982: I have no preference.</li>
<li>P2999: Still the possibility of sensitivities information leeking</li>
<li>P3003: It's not really right to exclude certain posts; someone could miss important news that way!</li>
<li>P3004: Words are powerful and can effect people for good or bad.</li>
<li>P3009: I don't see the harm in that person participating.</li>
<li>P3016: yes</li>
<li>P3021: It seems like a great way to find out how to make people's lives more positive so if researchers really think it will help why not.</li>
<li>P3028: to be able to participate in such study is a good thing for a student now a days.</li>
<li>P3034: I see no harm in this sort of study, so I would have no reservations about participants.</li>
<li>P3036: See no reason good or bad.</li>
<li>P3039: It is interesting to know how others attitudes affect each other.</li>
<li>P3043: It's for a good cause, and as long as they had permission from the users and the posts were not going to cause any harm and were true</li>
<li>P3045: It seems obvious that others moods affect people around them, seems like the experiment is a waste of time and money.</li>
<li>P3046: the research seems harmless enough.</li>
<li>P3047: I would be humiliated for the person I cared about if they had a tendency to share negative thought based on their friends.  </li>
<li>P3049: It is good to be positive</li>
<li>P3061: I think this would be okay but I am not entirely sure because maybe this could harm the subjects in becoming more negative but at the same time I don't think it is that much of danger to those being exposed to only negative or more negative comments.</li>
<li>P3062: It seems deceitful to make it seem like certain people are more positive or negative just because certain thoughts were omitted from the news feed.</li>
<li>P3063: I honestly don't care about Facebook statuses.</li>
<li>P3064: I don't see too much value in the experiment.</li>
<li>P3065: they signed up to keep in touch with friend not be a guinea pig.</li>
<li>P3066: the only downside i can think of is not seeing posts i wanted them to see</li>
<li>P3068: It might make him smile more</li>
<li>P3069: I don't want strangers see what I post</li>
<li>P3077: too much intrusion on a person's facebook page</li>
<li>P3078: The experiment seems to be intrusive to the participants social life. However results may be valuable. It would depend on rather the participants knew of the experiment they were in (even if they were misled to the purpose/strategy, it would be better than remaining ignorant of it entirely. Too much knowledge may invalidate the experiment)</li>
<li>P3079: Happiness is very subjective and I am not a big proponent of artificially inflating emotions.</li>
<li>P3082: Yes, but only if they were previously informed first.</li>
<li>P3084: This is no problem whatsoever, I don't mind at all.</li>
<li>P3086: If you're psychologically vulnerable enough to need Twitter's protection against Tweets, stay off of Twitter.</li>
<li>P3090: This seems like an invasion of privacy, done without users' consent.</li>
<li>P3094: I believe that if more negative posts were presented as a percentage that the outcome would not affect them adversely.</li>
<li>P3095: I think it is important to understand the implications of social media and this study would benefit humankind.</li>
<li>P3099: this is social manipulation. always bad</li>
<li>P3100: The Use of data based on whether or not it is positive or negative does not bother me. Especially if the information is non identifying. </li>
<li>P3102: ONLY if the people involved were aware ahead of time.</li>
<li>P3103: I wouldn't want my personal communications messed with, even if they are in a public venue such as Twitter, and I am sure the people I care about feel the same way.</li>
<li>P3110: The content and results won't be helpful enough to justify the tampering of a person's Facebook account, in my option.</li>
<li>P3117: There is no risk to this experiment. I think it would just help the participant learn more about himself or herself.</li>
<li>P3126: I see no harm in this one at all.</li>
<li>P3129: It doesn't matter to me.</li>
<li>P3130: I'm a positive person and would not want someone posting negative posts on my feed.</li>
<li>P3132: The only bad side of this that I see would be not being able to see all your posts. Your friend may call you and ask if you seen their post and you wouldn't have, then it would come out how Facebook is not posting all posts; which may lead to people not trusting Facebook.</li>
<li>P3136: This could harm the participants facebook experience.  They may not be made aware if something negative is happening that their friend posts because it is hidden</li>
<li>P3145: Facebook already has enough of my information</li>
<li>P3148: This study is too intrusive. Whose business is it that I share positive or negative post with FRIENDS. Why Does the Facebook platform care?</li>
<li>P3152: Manipulation of people without their consent is unethical.</li>
<li>P3159: If it increases their negative moods I would not want that.</li>
<li>P3161: I don't really consider social media to be very important.</li>
<li>P3166: this isn't all that invasive, but it is also pretty pointless as far as experiments go.</li>
<li>P3170: interesting</li>
<li>P3171: Facebook should not be able to delete posts that were intended for someone.</li>
<li>P3176: It seems interesting.</li>
<li>P3177: Again, there are never being told of their participation.</li>
<li>P3182: It doesn't hurt anyone</li>
<li>P3183: I don't use facebook so I don't care either way</li>
<li>P3185: This experiment interferes with the participants' personal relationships by excluding things that might be important.</li>
<li>P3197: It wouldn't affect them negatively in a long-lasting way if they were part of the experiment.</li>
<li>P3202: I don't think I would advocate anyone allowing even more permissions to people and organization to access their personal Facebook page and information. I ma not sure how you could protect all the data.  I would say no.</li>
<li>P3203: I'm curious.</li>
<li>P3207: Doesn't seem that important</li>
<li>P3208: I would not want my friend/family member's personal Facebook feed violated and altered in this way. It's too invasive.</li>
<li>P3209: There is no information taken from the user</li>
<li>P3217: It would be one thing if a university wanted to study this topic.  But I don't like the idea of Facebook getting any more immersed in people's personal lives than they already are.</li>
<li>P3225: This would require non-consent participation and so would not be ethical to conduct in this manner.</li>
<li>P3227: Wouldn't make a difference to me. It seems like there would be no harm done so I wouldn't care either way. </li>
<li>P3228: Facebook doesn't bother me nor do I care to follow it often.  I might suggest this briefly to a friend, but nothing else.</li>
<li>P3236: I am an individual who has suffered on social networks because of personal issues and negative emotions affected by the posts of others.  </li>
<li>P3240: Facebook can't be going into people's accounts and erasing positive or negative posts. It's bad and not ethical. I might agree if I'm notified that this was happening and they get permission to go into my Facebook page. But otherwise\r\nI would think that was unrthical.</li>
<li>P3243: The survey randomly chooses who has their posts withdrawn</li>
<li>P3245: Again this doesn't harm anyone, so I guess I would leave it up to my loved ones to decide if they want to participate. </li>
<li>P3246: This would be an interesting study to participate in</li>
<li>P3247: I don't care about facebook</li>
<li>P3258: At another level other than negative mood posting, this can be a good experiment to see why people tend to follow/mimic other people for the sole purpose of being cool and sociable.</li>
<li>P3260: The study interferes with people's ability to use Twitter.</li>
<li>P3268: Well for the negative experiment I think is hard to be playing with someone mood</li>
<li>P3273: There is no risk or harm</li>
<li>P3274: I hate facebook</li>
<li>P3275: I would not want on of my friends to only see negative post or only have their facebook friends see negativity in that friends feed.  </li>
<li>P3276: There is no real threat and it will add to the research material</li>
<li>P3279: If someone i cared about were a candidate participant for this experiment, it would not matter whether or not they participated. Them seeing what is or is not on their newsfeed is not a big deal.</li>
<li>P3281: It's a sociological experiment, it's far more than one's own importance.</li>
<li>P3289: That would be completely up to them. If they're wanting to see my posts, they'll go directly to my page.</li>
<li>P3296: Facebook experiments are ridiculous. Too mny trolls like myself on there. </li>
<li>P3300: no, their negative posts would make me worry</li>
<li>P3301: This is not a beneficial experiment, and excludes people from communicating with their friends/family.</li>
<li>P3302: It seems like a worthy research</li>
<li>P3311: I don't like the idea of someone secretly trying to affect my mood</li>
<li>P3312: Peoples' posts should not be removed as part of an experiment.</li>
<li>P3313: I don't think they should be allowed that much control.</li>
<li>P3314: It seems a little invasive</li>
<li>P3315: It doesn't really matter to me if someone I cares about wants to participate in this experiment.</li>
<li>P3316: Participants are not given a chance in advance to either participate or not participate in the experiment.</li>
<li>P3319: It depends on whether or not they know that they are being included. If not, some important information may be lost to them.</li>
<li>P3320: I don't like the idea of someone deleting posts from my account. Can't they just count the number of positive vs negative and get their experiment done without deleting things from someone's posts?</li>
<li>P3322: I rarely post anything, and so it would not involve manipulation of my content.</li>
<li>P3326: Most social media has a bad track record of folding for he NSA.</li>
<li>P3327: I have no preference because I don't care</li>
<li>P3328: I would say its similar to toying with ones emotions</li>
<li>P3331: They probably would feel better not seeing all of the negative thoughts.</li>
<li>P3333: It doesn't say whether the subjects are to be informed of this manipulation of their messages.</li>
<li>P3338: This seems like a violation of privacy.</li>
<li>P3340: I don't think this would hurt anyone.</li>
<li>P3341: I don't care what my friends do</li>
<li>P3343: I don't see why it would be a problem and it would be nice to know.</li>
<li>P3351: The experiment would be invalid if all posts are not included</li>
<li>P3354: I don't like the idea of hiding/censoring some posts.</li>
<li>P3359: Sounds like a very interesting experiment.</li>
<li>P3360: i do not use facebook.  to me it is a 2 way screen.  i value my privacy too much.  it is ok with me to deceive users.  </li>
<li>P3363: yes, most of the people I care about are very positive in life. </li>
<li>P3367: Sounds like a waste of time.</li>
<li>P3373: I do not foresee any negative implications connected to temporarily altering a person's Facebook feed.</li>
<li>P3378: Eh, I don't truly care that much about Facebook. </li>
<li>P3379: This experiment seems to intrusive and I would not want someone I cared about to be a part of it.</li>
<li>P3389: As long as they're aware the researchers are altering their Twitter feed in some way and they're okay with that. </li>
<li>P3393: People who I know who use facebook use it to connect with family that they normally would not have contact with on a daily basis. For this reason all information posted is important and bad assumptions made can lead to family problems. For this reason I think that not having all the information necessary would be a problem.</li>
<li>P3397: knowledge is power</li>
<li>P3403: Again, I feel like there is no risk</li>
<li>P3408: N/A.</li>
<li>P3412: People use Facebook with a level of trust that what they're seeing isn't being manipulated. If people who were already prone to depression, and used Facebook as a way to keep in touch with people, only saw negative messages, it would obviously cause them to feel even worse. </li>
<li>P3413: Because there's no mention of harm in participating.</li>
<li>P3416: Social networking is huge, and it would be nice to know how it is used, especially with negative postings.</li>
<li>P3426: This seems very manipulative.</li>
<li>P3427: I do not see any harm to participants in studying how people are tied together in their emotional responses.</li>
<li>P3428:  The researchers will not be able to produce anything valid from this, so I don't see why someone I know would participate.</li>
<li>P3430: It's a good lesson in internet safety. </li>
<li>P3431: I see no potential negative in running this experiment so it wouldn't matter to me.</li>
<li>P3432: It's a bit invasive to my privacy.</li>
<li>P3434: I think this is an important idea to explore, and I don't see the harm in anyone I know participating.</li>
<li>P3438: IT seems like a safe controlled study about a company. As long as they keep the individuals private they are fine.</li>
<li>P3440: I do not think it would be harmful at all. </li>
<li>P3442: It seems wrong to invade somebody's Facebook feed like that.</li>
<li>P3445: I don't use facebook that much, but some people may be offended that their friends' posts are hidden from them.</li>
<li>P3447: I have no strong feelings about this one way or another</li>
<li>P3453: I see no problem or privacy concerns with this.</li>
<li>P3456: This is a violation of privacy that raises strong red flags.</li>
<li>P3467: I like the idea of moods effecting each other and it would be interesting to be involved and see the impact we have on each other.</li>
<li>P3469: Blocking someone from seeing what the people they follow are posting seems wrong. It would make Twitter seem very untrustworthy.</li>
<li>P3472: I would like to see how it turns out.</li>
<li>P3475: I do not think it would be fair for my friend to have their Facebook friends' status censored. </li>
<li>P3482: It sounds like the researchers aren't asking these facebook members if they want to participate in an experiment and are tampering with their feeds without permission.</li>
<li>P3483: You are limiting the information someone can receive.</li>
<li>P3492: It's an invasion of privacy.</li>
<li>P3495: Unlike the others I don't feel like this is helping much in the short term or long term but I do feel your messing with someone's personal stuff without permission.</li>
<li>P3503: As there is nothing about permission of any kind being obtained. </li>
<li>P3510: It seems obvious to me that moods are contagious  both positive and negative.</li>
<li>P3516: This is more a personal matter.</li>
<li>P3518: Ii don't think that the experiment is harmful in any way and I wouldn't have a problem with it</li>
<li>P3524: I think this is useful and harmless.</li>
<li>P3525: I don't care one way or the other</li>
<li>P3526: It could help determine possible risk factors for potential crimes.</li>
<li>P3532: I feel as though this could end up badly if someone is experiencing a bad time in their life and it seems that everything around them is negative.</li>
<li>P3534: While I like the message of positivity with Facebook, I believe posts should be seen equally.</li>
<li>P3536: I'm still a little skeptical about Facebook research. I'd urge them to be cautious.</li></ul>	</div>
</div>
<div class='cap' style='max-width:30%;'>
	<div class='header closed'>OSCredentialSpoofing study, answers to Surrogate question</div>
	<div class='body'>
<ul><li>P6: Because password security is essential.</li>
<li>P11: deceieving premises</li>
<li>P12: I would feel comfortable with the research because no passwords are beinf stored in any way.\r\n</li>
<li>P20: I would participate so I have no issue with someone I care about participating.</li>
<li>P21: Because the passwords were not stolen and there was informed consent, I think this one is okay. However, I might advise my loved one to change passwords that matched the one given, just to be safe. </li>
<li>P27: I see no harm in this research.</li>
<li>P33: Well I wouldn't like to see someone I know deceived.</li>
<li>P43: I wouldn't care if someone I knew participated. </li>
<li>P45: I understand why an amount of deception is necessary in this case.  As long as no information is vulnerable during the process then I would not have a problem with it.</li>
<li>P52: Doesn't matter if it's someone I care about.</li>
<li>P54: This study seems very useful and doesn't have much potential to harm the participants.</li>
<li>P55: It is important that people see how prevalent this is as people may be currently unaware. I would want those I care about to be better informed and more well protected.</li>
<li>P56: It is good for the person I care about to be exposed to hacking techniques that might happen in real life. They can be wiser about how hackers try to trick them.</li>
<li>P59: As it would show the person what they did wrong and maybe next time that an actual hacker tries to steal their information they won't fall for it.</li>
<li>P69: I THINK THIS IS A GOOD WAY TO BEAT THE BAD GUYS</li>
<li>P75: its harmless</li>
<li>P77: The participants have consented to complete a HIT of some sort and therefore have necessarily consented to complete work for purposes of which they might be unaware or uncertain.</li>
<li>P80: They could learn from any mistakes they might make.</li>
<li>P84: It would be nice to open peoples eyes to how easily they can be hacked.</li>
<li>P93: By being part of this experiment, they will understand how easy it is to fool someone into providing a criminal personal information about oneself. </li>
<li>P94: Yes, because especially if the state the purpose afterwards, it would be of benefit and build awareness.</li>
<li>P96: It will be beneficial to everyone and poses no real threat to anyone so I would not mind.</li>
<li>P97: I wouldn't want their passwords taken by the researchers.</li>
<li>P101: Yes, because their passwords would not be stolen.</li>
<li>P106: Despite the initial necessary deception involved, no harm would be done and the end goal is very worthwhile.</li>
<li>P117: I don't know enough about what the researchers will do to agree.  I need more information.</li>
<li>P119: So people think twice about divulging passwords</li>
<li>P122: People are not to be trusted even if they say are doing it for research.</li>
<li>P124: What surety do you have that these people are genuine researchers?</li>
<li>P132: Even if they said they wouldn't store them, they could still get hold of someone's password. Many times people use the same password for many things. </li>
<li>P135: Their passwords aren't being stolen-- and to be honest these government hackers could do it regardless.</li>
<li>P136: It seems like a useful, and not dangerous study.</li>
<li>P141: Voluntary participation.</li>
<li>P143: I would not be concerned if they participated, but it would be up to the individual to decide.</li>
<li>P148: I think it's worth it to learn how you can protect yourself against password hackers. </li>
<li>P155: It's entirely their choice. The experiment isn't likely to hurt them, and may make them more aware of security issues via the debriefing.</li>
<li>P156: I do not care one way or the other</li>
<li>P159: I'm uneasy about researchers collecting passwords, but since the subjects will be told the true purpose of the study after it's complete, the subjects will be able to change their passwords (just in case the researcher database is compromised).</li>
<li>P169: The design seems responsible given that some participants could become alarmed. However, this study seems to take into consideration participant anxiety.</li>
<li>P171: Test them. Might help them later</li>
<li>P179: It would be a learning experience to find out how easily one is tricked. </li>
<li>P182: Its just an experiment</li>
<li>P184: They would learn a great deal about how to protect themselves online by participating in this study, so i would be in favor of them taking part.</li>
<li>P185: I would hope my friends wouldn't fall for this but if they did they would gain a good lesson.</li>
<li>P187: I don't trust anyone, especially under the guise of a password research project. </li>
<li>P188: I feel that no real harm is done and it might help further true hacker theft in the future.</li>
<li>P190: Although consent is given it involves passwords which I think is too much for researchers to ask.</li>
<li>P191: not my concern, everything seems safe</li>
<li>P192: It's just stressful on someone I care about I feel. I think they can find these things out other ways.</li>
<li>P194: it would be ok to include or not include as no harm will come to them</li>
<li>P198: This may be illegal.</li>
<li>P200: It is foolish to do anything like this at all, even in the name of science.  There is no way to be sure that your password will not be taken.</li>
<li>P203: It is interesting</li>
<li>P206: I don't entirely trust that the data won't be stored in this experiment</li>
<li>P211: too stressful</li>
<li>P218: I don't really care</li>
<li>P220: There is a risk of passwords being shared.</li>
<li>P231: I do not think anyone should be tricked into giving up their password, even if it is for science.  A person should be willing to participate in this experiment, and not be lied to.</li>
<li>P232: As long as they are informed later about the true purpose</li>
<li>P235: As long as passwords are not collected, the experiment might actually increase my friend's caution.</li>
<li>P239: No harm comex to them and they migh learn a lesson about Internet security.</li>
<li>P248: I believe the "deception" part of the study should not be used.  Trust is a major factor in this study. It must be present in all aspects of this study. "The end will not justify the means." The objective of this study will result to  a lot of good uses for society. For sure, there are a lot of people who will support this idea.</li>
<li>P250: It serves a purpose ... </li>
<li>P253: I don't fully trust it.</li>
<li>P254: Some things may go wrong and valuable information may be stolen.</li>
<li>P258: Sometimes people need a reminder of how careless they are.</li>
<li>P270: The researchers might not steal the password, but hackers or the NSA might.</li>
<li>P271: Stealing passwords is wrong regardless of intent</li>
<li>P272: I think it would be a wakeup call for people.</li>
<li>P282: So long as the people know they are in a study</li>
<li>P284: Because they may not be smart enough to avoid giving out personal information.</li>
<li>P289: This is a very similar scenario to the last experiment.</li>
<li>P291: Only if I thought my friend might be a victim of phishing. It's better to learn a lesson through a controlled experiment.</li>
<li>P308: I think this study is worthy to allow a person I know to do it as there will be no harm and it could benefit many people in the future not to lose their password to a hacker</li>
<li>P309: This research will be helpful overall.</li>
<li>P313: Worst case scenario, their bad internet habits could be revealed, and possibly corrected.</li>
<li>P314: It would be a nice teaching lesson about being careful on the internet. </li>
<li>P316: As long as the option to participate or not is allowed afterwards and not performed on personal computers</li>
<li>P317: I say no because some users will type in their real passwords but i say yes because it is a chance at educating people on poor password consequences</li>
<li>P322: sharing personal information is never a good idea, even if just for research, because a third party could hack it as well and use it</li>
<li>P324: Seems too risky and I wouldn't want to put anyone I care about at risk.</li>
<li>P325: Some people might become upset over something like this</li>
<li>P326: It would not matter to me</li>
<li>P327: if they choose to be a part of the study it is up to them, their information will not be violated</li>
<li>P334: Please see pfishing response.  This needs to be stopped.</li>
<li>P335: yes</li>
<li>P340: Very little risk</li>
<li>P347: provided the participant is sure that it is indeed a legitimate research survey, no harm should be done. </li>
<li>P350: I'd like to see the results of this study, I think a lot of good can come from this to prevent hackers to some degree.</li>
<li>P369: No data is collected.</li>
<li>P370: Sounds like it will provide tactics for protecting online activities.</li>
<li>P371: I think as long as the information is not being shared and all answers are secure I would be fine with someone I cared about doing this.</li>
<li>P374: Even if people say they won't use your password you never really know cause all it would take is the guy cleaning the floor at the end of the day to see a computer screen that somebody forgot to turn off. </li>
<li>P376: I think this is a valuable study, but the researchers need to be careful when tricking individuals who have not consented to the experiment. </li>
<li>P383: I couldn/t trust that the researchers would not use the information.</li>
<li>P384: It would be a valuable lesson.</li>
<li>P388: does not matter to me</li>
<li>P391: Hopefully it would inform them of their weaknesses or give them peace of mind.</li>
<li>P403: I think teaching people internet security is important but people shouldn't get used to sharing passwords.</li>
<li>P406: Participating could enlighten this person on how easily any of us can fall victim to hacking since, often, we tend to think that it will be someone else who is gullible and not ourselves. This could give the person new insight to protect themselves.</li>
<li>P409: I think that the findings in this type of study would be helpful to the participant.  It would help them look our for this type of behavior and let them know that these type of threats are real</li>
<li>P412: If performed under extreme caution and security, I would not object to this research.</li>
<li>P415: some good can come from this</li>
<li>P417: I think giving up your real password even to researchers is a terrible idea</li>
<li>P419: Even though the study says passwords won't be stored, I wouldn't believe them.</li>
<li>P425: If it is for a scientific experiment then i could see it being as helpful.</li>
<li>P427: I am against researchers trying to get user passwords, even if there are not planning on using them.</li>
<li>P428: There personal passwords would be at risk</li>
<li>P429: invasion of privacy</li>
<li>P433: I don't believe there is any harm in the study, so I don't care if someone I care about is a participant</li>
<li>P437: no information is going to be stored. the study is not harmful</li>
<li>P444: That could steal peace off mind since it is something related to passwords</li>
<li>P446: it is a good expierment</li>
<li>P449: it doesn't seem very invasive or negative so I don't really have a preference</li>
<li>P450: Is up them to decide this type of stuff. </li>
<li>P453: This could be a good lesson for someone I cared about not to give out there passwords so quickly.</li>
<li>P454: This is a harmless experiment since no passwords will be stolen.</li>
<li>P458: Teach my friends and family to not be so willing to give out personal data on the internet.</li>
<li>P462: A participant is free to decline participation at any point if they feel uncomfortable.  However, I do not really want someone I know being involved with something like this.</li>
<li>P463: People could still have access to these passwords</li>
<li>P467: This seems ok as long as a person being tested knows they are within the experiment itself.</li>
<li>P470: I would want them included in this experiment because I feel like they would be easily susceptible to this kind of attack by a hacker.</li>
<li>P472: As long as things are legit, I don't see the issue</li>
<li>P473: I feel neutral about it, depending on her experience.</li>
<li>P476: they will be debriefed afterward no harm done by participating</li>
<li>P479: The concept of the study is crafted based on reasonable facts.</li>
<li>P480: it's good to gain as much knowledge as possible</li>
<li>P485: Because i wish some of my family and friends wouldn't fall for that.</li>
<li>P486: Because "the researchers will not actually steal, collect, or store the passwords that users type".</li>
<li>P491: If experiment only determines whether or not a password was given, the subject is safe.</li>
<li>P496: I seriously do believe that research into how people fall for these type of attacks is useful. Since no passwords will be kept, I don't see any danger in this experiment. </li>
<li>P498: I could be a good learning experience</li>
<li>P505: I would be fine with this. It seems harmless.</li>
<li>P513: That way they wont fall for these things in the future. </li>
<li>P517: This is a choice of free-will and if people dumb enough to fall into a trap they can get themselves out of it and hopefully learn from it.</li>
<li>P519: Yes, actually. It would be a sort of wake-up call to let the other person know that attacks like this can happen. </li>
<li>P525: I think it is important to stop the hackers</li>
<li>P528: If someone I cared about called for these hacker tricks, they will learn not to do it again without dealing with and serious consequences. </li>
<li>P529: It would allow the researchers to get their data and non of the participants will be hurt in the process.</li>
<li>P531: Hacking is a serious problem and I am in favor of finding ways to stop it.  As long as the participants passwords are not compromised, I am in favor of the study.</li>
<li>P532: I think it would be interesting to see the responses of my friends or relatives in this kind of experiment, even in their retelling.</li>
<li>P533: I have no preference</li>
<li>P535: Users are still entering a password into a form, that even if discarded, will send the data to an untrusted source.</li>
<li>P538: Yes because sometimes we have loved ones who give out passwords without even thinking about it and this would serve as a warning.</li>
<li>P539: I'm just leery when it comes to passwords, and I wouldn't want someone I care about to have to be concerned with this experiment.</li>
<li>P541: Actually I'm not sure.  More in the next question.</li>
<li>P550: I think when people have to use really personal information then then the study should not be allowed.</li>
<li>P553: Again anything that has to be done for the researches to ban out hackers and spammers is a great study to be done on anyone computer</li>
<li>P554: Passwords are sacred.</li>
<li>P555: I think it could be an opportunity for learning experience given the researchers will present a detailed explanation of the deception to participants.  There is also no harm done if they  reveal the true purpose of the study, and reassure participants that no passwords were actually stolen during the study..  </li>
<li>P557: why wouldn't they?  No one is actually getting bamboozled</li>
<li>P558: If a user is actively opting into a HIT, then they know they may be deceived, and it's an active affirmation of activity on their part.</li>
<li>P560: It just seems like a violation</li>
<li>P561: Computer hacking has become a very serious issue</li>
<li>P573: I think it's important for users to be more aware of where or how they use their passwords, and how easily such information can be obtained and abused.</li>
<li>P576: It won't harm anyone and could actually improve software.</li>
<li>P578: I might be OK with it if it were on total strangers.  I wouldn't want it done to someone I cared about.</li>
<li>P583: For their safety</li>
<li>P590: I would need to know for sure the study doesn't get to see these passwords.</li>
<li>P591: Good warning for people</li>
<li>P594: I would not want someone I care about to be a participant because I feel they would be being taken advantage of because it is not the HIT that they agreed to complete. </li>
<li>P606: It's not cool to make people believe they've been hacked. </li>
<li>P608: It is a study that needs to be done. As long as the passwords are not stored anywhere, then little risk is involved. </li>
<li>P612: I think this experiment wouldn't reveal anything we already don't know so having someone i know participate would be a waste of their time.</li>
<li>P626: There is no harm done, and it might help them be more secure.</li>
<li>P628: it would better prepare them on the internet</li>
<li>P629: It not only provides good data but also shows users afterwards of their failings</li>
<li>P631: Collecting actual passwords seems like a slippery slope.</li>
<li>P633: It looks like ethical issues are being addressed and this is an important issue to understand more about.</li>
<li>P634: As long as the researchers truly could confirm that no passwords were stolen after the study, then it should be no issue.</li>
<li>P640: I wouldn't want them to be open to having their passwords stolen. Even if they say they won't collect them, there is no guarantee.</li>
<li>P646: No definitely not. </li>
<li>P647: We should be one or two steps ahead of hackers. Experiments like these are necessary. I don't see these being any more different than psychological experiments that also deceive. This might also be educational to participants NOT to fall for tricks.</li>
<li>P652: I think it would be hard to tell someone it is okay to give the researchers their private information not knowing if they are hackers or not. </li>
<li>P656: It would teach them how to be wary of such things online.</li>
<li>P658: I do not like the idea of having someone enter their passwords for researchers, even if they say they wont store it, who is to say that they wont?</li>
<li>P660: I would be concerned with the passwords not being safe.</li>
<li>P667: If something positive can come from the the research, then by all means proceed.</li>
<li>P672: I think it would still be possible to see the passwords.</li>
<li>P676: As long as the researchers do not have access to the passwords, I see no problem.</li>
<li>P678: to let them know not to fall to cheap tricks</li>
<li>P681: I believe there would be no harm done by participating in such experiment. </li>
<li>P682: I feel that to enter into research the parties need to be honestly advised of the information. This is deceptive.</li>
<li>P685: I would not want this person to be tricked.</li>
<li>P691: No personal information is being recorded</li>
<li>P692: I have no issues with this experiment</li>
<li>P694: this study will be very helpful for everybody who uses the internet</li>
<li>P696: Although it seems harmless enough, most people would be on guard against this deception if there was a HIT which requested their password.  Also, since the password would not be tested for accuracy, many people would likely make up a fake password to complete the HIT.</li>
<li>P702: I think it would be benefecial to people I care for to go through this because it would be a learning experience as to what could happen and ways to make their passwords safe. </li>
<li>P704: It 'appears' to have too much risk to the user.</li>
<li>P705: I disagree with the deception, and furthermore, the researchers would not be able to publish their results according to the last line of text, rendering such an experiment useless.</li>
<li>P707: I wouldn't want someone I cared about involved with something like this.</li>
<li>P708: I wouldn't mind either way. No personal data is actually being used.</li>
<li>P710: personal choice</li>
<li>P717: Since the experiment would be during a HIT and it was real that means that whoever is selected will still receive compensation and if they were doing the HIT in the first place, then they need said compensation.</li>
<li>P722: It's an experiment. As long as they know that it was just that, they will be okay.</li>
<li>P729: Yes but people should have a choice if they want their info included or not.</li>
<li>P732: I would want to be sure they're safe against hacking.</li>
<li>P735: If deception is purposely used I would tell people to opt out.</li>
<li>P737: The benefits out weight the potential temporary risk of anxiety/anger however i would rather it be done on someone other then myself or friends : ( ) </li>
<li>P761: It is crossing the ethical line.</li>
<li>P763: I think it sows distrust in the Turker community.  I don't think this is the place for that.</li>
<li>P772: It would highlight the need for caution to them.</li>
<li>P776: I would not want someone I care for to take the chance that his/her information could in some way be compromised.  The risk, even though small, may outweigh the reward.</li>
<li>P780: good lesson to learn the safer way than it actually happening to you </li>
<li>P784: Since no one is being harmed, the information could be helpful to protect consumers.</li>
<li>P787: I would want to truly make sure that my passwords were not being used. It makes me nervous that the researchers could get close enough to steal it, but choose not to. </li>
<li>P794: Hacking attempts are very common, and this experiment would likely terrify the participant into thinking their accounts were truly hacked, which could (in their minds) mean their identity and online banking is at risk. Not something I'd want anyone to go through.</li>
<li>P796: It would be a good way to tell if your password is secure enough</li>
<li>P800: Doesn't seem like there is any danger to participant.</li>
<li>P803: As long as their information is not compromised than it does not matter. </li>
<li>P811: They would be helping the researchers to see how people's passwords are being stolen and then be able to help people to prevent this from happening in the future.  I would change my passwords immediately after giving them out to protect myself.</li>
<li>P812: In this one, they're being told that it's part of research, but at the same time they're being deceived into giving the password. On one hand, it's a learning experience and on the other, it's better to make a stupid mistake that will be harmless rather than when it matters.</li>
<li>P816: I'm always suspicious of giving my password in any circumstance other than ones I am used to (like online banking), otherwise for testing purposes or what not, I would lose some trust</li>
<li>P821: Hackers and hacking is a huge concern in the internet world so studies like this that help to crack down on it are useful in my eyes. </li>
<li>P824: no as I previously stated I don't want someone I care about getting duped </li>
<li>P828: Passwords are sensitive information, any threat to that data is wrong.</li>
<li>P834: It could teach them to avoid hacking in the future.</li>
<li>P835: No risk, learning experience</li>
<li>P836: i think people need to be aware but I would be leery about my password not being collected there is always temptaion</li>
<li>P837: It would be helpful to get better data on this problem. Participation could work towards that end AND help the participant to be more aware of security practices they should observe.</li>
<li>P841: I would want them to know that they had been deceived by a source like this as opposed to a malicious source so they would become more aware of what they do on the internet.</li>
<li>P842: I just don't trust passwords ever being used/seen even if they aren't being collected. </li>
<li>P845: I see no harm in it and hopefully the debriefing would teach him or her something about protecting themselves from real hackers.</li>
<li>P847: I wouldn't want that person to take the slightest risk their password (and therefore data)might be compromised despite the assurances.</li>
<li>P850: Why not?  As long as the research was done by legitimate people, I don't see in the hard in learning a little about the tactics people use to steal passwords and such</li>
<li>P851: it could be a good learning experience for users.</li>
<li>P865: i do not trust that the passwords were not actually stolen. </li>
<li>P866: Not appropiated.</li>
<li>P870: I think most computer users are aware of hackers but that does not stop users from falling prey. Letting the participants know a head of time that such research is being conducted should not interfere with the results.</li>
<li>P874: I think that it would be a good idea for anyone who uses the internet to participate in this survey because it could help them prevent getting their personal information get stolen online in the future</li>
<li>P882: Regardless of whether the subjects are informed that their passwords were not stored, most would feel the need to change any personal passwords given as a result of this experiment.</li>
<li>P884: I believe a scientific expirement in this way will be very beneficial to law abiding internet users. Hackers stealing passwords is a serious problem, and has ruined lifes, and complicated homes. Any way we can help that situation not happen is good.</li>
<li>P886: This would actually be very helpful for someone I cared for in not only them participating and providing data, but would likely teach them a lesson about password security and possibly lead them to better habits.</li>
<li>P890: I know a lot of people who could easily fall for the tricks and I think they could use some help.</li>
<li>P898: i would be interested if this would actually work since a good majority of my friends are hardcore computer people and i dont think they would fall for this</li>
<li>P901: I wouldn't want someone I cared about to feel the fear that their password may have been compromised, either during the study or in the recent past.</li>
<li>P903: I would want my cared one to be aware of hackers.</li>
<li>P904: No one wants to have their passwords stolen.</li>
<li>P906: all for science and increased knowledge</li>
<li>P908: It seems pretty safe for them</li>
<li>P912: too risky</li>
<li>P913: It is not dangerous to them in any way.</li>
<li>P914: I think I would allow someone I cared about to be part of this study because it would stop hackers from collecting passwords from the internet.</li>
<li>P921: I am confident that the information gather is for the study and won't be released.</li>
<li>P922: I think this would be good to test but I can not tell my friend yes or no.</li>
<li>P925: this is difficult to imagine how the researchers would get people to give up their personal passwords in a HIT situation - we know that a HIT would not be a place to give out that information</li>
<li>P926: I think this study will reveal important information. </li>
<li>P927: doing such experiment is useless because the actual result would not come, and so only i would suggest anyone should be allowed to participate in this experiment</li>
<li>P936: Seems like a great idea.</li>
<li>P939: This experiment seems harmless. I think the researchers just have to have some solid evidence that not one password was saved. Maybe come up with some way where the participants will have to come up with a completely new password. This can be done by implementing various password "rules" that most likely, participants have never dealt with before.</li>
<li>P940: The researches set good limits for the experiment.</li>
<li>P942: most people want security improved and this could help</li>
<li>P948: How do you replicate the techniques without actually stealing</li>
<li>P949: not really they would get their passwords stolen</li>
<li>P951: because they will not learn from the study</li>
<li>P953: This experiment seems like it would work well.</li>
<li>P955: This experiment sounds like it could actually lead to an important finding that could benefit people. The security breeches associated with hacked passwords is a real threat and if researchers can ethically conduct research to find a way to minimize this threat, I think it would be okay if someone I cared about was a participant in this research.</li>
<li>P957: I would have no preference on this.  I understand the need for this type of research, and it does not seem to contain any risk.</li>
<li>P958: I don't see how this is harmful as long as no passwords are actually stolen.</li>
<li>P959: I wouldn't want someone I care about being deceived and having to go through the stress</li>
<li>P963: This experiment could save millions of users if the data is made public.</li>
<li>P972: You honestly never know about people these days. Even if they did participate, I'd encourage them to change their passwords afterwards.</li>
<li>P984: I wouldn't feel comfortable about the fact that their passwords were made available - even if they were not "stored".</li>
<li>P989: As long as the people close to me do not lose their passwords.</li>
<li>P1004: No real risk to participants.</li>
<li>P1005: I would want to participate just to see if I can "not participate" by being aware of the risk. This experiment would probably work best on the elderly btw.</li>
<li>P1007: It's a good lesson.</li>
<li>P1016: I would let this person decide.  </li>
<li>P1017: people should be aware of the threats out there and how to protect themselves from it</li>
<li>P1018: I don't think these types of Hits should be allowed on mturk.</li>
<li>P1019: minimal risk</li>
<li>P1026: I think that, while the setup of the experiment is necessary, it would lead those who participated to be more paranoid, nervous, and suspicious in general. </li>
<li>P1031: I am fearful of being hacked just even reading about it right now, much less giving any password information.</li>
<li>P1050: This seems far more ethically designed than the previous (phishing) study, since no password info is being recorded.</li>
<li>P1054: If it teaches them to be safer, why not?</li>
<li>P1055: It would be helpful for the people doing the survey.  I'm not sure anyone I know would give out passwords though, although some of them may be tricked into it.</li>
<li>P1056: It's data that will help increase security</li>
<li>P1057: The more research and investigation that goes into preventing cyber crime, the better off our technology dependant society will be. I believe it will also help that person to recognize future attempts for getting their password stolen.</li>
<li>P1058: It is completely up to the individual to want to participate or not. I think this would be a fun study.</li>
<li>P1059: They will learn about methods to steal passwords.</li>
<li>P1062: I'd rather not anyone I cared about be put in a situation where they're providing their passwords, secure or not, unnecessarily.</li>
<li>P1063: Putting passwords out there, even if the researchers will not steal it, is dangerous</li>
<li>P1068: It would give them a chance to be better protected in the future. </li>
<li>P1072: Anything to make password theft decline.</li>
<li>P1083: They would learn to never fall for this type of trick from scammers again and be cautious.</li>
<li>P1084: I think that they would benefit in the by being told that they could have potentially given out their information to hackers and maybe not be as likely to do it in the future.</li>
<li>P1089: There is to much at risk, the security of the passwords cannot be guaranteed.</li>
<li>P1090: i feel like participants would come out of it with a better idea of how to avoid password hacking</li>
<li>P1108: I don't see any harm in this study. It's not like the person is really going to get hacked. I would care either way.</li>
<li>P1109: Most of these issues can be solved by common sense.</li>
<li>P1110: I think it would show many people how the information that they provide on the internet is not necessarily always safe. </li>
<li>P1111: The researchers have everything controlled and anonymous, so there is no harm to the participant.</li>
<li>P1112: I think it would be upsetting for people to participate in this experiment.</li>
<li>P1113: The explanation would help them understand how to be safer with their information in the future. </li>
<li>P1116: The idea is good and it won't harm them.</li>
<li>P1119: I would want them to participant in this experiment because not only they are not in danger of losing their confidential information, but they will also learn anti-phishing measures. Not to mention the researchers will have gained more data.</li>
<li>P1120: Because the researchers will inform them that this was all done for research and they'll reassure participants that no passwords were actually stolen during the study.</li>
<li>P1123: Though this is an interesting experiment, I am not sure if I would want others I care about to participate.  I would be cautious for them.</li>
<li>P1130: Again, I think my friends and family are savvy enough not to be tricked.</li>
<li>P1131: Teach people about the dangers of password security.</li>
<li>P1138: I think it is important to understand these attacks but i am unsure of someone i care for participating.</li>
<li>P1140: I think they would go along with it.</li>
<li>P1147: As long as the study does not collect passwords then there is no harm in the study.</li>
<li>P1157: Deception is fraud.  Research based on fraud is potentially harmful to participants.  Enough said.</li>
<li>P1158: The topic is important, and knowing beforehand would skew results. As long as the researcher is reputable, I see no problem.</li>
<li>P1162: this is another problem that needs to be studied</li>
<li>P1165: Even though I don't like the idea of the experiment, I think my friends could handle it and might even put happy thoughts to counter the negative thoughts.</li>
<li>P1174: because its their information and dont trust it</li>
<li>P1176: There is harm in doing the experiement and they might learn to be more careful</li>
<li>P1178: I think it will greatly help research and the more people who are able to help, the more that should.</li>
<li>P1179: That password might be used for other accounts and if that would get out on accident there would be some real risk for the participant. </li>
<li>P1180: This sounds like an ok experiment. As long as the participants are told at the end that they are part of an experiment, and as long as they are told before submitting their HIT and having their data recorded, then it doesn't matter to me who participates.</li>
<li>P1183: Because it is for the better good</li>
<li>P1192: This experiment appears to have beneficial value in that it could teach people what types of emails are dangerous to the security of their computers</li>
<li>P1195: Says information will not really be collected, stolen, or stored. Only for the purpose of research.</li>
<li>P1196: if individuals are taking the proper precautions when using the Internet, then it will not matter if this is a real hack or and experiment. </li>
<li>P1199: again, as long as no one is being harmed by this study there is no reason why the research cant be conducted.</li>
<li>P1211: A lot of my friends are concerned with internet safety. Although researchers say that the pts information is not saved, no one can ever be too safe. </li>
<li>P1216: The experiment deceives people who never agreed to participate.</li>
<li>P1217: this could be a valuable lesson </li>
<li>P1220: This is an invasion of privacy and puts security of the participants at risk, it should not be permitted.</li>
<li>P1227: There is no real danger to the person.</li>
<li>P1230: If somebody was doing things to put them at risk, I would want them to find out about it and correct their action. This would be a safe way to do it.</li>
<li>P1233: It is better for them to find out about threats in a study were it is safe than in the real world.</li>
<li>P1234: thheir participation is their decision.</li>
<li>P1238: doesn't really affect anyone</li>
<li>P1239: It's wrong because you don't know if that researcher is going to steal your information or not.</li>
<li>P1247: People can be taught not to be careful with passwords without being deceived.</li>
<li>P1248: No. Regardless of whether it was a scientific study or not. I would not fully trust the researchers with their password and other sensitive information.</li>
<li>P1253: While tricking people should not be done, where there are guards, like in the experiment, I think it is ok, but only for serious research.</li>
<li>P1260: Because it could be a ploy just to get your password or info about passwords</li>
<li>P1261: They might feel tricked into revealing a password which they might not feel very happy about even though their password was not collected. </li>
<li>P1262: So that they would be more willing to step up the security of their passwords.</li>
<li>P1264: It seems that this experiment would not be as upsetting to participants as some of the others, as they would voluntarily provide their information. It may even become a valuable learning experience for them.</li>
<li>P1266: Because I know some people for whom this could be a wonderful education in what not to do. how not to be caught by hackers.</li>
<li>P1267: Though, this seems like a blatant breach of privacy I think it can lead to better security for websites and individuals.</li>
<li>P1269: This is a valuable research project.</li>
<li>P1270: there would need to be some paper statement showing that none of that persons information would be used outside this task.</li>
<li>P1272: Use your friends, not mine.</li>
<li>P1273: It is the participants choice not mine.</li>
<li>P1274: It is their decision. </li>
<li>P1278: I don't like the idea of being deceived.</li>
<li>P1279: I don't know someone on twitter.\r\n</li>
<li>P1285: I would want my loved one to know whether they were at risk for having passwords stolen.</li>
<li>P1286: It would help this person be safer in the future when someone is actually trying to steal their password.</li>
<li>P1288: I don't think many people would give their password during a HIT...it would be interesting to see the results of the survey.</li>
<li>P1289: participants' security will not be compromised in any way. </li>
<li>P1295: Deception is still deception and trust doesn't come easy.</li>
<li>P1296: As long as they actually don't steal information from people, it wouldn't matter to me.</li>
<li>P1297: At the end of the experiment they will have a better understanding on how to protect themselves later and what to avoid.</li>
<li>P1299: As with the previous 2 possible research questions, this just doesn't seem ethical. You can just people who have been hacked their previous experiences instead of doing all of this.</li>
<li>P1300: It would be a good way to promote increased cyber security.</li>
<li>P1301: Sure why not, I could be in the middle of an experiment right now.</li>
<li>P1302: So they can learn their lesson, if they were gullible enough to fall for it. </li>
<li>P1310: My mother has fallen for these sort of scams. I think it's important to study this topic. I wouldn't mind if someone I cared about took the test if it's a reputable study. </li>
<li>P1311: It is really an invasion of privacy</li>
<li>P1316: As long as everyone receives payment for the HIT.</li>
<li>P1318: It is for reasearch and no harm is done except with maybe self esteem.</li>
<li>P1319: People I care about should know about the dangers of getting their passwords hacked and this is a good way to raise awareness while also learning things.</li>
<li>P1321: Can't trust the organization</li>
<li>P1330: This might help people learn to be more secure about their passwords.</li>
<li>P1338: I would want other people to be aware of the tricks that hackers use.</li>
<li>P1340: No I would not since this research sounds like a scam.</li>
<li>P1343: Nothing is being stored and they would be informed of the study afterwards. </li>
<li>P1344: Nobody can guarantee that someones actual password would not be stolen. Anybody is capable of anything.</li>
<li>P1346: I trust the researchers and I think that this study would do a lot of good for individuals online security procedures.</li>
<li>P1356: deception. plain and simple. I don't like it</li>
<li>P1357: Don't like the idea of passwords being entered just for a sutdy</li>
<li>P1360: I think that this study is important for scientists to learn how to stop or reduce such attacks in the future.</li>
<li>P1363: I don't want to have anyone's password be more vunerable</li>
<li>P1371: Netsec is a very important issue, and since most accounts are compromised by social engineering, more information about this method of hacking accounts needs to be compiled and become public knowledge</li>
<li>P1374: It would help to inform them, after the fact, of their behavior that is putting them at risk.</li>
<li>P1389: I would not trust the integrity of the experiment.</li>
<li>P1410: Change your password afterward, no big deal.</li>
<li>P1419: The study would not put the participant in any threat to attacks while using a password.  It would just serve the purpose of allowing researching ways to stop serious hackers from robbing personal information.  </li>
<li>P1423: I wouldn't mind them being a candidate. </li>
<li>P1426: So that they learn if they are susceptible to be hacked.</li>
<li>P1427: In light of all the recent security breaches, this would be a step in the right direction when it comes to educating people about how to keep with cyber information safe. </li>
<li>P1432: Learning how to deal with threats on a computer is important, especially since many older people do not know any better and will believe almost anything on the internet</li>
<li>P1443: They should decide for themselves</li>
<li>P1446: They are protecting and revealing to the participants.</li>
<li>P1452: Not convenient and able to perform duty </li>
<li>P1456: Actually it's of little use as it would be easier to ask to see the Police Files to gain the needed results as it would be a more Valid Result!,.</li>
<li>P1470: Again, I do not like to see people the subjects of experiment without their permission.  </li>
<li>P1471: If they are careful, they will not have their passwords "taken". If they are not careful, they will have their passwords "taken" but with no lasting effects, and this will perhaps teach them to be more careful in future and how to avoid falling prey to attacks.</li>
<li>P1472: Password security is serious and would like my friends and family to be better educated on it.</li>
<li>P1479: Sensitive data is involved in this study</li>
<li>P1487: Just to be safe, I would not want to participate in the experiment because my password would be jeopardized (assuming I fell for the hackers trick, and despite the fact that the passwords would not be stored).</li>
<li>P1488: BECAUSE THIS HAPPENS WAY TO OFTEN AND SOMEONE NEEDS TO FIGURE OUT A GOOD WAY TO PREVENT IT</li>
<li>P1489: It would help them learn</li>
<li>P1492: I'm not sure how I feel about this one. On one hand if they are volunteering for the study (even if they are being lied to about the actual purpose) I could see this being ok. On the other hand I could see how such a study could get out of control and leave some data vulnerable. </li>
<li>P1497: I don't want anyone I care about giving out their personal passwords to anyone, even researchers.</li>
<li>P1503: It wouldn't harm them</li>
<li>P1507: This is an actual risk as someone reveals their password.</li>
<li>P1508: it's a case of crying wolf and may have unintended results</li>
<li>P1510: I would want them to see the techniques used and be able to try to avoid them in the future.  Most people I know aren't very savvy about this kind of stuff.  I wouldn't want them to participate, though, if it attempted to trick them using sensitive passwords.  I would expect the test to include some kind of new/specialized site with specific instructions to not choose a password commonly used on other sites for their own protection.</li>
<li>P1513: I feel this is too dangerous and risky.</li>
<li>P1514: i really dont get into my friends' buisness.</li>
<li>P1517: This experiment would once again be valuable to those who I care about by teaching them how to avoid this type of theft in the future.</li>
<li>P1519: I can understand the purpose of the study but it makes me a bit leery to have things done without knowledge or consent beforehand.</li>
<li>P1522: It really wouldn't matter to me if they were included or not, it would be entirely up to that person.</li>
<li>P1523: I don't want any of my close friends or family to be "deceived"</li>
<li>P1524: As long as this is a truly legitimate experiment.</li>
<li>P1526: I think the information gathered could be useful for internet safety education</li>
<li>P1528: Because it would teach them, hopefully, how easy and manipulatively deceiving hackers can be. </li>
<li>P1534: It doens't matter to me. Doesn't seem like they will get hurt.</li>
<li>P1538: As long as the passwords are hashed and not stored there would be no harm in this experiment.</li>
<li>P1540: They are not actually storing information or passwords.</li>
<li>P1546: Because it will help them learn about any security flaws that they may have.</li>
<li>P1547: They'd have to go about changing their passwords to feel safe, whether or not you saved them.</li>
<li>P1552: their choice not mine</li>
<li>P1553: If anything this will only raise awareness to the participate about the dangers of not being careful with their passwords.</li>
<li>P1556: This is another very important topic of study.</li>
<li>P1563: No danger to participates information.</li>
<li>P1572: I guess it would be a wake up call to the user.</li>
<li>P1580: This will gain some valuable information, without harm.</li>
<li>P1582: Researcher or not I don't want anybody pretending they are hacking to get my information or the information of anybody that I cared about.  </li>
<li>P1583: Such security threats are important enough that data needs to be collected and research needs to be done to prevent them in the future.</li>
<li>P1588: I feel they would not trust me anymore.</li>
<li>P1593: I would hope no one I cared about would fall for the tricks, and if they do, it's a lesson they need to learn without any of the consequences of falling for it for real.</li>
<li>P1597: This is a learning experience. By the definition provided above, this experiment will not only help individuals and companies learn about what makes users tick, but it will also positively help the individuals within the experiment itself.</li>
<li>P1598: I sounds mean.</li>
<li>P1604: I think everyone should be made aware of just how easy it is to have their computers hacked and their information stolen. Again, I think the researchers should be monitored, to ensure the safety of those being "hacked" for scientific reasons.</li>
<li>P1612: I believe this is valuable research.</li>
<li>P1614: I believe this study is for the greater good, and the deception is explained in the end.</li>
<li>P1616: They will help in stopping  real hackers</li>
<li>P1617: It would be nice for my computer illiterate parents to be slightly more aware of the dangers.</li>
<li>P1629: It seems that the information is kept private and secure. </li>
<li>P1630: I would not trust that no passwords were actually stolen.</li>
<li>P1633: As long as the researchers deleted every password things seem very safe. </li>
<li>P1650: Conducting a security exercise is shady without letting the people know UNLESS the end result would vastly increase security features</li>
<li>P1651: It doesn't seem like it would hurt anything to be involved. so I have no preference one way or the other. </li>
<li>P1655: To see how likely they would leak their information because most of my family is not computer smart.</li>
<li>P1657: Can the participant be assured that no data was collected nor stored?</li>
<li>P1658: I still feel that since no real harm would be done and the participant would learn from the experience, it would be okay.</li>
<li>P1664: There is a risk of data being breached even though researchers are saying its on their honor. </li>
<li>P1668: Then the person I cared for would learn a little more about password security!</li>
<li>P1671: As long as no password data is stored, this is acceptable.</li>
<li>P1674: I think they would feel somewhat violated.</li>
<li>P1678: This seems sketchy to me. </li>
<li>P1680: I don't have a preference because there is no invasion of privacy or harm.</li>
<li>P1681: I know a few people who can use a little more help on password security.</li>
<li>P1683: i dont trust that these researchers will not collect or store passwords.</li>
<li>P1686: Since no passwords are actually collected, I wouldn't have a problem with it.</li>
<li>P1693: To help with the research</li>
<li>P1704: I am very protective of passwords, mine and others.</li>
<li>P1705: anything to help enhance security in a controlled enviroment</li>
<li>P1707: These types of studies are important to increase hacker awareness</li>
<li>P1709: I feel like such a study would allow the person I care about to re-evaluate their security standards and make positive improvement.</li>
<li>P1715: That seem informative, many people I know could stand to learn what tricks not to fall for.</li>
<li>P1724: I think it is too dangerous for a security breach</li>
<li>P1725: As long as the participants are aware of the experiment afterwards there is no harm.</li>
<li>P1733: Their information would not be collected or stolen so I see no harm in this. </li>
<li>P1738: Again, I think it would benefit people I know who are not very computer savvy to learn how passwords can be stolen.</li>
<li>P1740: Lots of people I know fall for this so I think it would be beneficial for them.</li>
<li>P1742: Very serious violation.</li>
<li>P1744: Since not storing password seems ok</li>
<li>P1745: Would be an interesting thing to see</li>
<li>P1746: If they're not actually stealing the data, I don't see a problem with it.</li>
<li>P1753: It is causing them no actual harm and will help teach them and others how to avoid these attacks from real hackers who intend to use there information in a harmful way. </li>
<li>P1757: May be educational due to the debriefing.</li>
<li>P1758: I feel like this would not be as much an invasion of privacy as the social networking one was. Plus the participant would be debriefed following the study. </li>
<li>P1764: Again, no harm in participation.</li>
<li>P1766: i personally dont mind to be a participant but not one who i care</li>
<li>P1770: I wouldn't want anyone I know to give up their passwords to anyone</li>
<li>P1771: It is done by researchers, not hackers, so information will not actually be stolen and the researchers are making the participant aware of the "deception".</li>
<li>P1773: Since it seems like there is full disclosure to the participant, I wouldn't have a problem with those close to be participating.</li>
<li>P1774: I am a little more skeptical about this research. I see that it says the passwords will not be collected, but it seems that the study would require the participant to possibly give up their passwords which makes we think this could be a danger.</li>
<li>P1775: You can bet I am checking my computer after this survey.</li>
<li>P1783: This experiment seems more ethical in that the passwords aren't recorded.</li>
<li>P1785: I see no harm in it.</li>
<li>P1786: The experiment sounds harmless enough, as long as no information (passwords, participants personal info) is stored for any length of time. </li>
<li>P1788: Because, even if it is an experiment it sounds like there is too much possibility that they could gain sensitive information. </li>
<li>P1793: It's nothing dangerous, and the passwords will not be stored.</li>
<li>P1800: I don't trust this experiment</li>
<li>P1806: Because this can help with many of the problems people face with their information being stolen. </li>
<li>P1825: It is an important study to learn how to protect people better</li>
<li>P1827: Researchers are making people aware of the study and helping to prevent further attacks.</li>
<li>P1829: Since the researchers disclose what is going on during the study, then it would be okay. </li>
<li>P1835: I think that person would worry and feel a little violated even if the hacking was fake</li>
<li>P1837: I think it would be a good experience as long as there is no real threat</li>
<li>P1839: I would not want to have my friend feel tricked by this experiment</li>
<li>P1840: I doesn't seem like the experiment is too harmful.</li>
<li>P1841: Yes, as long as there was a full disclosure pertaining to why there was deception to begin with.  </li>
<li>P1848: It would provide good insight into internet safety that the participant was obviously lacking.</li>
<li>P1850: Not much harm, benefit in the end.</li>
<li>P1851: As long as no passwords aren't actually stolen, I think it would be a good way to see how hackers work.</li>
<li>P1853: There's no real threat, and it is anonymous. </li>
<li>P1857: Even though the researchers aren't storing the passwords, it still feels like the HIT could go wrong somehow and the participants information could be compromised. Passwords are something very personal and I don't think it is right to try to trick people into revealing them in this manner. </li>
<li>P1864: Again, anything that helps a subject learn to be more secure is ok with me (as long its harmless in the long run)</li>
<li>P1866: I would want them to know how people steal the information so that they can look out for it, and it wont happen to them. </li>
<li>P1870: No information about the participants is being stored, so they are safe.</li>
<li>P1871: I believe in FREE WILL and everyone has a choice to make when participating.</li>
<li>P1873: No harm done, and it might help people with security.</li>
<li>P1874: There will be no malice behind this, and nothing ill will come from it to my loved ones, and they will learn to be more cautious when dealing with passwords and such.</li>
<li>P1876: If they do not use the information then it should be fine</li>
<li>P1877: I don't believe this specific method of study is needed, but I don't find it harmful if done appropriately.</li>
<li>P1878: once again they might learn to stop giving out their info, doesn't appear to be a risk </li>
<li>P1884: No way that is too real.  I would worry for my friend who had to be part of that. </li>
<li>P1890: There is always the risk that the participants password could be stolen.</li>
<li>P1892: There is no benefit for the users as information that would help users prevent an attack will not be published.</li>
<li>P1893: They aren't actually collecting the data, so I don't see any harm.</li>
<li>P1897: This is important research.</li>
<li>P1901: If they wanted to participate, that is fine.  But why would you not have recommendations to help those affected?</li>
<li>P1904: Hacking is a major ongoing issue which needs to be investigated.</li>
<li>P1913: Yes, it is interesting and no-harm</li>
<li>P1916: This is a good way to identify how secure your internet and passwords are.</li>
<li>P1918: Deception is very dangerous.</li>
<li>P1929: Hacking must be stopped</li>
<li>P1930: Doesnt affect me directly </li>
<li>P1934: If they were made aware of their participation, then it's up to them. </li>
<li>P1942: People may be frightened that their password actually WAS stolen, there is no guarantee to the average user.</li>
<li>P1948: It's a study so in the end nothing bad will happen to my friend and they'll know more about hackers.</li>
<li>P1953: This research could be very valuable for improving security of passwords and preventing hacking and data collection, so I would support anyone to take part in it, since their private data is not actually collected.</li>
<li>P1955: It might actually make them savvier to the kind of things that might cost them their passwords. I can see this as a net benefit.</li>
<li>P1960: I have no preference because no real harm will come to them, they will not really fall victim to password theft.</li>
<li>P1963: There will be no real harm done, it may feel like they have been violated somewhat but I feel it is mostly for a good cause.</li>
<li>P1970: What does "researchers want to learn the fraction of Internet users" mean?  </li>
<li>P1971: No passwords are actually being stolen.</li>
<li>P1977: I wouldn't want my worst enemy to be included as a participant. It sounds creepy.</li>
<li>P1978: Passwords should never be part of an experiment. It is too much of a temptation for the researchers and Dangerous for the participants.</li>
<li>P1979: It would be their decision as to whether or not they want to participate.</li>
<li>P1982: I would not want a friend of mine being deceived by this.</li>
<li>P1989: Since the passwords are not stored or collected, then there is no harm to the participant.</li>
<li>P1991: I would not trust the researchers to safely dispose of the collected information. </li>
<li>P1998: Again, the ends do not justify the means. Phishing and hacking for science is still unethical, and I would want to protect my loved ones from such a thing.</li>
<li>P2002: I would want the people I know to be better informed on how passwords can be stolen.</li>
<li>P2003: Like the phishing scam, they could learn valuable information and know what to look for in the future.</li>
<li>P2004: I know lots of naive people that could benefit off of this.</li>
<li>P2006: No, the participants may feel violated to know they were part of an experiment to which they gave no consent. </li>
<li>P2016: Not actually stealing the pw.</li>
<li>P2025: They wouldn't fall for it.</li>
<li>P2026: It is up to my loved one to participate. There seems to be no real threat.</li>
<li>P2027: this can only help internet security, its a good thing and its harmless</li>
<li>P2032: No tampering with the computers please.</li>
<li>P2040: I wouldn't mind if they were included or if they weren't included.</li>
<li>P2044: they will become aware of situations where their information can be stolen and they will hopefully be able to avoid similar situations in the future</li>
<li>P2046: It is harmless and might be educational to those involved.</li>
<li>P2048: Not enough information about account creation and password being associated with it, and what length of time the user thinks that it is valid.</li>
<li>P2053: I think the research would be useful for the research itself to help stop this and since the do inform participants after it would also be a learning tool for those who gave up their passwords</li>
<li>P2060: This is research that needs to be done.</li>
<li>P2061: it is better to know and learn the extent of this happening everyday</li>
<li>P2063: This is too deceptive, I would not want anyone I care about to agree to this.</li>
<li>P2067: Potential to have their passwords exposed if the researchers do not handle the experiment properly</li>
<li>P2070: Seems pretty harmless</li>
<li>P2072: Sending test like this doesn't let you know the tests from the real hackers.</li>
<li>P2076: There is no harm in the experiment, so I wouldn't mind someone I cared about was involved. </li>
<li>P2082: If I was getting paid for it, I would have no problem.</li>
<li>P2083: I think it would teach the participants a valuable lesson.</li>
<li>P2084: BECAUSE IT WILL THEM BE more vigilant of a real hacker and this wont hurt them </li>
<li>P2089: To teach them to be more careful on the internet.</li>
<li>P2094: I want those I care about to be safe, and participating would either serve as an enforcement of their savvy-ness or as a warning to help them avoid future pitfalls.</li>
<li>P2097: After giving the researchers their passwords, they would have to go to the trouble of changing all of their passwords. Hackers could read the results of the researchers studies, and use it to their advantage.</li>
<li>P2100: It would probably provide useful data.</li>
<li>P2103: They are not storing passwords and informing the participants after the study could allow them to learn from their mistakes. </li>
<li>P2114: I don't think there's any risk to the participant.</li>
<li>P2117: I see no violation of subjects' rights. </li>
<li>P2119: I don't think I would mind as long as they were informed after the fact and no passwords would be kept or noted at all.</li>
<li>P2121: I want my friends to be cautious, so this experiment would show them if they're being unsafe with their passwords.</li>
<li>P2123: they will let the people know they were being used in an experiment</li>
<li>P2125: I would like to further the results of the research.</li>
<li>P2126: Since it is up to the participant to voluntarily provide passwords or personal information if they choose to, I see no harm in this experiment and it seems like a good way to obtain valid test results. No one will be harmed, no information wil be stolen and no participant will be compromised.</li>
<li>P2131: Again, not comfortable with the idea of people having access to personal information that is not willing given</li>
<li>P2132: Sounds like passwords could be stolen.</li>
<li>P2135: That information could get leaked, and it could be one the slyest ploys to gain people's passwords.</li>
<li>P2140: Don't really trust it. Would need to see credentials to prove that these people wouldn't steal information. </li>
<li>P2144: It's trickery. </li>
<li>P2150: They will probably steal info.</li>
<li>P2155: No because I do not want anyone I know to be deceived.</li>
<li>P2156: To raise awareness for folks that this threat is real </li>
<li>P2172: It would make the participants more aware of tricks used by hackers.</li>
<li>P2175: This experiment seems unnecessary and risky.</li>
<li>P2177: This experiment has many benefits and no harm is actually done to the participants.</li>
<li>P2181: It will teach them not to click on the bad links</li>
<li>P2183: There is no harm to the person taking the experiment and the results could benefit many people.</li>
<li>P2193: This may be a good way to warn people to be more careful.</li>
<li>P2194: I myself have had my identity stolen so yes I would want someone that I cared about to be a participant.</li>
<li>P2204: I would not want their passwords known even if they weren't collected and saved. </li>
<li>P2205: Again my concern is that sensitive information can be stolen or leaked from the researchers and fall in to wrong hands.</li>
<li>P2208: There's always a chance that passwords could be stolen even from the people who run the experiment.</li>
<li>P2212: I think it would be good for the individual to learn the lessons, but I'm also slightly iffy regarding the group of researchers and would like to know more information about the actual deception techniques and the masking strategy.</li>
<li>P2213: As long as the scientists announce to the public beforehand that they are conducting an experiment, then it would not be considered deceptive.</li>
<li>P2216: If the research was conducted by a trustworthy organization I would have no problem with it</li>
<li>P2218: The research depends on a violation of personal trust. I would not want a friend to be subjected to that kind of testing.</li>
<li>P2219: It's important to learn internet safety, especially for older adults. </li>
<li>P2221: Their passwords are not actually stolen, nor stored so their privacy is not violated in the least.</li>
<li>P2227: I still do not think it is right.  Science is not the end all be all, personal liberty and privacy are.  Even at the expense of science. </li>
<li>P2233: They might learn to be more cautious online.</li>
<li>P2234: It is important to be aware at all times that hackers have many ways of getting passwords from people who are not cautious.</li>
<li>P2237: Being hacked, even if it's jut an experiment is worrisome.</li>
<li>P2238: Only if the passwords are encrypted.</li>
<li>P2243: cause maybe they would learn how to protect their online security</li>
<li>P2244: Again, it is needed information. We have gotten to the point where we take the security of the internet and what we do online for granted. We expect that the sites we go to are secure and no one would steal our information however nothing is further from the truth.</li>
<li>P2245: Why not just send information regarding how NOT to fall for this emails instead of trying to deceive people for your own research benefits. </li>
<li>P2250: This could show someone a security problem without having to actually deal with it. Maybe they would be more careful in the future and avoid a potential threat</li>
<li>P2253: It is harmless and somebody has to participate</li>
<li>P2254: hacking of people's password is a real issue and needs to be addressed</li>
<li>P2260: The researchers would still have your passwords. </li>
<li>P2261: This sort of thing i'm sure is done all the time. </li>
<li>P2273: There is nothing to saw that someone is pretending to be a research on  Mturk. Easy enough to get an  account and post  a  study as  a researcher.  Could be a scam.</li>
<li>P2276: I feel like there is much to be gained from doing this as long as it is handled properly.</li>
<li>P2280: Hacking is a problem whether its one person being hacked or a million.The percentage is irrelevant.</li>
<li>P2281: I think this persons time would be wasted.</li>
<li>P2284: They might learn that they do certain things that put their password at risk.</li>
<li>P2285: I think this could benefit everyone and make them more aware of different scam methods so yes</li>
<li>P2286: It would be very difficult to determine if this was an actual study or if it was an elaborate scam using the HIT system</li>
<li>P2289: I would like for he or she to be aware that it can happen to  him too.</li>
<li>P2296: It's wrong to make people unwilling part of a study that deceives them.</li>
<li>P2302: This study doesn't bother me because personal information is not being stored.</li>
<li>P2305: I think they might learn from the task and be less likely to give out personal information in the future.</li>
<li>P2306: Because network security has a lot of tricks and traps meant to reveal personal information. As a network security professional I would not feel comfortable having a person participate in this study. Plus it's not hard to figure out the "FRACTION" of users that fall prey to this without testing.</li>
<li>P2307: It depends on the person's wishes and personal feelings on computer security.</li>
<li>P2308: It's a good way to inform people in a controlled environment. </li>
<li>P2309: This study is unethical because the participants have not provided consent that they wish to participate. </li>
<li>P2314: I would be skeptical because how could it be guaranteed that none of the researchers would steal passwords.</li>
<li>P2316: Yes, as long as they didn't actually get there password stolen. </li>
<li>P2323: As long as their information isn't being collected by the researchers, I think this is an important research experiment.</li>
<li>P2324: Again, seems like a good idea to study how/why people fall for these scams in order to educate</li>
<li>P2325: THe more data the researchers get the better understanding they have.</li>
<li>P2326: Because no actual theft or collection of password occurred I would not mind if someone I cared for participated in this research.</li>
<li>P2328: How would we know if they weren't actually stealing passwords?  Right now i'm tempted to return this HIT, because of this listing.</li>
<li>P2340: I don't like participants to be deceived. I think if you told people what research was being conducted they wouldn't change their habits.</li>
<li>P2348: It wouldn't be part of my interest</li>
<li>P2349: It seems harmless and it is for educational purposes.</li>
<li>P2350: I wouldn't mind being part of this experiment because at least they researchers let you know of the experiment.</li>
<li>P2351: It seems okay as long as they inform the participants at the end.</li>
<li>P2353: Yes, I think research into this topic is valuable.</li>
<li>P2354: No one wants to be subjected to hacking.</li>
<li>P2357: The scientist could steal the password for themselves</li>
<li>P2361: 0</li>
<li>P2368: It's up to them if they want to be involved. There should theoretically be no risk in it.</li>
<li>P2369: It would demonstrate to the participants the importance of internet security without compromising their  actual security</li>
<li>P2370: my loved ones are not knowledgeable in the use of emails. they would not serve this study very well.</li>
<li>P2372: This has the potetentil for institutional abuse.</li>
<li>P2378: I think this study can be very beneficial in measuring the ways that people fall for this trick.</li>
<li>P2382: As long as the usernames are private/anonymous, there shouldn't be a problem with receiving passwords, even if the experiment turns malicious. A password by itself isn't enough to harm the privacy of an individual.</li>
<li>P2386: Again, you have to give up personal information, which I don't agree with.</li>
<li>P2392: They are participating in the study of their own free will AND are told at the end what happened. The only thing that could happen is they become more educated about internet security and less likely to fall victim to real hackers, or they already avoided typing in their password. But, they may think the HIT is a scam and return it, thus maybe ruining their hit score. Run the study if there is an option to complete it without entering your password, and there seems to have to be.</li>
<li>P2396: While their intentions are good, not everyone involved in academics is pure. They may say they will not store or steal the data, but I would never be 100 percent certain.</li>
<li>P2397: This, along with the other security experiment, I think can greatly benefit internet users everywhere.   </li>
<li>P2403: This could be a trick by a hacker claiming to be a researcher.</li>
<li>P2408: This seems like it would be very distressing to participants.</li>
<li>P2409: I cannot tell others what to do with their lives. But, me personally, I would not feel comfortable with my password being intercepted in such a manner.</li>
<li>P2411: participant could be deceived into thinking that this research is safe and secure.</li>
<li>P2424: I trust that their information would not be compromised</li>
<li>P2425: Anything that is done legally to help stop hackers seems like a good idea to me.</li>
<li>P2432: This would be a good learning experience for someone I cared about to be more safe when typing sensitive material stuff like ssn or credit card numbers to apply for thing that pop up on their screen.</li>
<li>P2433: I would want that person to learn what to look for so that they do not get hacked.</li>
<li>P2435: I think that anything to keep the hackers from invading our privacy and taking over would be a good thing. It might seem a bit deceitful but sometimes that's the way it has to be done in order for it to really work. </li>
<li>P2445: If it were to help contribute to computer science then I don't see why not.</li>
<li>P2450: Because they might learn some tricks that hackers use and avoid them</li>
<li>P2451: The value of the research </li>
<li>P2456: Just because they say they won't steal and abuse the info they gather doesn't mean they don't have a rotten apple in the bunch that will.</li>
<li>P2457: violates privacy...my friend or family member would be giving up their private info</li>
<li>P2463: Even though it is a harmless research, someone without knowledge seems wrong. </li>
<li>P2466: Same reason as #1.</li>
<li>P2473: They are letting the participants know and this could help spread by word of mouth.</li>
<li>P2475: Its harmless</li>
<li>P2480: It seems like a lot to gain here and little to lose</li>
<li>P2483: I think when we start to investigate the actions of hackers with real individuals regardless of their anonymity is dangerous.</li>
<li>P2485: sounds useful</li>
<li>P2488: I guess I would have no issue with it if I knew beforehand that it was all part of an experiment.  This project also makes me feel a bit uneasy, since the issue of stolen passwords is a very serious one.  I'm not sure I would feel totally certain that my loved one's password(s) weren't stolen.</li>
<li>P2491: It's actually an interesting study and everyone that gets "hacked" is informed. therefore less likely to fall for such tricks in the future.</li>
<li>P2495: They should hear the ways their information can be stolen or acquired or hacked</li>
<li>P2496: I wouldn't want anyone to lose their password even to just a study. </li>
<li>P2507: Way too many people are susceptible to this kind of thing. They need to be exposed.</li>
<li>P2511: When it comes to security or keeping yourself protected, I wouldn't risk that even for research. There is no telling what the information would really be used for (actual research or for other proposes). I would tell them it's not worth it and to think about it.</li>
<li>P2513: It sounds like a devious way to steal information.</li>
<li>P2514: It is up to the participant,</li>
<li>P2517: Whenever you have to "trick" someone, you are doing something you shouldn't be doing.</li>
<li>P2522: I would want my acquaintance to participate because it is a valuable experiment. </li>
<li>P2525: No I would not because I feel as though we're being taken advantage of</li>
<li>P2528: Hacking is a serious issue and any study of such an issue is crucial.</li>
<li>P2530: I would not accept people I care about becoming victims of a hacker. These people are real and not just data for some know-it-all holier-than-thou researcher.</li>
<li>P2532: People need to learn what not to do. </li>
<li>P2533: I think this experiment would be going to far into peoples privacy.</li>
<li>P2536: participants would be tricked into participating</li>
<li>P2539: I think there are better ways to study this issue. I don't like that private information would be compromised.</li>
<li>P2542: Same as the previous experiment. This could be beneficial and causes no harm to the participant.</li>
<li>P2543: The study seems like it could easily result in dangerous abuse.</li>
<li>P2545: I think there are pros and cons with this experiment. If I had to choose, I would probably lean more towards suggesting them not participating in this experiment. It requires giving up too much information without the participants knowledge</li>
<li>P2547: Because it can teach people the awareness of how they set their password, and to not use obvious techniques when they set it. </li>
<li>P2549: This study is harmless to the participants so it wouldn't matter to me</li>
<li>P2556: to help warn friends of techniques hackers use</li>
<li>P2561: This would actually be beneficial for the participants as they will learn about their own potentially careless online behavior.</li>
<li>P2563: It can be informative for someone to become more aware of what can happen while online. Many people are naive to a hacker's potential.</li>
<li>P2565: I think it will benefit many people</li>
<li>P2571: I believe it would be a daunting task and in the end prove nothing.</li>
<li>P2572: it would not matter 1 way or the other to me .</li>
<li>P2574: The true purpose of the study gets revealed in the end.</li>
<li>P2575: I am slightly skeptical.  </li>
<li>P2576: Assuming it is a reputable research team that could be trusted, I feel like there would be no harm in participating.</li>
<li>P2578: It doesn't seem to present any risk to the participant</li>
<li>P2579: It will help us know what hackers do to get our passwords.</li>
<li>P2586: As the world moves more and more on-line, security concerns are everyone's problem, and awareness is the first line of defense.</li>
<li>P2588: People need to be aware of attacks like this</li>
<li>P2589: There's no harm being done</li>
<li>P2590: I would want more information first. This doesn't really describe how they will act like criminal hackers and know if they are successful if no information is collected or stored.</li>
<li>P2592: I would want someone to see how easy it is for information to be stolen.</li>
<li>P2595: I think this could be really useful in helping people not fall victim to hackers, people these days are too gullible and give out sensitive info to easily.</li>
<li>P2596: because I would not trust that the researchers were all honest. There could be fraudulent activity with the hacked passwords.</li>
<li>P2605: I don't see any negative effects resulting from this study, so I'd be fine with family or friends participating.</li>
<li>P2610: I take computer security and personal information security seriously. This is a deception that I think is grossly unfair and unethical.</li>
<li>P2612: I think this is alright... ONLY IF... the subjects are put somewhere such as a campus computer lab and given passwords that only apply to that location and that situation.  </li>
<li>P2613: I would want them to experiment as long as the experiment is with a reputable group and not too much personal information is given out. This could be one way to steal personal info. </li>
<li>P2618: It says they won't steal or collect passwords, but they're still seeing them. Can the people who do this work be trusted? What if their computer is infected with virus or something that can see what is typed?</li>
<li>P2619: Whether for research or not, I don't think it is right to trick people into revealing any kind of password information. </li>
<li>P2623: I feel this experiment poses no harm </li>
<li>P2628: I would be to worried about people stealing my passwords.</li>
<li>P2638: Worthwhile study.</li>
<li>P2639: You don't know these people.</li>
<li>P2674: would make you open your eyes to the facts of how easy it is</li>
<li>P2676: If my mother did this experiment, it would make her paranoid about the internet even more so than already.</li>
<li>P2678: If they're not actually stealing information it shouldn't be that much of an issue.</li>
<li>P2682: I am unsure how i feel about the study.</li>
<li>P2685: It would teach the participant how they can get deceived and prevent further deception.</li>
<li>P2686: When the study is revealed, there might be emotional harm from the revelation of security vulnerabilities.</li>
<li>P2688: Again, the worst case scenario is that this person would learn a valuable lesson about security.</li>
<li>P2689: I think that the research is harmless to the participants and may help them learn something about how to protect their passwords/personal information on the internet.</li>
<li>P2690: if it will help security, than so be it.</li>
<li>P2692: Deceptive and I beleive illegalor should be</li>
<li>P2699: I think it would help them to realize how easy it is to be scammed.</li>
<li>P2713: Again. Tricking a person in this way is wrong.</li>
<li>P2716: As before, there is no negative impact to the user, and the user is being compensated for their time.</li>
<li>P2717: It would be a reminder that it's important to pay attention to what is going on while surfing the web and reading emails. </li>
<li>P2723: its not going to cause any harm so I dont care if they are or are not a part of the experiment</li>
<li>P2727: I think it's a good idea to raise awareness on this issue.</li>
<li>P2732: There are no major risks associated with this experiment </li>
<li>P2735: I'm not sure if I can trust the researchers in safeguarding these sensitive information.</li>
<li>P2736: I don't see a problem with it</li>
<li>P2740: Again there isn't much of a risk involved.</li>
<li>P2743: Again, seems ethically questionable</li>
<li>P2747: this goes back to showing how easy it is to get information from people online and people need to be aware of this</li>
<li>P2750: thats their decision</li>
<li>P2753: My friend uses same easy password for everything\r\n</li>
<li>P2759: It's stealing someone's password how is that right?</li>
<li>P2768: It's a little risky but I think everything would go smooth.</li>
<li>P2777: Why wouldn't we try to help maximize safety? Plus, they may be more cautious in the future.</li>
<li>P2781: I think this experiment could give hackers new ideas.</li>
<li>P2792: If someone I cared for was involved they would be contributing to useful research which could lead to useful information to help protect.</li>
<li>P2793: Even if this was just for research, I would not feel comfortable having personal info looked at by a stranger who could steal the info if they really wanted to.</li>
<li>P2794: I wouldn't want someone I cared about taking part in this just in case their passwords got out.</li>
<li>P2795: As long as the reason was disclosed in the end and not bad was done.</li>
<li>P2797: just doesn't seem like the right thing to do even despite the benefits.</li>
<li>P2800: IMHO it would invalidate the test if I knew the person. Subjects should be a random sampling. </li>
<li>P2802: This study is something that should be safe but i would not personally participate and would not care one way or the other if a friend did.</li>
<li>P2804: Only because I could see this being very beneficial.</li>
<li>P2813: I am not sure about this one either only because I am not comfortable with the knowing my password thing.</li>
<li>P2818: I would like to prevent myself from these scams</li>
<li>P2820: I think that the data collected for this experiment is purely for research purposes only and will not cause any harm in reality to personal information collected. </li>
<li>P2823: I wouldn't want the researchers having the password of a person I care about. I don't trust the researchers when they say they won't store the passwords.</li>
<li>P2827: it is important for everyone to be cautious when using passwords</li>
<li>P2828: Another security problem that needs to be dealt with and I would participate so I have no problem with anyone else participating.  </li>
<li>P2829: As I would like for anyone who I cared about to learn the evils of how hackers still your passwords and that they would know the next time a real hacker tried that this is a deception.</li>
<li>P2830: I believe research such as this is beneficial. This would eventually protect the people I care about. </li>
<li>P2834: I think they might be angry or feel violated and I sure wouldn't want them to think I would encourage or recommend them for such an experience.</li>
<li>P2837: Again, no informed consent beforehand, no matter the justification, seems dishonest to me.</li>
<li>P2838: They may not have stolen the passwords, but this task is a form of burglary.  </li>
<li>P2841: I don't want someone I care about to be hacked.</li>
<li>P2844: The best way to find out why and prevent these kinds of things from happening is to do research like this. </li>
<li>P2845: Personal feelings shouldn't hinder legitimate research</li>
<li>P2848: Researchers should not have access to passwords.</li>
<li>P2850: Definitely would want people I cared about to be a part of this. The information is valuable and the negative ramifications seem to be very low.</li>
<li>P2856: This is a great experiment to teach both the users and the website owners of how hackers do it and then stop them.</li>
<li>P2860: At the end of the HIT, the participant is told the purpose of the study.</li>
<li>P2861: I WOULD WANT THEM TO KNOW THE DANGERS. </li>
<li>P2865: I am not involved.</li>
<li>P2869: I would like everyone I know to participate in this experiment. </li>
<li>P2871: It would be up to them if they wanted to go into doing this in the first place, they should be going in knowing people are deceiving.</li>
<li>P2872: I don't know what kind of passwords(like net banking) are being recorded. So I would prefer to be on the safer side.</li>
<li>P2874: They would learn a valuable lesson from it.</li>
<li>P2879: Participants will not be identified and will remain anonymous? I don't believe it.</li>
<li>P2880: They will remain anonymous and no information will be stored. It may also make them more careful in the future.</li>
<li>P2882: I do not like that the participants don't know that they're involved.</li>
<li>P2886: So they can learn their lessong and be more careful in the future.</li>
<li>P2888: Sure, I see no harm being done.</li>
<li>P2892: help people not get hacked</li>
<li>P2893: It could be a good opportunity for someone to learn about this issue and keep their passwords safe.</li>
<li>P2896: if they were or weren't it wouldn't really matter to me. Either way their life will not change. </li>
<li>P2905: again, seems researchers falling to level of criminals...</li>
<li>P2906: It's harmless and perhaps they will learn from the experience to not so willingly give out their password.</li>
<li>P2920: Even though it is an experiment, if any personal information was actually revealed I would be nervous about that.</li>
<li>P2923: It seems like a legitimate reason and it's not hurting anyone.</li>
<li>P2924: i value their privacy</li>
<li>P2929: Most of the other people I know are amateurs with computer security.  Even if they were told that nothing was actually stolen from them they would end up in a panic and be upset that they were deceived.  </li>
<li>P2930: This is needed for security</li>
<li>P2934: This is another situation where it is good to know what CAN happen to you. If you are high risk then it is good to find out that you are not protected first-hand.</li>
<li>P2939: I think that one's privacy is being compromised.</li>
<li>P2941: it is useful to help educate users on preventing hacking</li>
<li>P2945: It's a good reason to run the experiment but there is some risk of passwords actually being stolen via said research so it's more of a gray area.</li>
<li>P2946: I don't see what the harm can be</li>
<li>P2947: This is something of value to the world, and it seems very safe for the candidates chosen to participate.</li>
<li>P2948: could make them more alert and security-minded on the internet</li>
<li>P2955: The experiment causes no harm, provides valuable research, and may serve to remind the candidate participant to be more vigilant about their security.</li>
<li>P2956: This seems like it would be really beneficial in helping prevent people from getting their passwords stolen.</li>
<li>P2959: I'm not comfortable tweaking with individuals passwords.  Also how are you going to 'Insure' no passwords were collected?</li>
<li>P2964: So they will know when and when not to give out there password</li>
<li>P2966: That would be up to them</li>
<li>P2972: It does not appear unethical or harmful because no personal information is actually being collected. </li>
<li>P2979: As long as data is anonymous and non-identifiable</li>
<li>P2983: Please make this HIT.</li>
<li>P2986: So they would become aware of the tricks people use to steal passwords</li>
<li>P2999: still the optional of security breach</li>
<li>P3002: I would be concerned that if a participant fell for the trick from researchers and later learned it was part of a study, they may not be a cautious in the future because they may think it may be another study.</li>
<li>P3003: Could be important for future protection from hackers.</li>
<li>P3009: I think this kind of personal data is too sensitive for me & other users to be used for an experiment even if told no personal data would be collected.</li>
<li>P3016: yes</li>
<li>P3021: If they learn how it's being done they will be able to protect themselves in the future.</li>
<li>P3024: It would not adversely affect them in any way.</li>
<li>P3028: so that he or she can learn a thing or two in this kind of real situation in life.</li>
<li>P3032: Seems like it would be informative about keeping your personal information safe.</li>
<li>P3034: If someone I cared about were to fall for one of these sorts of scams I would want them to know and recognize the issue.</li>
<li>P3036: No trust here. Someone could go rogue</li>
<li>P3039: It sounds like another scam.</li>
<li>P3043: It is for a good cause, but for some reason I feel more uncomfortable with this scenario.</li>
<li>P3045: Because there's no true risk and it would teach them an invaluable lesson to be careful online.</li>
<li>P3046: yes , it would alert them to be more careful , after the research.</li>
<li>P3047: I believe it's good information to know and be aware of how nt o be a victim of real crimes.  </li>
<li>P3061: I think this would be a safe experiment but I have no preference of whether they participate because there is no direct negative consequence, nor benefit(s).</li>
<li>P3063: I've been teaching the people I care about, about computer security for as long as I can remember.</li>
<li>P3064: I think subjects could benefit from the post-experiment debriefing for the purpose of creating more secure passwords.</li>
<li>P3066: seems innocent</li>
<li>P3068: Participants will be able to protect their passwords more</li>
<li>P3077: this seems safe</li>
<li>P3078: May teach candidate to have more care when using the internet.</li>
<li>P3079: To inflate number of participants and to create awareness of said things. </li>
<li>P3081: It really doesn't matter to me whether or not that person participates. It would be up to him or her and since there is no visible risk I would not object.</li>
<li>P3084: Same answer from the last two studies, no harm done, no problem</li>
<li>P3086: No passwords are actually stolen, but good can come of it.</li>
<li>P3094: It is difficult to decide but I think that the possibility may exist that this study could be used by a malicious third party.</li>
<li>P3095: This research will help prevent future password theft.</li>
<li>P3096: It could still be risky.</li>
<li>P3099: making passwords available is bad no matter what\r\n</li>
<li>P3100: Tricking people, even in the name of research is wrong.</li>
<li>P3103: Too much upset and inconvenience.</li>
<li>P3105: That's up to them. It doesn't seem harmful but could be.</li>
<li>P3117: Being a participant would help the person see how they are being duped and help prevent them from falling victim to real scammers.</li>
<li>P3124: Stopping hackers is a great thing. </li>
<li>P3125: Seems unethical</li>
<li>P3126: As long as it doesn't involve malicious software it seems fine.</li>
<li>P3130: I have a hunch I've just been included in such an experiment.  I'm not crazy about being deceived and wouldn't wish that on another.</li>
<li>P3132: As long as they are not storing or using the passwords.  I would rather a researcher steal my passwords and let me know they could do it rather than a real thief stealing it.  This could also help people to take extra precautions for passwords. </li>
<li>P3136: I think the researchers acting as hackers would make people feel even more insecure online once they learned it was all part of a study</li>
<li>P3139: The experiment aims to deceive the participants and I would not want someone I cared about to be deceived.</li>
<li>P3143: If no personal information is being stolen then the study is harmless.</li>
<li>P3145: I value privacy.</li>
<li>P3148: I would encourage anyone to participate with the researchers. The criteria in the study doesn't demonstrate any risk in my opinion.</li>
<li>P3152: This study would be educational to any who participate.</li>
<li>P3159: I shouldn't cause any harm.</li>
<li>P3161: It would really help people like my parents.</li>
<li>P3164: The manner, which is ultimately deception in the name of science is deceptive in nature.</li>
<li>P3166: This type of research can be beneficial by helping people become aware of the dangers if they are not already and being informed after the fact will be relaxing to them.</li>
<li>P3168: I don't think you can ever trust that someone will not store or use a password. I would feel very uncomfortable knowing that it was taken from me. </li>
<li>P3170: We need to learn more on this topic.</li>
<li>P3177: They will be told of the study and given the option to withdraw their data if wanted afterwards.</li>
<li>P3183: they need to learn not to fall for these tricks</li>
<li>P3184: None of the information they collect will be used so what dose it matter?</li>
<li>P3185: It's not like the passwords are being collected.</li>
<li>P3202: In my opinion, the actual safety and security of information given via a HIT even under the premise of a "study" does not mean it is safe.  I would not support being a participant in the study.  Although it could be a good test to see if the person will think before just handing out their email or password. This is just not the place for that type of experiment due to safety and protocol concerns.</li>
<li>P3203: This is a learning experience everyone should take part in.</li>
<li>P3207: So they know if they'd fall for the tricks or not</li>
<li>P3208: Hopefully the person I cared about would learn more about password security through participating (after the debriefing). Thus I would want them to learn so they could be more secure in the future.</li>
<li>P3209: no data stolen but still shadt</li>
<li>P3217: Even though the researchers have good intentions, I'd still be nervous that the person's password information would be floating around.  I would worry that they would be in a situation in the future where they wouldn't be able to determine someone's intentions.</li>
<li>P3223: i wouldn't want someone I liked being lied too </li>
<li>P3227: Don't care either way. </li>
<li>P3228: I am still convinced that projects like this would benefit given the outlines.</li>
<li>P3236: doesn't matter</li>
<li>P3240: If they are   used for scientific knowledge and their is no harm to them or their computer I say ,yes. I would love to know how hackers get personal passwords. I think this would be benefical research. </li>
<li>P3243: Great education!</li>
<li>P3245: Yes, since no actual PW would be recorded. This could teach them a helpful lesson with being careful with phishing sites. </li>
<li>P3246: this would be very educational to learn, and could prevent future hacking</li>
<li>P3247: Passwords are sacred</li>
<li>P3252: I would be interested in their results</li>
<li>P3258: I know several people that are not careful, to the point of reckless on the internet.  This can be a great education for them.</li>
<li>P3259: I don't believe anyone I know would purchase anything they learned about through spam</li>
<li>P3260: It's their choice.</li>
<li>P3262: This is dishonest</li>
<li>P3268: With caution</li>
<li>P3269: This would presumably not cause any anxiety for the participant during the experiment.</li>
<li>P3274: it does not affect me</li>
<li>P3275: This would be interesting to see if the candidate did indeed give security information. </li>
<li>P3276: No real threat in it.  Participating will add to the research material.</li>
<li>P3281: It's discomforting to me</li>
<li>P3289: It's a good lesson & some people may need this type of thing to (hypothetically) happen to them, to get the point of the severity of this problem</li>
<li>P3296: Isn't this the same idea as the other ones?</li>
<li>P3300: I would want them to know where the errors in judgement are</li>
<li>P3301: As long as the passwords aren't stored in any manor, I don't see this being a harmful experiment. </li>
<li>P3311: I would want those close to me to realize the dangers of hackers.</li>
<li>P3312: I would not want their passwords being available for hacking, even if they weren't at risk.</li>
<li>P3313: I don't think it would matter if they did. No one actually had their password stolen.</li>
<li>P3314: It would be a good lesson for people to learn</li>
<li>P3316: The results of this experiment are very important.</li>
<li>P3319: Again, there is the danger of important information leaking out.</li>
<li>P3320: If they are participating in a fishing scheme unknowingly, they need to know, so I approve of this experiment, since they will be informed afterwards.</li>
<li>P3326: solo person voluntary involvement.</li>
<li>P3328: as long as the passwords are not stored I would have no preference</li>
<li>P3331: It would help to make people be more secure on the internet.</li>
<li>P3333: The experiment would make at least some of those who fell for the attempt to obtain their passwords  foolish. </li>
<li>P3334: Seems dishonest, I dont want to make someone I care about feel dumb and vulnerable.</li>
<li>P3338: It doesn't make a difference to me who is in the experiment.</li>
<li>P3340: It could be a valuable lesson.</li>
<li>P3341: I see no risk, sometime researchers need to use deception. And they would learn how to prevent future attacks</li>
<li>P3343: If there is really no risk, I don't see a problem.</li>
<li>P3347: As long as it's a study, I see no harm as long as it isn't used maliciously.</li>
<li>P3354: This is better than the other one because they are not storing/checking the passwords.</li>
<li>P3359: This one just freaked me out, I hope YOUR not a hacker.</li>
<li>P3360: knowing the fraction of internet users who divulge something which results in hackers getting their passwords is not that important.  knowing that passwords are being hacked and enough users compalin about it to try to outwit the hackers is important.  knowing what fraction gets hacked is not important to do wuch a complex, difficult and deceptive stuff</li>
<li>P3367: It sounds like useful research.</li>
<li>P3368: So they become more informed about internet security.</li>
<li>P3373: If someone I cared about were to fall for the ruse in this experiment, I believe it would be a valuable learning experience for them to realize that it happened and be given an explanation of how to avoid it in the future.</li>
<li>P3378: I think that if I'm tricked into giving away my password in a safe environment, I would want to know to better protect myself.</li>
<li>P3387: It might have a side effect of teaching them how to be more safe online. </li>
<li>P3389: It's for a good cause and no harm will be done to them. </li>
<li>P3391: It causes no harm to the subject </li>
<li>P3393: I think this because I want them to be able to help in anyway that they can with security while also making them more aware of the risk they might encounter. </li>
<li>P3397: to understand the problem of hacking and how devastating it can be</li>
<li>P3402: i would have no problem with them participating</li>
<li>P3403: Again, I feel like there would be no ill effects.</li>
<li>P3408: N/A.</li>
<li>P3416: There is no way for a participant to actually know that their computer is not threatened.</li>
<li>P3426: Yes, it is a good chance for education in secure environment.</li>
<li>P3427: Although the researchers plan to dupe the participants in the beginning of the study, they will inform them after the study completion. In doing so, the participant will be more highly informed on online security.</li>
<li>P3428: This study is much more dangerous, as an unscrupulous researcher might steal the passwords.</li>
<li>P3431: Deception is used in a large percentage of HITs so participants should be used to it anyway.  It is used for a different reason, but still used.</li>
<li>P3434: Passwords can be very personal and I would not want something like that being put into a form anywhere other than where I know it is safe.</li>
<li>P3438: This seems to be a safe experiment. They protect the users information.</li>
<li>P3440: I do not think it is good for the research to get personal data from people without consent.</li>
<li>P3442: I feel torn.</li>
<li>P3445: It will help prevent future computer users from falling for the tricks of hackers.</li>
<li>P3447: There is no danger, since no passwords will actually be stolen. </li>
<li>P3453: Because people are still accessing their data, regardless if it is collected or not.</li>
<li>P3456: I don't see how they would be harmed in this particular manipulation of the experiment.</li>
<li>P3460: TO SHOW HOW VULNERABLE THIS PERSON IS</li>
<li>P3463: If they actually fell for it, they would most likely smarten up after reading that it was a fake attempt to steal their information, and would be less likely to fall for it in the future.</li>
<li>P3464: I do not like the idea of a loved one sharing any important information, even for an experiment.</li>
<li>P3467: It still sounds too much like the last one. I still have a funny feeling about it.</li>
<li>P3469: It just feels very unsafe.</li>
<li>P3472: I would like to see if they fall for it.</li>
<li>P3483: Since nothing is actually taken and it is all controlled I think it's justified.</li>
<li>P3487: I think this could be a useful experiment and if a friend of mine did this experiment and learned something - even though they were tricked at the outset - it might help them better protect themselves in the future.</li>
<li>P3491: I don't see why I would have to be worried about someone I care about participating in this experiment. It seems rather harmless.</li>
<li>P3495: Seems a little fishy to me</li>
<li>P3503: I would not like someone I cared about to be part of an experiment without their permission.</li>
<li>P3508: I believe this would be illegal to do this.</li>
<li>P3510: Only if they did not give any real usable information or passwords</li>
<li>P3516: As long as no harm would come to them I would leave the decision up that person.</li>
<li>P3523: that way they would learn not to give out there passward</li>
<li>P3524: I think it could be psychologically harmful.</li>
<li>P3525: It sounds like it would be a good opportunity for this person to learn how hackers operate</li>
<li>P3526: Could further internet security and attack prevention.</li>
<li>P3532: No harm is being done, so I do not mind.</li>
<li>P3534: Researchers have outlined safety measures and will explain in detail to participants what the study involved.</li>
<li>P3536: Again, it's up to them. Actually I think this would be useful information for most people since we use passwords every single day to access our emails, facebook, etc. In fact, it'd probably be a good idea.</li></ul>	</div>
</div>
<div class='cap' style='max-width:30%;'>
	<div class='header closed'>SocialPhishing study, answers to Surrogate question</div>
	<div class='body'>
<ul><li>P6: This study is a big no no for me. A study that researches the person to use it against.</li>
<li>P11: invasion of privacy</li>
<li>P12: I would not condone the participation when passwords are being taken and used, whether it is secure or not. </li>
<li>P16: I would want that person to be aware of whats happening and to be educated in how to deal with it.</li>
<li>P20: I'm unsure about this one, it's kind of too sneaky.</li>
<li>P27: This research is just as bad as the hackers who do phishing!</li>
<li>P33: seems deceitful and wouldnt want someone I know participating</li>
<li>P38: If any of my family or friends fell victim to a phisher, they should learn not to.</li>
<li>P43: This will cause them to worry about their friend's identity. </li>
<li>P52: It just doesn't make a difference if it's someone I care about because its only an experiment.</li>
<li>P54: I wouldn't want their privacy to be violated. The researchers would be viewing their Facebook profiles and would even have access to their passwords.</li>
<li>P55: They should know better than to open phishing links, so if they participate it is on their own head.</li>
<li>P56: This will teach the person I care about to be careful about opening emails and entering passwords.</li>
<li>P59: It would help them by teaching them how not to fall victim to these attacks</li>
<li>P60: I don't think it's fair to do the experiment without willing participants </li>
<li>P61: If they were a student in the university, then I have no objection with the caveat that each student is informed afterward, and passwords are changed. It would be done within a closed system with accountability and a way to inform.</li>
<li>P65: Its dangerous and the morality is not questionable but wrong. What happens if one of the researchers is not an ethical person and uses those passwords and other gathered information?</li>
<li>P69: THINK THIS IS A GOOD IDEA</li>
<li>P77: I believe it is unethical to conduct any study without the consent of its participants.  </li>
<li>P79: I'd prefer to leave unsuspecting friends out of the studies i sign up for.</li>
<li>P80: This seems like it's a tad too invasive.</li>
<li>P84: too invasive</li>
<li>P93: This seems unethical.</li>
<li>P94: Thats scary!</li>
<li>P96: It seems borderline invading privacy though poses no threat so it would be up to that person.</li>
<li>P97: Facebook passwords could be used for personal emails as well, it's not a good idea to share this with anyone.</li>
<li>P101: Yes, I would want that person to be included because even though the experiment is a bit risky, the benefits seem to outweigh the risk.</li>
<li>P106: No harm would be done and the research yielded would be worthwhile.</li>
<li>P117: Not unless the researchers also get permission from the "friend" on facebook.  Otherwise their experiment could harm the relationship between the two people in the time between the phishing e-mail is sent and it's revealed to the participant that it was part of an experiment.</li>
<li>P118: Too much impersonation</li>
<li>P119: Because they should be warned not to open such messages</li>
<li>P122: I don't think this a legitimate research. There is no reason to do this.</li>
<li>P132: Yes. While it seems dangerous, if the party researching is under careful observation, I would be okay with conducting an experiment. This is a hard subject to really get good information on.</li>
<li>P135: Once again, what is the point? These researchers won't be able to help victims from falling prey.</li>
<li>P136: There's no pre-consent.</li>
<li>P143: Too much exposure on sensitive passwords like bank accounts, and too much room for the data obtained to be used against the participant no matter the security measure in place. </li>
<li>P152: I would not want them to be phished and have their information taken, even if it was for a legitimate experiment by a recognized university.</li>
<li>P156: I wouldn't want anyone to feel the panic that would involve.</li>
<li>P159: I already know how people fall victim to phishing attacks, and there is already plenty of information out there (including the Help pages of most major websites, like banks, credit cards, and even Amazon.com).</li>
<li>P161: I think this may be a good experiment to have on a college campus but I don't necessarily feel that a person I cared about would really need to be involved in this. They may benefit if they are involved though.</li>
<li>P166: Their information will be safe</li>
<li>P169: Phishing is so common, and people I know so commonly respond, that I would like them to learn about the technique so that they do not participate in the future.</li>
<li>P171: Seems a little unfair as it comes from trusted source but probably can't be too cautious these days. </li>
<li>P179: Too much privacy invasion. </li>
<li>P181: possible identity theft</li>
<li>P183: What other people do is up to them.</li>
<li>P184: It involves the collection and examination of actual passwords. I would rather that someone else provide this data rather  than someone I cared about, as I do not fully trust that the researchers will protect the passwords.</li>
<li>P185: No one should be used without prior knowledge</li>
<li>P186: n/a</li>
<li>P187: There is still that possibility one of the researchers would take the information to get the money or get into someone's account </li>
<li>P188: I feel this is an invasion of privacy to a high degree.</li>
<li>P190: There is no prior consent.</li>
<li>P192: This is all too invasive and stressful. I see a trend.</li>
<li>P194: there is no harm in being included</li>
<li>P198: This seems too unethical.</li>
<li>P200: The fact that they actually verify the passwords makes this too dangerous to condone.</li>
<li>P206: this would make all the participants very paranoid about data security</li>
<li>P211: since it is controlled no real harm</li>
<li>P215: Potential for privacy violations</li>
<li>P218: no preference</li>
<li>P220: I'm sure there's another way to conduct this study.</li>
<li>P231: The study is only directing the students to the universities website.  The university researchers and the one controlling the experiment I don't see a problem with this.</li>
<li>P232: Seems to be for a good cause</li>
<li>P235: I don't approve of collecting the passwords.</li>
<li>P239: They're providing their passwords which seems like a beach of privacy to me. I'm not comfortable with this.</li>
<li>P242: it will encourage students to be more aware of attacks</li>
<li>P248: I think the objective of the research will not justify the risk involve in getting people's sensitive information.  Without research, one can safely assume that success rate of phishing email coming from trusted people increase significantly. I do not see the advantage or the use of knowing whether success rate increase 50% more or 100% more. How will the study result to helping society control or eliminate phishing? Or....can it be eliminated at all?!!!</li>
<li>P250: Passwords have no business in the hands of anyone not authorized to use said accounts</li>
<li>P253: It could confuse future attacks.</li>
<li>P254: This is all for the greater good, so it doesn't really matter to me.</li>
<li>P258: Same reasons as last study</li>
<li>P270: It's an invasion of privacy, its purpose notwithstanding.</li>
<li>P271: The experiment is simply wrong, and no university in their right mind would be a part to such a scam</li>
<li>P272: It will raise awareness.</li>
<li>P282: So long as the experiment resulted in a way to stop phishing</li>
<li>P284: Because i would hate  to see someone i care about information get out in case something goes wrong.</li>
<li>P289: This is too invasive into the personal lives of the participants.</li>
<li>P291: Only if I thought my friend might be a victim of phishing. Better to learn a lesson through a controlled experiment.</li>
<li>P302: privacy is being violated</li>
<li>P303: Would not feel comfortable with researchers having that level of access to someone's account.</li>
<li>P308: again this is a very good study that could help many people - so since no harm would come to the participant I say go for it</li>
<li>P309: I think the research is helpful overall.</li>
<li>P314: nice teaching lesson about the dangers of trusting on the internet. </li>
<li>P315: seems invasive even for an experiment</li>
<li>P316: Yes, this is a common problem and not only will this provide data but teach the participants about a very real problem and how to identify it.</li>
<li>P317: I would allow someone I know to participate in this experiment if it will not do any harm to their being.  I would expect education from this experiment so that may better be prepared to avoid this scenario.</li>
<li>P322: they are not only collecting passwords, but testing them to see if they are correct. This is a serious violation of privacy</li>
<li>P326: That is becoming a bit on the big brother side in my opinion</li>
<li>P327: i do not believe that the invasion of privacy should occur</li>
<li>P334: Pfishing is another means of identity theft, and needs to be stopped.  My friends, family, and I would gladly participate in a safe research project like this, whether we knew of it ahead of time or not.</li>
<li>P340: Anonymity and the possibility of helping prevent phishing make it worth participating in.</li>
<li>P344: n/a</li>
<li>P347: There is a chance that the information could leak and be used inappropriately.</li>
<li>P350: Assuming no passwords would be compromised, this is a very good study</li>
<li>P369: As long as passwords are kept secure, I don't see any harm.</li>
<li>P370: Sounds like another good study to help online users eliminate more negative attacks.</li>
<li>P371: Since they will be informed after and be allowed to choose weather or not their information is used.</li>
<li>P376: I feel that this isn't fair as the student has no knowledge of the experiment ahead of time. </li>
<li>P386: Its a terrible idea</li>
<li>P402: I don't see any harm in this experiment.</li>
<li>P403: Don't want their privacy invaded.</li>
<li>P406: This involves not only a participant but a participant's friend and it is unethical since the friend presumably isn't being contacted to give consent.</li>
<li>P409: I think this is dangerous and do not see the benefit for the participant.  If they signed up for this experiment, then it is fine.  University giving access to student passwords is a no-no</li>
<li>P412: For the purposes of research, I would not oppose someone I care about being included, if it is for the common good.</li>
<li>P415: not ultimately harmful</li>
<li>P417: This doesn't sound like an ethical experiment, so I'd want them to avoid it</li>
<li>P419: I don't like the fact that students would enter their real passwords and the university's systems would be able to verify whether they were valid or not. </li>
<li>P425: If the intended victim uses fictious information then it could produce good results.</li>
<li>P427: I'm ok with this in a student related setting.  I think people could learn a lot about internet safety from this experiment.</li>
<li>P428:  they will be gaining access to personal information</li>
<li>P429: I don't see what it would hurt if it's only an experiment.</li>
<li>P437: You giving them your bank account password and their verifying it.</li>
<li>P444: Again it is dealing with a password , I would advise my loved one not to participate</li>
<li>P446: as long as the person knows it is an experiment there is no harm done</li>
<li>P449: again, there really are no negative results from this</li>
<li>P450: it's compromising </li>
<li>P453: this is harmless and may help fight phising.</li>
<li>P458: I would like to see how gullible my friends are to cyber attacks.</li>
<li>P463: People would be including their real information and as a result someone could actually use the information to log into a bank account or something else.</li>
<li>P464: Since this is just an experiment, their passwords are not actually being compromised. This will also make my friend more aware of real phishers out there and will encourage them to be more cautious.</li>
<li>P467: This seems like a violation of privacy.</li>
<li>P469: Even fake phishing is wrong</li>
<li>P470: I wouldn't want someone I cared about to participate in this experiment because of the risk of there bank password falling into the wrong hands. </li>
<li>P472: Seems overly deceptive. Taking data directly from Facebook seems a little too far</li>
<li>P473: It's a fake site so there are no real consequences.</li>
<li>P476: no harm would be done</li>
<li>P479: The facts and intent of the study is genuine and it only rational to accept inclusion.</li>
<li>P480: it's important that way they can understand how dangerous this is.</li>
<li>P485: this would raise awareness.</li>
<li>P486: The researchers are violating the person's privacy. They first crawl the user's facebook profile to get their friends, and then obtain the person's password BEFORE the user has any say in being a participant in the experiment. </li>
<li>P487: Time is valuable</li>
<li>P491: No guarantee that collected passwords will not be used by researchers. Better set up through specialized university page that does not compromise use password.</li>
<li>P496: It sounds like it would be a useful study to learn about phishing attacks, and doesn't seem to have any drawbacks other than embarassment if they fell for the phishing attack. Since the information is anonymized, it is highly unlikely other people would find out that you were tricked into such a thing.</li>
<li>P498: It could be an experience to teach them to be more carefut</li>
<li>P505: I would not care either way. I see no harm done by them being included but could understand if they didnt want to be.</li>
<li>P513: I don't want anyone to be lied into giving out their information. </li>
<li>P515: Phishing attacks are wrong no matter what the circumstance.  Even though this is an experiment, people are still being deceived by it.</li>
<li>P517: The school should be able to do this safety measures. The students should learn more about how to protect themselves online.</li>
<li>P519: Like the previous experiment, this one would help people realize and become more aware of the potential dangers on the internet. </li>
<li>P528: This actually involves invasion of privacy. </li>
<li>P531: I feel that this could lead to bad feelings between friends before the fact that this was a research study was revealed.</li>
<li>P535: This would be a huge breach.  User's passwords getting into the hands of any other person is a huge risk.</li>
<li>P538: I would like them to participate so that they would learn about the dangers of sending out personal information without thinking about it.</li>
<li>P539: A BIG NO!!  Passwords are valuable and some people will divulge them to friends even though they shouldn't.  How secure will those passwords be in the hands of researchers?  I'm not that trusting, and just the thought of this one makes me crazy!</li>
<li>P541: It's too invasive and abusive of our rights.</li>
<li>P548: I don't think it would be harmful to them. </li>
<li>P554: difficult to answer. on the one hand, such an experiment can yield great, useful results. On the other hand, people might get very mad that they were subject to said experiment.</li>
<li>P555: I would want someone I cared about  to see how easy it would be to deceive them into sharing their password</li>
<li>P557: I think it's for a good cause and there really is no harm no foul.</li>
<li>P558: The plan here is to impersonate third parties to send a scam email to other third parties?  At what point here do you start to worry about running afoul of the law with this level of aggravation of people?</li>
<li>P562: Do believe this is a just experiment do to no harm being done and the subject not realizing that he's been used for an experiment until after the research has been completed than the subject is allowed to withdraw any info taken from him</li>
<li>P573: I would like them to be a part of the experiment because it could only do good.  If they are currently unaware of "phishing," perhaps this study will help make him/her more cautious about clicking links and inputting important, confidential information into potentially dangerous websites.</li>
<li>P578: You shouldn't be looking a people's passwords (even if that ability exists).</li>
<li>P583: Awareness</li>
<li>P590: Again I could see this having the potential to be very harmful.</li>
<li>P591: Think it is important for young people to understand risks</li>
<li>P594: I would not want someone I care about to be a participant because their privacy is being violated, not only by being lied to through their personal university email but also through their Facebook profile. </li>
<li>P603: There's a certain education aspect to this.  While a white hand hack is non-intrusive, it also teaches a valuable lesson to the person who "fell for it" maybe giving them some tools to better identify a phishing attack in the future.</li>
<li>P606: I said no because no one should be allowed to gain access to student's passwords. Plus, someone on the research team may be dirty and keep the passwords. </li>
<li>P608: There should be more control over the group selected. No one should unknowingly give their passwords even for research. What if someone with bad intentions got a hold of the information?</li>
<li>P609: this leaves people open to having info stolen even though it is a controled study</li>
<li>P612: I would not want anyone I know to be involved in this. Not only is it deceitful and an invasion of privacy, but this could cause a rift between friends. </li>
<li>P626: collecting passwords should never be part of an experiment, what if one of the researchers secretly kept them?</li>
<li>P628: information could be useful to help protect them in the future</li>
<li>P630: I don't think it will prove anything.</li>
<li>P633: I think this is an important study and as long as people are debriefed after I think it's OK. It would even be educational for participants. </li>
<li>P634: I believe this type of study is too sensitive, and potentially dangerous for the participant.</li>
<li>P646: No way.I don't want someone I love to go through the stress that this would cause someone. Only to find out that it wasn't real.</li>
<li>P647: I think experiments like these are necessary to ensure a more secure infrastructure, even if they are deceiving and somewhat invasive. We need to be 2 steps ahead of hackers and phishers.  </li>
<li>P652: I think this is a great research to do but a little risky and could be frustrating to people who are participating. </li>
<li>P656: It would educate them in the methods of phishers.</li>
<li>P658: I don't think it is alright to be collecting passwords unknowingly from anyone.</li>
<li>P660: I would be concerned about the security of the passwords.</li>
<li>P672: I wouldn't want passwords getting out like that. Even for research.</li>
<li>P676: So, the university will allow the team to verify the passwords? Yeow! Ironically, this sounds like it would make a great phishing scam :-(</li>
<li>P678: expose these tricks to them so they may learn</li>
<li>P682: I do not believe that phishing needs to be researched but stopped!</li>
<li>P685: I don't like that they lie to people and include them without informing them.</li>
<li>P689: The concept is good, but the method seems a little too invasive of someone's privacy.</li>
<li>P691: There are no outside sources that will have access to personal information.</li>
<li>P692: I wouldn't want their privacy/Facebook profiles accessed.</li>
<li>P694: this is a beneficiary study</li>
<li>P696: The seems invasive, as the researchers would have to know who at the university was friends with who, would require researchers to access the students email accounts, and would collect passwords and personal information they did not consent to.</li>
<li>P702: I do not want anyone I care about being sent to phishing web site because they could give private info thinking someone they knew thought it was safe. That is not fair to have someone i care for tricked into possibly releasing their info. </li>
<li>P704: Very dangerous.</li>
<li>P705: Most of the people I know wouldn't fall for a phishing scheme.</li>
<li>P707: This would likely anger, disturb and likely embarrass the person.  I wouldn't wish that on someone I cared about.</li>
<li>P708: I would not want someone I know to divulge personal information to anyone even if it is an experiment.</li>
<li>P709: This could get tricky due to privacy concerns. </li>
<li>P710: personal decision</li>
<li>P717: I don't think this experiment is harmful to the person picked so I didn't choose No, but at the same time the person picked doesn't gain anything personally so I didn't choose yes either.</li>
<li>P721: I think that going through this experiment would be good for them to know how to be safer in the future. Also, a university account isn't as critical as, say, a bank account.</li>
<li>P722: This one would have to be totally up to the person> I wouldn't want to have a say in it, nor would I have a recommendation.</li>
<li>P725: to know the risk and to help them be aware</li>
<li>P729: They have a choice in having their data excluded so seems ok.</li>
<li>P732: I would want to be sure they're being secure with their passwords.</li>
<li>P735: The project says nothing about getting permission from the students. If they agree to participate then I don't see any problems with volunteering to be in the study.</li>
<li>P737: I can see how it would be beneficial to the research? However it may startle or upset someone so its hard to say yes id want to include my friend.</li>
<li>P741: So they can learn to be careful</li>
<li>P749: Nobody should have access to ones passwords without permission.</li>
<li>P750: I wouldn't want them to incur the stress even if it was for research purposes. </li>
<li>P761: It is unethical because the student doesnt realize he was a participant</li>
<li>P763: It might be possible to include contractual language into a student's acceptance of the email account that allows for this.  If this is the case, then it is fair game... since they will also be notified.</li>
<li>P765: As long as there information isn't given out I wouldn't see the issue.</li>
<li>P770: I wouldn't want anyone else to have access to my valid passwords.</li>
<li>P772: No real passwords are given and feelings maniuplated by use of friends.</li>
<li>P776: I would not want my friend's University password being verified by the to the researches without his/her permission.</li>
<li>P780: I think it would be a good lesson to learn, better learn it through being experimented on than through a true predator who might make off with your entire bank account fund </li>
<li>P784: I think this experiment gets to personal, by actually accessing passwords, and this issue, receiving an email from a friend, as part of phishing, does not seem as relevant.</li>
<li>P787: I don't really trust this as it brings unwanted emails. I think universities do not have the authority to give out emails of students even if it's for research purposes, and a student who signs up for this would know why they are signing up and that may mess up the data. </li>
<li>P788: There are too many things that could go wrong with this experiment that could result in sensitive information being leaked.</li>
<li>P793: If someone is going to fall victim to this type of thing, I would rather it happen in a controlled experiment where they weren't actually hurt, then they could be notified and learn from their mistake.</li>
<li>P794: I've had viruses as a result of untrustworthy email. Even if this is an experiment, email is not something I feel should be used. It's too fragile, and too many internet threats rely on email.</li>
<li>P800: It's not entirely ethical I suppose. However, I cannot imagine how anyone could truly be hurt or damaged by it.</li>
<li>P803: As long as their information is not compromised.</li>
<li>P811: People fall for this everyday and loose lots of money because they usually give their password to their accounts without realizing they have falling prey to phishing.</li>
<li>P812: Snooping around on someones facebook to find out their friends just to use in the experiment seems to be going a little too far. Couldn't they simply use a teacher as the 'person of trust'?</li>
<li>P816: I think this is also a good experiement</li>
<li>P820: would be an interesting experiment to see.</li>
<li>P821: I once again don't see any problems with it as long as nothing malicious is being done to the participant.</li>
<li>P828: Same reason as the previous password research experiment, passwords are sensitive information.</li>
<li>P834: The study doesn't seem beneficial or detrimental to the participants.</li>
<li>P835: Nobody is at risk here unless the researchers are also malicious, which is unlikely.</li>
<li>P836: I want people to understand the dangers that are out there and the lengths upoin which devious people would go to to get there information.</li>
<li>P837: Using the University as a foil for the attack could reduce the participants trust of the organization itself. It reduces the trustworthiness of all future communications.</li>
<li>P842: I find that this study goes too far as far as privacy is concerned. </li>
<li>P847: There is significant potential for compromise via theft or abuse of the users' passwords.</li>
<li>P858: Passwords being tossed around any system unnecessarily is a bad idea.</li>
<li>P865: it sounds harmless, so i don't think i would mind either way as long as the person  i care about will not in anyway be harmed </li>
<li>P866: I think it is not appropiated.</li>
<li>P870: Yes, but they should be warned before hand in a very general way and asked if they would like to participate, otherwise there could be a lot of opposition when the person finds out.</li>
<li>P874: I believe that being exposed to this form of cyber attacking can be beneficial so that people understand that they are at risk and can be smarter in the future</li>
<li>P882: This seems like more of a violation of privacy, essentially running a phishing scam for real on the promise that the data will be deleted.</li>
<li>P884: Especially with the use of the internet for personal banking among university students, this is an experiment that would keep them safer.</li>
<li>P886: Too much private information violations, getting friends from Facebook, using the University's systems for passwords, blogging, all seem a bit to public.</li>
<li>P890: This is wrong in my opinion. People cannot consent to participate and I feel that their privacy is being violated.</li>
<li>P898: honestly most of the people i know would spot the issue right away and not submit the information</li>
<li>P900: Seems safe enough.</li>
<li>P901: The study looks to pry to closely into participant's personal lives by looking through their friends on facebook.</li>
<li>P903: I would want my cared one to participate in this experiment so that they could understand the importance of phishing and how to avoid phishing scams.</li>
<li>P904: No one wants to receive spam</li>
<li>P905: Because people would find out the password to an account.</li>
<li>P906: awareness is a good thing</li>
<li>P914: I would not want someone I cared for be part of phishing experiment due to privacy and password protection.</li>
<li>P921: Even for a study, I wouldn't want their password to be known by anyone. </li>
<li>P925: this is scary in that it enables a third party to access the participants personal information and could cause identify theft if someone untrustworthy got ahold of the information</li>
<li>P926: I think this study will reveal important information. </li>
<li>P927: according to me this experiment would not work out, as this type of malpractice happens basically with bank account website and not in university website, so to get a proper feedback and result on this issue, it would be better to find a different option to get the result</li>
<li>P930: This is basically an attack...gets a lot of personal info</li>
<li>P934: i think it's a good experiment for research, so i don't mind.</li>
<li>P936: this would harm nobody</li>
<li>P939: The experiment seems harmless. </li>
<li>P942: it should be up to the person involved</li>
<li>P948: It's phishing</li>
<li>P951: because they are collecting true passwords</li>
<li>P953: It just does not seem like an ethical experiment.</li>
<li>P955: I do not feel that allowing a research team to have access to private information such as internet passwords is ethical. The way the study is set up sounds like they're trying to do things in a way that would protect the students' privacy, but I still don't agree with it. </li>
<li>P957: I would not someone I cared about to participate because although this is a test,  think they could fall victim to other phishing scams.  Also, I do not like the idea of personal sites such as website because used without consent of all participants.</li>
<li>P960: Invasion of privacy via social networking sites.</li>
<li>P963: This may increase future online security.</li>
<li>P967: I just honestly wouldn't care one way or the other.</li>
<li>P972: With the university involved, it seems to be handeled in a professional manner.</li>
<li>P984: I would think that it would compromise their password in other situations - assuming that they may use the same password frequently.</li>
<li>P986: Yes as long as they are willing to help research</li>
<li>P989: My parents aren't fluent in English so I would be glad for them to see how easy it is to be tricked and sent to a malicious website. They occasionally end up on bad websites accidentally and seem to be slightly gullible for the internet.  </li>
<li>P991: They will remain anonymous so it doesn't matter.</li>
<li>P1004: The appearance of using an email address of a student's friend to get to them bothers me, as does compromising my friend's own password this way.</li>
<li>P1005: I would want to know if my kids were smart enough to spot a scam.</li>
<li>P1007: Once again, don't give passwords out to anyone.</li>
<li>P1010: Although one has been informed of such an experiment, there is always a possibility that one can be truly scammed.</li>
<li>P1012: This one is risky.</li>
<li>P1016: It is really up to the person to decide.  I would not want to interfere if that person wanted to participate.</li>
<li>P1017: i would hope my friends would not fall for this... my parents i'm not so sure</li>
<li>P1019: again seems pretty harmless</li>
<li>P1024: way too risky </li>
<li>P1026: This seems to be a high-risk experiment.  Passwords would be at risk. </li>
<li>P1028: This experiment could cause more problems than it solves.</li>
<li>P1031: I don't see how this could be used to prevent people from falling for phishing scams. </li>
<li>P1041: It's a violation of their privacy.</li>
<li>P1050: Impersonating candidate's friends and gaining their passwords in this manner is highly unethical.</li>
<li>P1055: It is a difficult question, but it seems that the researchers are doing this phising for a good thing.  So I would hope my friends would participate in this experiment.</li>
<li>P1056: It can be helpful in reducing the risk of getting phishing emails</li>
<li>P1057: It will teach them a lesson to not click on strange emails.</li>
<li>P1058: I think that people should be completely aware that they are part of a study before proceeding with a university wide experiment. I think this would cause an uproar between students, faculty, and family members. </li>
<li>P1059: They might learn the importance of identifying phishing emails.</li>
<li>P1061: I don't think participating would be harmful or beneficial to the participants.</li>
<li>P1062: The grounds of this study is deceptive and I'd want people I care about to have no part in it.</li>
<li>P1063: People may think that their friends are trying to scam them</li>
<li>P1069: Very good idea for a survey.</li>
<li>P1071: I think this is okay as long as they are notified about it afterwards, and the information that is being phished is not too private or personal.</li>
<li>P1076: Sure, why not?</li>
<li>P1083: Because they would learn their lesson and be careful from then on.</li>
<li>P1089: I feel this study and the results of the study could be dangerous.</li>
<li>P1090: people are already really likely to fall for this crap, i feel like this just reinforces their dumb behavior.  LOL IT'S OKAY IT'S PROBABLY A STUDY OR SOMETHING, I CAN CLICK ANYTHING</li>
<li>P1097: Phishing is never right, even when it is a harmless experiment</li>
<li>P1109: Most of the situations can already be avoided with common sense, such as if some link seems out of the ordinary with what a friend posts.</li>
<li>P1110: This seems to be an extremely invasive study. </li>
<li>P1112: I do not like the idea of creating a bogus phishing email to see if it works.</li>
<li>P1116: I wouldn't want them to be hurt.</li>
<li>P1119: I would want them to participate in this experiment, because they become aware of how easy it is for an unsuspected individual to be phished of critical data and learn how to prevent falling for it again.</li>
<li>P1120: Because the researchers will notify students that this was a research study.</li>
<li>P1123: I would want as many of the people I care for be aware of these phishing schemes and recognize perhaps when they may occur. </li>
<li>P1130: This would be interesting to see and hear about.</li>
<li>P1131: I would be interested in knowing whether I would fall victim to phishing</li>
<li>P1140: I am not entirely sure if a person I cared about would like to be in this experiment.</li>
<li>P1157: This amounts to victimization of participants without their consent or awareness.  That is unethical and should be illegal.  The university's complicity in this fraudulent project is horrendous.  What if the researchers are actually seeking to victimize the university by gaining access to password files?</li>
<li>P1158: This use of Facebook is inappropriate. </li>
<li>P1162: nobody will be harmed and it is a worthwhile experiment</li>
<li>P1163: Huge violation of privacy. </li>
<li>P1165: I don't think a university web site should ever be used.  Getting someone's personal information in pretense is not cool.</li>
<li>P1168: I would want them to be aware of this danger and to be cautious when they receive such emails</li>
<li>P1173: This study could make people be more aware of phishing. It could make people be more careful in following links. </li>
<li>P1174: its not right</li>
<li>P1176: I'm not sure that this mimics actual phishing attacks</li>
<li>P1178: I think it might be a little dangerous to have someone sent emails with the intent to steal their password. You can't really trust anyone on the internet, regardless of their purpose for this experiment.</li>
<li>P1179: I feel there is too much personal information revealed here. </li>
<li>P1180: It depends on the laws governing university research of unknowing students and if, when students register with the school are they informed that they may be used as research participants without their knowledge? Only if students are clearly told that they may be involved in university research experiments while attending university, then definitely I would not want anyone I know to be included. </li>
<li>P1181: Yes. As there is no actual harm being done.</li>
<li>P1183: Seems to violate privacy rights (such as using Facebook friends)</li>
<li>P1186: Too much personal information accessed. </li>
<li>P1187: Learn a valuable lesson.</li>
<li>P1191: To understand how trusting we can be and how vulnerable anyone on the internet is.</li>
<li>P1192: Either I'm not understaning it or at least to me it doesn't appear to be anything gained that could result in phishing less.</li>
<li>P1195: I say yes only if this is the only way to collect data for this type of study but I am hesitant and think that researchers should explore another way if possible.</li>
<li>P1196: - Impersonating friends causes potential problem between the individual and these friends.\r\n- The researchers are asking to actually use the passwords they get and want access to the university's password verification system.  There is too much risk with this study.</li>
<li>P1199: it can help us all be aware about these types of emails.  especially the younger students.</li>
<li>P1200: I would hope they would not enter their password, but if they did, it would be better to learn not to do so in a study. </li>
<li>P1203: If the user falls for the tricks, it's their own fault.</li>
<li>P1209: I'd rather not have someone I care about possibly divulge their password online. </li>
<li>P1211: Nope. There is a lot of confidential information located on school databases that are student protected. Compromising that information is unwise. Plus, almost EVERY school has some type of campaign wherein they stress not sharing passwords-- why would the university sponsor this type of study. </li>
<li>P1216: The people being experimented on did not agree to participate in an experiment.  I find that unacceptable.</li>
<li>P1217: This seems like something that could make someone more aware and cautious about phishing</li>
<li>P1218: Sounds dishonest.</li>
<li>P1220: It should not be permitted because it is still an invasion of privacy and also puts peoples security at risk. If the experiment is to happen, the participants should be informed about the test first.</li>
<li>P1227: AS long as there is no real danger to the person, I wouldn't mind. </li>
<li>P1230: I don't like that there is no choice on whether to participate.</li>
<li>P1233: It is better for someone to learn about the dangers of phishing through a study than to experience in the real world. Perhaps the users will be taught a lesson!</li>
<li>P1235: This is for the greater good, we need to know these statistics.</li>
<li>P1238: doesn't hurt anyone</li>
<li>P1239: It feels like an invasion of privacy, the people are being "tricked" into being a part of research.</li>
<li>P1242: I would allow some of my friends to participate because they are very careless with information, and it would benefit them to have a real scare like this happen.</li>
<li>P1247: I don't feel it's important to understand how often users fall victim to phishing, so I would not want someone I knew to be used in this manner.</li>
<li>P1248: I have mixed feelings. On one hand, I would trust the study if it was sanctioned by the university.  a lot of the students may receive phishing emails anyways. This could be a teaching moment as well as an experiment.</li>
<li>P1253: The combination of a phishing attack with checking using the University computer system to check passwords is allowing the researchers too deep an access into the students life.</li>
<li>P1260: I just wouldn't want someone I cared about to be involved in a phishing scheme. </li>
<li>P1261: As long as their information is kept save i would have no real problem if they participated or not. </li>
<li>P1262: So that they would be informed on how dangerous and real the threat is.</li>
<li>P1264: Although the topic being studied is important, I don't believe carrying out the experiment in this manner would reinforce a positive relationship between students and their university. Academic establishments should protect their students from illegal activity-- 'scientific' or not. Otherwise, this is a serious breach of trust.</li>
<li>P1265: Too much deception is involved in this study and I would feel bad for any friends that took part in it.</li>
<li>P1266: This is too open to attack.  And it would also open up the student's real passwords for others. The college should not even have that information in an aggregate form.</li>
<li>P1269: This is a valuable security research project.</li>
<li>P1270: people will be victims with or without this data it seems not trustworthy</li>
<li>P1272: If they wanted to try this they can try it out on their own friends, not mine.</li>
<li>P1273: It is their choice to make if they'd like to participate or not.</li>
<li>P1274: This might teach them a lesson.</li>
<li>P1278: I wouldn't want to make them feel bad by being tricked.</li>
<li>P1283: Researchers had to look at Facebook profiles and are violating trust of participants.</li>
<li>P1286: It sounds like it could help the experiment and the person I cared about would not have their information stolen.</li>
<li>P1288: It may teach some people to be more cautious about where they go and to whom they give a password.</li>
<li>P1289: Participants will ultimately benefit from the research and won't be harmed</li>
<li>P1295: It sounds valid and controlled.  It's remaining within the confines of the University system and not collecting data that isn't readily available to the University already.</li>
<li>P1296: They would need to learn, in a safe environment, web safety, as a lot of people don't know the basic rules of web safety.</li>
<li>P1299: I think just asking people would suffice</li>
<li>P1300: It might help them realize how common phishing schemes are.</li>
<li>P1301: It's a good real world experiment, and if it's not malicious it may have educational merit. Although I think the students should be made aware of it afterwards, to teach them to think that we are not as smart as we may think we are.</li>
<li>P1302: There is valuable information and private information being shared. Such as passwords. </li>
<li>P1310: I think it may educate the person I cared about on how to avoid such scams in the future.</li>
<li>P1311: I still feel like it is an invasion of privacy, but less invasive since it will be done through the university's website.</li>
<li>P1316: This seems like too much entry into personal information.</li>
<li>P1319: I think this experiment carries a low risk to cause damage to anyone, and would serve as a good way to educate students that would fall for the attack.</li>
<li>P1327: I don't want anybody I know to have to be a victim of phishing. I guess if they went through an experiment it might make them more cautious in the future.</li>
<li>P1328: It doesn't seem uncontrollable, aLTHOUGHT STILL UNFAIR</li>
<li>P1330: This experiment could help people learn to not fall for phishing scams.</li>
<li>P1331: I don't see how this can harm anyone and it may teach us something.</li>
<li>P1332: I am leaning towards yes, since it seems mostly safe.</li>
<li>P1338: It all depends on how comfortable those candidates feel.</li>
<li>P1340: No I don't want someone I care about getting mad after clicking on a fake website.</li>
<li>P1343: The experiment is explained and the subjects are given a chance to opt out. </li>
<li>P1346: I think that ir would be a very helpful and interesting experiment.</li>
<li>P1350: Oh yes, it can teach us about the danger we face every time when typing our password...</li>
<li>P1351: I don't understand the point of it.</li>
<li>P1356: I wouldn't want to participate nor would I want someone I care about to participate</li>
<li>P1357: Don't like the idea of passwords being used for this study</li>
<li>P1360: Yes, I think it's important that the researchers make a determination about phishing attacks and how they can be stopped or reduced.</li>
<li>P1363: I don't want independent people from the University being able to see someone's password</li>
<li>P1373: If they are dumb enough to fall for a phishing scam, I'd want them to be more aware.</li>
<li>P1374: I think that someone would benefit from being better aware of phishing scams.</li>
<li>P1386: If someone I cared about were in this experiment, they would freak out at first, and be very upset because these cyber attacks are very scary and dangerous.</li>
<li>P1395: I do not believe looking deeper into the interpersonal relationships of participants on Facebook is ethical information seeking.</li>
<li>P1400: It seems harmless.</li>
<li>P1404: Heightened awareness is always good</li>
<li>P1406: I trust the people I know to decide for themselves which links they want to click.</li>
<li>P1410: I'm cancelling my Facebook account.  By the way, don't you have better things to do?  Try manufacturing, the country could really use more of that.</li>
<li>P1419: After the participant become aware of the purpose of this research I would say that they would appreciate being part of trying to find a solution for future protection against phishing attacks.  </li>
<li>P1420: Much too risky.</li>
<li>P1421: It might cause the person to have some trust issues and I wouldn't want them to start second-guessing everything they were sent.</li>
<li>P1427: As long as the student change their passwords after the experiment there is a little risk. </li>
<li>P1432: It seems harmless to me</li>
<li>P1438: I don't believe in the purpose of this study.</li>
<li>P1443: Individual decision</li>
<li>P1446: Maybe teach them to be careful.</li>
<li>P1452: Different preferences and can't decide</li>
<li>P1456: Again the study is not really needed as due to actual cases being known it would be rather redundant?, Wouldn't a better study be to try and test or promote higher intelligence and awareness among-st the general population as the usual victims are mostly the "Lazy and Ignorant" segments of the Population!.....</li>
<li>P1465: Does not seem to have any risk towards the participant.</li>
<li>P1470: I do like that the students would have the opportunity to have their data excluded and give comments.  </li>
<li>P1472: Another security issue the public should be educated on</li>
<li>P1485: Good way to help people who dont know about phishing</li>
<li>P1486: I think it seems relatively safe</li>
<li>P1487: Password security would be compromised.</li>
<li>P1488: because they will be able to understand spamming and phishing at the end of the study</li>
<li>P1489: Everyone should know about phishing.  Some people just don't pay attention what comes in their email.</li>
<li>P1492: I don't think its right to trick someone into being part of an experiment even if the results may be helpful. </li>
<li>P1497: This sounds like a really interesting study to me, but I could see reasons why someone wouldn't want to be included. I would personally do it, but I can easily see why someone would be uncomfortable...It should be up to the individual.</li>
<li>P1503: They wouldn't be harmed, and may become more cautious</li>
<li>P1507: This involves actually revealing one's password thus poses a risk.</li>
<li>P1508: it seems too risky</li>
<li>P1510: Since this involves real passwords that are being stored, no, I would not.  There would be too much potential for abuse and overlap with other passwords the user is currently using.  </li>
<li>P1513: This is too risky in my opinion.</li>
<li>P1514: i really think its their own buisness,so i think they should decide despite my opinions.</li>
<li>P1517: Yes, this experiment would teach someone I cared about a valuable lesson about phishing scams so that they would not become victim to one again.</li>
<li>P1519: I think the benefits outweigh the risks in this case. Phishing is a very real issue and can cause lots of damage.  </li>
<li>P1522: I think this could really benefit people and make them more aware of this happening.</li>
<li>P1523: The last thing I need is for any of my student friends calling me at the IT desk about a  phishing attack, This is a breach of privacy</li>
<li>P1524: Again, there is no real risk posed, so I wouldn't mind if someone I cared about were involved.</li>
<li>P1526: Seems dishonest.</li>
<li>P1528: Good learning experience.</li>
<li>P1538: I would not want to participate in the study because I don't feel comfortable allowing researchers that type of access to my account. If a friend of mine were a candidate I would likely tell them my concerns but it would not matter to me if they wanted to participate.</li>
<li>P1540: I don't believe that they should lead them to phishing sites.</li>
<li>P1542: Going through a person's social media contacts and impersonating someone is wrong.</li>
<li>P1543: I don't know that I would trust the experimenters.  I wouldn't mind if it were for a site for something that couldn't cause harm, but I'm not sure what that would be.</li>
<li>P1546: It will help people learn about security flaws that they may be processing.</li>
<li>P1552: their choice not mine</li>
<li>P1553: I believe this becomes an invasion of privacy.</li>
<li>P1554: seems useful</li>
<li>P1558: There is too much risk of privacy loss with the current design of this study, and the actions described herein appear to be illegal.</li>
<li>P1563: No one should know your password, and the school doesn't have authority to help acknowledge studends passwords.</li>
<li>P1572: There seems to be no damage done since it is anonymous and the person can have their results excluded.</li>
<li>P1580: I don't like the idea of collectiong personal data.</li>
<li>P1582: I think younger people need to realize the harms that can come on a computer.  Maybe this would help them be more careful.</li>
<li>P1583: I think that, because it is a study that intends only to collect data and not to actually infiltrate the accounts of the university students, participation will be safe.</li>
<li>P1593: Again, it's a lesson learned</li>
<li>P1597: Permission was not obtained. This is a direct violation of privacy, albeit a minor one.</li>
<li>P1598: I believe everyone needed to take more care on the internet.</li>
<li>P1604: I think everyone should be made aware of just how easy it is for someone to get their information on the internet.</li>
<li>P1612: too much manipulation on the part of the researchers</li>
<li>P1617: i don't really care one way or the other.</li>
<li>P1620: I wouldn't want them possibly seeing my friends password</li>
<li>P1629: It violates the participant's privacy</li>
<li>P1633: Again the researchers seem to have the situation under control. I wouldn't fear for someone involved.</li>
<li>P1634: Could prevent or slow future attacks</li>
<li>P1643: I would just not want someone I cared about to deal with the hassle of going through this deceitful experiment. </li>
<li>P1650: I do not want anyone I care about to be involved in a phishing operation</li>
<li>P1651: This one involves to much actual personal info researched to even get it started, with facebook stalking, pretending to be someones else, etc.  </li>
<li>P1655: While i believe this study is good, it also invades those involved privacy.</li>
<li>P1658: On one hand, the participant would learn a valuable lesson from the experiment but, on the other hand, passwords are very protected and could cause the person to be upset about the status of their password.</li>
<li>P1662: Phishing is very much prevalent in today's technologically advanced society. I would want to help protect anybody's information if I could.</li>
<li>P1671: I do not believe the researchers should have access to passwords, it goes against security ethics.</li>
<li>P1673: It's not my problem.</li>
<li>P1674: The experiment seems to push beyond ethical boundaries, and is ripe for exploitation</li>
<li>P1680: They don't violate the ethics law, so it's up to the person if they wish to participate or not.</li>
<li>P1682: Again not without testing permission.</li>
<li>P1686: It would help keep their email more secure</li>
<li>P1696: I know many people that would say "but it has (company)'s logo.</li>
<li>P1701: It is a good experiement</li>
<li>P1704: Too much deception to gather very sensitive material... could also cause people to stop trusting friends</li>
<li>P1705: advancing protection against those people out there wishing to steal from us is a worthy cause but dupping the unknowing seems wrong</li>
<li>P1708: I would feel a bit better about them participating if there's a fake site involved. </li>
<li>P1709: I feel like this is a breach of the candidates personal information and the study should not be carried on.</li>
<li>P1721: This could possible cause emotional side effects.</li>
<li>P1724: I think it is too dangerous for a security breach</li>
<li>P1725: As long as participants are notified afterwards there is no harm provided any personal information remains private to the individual student.</li>
<li>P1733: While I think this is important research and would be beneficial I would not want my loved one giving out their personal information.  Who is to say you don't have a corrupt researcher?</li>
<li>P1738: I think this experiment would also provide valuable lessons to people about how phishing works and how easy it is to get tricked.</li>
<li>P1740: If the person were to be notified about being a participant I would so it could help them avoid such attacks in the future.</li>
<li>P1744: I wouldn't want someone to be tricked in giving real password</li>
<li>P1745: It might be interesting to see the experiment</li>
<li>P1746: I think people need to be scared into realizing that phishing is a very real threat. People need to know that giving their password can be potentially harmful.</li>
<li>P1748: To help them understand the potential risks of phishing.</li>
<li>P1751: It's only a study-- they won't actually be harmed.</li>
<li>P1752: its potentially harmful</li>
<li>P1753: they arent actually harming or hiding anything from the students instead they may learn from the experience </li>
<li>P1758: This seems like an invasion of privacy (recording passwords and also getting access to passwords from the school). Also looking at facebook to find friends and then using the friends name to trick the person into opening the email is not good. </li>
<li>P1763: Too much of an invasion of privacy (finding friends, verifying passwords, etc.)</li>
<li>P1770: Seems sneaky and not fair</li>
<li>P1771: Too intrusive. People seem to fall for these phishing schemes no matter what.</li>
<li>P1773: I feel that this goes to far.</li>
<li>P1774: I think once again, I am having trouble with the participants giving up their passwords. I also think it is a problem that the study requires impersonating a university email address and looking up personal information from the student's Facebook profile.</li>
<li>P1775: Again I feel this is an invasion of privacy. I think it would undermine their trust in the university. It certainly makes me wonder kind of university would ever give out student passwords. That is just wrong.</li>
<li>P1777: While I would want to help the research and would care about the online security of this person, I would not want to infringe upon their privacy. </li>
<li>P1783: I think their personal information would be exposed, even if it was a controlled experiment.  You would still be recording their password.</li>
<li>P1785: No real harm will come from this</li>
<li>P1786: The experiment takes way too much personal information and invades on the privacy of the participant in more ways than one. The experiment would also be taking their real passwords, which means everyone in the study would need to change their password. I have a feeling everyone involved, once they found out the truth behind the study, would be really angry. </li>
<li>P1788: I would be concerned that the wrong people would get my password</li>
<li>P1795: I would like a close friend to learn to recognize these kind of attacks.</li>
<li>P1800: I wouldn't want their password information revealed</li>
<li>P1806: It's not going to hurt them and there can be a positive outcome form it. </li>
<li>P1825: If they are too trusting with emails, they will learn to be more conscious</li>
<li>P1827: Students are made aware of the study and it will help prevent further attacks.</li>
<li>P1829: Since they disclose the study it would be fine. </li>
<li>P1833: It wouldnt hurt them</li>
<li>P1835: It won't really do them any harm and will educate them about phishing, so I wouldn't have much concern either way</li>
<li>P1837: The risk is too unpredictable</li>
<li>P1839: I would not want one of my friends to feel tricked by this experiment although the research is vital.</li>
<li>P1848: Yes because they need to be more informed about phishing and experience first hand how vulnerable they can be.</li>
<li>P1850: Faking a friend email is to personal</li>
<li>P1853: Anonymity is important, and the lack of a real threat. </li>
<li>P1857: This experiment feels like a large invasion of privacy. I don't like the idea of the researchers "creeping" the participants Facebook pages for information, then pretending to be a friend and sending out a fake email. It doesn't sound very ethical. I can't believe the university would agree to this. </li>
<li>P1864: I think its a great way to be exposed to this type of attack without being harmed.</li>
<li>P1865: I don't like that the students do not know they are part of a study, until after the emails have been sent.</li>
<li>P1870: The researchers have access to the student's passwords without the student's consent.</li>
<li>P1871: People need to learn about what threats exist out on the interwebs</li>
<li>P1873: It would be really hard to trust every person involved in the experiment.  Some people might have access to sensitive information and password.</li>
<li>P1876: If they do not use the personal information then it should be ok.</li>
<li>P1877: Bringing in personal information about the participant feels over the line. If it was "someone I cared about," *I* could even be used to try to trick them.</li>
<li>P1878: since they won't be identified there really is no risk, and perhaps they might learn a bit about online security</li>
<li>P1884: They don't need that kind of stress in their lives thinking their account has been hacked. </li>
<li>P1889: This sounds incredibly envasive, and prying in on someone's privacy.</li>
<li>P1890: The password that would be obtained by the researchers from the students might leak out and used against the students.</li>
<li>P1892: I think its an invasion of their privacy and freedom of choice.</li>
<li>P1893: Many people use their passwords for multiple websites. No one else should know their passwords, not even researchers.</li>
<li>P1896: This experiment seems less risky than the first one presented, but it still seems like there is a potential for some subjects to be harmed through the research.</li>
<li>P1897: This is good way for phishing to be tracked.</li>
<li>P1901: I think we need to better understand these online issues, so if they wanted to be included I would be for it.</li>
<li>P1904: Phishing is a major problem which needs to be investigated.</li>
<li>P1906: I think most of my friends are unaware of phishing and maybe they would pay better attention if it happened to them.</li>
<li>P1913: It is non-harmful</li>
<li>P1916: Too sensitive and could cause tension in the family</li>
<li>P1917: I do not see the harm in this type of experiment. It would actually be helpful to them to learn about the dangers of phishing. </li>
<li>P1930: Doesnt affect me personally</li>
<li>P1934: It doesn't seem as though the students are made aware of their participation. </li>
<li>P1936: As long as the person was notified that they were part of the study, the passwords were not used to gain access to the users' accounts and they were sent recommendations to change the password for the account affected.  This is a great opportunity for many users to learn about online safety.</li>
<li>P1938: I'm not sure, really.</li>
<li>P1942: Many people use the same password for multiple websites. This could be disastrous if leaked.</li>
<li>P1945: To show that you should always be careful when visiting websites, even highly reputable ones.</li>
<li>P1951: I think it would be a good idea to teach someone how phishing works and maybe they would be more cautious in the future.</li>
<li>P1953: I think this research would be valuable and could help prevent future phishing attacks and intrusions, so I would want the person to be involved.  There appear to be no risks involved in the research, so I would encourage everyone to take part in it.</li>
<li>P1955: No. I wouldn't want any of my loved ones personal information at risk to this research.</li>
<li>P1956: I would like them to participate to see if they are susceptible to phishing and if so better protect themselves in the future.</li>
<li>P1960: It does not seem like any real harm would come to any body.</li>
<li>P1963: I think that the harm from this is minimal but still very deceitful. I would be ok if they were included.</li>
<li>P1970: It's an obvious conclusion that someone would more likely act on a recommendation by someone they trust and know then someone they don't.  It's a pointless experiment.</li>
<li>P1971: There is a possibility that they will enter their real password and have it compromised.</li>
<li>P1977: It's deceitful.</li>
<li>P1978: This violates a thousand laws and is not an ethical study!</li>
<li>P1979: I think others should decide for themselves as to whether or not to participate</li>
<li>P1982: I would not want a friend of mine to participate in something that seemed to be set on a fraudulent basis.</li>
<li>P1989: I think computer security is an extremely important concept in today's world.</li>
<li>P1991: As long as the passwords were properly controlled and disposed of, and if the university is monitoring the researchers, I think the experiment is okay. </li>
<li>P1998: This one is a bit more grey. While I can't discern how precisely anyone would be harmed by this, it feels wrong, and seems unethical. Therefore, I would want to protect people I care about from such a thing.</li>
<li>P2002: I would want them to help the study, but I wouldn't want their password given out.</li>
<li>P2003: It could be a valuable learning experience for them. Never give out your passwords.</li>
<li>P2004: Same as the spam one, it would be annoying.</li>
<li>P2006: Absolutely not. This study would be completely unethical. You have access to the student's personal information without their knowledge. And if you obtained consent well then your study wouldn't illicit any useful information since the students are aware that they will be sent a phishing email. </li>
<li>P2016: Theyre still giving out there real pw.</li>
<li>P2025: People are aware of this practice. </li>
<li>P2026: There really isn't a threat in this situation, but it could cause some anxious feelings, so it would be up to the loved one to decide.</li>
<li>P2027: i think its good to do this, helps people learn about the phishing problem and it seems harmless</li>
<li>P2029: I am a bit confused about the participation. </li>
<li>P2032: Its fine as long as it is the property of the university and no harm comes to study participants.</li>
<li>P2034: If it prevents phishing scams in the future why not </li>
<li>P2036: the risk seems minimal to non-existent </li>
<li>P2037: Yes because I would want to see who would fall for it</li>
<li>P2039: help with cutting out phishing emails</li>
<li>P2040: I wouldn't mind if they were included or if they weren't included.</li>
<li>P2044: it will make the person more aware of what phishing is and how to avoid being scammed in the future</li>
<li>P2046: Using hypothetical stuff is one thing. Using people's actual stuff is another.</li>
<li>P2048: It violates their privacy.</li>
<li>P2053: I think it would be a useful learning tool.</li>
<li>P2060: I would think this would be  a good thing as long as the explanation came with a warning of what not to do.</li>
<li>P2061: this is the most recent way of getting your private info so it should be stop</li>
<li>P2063: How could they be sure their information would remain confidential and not be used for some other purpose?</li>
<li>P2067: Their password would be exposed and verified. I don't think that's safe for them</li>
<li>P2072: Would not want their password compromised. </li>
<li>P2074: Phishing, whether for a scientific purpose or not, is a violation of privacy.</li>
<li>P2082: I just wouldn't want to put the time into it for free.</li>
<li>P2083: It is too much of an invasion of privacy on several levels.</li>
<li>P2089: It might make them more aware and allow them to be more careful on the internet.</li>
<li>P2094: I want those I care about to be safe online. Being a part of this research would reveal whether or not they knew how to recognize a phisher, and if they were previously unaware, they would be made aware and thus protected from future assaults. The risk of being a participant appears minimal, so long as the researchers didn't use the login/password info they gained from gullible participants to alter the students' information/acocunts.</li>
<li>P2100: They should not be able to involuntarily obtain passwords.</li>
<li>P2114: I don't feel there's any legitimate risk to anyone here.</li>
<li>P2117: Using their Facebook or other social media to find out who their friends are, and then sending bogus e-mails from their friends is violating privacy, and is deceptive. This is just unethical. Unless they signed up as a participant and had given some form of consent for researchers to go snooping through social media and personal information, this is unethical.  </li>
<li>P2119: I don't like how much this would encroach upon privacy of the participants.</li>
<li>P2121: I want someone I care about to see that they're being careless.</li>
<li>P2123: they are being told they were part of an experiment and are being told recommendations on how to learn to recognize such attacks</li>
<li>P2125: Some lessons have to be learned the hard way.</li>
<li>P2126: I think no person would appreciate being in this type of experiment as they might be embarrassed if they fell for a phishing e-mailand ended up providing their passwords</li>
<li>P2131: Not ok with hacking into personal information without consent upfront</li>
<li>P2132: I've seen this stuff before in personal e-mails.</li>
<li>P2135: Sounds suspicious, and too risky.</li>
<li>P2137: i wud like to inform about such kind of research</li>
<li>P2148: Yes, because they are doing important research.  The only thing I would do differently is I would not verify if the information is correct.  That's the students personal information.  Just that they would submit something would be proof enough that the scam worked.  I do understand that students may put in incorrect info to throw the 'scammer' off but that is something that can be explained in the discussion.</li>
<li>P2155: I do not want anyone I care about to become paranoid about phishing attacks.</li>
<li>P2156: I would use it to show them they should not trust every email they recieve and how easy it is to be victimized. </li>
<li>P2159: It teaches a valuable lesson about internet security safety. </li>
<li>P2172: It would make them more aware of phishing scams.</li>
<li>P2175: I can't believe anyone would think this is a good idea.</li>
<li>P2177: This would be based on the individual selected.  Some people would be more comfortable than others with this.</li>
<li>P2183: If I was sent a phishing email from a friend, I would immediately contact them after I discovered it.  My friend would probably worry/delete their email account.</li>
<li>P2188: I wouldn't want them spammed either</li>
<li>P2189: It would be good for them and others to participate and see how vulnerable they are.</li>
<li>P2193: I want to see how he would trust a friend like me in that situation.</li>
<li>P2194: If the goal is to stop phishing then yes for any other reason I would say no to it.</li>
<li>P2204: I wouldn't like their info being used without them knowing. </li>
<li>P2205: The first experiment was o.k. However, after reading the second experiment I have doubts as to whether or not this is ethical</li>
<li>P2208: I don't like the idea of anyone taking personal information from someone i cared about.</li>
<li>P2212: I personally feel that the participant's rights would be violated</li>
<li>P2213: I feel like it's wrong to deceive people about having them participate in an experiment. If you feel like people will not participate in an experiment, then maybe it's not right.</li>
<li>P2216: The university has access to most of the students information anyways</li>
<li>P2218: I would consider this a violation of trust on my friend, by staff members, to students of their own college professors. I would be very angry.</li>
<li>P2219: This seems very intrusive and deceptive; I wouldn't want that for any loved one. </li>
<li>P2227: It is not right to invade people's privacy against their will -- even if you have only scientific intentions. </li>
<li>P2233: I don't think there is any harm as long as passwords are not released. Also they could use the information.</li>
<li>P2234: I think younger people are more vulnerable to a phishing attack like this.  They have more friends and are not as cautious as older people.</li>
<li>P2237: I would like them to contact people beforehand instead of doing the experiment secretly.</li>
<li>P2238: Doesn't sound safe.</li>
<li>P2244: It is important that information such as this is provided. I also think that especially with college students they need to be aware as they are beginning their lives and careers are can be quite susceptible to such an attack especially through what looks like their bank offering credit cards and other information.  </li>
<li>P2245: It's a breach of privacy.</li>
<li>P2247: I take internet security very seriously, and even though this experiment is just a simulation of a phishing, you can never be sure what could happen to the data collected. </li>
<li>P2250: this could teach a lesson about phishing scams. </li>
<li>P2253: I think it would be good for someone to know if they are being careful enough online.</li>
<li>P2254: this is a big problem in internet use and needs to be researched and addressed</li>
<li>P2260: There is too much risk</li>
<li>P2261: I would want them to learn a lesson, i'm always trying to tell people to watch out for this stuff.</li>
<li>P2273: IF the researchers are  really on the up and up  I think it is  a good idea.  We need to  get to the  young people to be  careful  about  where they go and what  they do online.  IT would be a  good  lesson for  young and old.</li>
<li>P2276: I want everyone close to me to be able to recognize and ignore these sorts of messages.</li>
<li>P2280: Phishing, regardless of the context, is  a malicious act</li>
<li>P2281: I would not want my friend to give their time to an experiment without being told so ahead of time.</li>
<li>P2284: Seems like it puts people in a dangerous position.  The data could be compromised.</li>
<li>P2285: I can't say yes or no. I don't see this experiment providing useful info</li>
<li>P2286: yes it poses minimal risk and it is about a subject (phishing) that has become a fairly large problem over the last few years. </li>
<li>P2289: It wouldn't matter to me.</li>
<li>P2291: it's up to them</li>
<li>P2302: I am uncomfortable knowing that the researchers would have access to the person's password.</li>
<li>P2307: Potential misuse is too high.</li>
<li>P2308: It's a good way to inform people in a secure environment. </li>
<li>P2309: It is unethical to include people in a study who have not given their consent that they wish to participate.</li>
<li>P2314: There is not a security risk so it would be okay</li>
<li>P2315: It may save them from an actual phishing scam later in life.</li>
<li>P2316: Yes, so they could watch out for suspicious Html coded URL's, they may not be authentic, so I would  tell them go to the actual business.com page. </li>
<li>P2323: It is important to know about this so they can avoid being phished.</li>
<li>P2324: Yes - It sounds like a thing worth studying since it's such a big issues these days</li>
<li>P2326: Again, it does not hurt the person I care for so I have no preference.</li>
<li>P2328: I do not like the principal on testing people without their consent.</li>
<li>P2340: I think that people are already aware of phishing techniques. Yet they continue to fall for them. </li>
<li>P2348: It wouldn't be of my interest</li>
<li>P2349: I would be worried about vital personal information getting out.</li>
<li>P2350: The experiment sounds legit and offers the participants to exclude their data if they want. It also lets all of the students know that this was part of a research experiment.</li>
<li>P2351: It seems wrong to impersonate someones friend to collect data for an experiment.</li>
<li>P2354: This could affect my friend adversely and cause future psychological harm.</li>
<li>P2357: That's creepy and goes too far into the person's private life.</li>
<li>P2368: It's their choice.</li>
<li>P2370: my cared ones do not have enough knowledge of spam and the internet for them to be comfortable with such an expirement.</li>
<li>P2372: This undermines the credibility of Institutions that should be trusted.</li>
<li>P2378: I think the information the study is looking for would be beneficial and I see no harm in it.</li>
<li>P2382: There is validation of whether or not collected passwords from students/participants is correct. This can compromise their personal information.</li>
<li>P2386: I don't believe in any experiments that involve divulging your password.</li>
<li>P2390: The way the research was explained seemed like an invasion of privacy.</li>
<li>P2392: If they click on the link, it's voluntary, and it never hurt them or made them scared, and caused them no detriment, as the researchers would tell them immediately that they fell victim to fake phishing.</li>
<li>P2396: This could possibly harm the relationship between the student and the person the scientist pretends to be.</li>
<li>P2397: Again, I believe this is another vital experiment.</li>
<li>P2398: It will be helpful.</li>
<li>P2401: If this study would help find ways to prevent phishing from occurring then I think that my friends would want to help with this.  </li>
<li>P2403: I would be concerned that the password would fall into the wrong hands</li>
<li>P2406: I don't think it would either harm or help them.</li>
<li>P2408: This seems very aggressive, and the delay in debriefing seems too long. </li>
<li>P2409: The students have the option to have their data excluded.</li>
<li>P2425: If this research can stop phishing which is harmful to people who are vulnerable to opening emails that may entice them to reveal their information and then disaster follows.</li>
<li>P2428: I don't see how this information/data could be used for good.</li>
<li>P2433: This is something that happens all the time and many people fall for it.</li>
<li>P2435: This is something that would be very useful for all of us because I know I myself have gotten 'emails from friends' which turn out to not be from them after all. Luckily I haven't clicked on the link knowing that it is false but I know a lot of others who have done this and wind up with a virus on their computer.</li>
<li>P2437: So they become more aware.</li>
<li>P2445: If it helps contribute to computer security, then I don't see why not.</li>
<li>P2449: the way this is performed could case stress on the participant. effecting someones mood or life is not ok with out their consent</li>
<li>P2450:  Like i said before it would help everyone out.So people will know what to watch out for.</li>
<li>P2451: The research is valuable</li>
<li>P2453: It would be up to the indevidual.</li>
<li>P2456: It feels very shady.</li>
<li>P2457: violates privacy</li>
<li>P2463: At first i thought it would be a bad idea. But i rather have people i care about learn a lesson this way instead of a real phishing attack.</li>
<li>P2466: You shouldn't take people's information without asking. There is also deception. There have to be other ways of studying these things ethically.</li>
<li>P2473: Once again may help the greater good</li>
<li>P2475: I don't want my password to go to anyone, so I wouldn't want that for a friend.</li>
<li>P2480: This will help more people tans no one is harmed</li>
<li>P2488: This experiment makes me feel uneasy - receiving e-mails from "friends," the researchers' perusing personal Facebook profiles, etc.  I would not feel comfortable with anyone participating in this research.</li>
<li>P2491: tricking people via fake phishing ( from a "friend") is morally wrong.</li>
<li>P2495: this is VERY important for people to know that this can happen</li>
<li>P2496: I wouldn't want anyone's real password shared with researchers. </li>
<li>P2501: I do not see any risks to this study so I don't see any reason why this person shouldn't participate</li>
<li>P2507: People need to be more aware of this attack.</li>
<li>P2513: Sounds like a devious way to steal information.</li>
<li>P2514: I think this is a good experiment and would cause them no person harm.</li>
<li>P2517: I think the way the study is carried out makes it unethical.</li>
<li>P2522: I would not care if someone I cared about was participating in this experiment as long as they had volunteered to do so.</li>
<li>P2528: People should be educated on this issue. Such an experiment is crucial to Internet security.</li>
<li>P2530: I do not want people I care about to be used as test subjects controlled by researchers I do not trust, and information about these people to be harvested like this. </li>
<li>P2532: Seems like a fishy experiment. </li>
<li>P2533: The researchers need too much information.</li>
<li>P2536: It's up to them</li>
<li>P2539: Yes I think it would be worthwhile and is an academic setting. The password information is for University websites and belongs to students.</li>
<li>P2542: I don't like the idea of people's passwords being bought to light, and am definitely uncomfortable with the idea of the University validating that information. This is sensitive information that should not be shared.</li>
<li>P2543: The participants in this studies are being spied on by the researchers. No one knows how someone might react to the information.</li>
<li>P2546: I believe that by being a participant, you learn the dangers of phishing without the actual repercussion</li>
<li>P2547: I think that this is just a small portion of the phishing problem, so it could get a little bit accomplished, but not much. </li>
<li>P2549: The fake emails made to look like they came from a friend could cause people to become angry with the friend until the researchers reveal it was just a study.</li>
<li>P2551: This is an unethical experiment.</li>
<li>P2555: it's exploitative</li>
<li>P2556: sounds too deceiving</li>
<li>P2560: may make those students more aware of the phishing emails.</li>
<li>P2561: It is too intrusive and may incur damage to one's social circle.</li>
<li>P2563: I don't like experiments where the subject is unaware & has not given consent to be a participant in such an experiment.</li>
<li>P2565: It may cause the person to be too paranoid to use internet services</li>
<li>P2571: What do you have to loose ?</li>
<li>P2572: it does not matter to me what they do</li>
<li>P2574: This would cause unnecessary stress and would be a breach of privacy. </li>
<li>P2575: Way too invasive.</li>
<li>P2576: There would need to be a high level degree of professionalism and confidentiality, but yes, it seems like a good project.</li>
<li>P2578: I think this experiment is an invasion of privacy.</li>
<li>P2579: Websites like this cause many people problems back hacking their information</li>
<li>P2581: I wouldn't want anything attacking my account.</li>
<li>P2588: People need to be informed about phishing attacks.</li>
<li>P2590: It seems dangerous for the researchers to be allowed to verify that the password obtained is valid. I don't trust them. They shouldn't have access to actual passwords.</li>
<li>P2592: It's not harmful to them.</li>
<li>P2595: I think this would be a good experiment because people don't pay enough attention these days and are easy prey...it would definitely tech people how to be more careful.</li>
<li>P2596: passwords should not be in the hands of anyone but the user. No consent to be a part of an experiment = immoral.</li>
<li>P2599: It would educate them to be careful about what links they click on.</li>
<li>P2601: By being included in the experiment, data that they provide can be used to potentially improve security risks/concerns.</li>
<li>P2605: I'm a bit nervous that passwords might not be stored securely enough and would be easily lost or stolen or misused</li>
<li>P2610: Good lord, is there no ethics committee that oversees such unabashedly bad proposals?? </li>
<li>P2612: No... not just no but HE** no! I believe this is unethical. Not just because it exposes students to actual phishing... yes that is what the researches would be doing.  But also because the internet is not a safe place. Others break into and watch people's on line activity every day.  Even a pretend attempt puts people at unnecessary risk. </li>
<li>P2618: You're dealing with people's real passwords here. And to their bank accounts no less. Bad idea.</li>
<li>P2619: This is completely wrong because the "participants" are not even aware they are being part of a study at all, let alone what the study pertains too. Also the "searching" of the Facebook profile seems a bit off too.</li>
<li>P2623: I do not feel the experiment poses any harm</li>
<li>P2627: seems a little odd to enter personal information</li>
<li>P2638: There's a slight risk, but seems controlled. </li>
<li>P2639: Again with the passwords.</li>
<li>P2644: Most people I know have heard of these attacks and are aware, but I'd still like for the attempt to trick them to be made. </li>
<li>P2650: It is a good lesson on how easily it is to be hacked.</li>
<li>P2654: Their valid passwords would be revealed to researchers.</li>
<li>P2669: No messing with computers</li>
<li>P2674: harmless and beneficial</li>
<li>P2677: because it's unethical </li>
<li>P2686: This seems like a legitimately safe experiment to perform.</li>
<li>P2688: At the very worst, the person in the experiment would learn a valuable lesson.</li>
<li>P2689: This also seems harmless and may help people to protect their data</li>
<li>P2690: so we can be helped with security.</li>
<li>P2691: It doesn't matter who the candidates are as long as the researchers get good results. </li>
<li>P2692: Privacy is a concern when particpating in a "survey".  There is none here,.</li>
<li>P2699: I think it will encourage them to be careful with their passwords</li>
<li>P2713: I know about phishing and hopefully know how to avoid it. I use my computer very cautiously, I hope. I am hoping that I or the person I care about would not participate nor recommend anyone I know to participate.</li>
<li>P2716: This seems as though it would provide a positive educational benefit to the participants.</li>
<li>P2717: It is important for people to know that these things occur on the internet every day. After participating, the person would know no to click on similar links in emails. </li>
<li>P2723: they will know that it was an experiment in the end so it wouldnt bother me at all. </li>
<li>P2727: I feel in general it would raise awareness of phishing schemes and how often people unknowingly fall victim to them.</li>
<li>P2729: I feel that this would be a huge invasion of privacy, on several different levels.</li>
<li>P2732: I believe there are no risks in this experiment. </li>
<li>P2735: The risk is more manageable since this is being done on a university's server and not a real bank.</li>
<li>P2740: His/her password could mistakenly be kept and sent out to thousands of people.</li>
<li>P2743: It might be a good lesson for people who fall prey to phishing scams.</li>
<li>P2747: Some people dont realize how easy it is to get your information over the web by pretending to be someone else.</li>
<li>P2749: I feel it would be better for the person to err in an artificial environment than if it were an actual scammer. Perhaps the individual would learn to make smarter choices.</li>
<li>P2750: thats their decision</li>
<li>P2753: I have friends who do not take caution on the internet and this could prove a good point.</li>
<li>P2757: Their privacy seems to be compromised in this study.</li>
<li>P2758: It may lead to them falling for phishing  attempts that were not part of the experiment inadvertently.</li>
<li>P2768: This seems too deceptive of a study.</li>
<li>P2777: If it's safe and helps with research, why not?</li>
<li>P2781: I would be concerned that this experiment could compromise my friend's privacy. Facebook has been known to violate the privacy of its members. </li>
<li>P2786: I wouldn't want a friend/loved one to fall for a phishing scam, for any reason, even research.</li>
<li>P2792: I would want them to get first hand experience with phishing and either verify they would do the right thing and not fall for it or the would learn a lesson in a safe environment.</li>
<li>P2793: I don't feel anything should be sent to someone without their knowledge.  This is how things get taken out of context and issues occur.</li>
<li>P2795: It seems like a harmless deception. </li>
<li>P2800: Nah, I don't like the idea of them trying to validate an actual password. </li>
<li>P2802: Again not something I would personally participate in and something that I would not encourage friends one way or another on.</li>
<li>P2804: Sure, they shouldn't be dumb.</li>
<li>P2807: I want them to recognize dangers out there.</li>
<li>P2811: I think that it is better to find out about the results of this type of thing in a controlled atmosphere, where you are not really open to the damage that could be caused, but made aware of what can happen. I would tell the person that I cared about to participate not only to help them, but everyone else as well.</li>
<li>P2812: unethical</li>
<li>P2813: This one sounds weird and doesn't even make sense on why you would want to do research on phishing people using their friends account.</li>
<li>P2818: Would like to help prevent this kind of thing</li>
<li>P2819: Because it is up to my friend if they want to participate.</li>
<li>P2821: you can already teach people how to protect themselves from the most frequent phishing types without "gathering" any information. common sense helps but the truth is most just don't pay attention</li>
<li>P2822: I think we should not allow</li>
<li>P2823: I would not want someone I cared about tricked into providing their password to a phishing link sent by a "friend." That would be traumatizing, experiment or not. </li>
<li>P2827: Everyone should know how to distinguish between fraudulent websites and legit websites</li>
<li>P2828: Since I would volunteer I have little hesitation in letting someone I know be included.  This experiment would hopefully as the researchers suggest enable better measures to deal with and eliminate phishing attacks.</li>
<li>P2829: Study or not, I would never want my someone I cared about to give their password or any personal information to a party other than the one that it was supposed to be for.</li>
<li>P2830: I believe this would be harmless to the participant </li>
<li>P2834: I didn't read anything about the researcher getting permission to examine the subjects/student's Facebook account. Seems this would be an invasion of privacy and possibly against the law. Seems also there would be a liability of students passwords getting misused or stolen.</li>
<li>P2837: This study has too much potential for abuse.  In addition, failure to gain informed consent is dangerous for any psychology study.</li>
<li>P2838: There has to be another way to out phishers.  </li>
<li>P2841: It's okay to use Facebook for research</li>
<li>P2844: This one might help keep others from being victim to this kinds of attacks on their personal information and money.</li>
<li>P2848: It would help prevent phishing.</li>
<li>P2850: I have some of the same ethical reservations as previous experiments, the fact that the participants are unknowingly participating, but this one is more controlled than the previous ones.</li>
<li>P2853: Going through facebook and impersonating a friend of a person does not seem reasonable.</li>
<li>P2856: I think someone I know would get upset by this study. And explaining to them how it seemed as if a friend sent it would be agonizing</li>
<li>P2857: Anyone that got caught in the experiment would learn how easy it is to be tricked and become more cautious online - a good lesson for all</li>
<li>P2860: I think this would be okay because the participant is notified about this being a study.  Also, since phishing is such a problem these days, this experiment would be helpful.</li>
<li>P2861: IT WOULD HELP EDUCATE THEM NOT TO DIVULGE CERTAIN INFORMATION</li>
<li>P2865: Phishing is dangerous business.</li>
<li>P2874: This would help further research.</li>
<li>P2879: I don't like giving out information on my friends and I don't like using my friends: online or in the real world.</li>
<li>P2880: Could damage trust in emails and I don't like the University verifying the passwords.</li>
<li>P2882: I don't like that the participants don't seem to know that they are participating.</li>
<li>P2888: This is a tough one, it almost doesn't seem right that they make it appear to be from a friend by using Facebook, but I get why they are doing it, but it is kind of tricky and misleading. </li>
<li>P2892: teach people how easy this is to get caught in</li>
<li>P2893: It would be kind of a waste of time to have to go through unwanted emails.</li>
<li>P2896: I don't want people giving out their information to people like this. </li>
<li>P2905: this seems invasive, involving more than one human, choosing people from fb...all too Orwellian for me</li>
<li>P2910: Again, this is an experiment that is in peoples best interests. Some people may think some of these are "unethical" but if an experiment is done for good reasons, I don't see why people are so worried.</li>
<li>P2920: I don't think it's safe to reveal your passwords, even for a scientific study.</li>
<li>P2923: I think it's safe enough but the results would help phishers be more effective.</li>
<li>P2929: This again is a very deceptive study and I would not want anyone I know to participate in it.</li>
<li>P2930: This one seems a bit deceptive even though the researchers will inform afterwards.</li>
<li>P2934: I would want someone that I love to be protected from these awful scams, so as long as they don't actually get hurt by the experiment, I would like for them to feel the effect of a phisher and see directly how dangerous it is. Especially my mom! She's so naive...</li>
<li>P2941: phishing is not something to be taken lightly and I wouldn't want somebody i know to be exposed to it</li>
<li>P2945: Since this is such a wide spread but not widely known issue it's important that people be made more aware of it. </li>
<li>P2946: It wouldn't matter to me if they were involved or not.</li>
<li>P2947: I do not like how much access the researchers have to both facebook and to the campus passwords.</li>
<li>P2956: The results could help people decipher a phishing scam or not.</li>
<li>P2959: Are you going to trust human beings to not test temptation by trying the passwords elsewhere.  Most people use the same password across multiple sites.</li>
<li>P2964: We should never give out our passwords</li>
<li>P2972: For the purpose of research, I do not see it unethical. However, I feel that the student participants should be chosen depending upon the chosen program. So, say if the the research team is independent of their (participants) cohort (assuming that the researchers are student or instructors) it should be fine.  </li>
<li>P2979: Phishing seems wrong</li>
<li>P3002: I would be concerned that the participant's personal information gathered by the researchers could end up in the wrong hands. For example, this could happen if a third party found out about the study and hacked the researchers' data.</li>
<li>P3003: It could really help!</li>
<li>P3009: I'd consider this as sensitive as the hacking experiment. Passwords are sensitive data so I wouldn't do it.</li>
<li>P3012: Its up to them</li>
<li>P3013: So that the researchers can find out more about phishing.</li>
<li>P3016: no</li>
<li>P3019: password access is very sensitive and should be guarded highly</li>
<li>P3021: Yes because then they would have a safe opportunity to see how easy it is for someone to obtain their info and would then think twice before entering it.</li>
<li>P3028: i have been a victim of this kind of act Phising. where in they got a hold of my email and in my email there was tons of important files connected to my bank.</li>
<li>P3032: Since they will be notified that it was simulating a scam, it could help them become more aware of real scams and be more wary in the future.</li>
<li>P3034: Phishing is an ongoing threat and studying it is important. Phishing is not difficult to spot, so this will help participants learn how to spot such attacks.</li>
<li>P3036: Really don't care either way. See no harm</li>
<li>P3039: This is deceiving.</li>
<li>P3043: It is for a good cause, and as long as the someone were allowed to exclude themselves from the study afterward and their information were not used.</li>
<li>P3045: Would educate them never to give out personal information.</li>
<li>P3046: I think that this sort of study is the wrong kind to pursue.</li>
<li>P3047: This experiment doesn't appear to benefit the participants. </li>
<li>P3061: I don't think this is harmful to the subjects, so I am not opposed to the study being done on myself or someone I know and care about. I don't think it would benefit them directly either. </li>
<li>P3062: I would not want to them to accidentally enter their password to anyone. Even if it's a university experiment, the password is still personal and the person who entered it was still being deceived.</li>
<li>P3063: Most people fall for phishing e-mails.</li>
<li>P3064: I wouldn't want someone I care about having their facebook page examined by researchers.</li>
<li>P3065: students are there to learn not be unwilling/ unknowing research subjects.</li>
<li>P3066: why am i supposed to care whether or not someone I know participates in a study?</li>
<li>P3068: This person may be able to protect themselves better in the future against cyber attack</li>
<li>P3076: the information collected is too risky and this is illegal</li>
<li>P3077: I don't think passwords should be disclosed</li>
<li>P3078: It may teach my friend/family member to be more careful with such information.</li>
<li>P3079: I would not want to subject them to such. </li>
<li>P3084: Ok, again, no harm, but I also see this as a bit of a "lesson" for everyone who clicked on the emails, perhaps it will help them in the future...hmmm, be more careful about what you click, right!</li>
<li>P3086: It would increase the availability of security against phishing scams, and not hurt anyone.</li>
<li>P3090: Again, this invasion of privacy is a ludicrous idea for a study. No way I would allow someone I care about to participate.</li>
<li>P3094: They have no guarantee that the passwords were protected and could not be used maliciously as the study was going on.</li>
<li>P3095: This research will help prevent phishing attacks in the future and is beneficial to society.</li>
<li>P3100: People should not be put in a place where their private information has the potential to be comprimised. </li>
<li>P3103: There are all sorts of ways this could go awry. Subjects are being placed at risk, and there is no way for the researchers to guarantee the security of the data collected.</li>
<li>P3117: I would want the person to learn not to divulge their personal information to anyone online even a close friend.</li>
<li>P3121: you shouldn't mess with some one's passwords</li>
<li>P3123: I want people I care about to be aware of phishing attacks so they can be more cautious in the future.</li>
<li>P3125: This seems unethical.</li>
<li>P3126: While I don't like the idea of someone collecting student passwords as long as they notify them of the project and tell them to change their password I see no problem.</li>
<li>P3130: While I understand the purpose of the study, trolling through someone's Facebook page to glean their "friends" just seems a bit unethical.  It could also threaten the individuals relationships with those friends.</li>
<li>P3132: As long as they are not using the passwords to gain access to the student's information, I think this could actually be beneficial in the long run.  Student's and the public could see just how easy this can happen.</li>
<li>P3136: I don't see any harm at all from this experiment.  There is not an actual bad guy trying to get the passwords and the students will have the opportunity to change them after the experiment if they feel uncomfortable.</li>
<li>P3148: Being a victim myself I would encourage anyone to participate. A few years ago I received an email from PayPal that was not addressed to me personally and gave all my information. What a mess…</li>
<li>P3152: This is illegal regardless of disclosure.</li>
<li>P3159: It would not cause harm.</li>
<li>P3161: Phishing awareness is important.</li>
<li>P3166: This again would help people better adjust their behaviors for a technological world.</li>
<li>P3168: I understand the necessity of studies like this, but I would feel taken advantage of and victimized. It would make me even more wary of entering my information online.</li>
<li>P3177: This study wouldn't hurt them in any way and would be helpful to other people.</li>
<li>P3182: They are taking someone they trust and using them to do their research without telling them</li>
<li>P3183: I feel it is important not to fall for these scams and taking part in it will teach people about it</li>
<li>P3185: The students have the right to exclude their data.</li>
<li>P3193: feels like an invasion of privacy</li>
<li>P3197: It's not safe to have passwords exposed even though it's kept within the university.</li>
<li>P3202: Yes, I think it would be a good experience for anyone to participate, as it is a strong test if one is willing to click unknown sites or provide personal data just because it appears to come from someone they know.</li>
<li>P3208: The person I cared about would feel manipulated and used. Plus his/her password would be potentially compromised by the researchers (and who knows if they are trustworthy).</li>
<li>P3209: This is fraud and shady</li>
<li>P3217: I don't like the idea of the researchers collecting personal information on the person's friends in order to deceive them.  I would prefer if the student knew at least to some degree that they were going to be part of an experiment.</li>
<li>P3223: to much lying involved</li>
<li>P3225: This requires opting in others without their consent, namely using the Facebook friends email.</li>
<li>P3236: I guess it really doesn't matter who does it</li>
<li>P3240: I think phishing is terrible and would do almost anything to stop it. Or learn more on how to combat it or be able to identify it. I don't think it's unethical to go into someone's friend list on Facebook and do phishing research.</li>
<li>P3243: AS long as he/she was advised of this beforehand</li>
<li>P3245: Same as the previous one. It could be a helpful lesson. </li>
<li>P3246: a lot of my friends and family are unaware of these scams. It would open their eyes to what could happen</li>
<li>P3247: Leads to lack of trust</li>
<li>P3258: I have friends that are completely careless about their online security.  I feel this would be a great education for them.</li>
<li>P3260: Because their passwords could be compromised</li>
<li>P3268: I think it's horrible to be trick like that</li>
<li>P3274: it does not matter</li>
<li>P3275: This experiment does not seem to do any harm.  I would not care either way if a friend were part of it.  </li>
<li>P3276: Doesn't seem right that the actual passwords are verified to be correct</li>
<li>P3289: The more knowledge we have, the better. Some of these emails look completely legitimate & it's good to actually let people get a look at them and see how easy it could be to fall for this crime.</li>
<li>P3296: I think it's fine. They are researching a a legitimate event. </li>
<li>P3300: Buying information can be personal </li>
<li>P3301: This is intrusive, by getting information on the students school and their friends.</li>
<li>P3306: By entering a password that can be captured, the researchers now have a password that the subject has used for other accounts.</li>
<li>P3311: My concern is using Facebook profiles to find who the candidates are friends with.  </li>
<li>P3312: Why would this have to be quantified?  The study deceives participants.</li>
<li>P3314: I think it's an important topic to research</li>
<li>P3316: The participants are not given a chance in advance to be either included or excluded from the experiment. </li>
<li>P3319: There is a danger of the information leaking regardless of the intent of the researchers. I wouldn't want them to take the risk. </li>
<li>P3320: Being informed is a big plus on this experiment. If the university approves the study, I think it would be okay to do, as long as the 'victims' are later informed so they can change their passwords, etc. </li>
<li>P3322: This study seems particularly invasive and unkind in its impersonation of friends</li>
<li>P3326: This could have negative affect how people behave in the future.</li>
<li>P3328: I think a password should remain private</li>
<li>P3331: They would suffer no harm from this.</li>
<li>P3333: For one thing the experiment is using someone's identity without permission.</li>
<li>P3334: It seems a little too intrusive and dishonest.</li>
<li>P3338: The university is logging on to their personal information, this is not OK.</li>
<li>P3340: It could be a very valuable lesson.</li>
<li>P3341: I see no risk but no informed consent prior is a problem to me</li>
<li>P3343: It would be nice to know if they could fall victim to this.</li>
<li>P3344: Within the bounds of a university setting this may go well enough, especially since the university has a hold and ownership of the data.</li>
<li>P3347: I feel this is an invasion of privacy. </li>
<li>P3354: It sets them up for future fraud.</li>
<li>P3358: Privacy concerns over obtaining access to their facebook accounts</li>
<li>P3359: Good way to teach people not to put their passwords into anything.</li>
<li>P3360: the method used to find out involve faacebook pages and blogs.  these change quickly.  a finding will not apply 5 years from now because the whole facebook thing will have changed too much</li>
<li>P3367: So they can better protect themselves in the future.</li>
<li>P3373: I am concerned about the ethicality of impersonating friends of the student participants.  It seems plausible to me that misunderstandings might occur which could have long-term detrimental implications for the relationship used to facilitate the simulating phishing.</li>
<li>P3378: I don't really like the fact that people are using Facebook to do research on me.</li>
<li>P3387: I think it is unsafe to send actual phishing messages and actually take the passwords. What happens when the password database is hacked? </li>
<li>P3389: Verifying the password is correct gives the researchers too much personal information. </li>
<li>P3391: This sounds unethical and the passwords could be missued</li>
<li>P3393: I would want them to take part in this particular experiment because it deals with an issue that I worry they will fall victim to. This will allow me to find out if they know about such an issue and it will also help them become aware that phishers will use this to get to them.</li>
<li>P3397: this is serious stuff</li>
<li>P3402: it does not sound like a harmful study, and would allow them to be in it</li>
<li>P3403: Again, I feel like there is no psychological risk</li>
<li>P3408: N/A.</li>
<li>P3409: I think this is very tricky and should not be done to any one especially since internet attackers or out there everwhere</li>
<li>P3411: There does not seem to be any risk associated with any of these therefore it wouldn't matter to me if someone I cared about participated or not. </li>
<li>P3412: Without prior consent to being a part of some kind of experiment, people shouldn't be experimented on.  The security implications of giving up your password, having access to the university's password database, etc.  It's too much.</li>
<li>P3416: This experiment is another one that could possibly be unsafe.  I mean the hackers could hack the experiment, or the experimenters themselves could be hackers.</li>
<li>P3426: Yes, it would either verify in a secure environment that they are taking appropriate security precautions or make them realize that they need to take precautions in the future.</li>
<li>P3427: I see no harm coming to the participants and they are informed afterward about the participation. Participants will be more aware and knowledgeable on phishing attempts at completion.</li>
<li>P3428:  Same as previous, no results = no involvement by my friends.</li>
<li>P3430: They should learn their lesson if necessary.</li>
<li>P3431: I have received false e-mails from what appeared to be a friend, it happens a lot from people on my FB friends list.  I wouldn't want to have someone I care about think that happened to them even for a second.</li>
<li>P3438: It is a harmless experiment that could help the person I care about in the future. Making them aware on how easily they can be caught by phishing attacks.</li>
<li>P3440: This is taking private information from people without consent.</li>
<li>P3442: It's harmless and could potentially open their eyes to the dangers of phishing.</li>
<li>P3445: As long as their private information is deleted after the experiment, no harm can come from the study. </li>
<li>P3447: There's no danger, since passwords won't be kept</li>
<li>P3453: It sounds like passwords and data would be collected and I do not want them for someone I care about.\r\n</li>
<li>P3456: I feel that this experiment violates personal privacy too much.</li>
<li>P3460: TO SHOW HOW VULNERABLE THIS PERSON IS.</li>
<li>P3462: Would help them to be more aware</li>
<li>P3463: It would, ultimately, make them more aware about phishing attempts through email.</li>
<li>P3466: If something went wrong I wouldn't want someone I know getting hurt.</li>
<li>P3467: No, probably not. It seems a bit fishy to me. :) I think it is too much of an invasion of privacy. </li>
<li>P3469: I think it would be ok if they were part of it, because it would be disclosed to them, but I don't see a real benefit to the individual being included.</li>
<li>P3472: I would not want them to think I sent them that.</li>
<li>P3483: I disagree with the fact their Facebook is being looked at.</li>
<li>P3487: Most people should already know NOT to give out password information under any circumstances, and it doesn't take a research project that could compromise personal information to draw these conclusions. \r\n</li>
<li>P3488: I believe it looks pretty safe, if it's just for research</li>
<li>P3489: seems personal</li>
<li>P3491: I don't really like the idea of actual password information being collected since I don't know the conductors of the experiment. It seems more personal and there seems to be a risk of real password information being compromised.</li>
<li>P3492: It's invasin of privacy, and is unethical. Any "research" undertaken with such ethical concerns is invalid and should never be given creedence.</li>
<li>P3495: I believe it will help people in the long run.</li>
<li>P3498: This study seems very shady and I do not believe that the University should give out personal information like this to researchers.</li>
<li>P3503: Because tricking someone by pretending to be their friend seems invasive.</li>
<li>P3508: I think the sending of the phishing emails would be illegal.</li>
<li>P3510: There must be a better way of teaching people about it without having them fall victim to it.</li>
<li>P3516: Because there is no way to know if the e-mail received is an experiment or real phishing</li>
<li>P3518: Having the users think they are a part of a phishing scam could be harmful</li>
<li>P3523: it helps people</li>
<li>P3524: I think that in a controlled, and safe environment this would be a relatively harmless approach to do their research.</li>
<li>P3525: Because I already know most people I care about would fall for the scam</li>
<li>P3526: Protects us from cyber id theft.</li>
<li>P3532: Since it's only an experiment I have no qualms about such a thing.</li>
<li>P3534: This experiment does not seem harmful in any way, however I am apprehensive of someone I care about having to deal with extra emails and the worry of having been part of a blind experiment.</li>
<li>P3536: As long as they want to participate. There's nothing bad about this experiment. Might be some potential benefits to it.</li></ul>	</div>
</div>
<div class='cap' style='max-width:30%;'>
	<div class='header closed'>WarningsDeception study, answers to Surrogate question</div>
	<div class='body'>
<ul><li>P3: I've no issue with my hubby or kid participating in such an experiment.</li>
<li>P11: I don't care to be decieved</li>
<li>P12: As long as the participant is at no true risk, then I would support their participation.</li>
<li>P16: I wouldnt want someone that I cared for to be deceived about their security.</li>
<li>P20: I would participate so a loved one participating is fine with me.</li>
<li>P21: There is informed consent and the subjects will be debriefed and remain anonymous. This seems perfectly acceptable. </li>
<li>P27: I see no harm in this research experiment.</li>
<li>P33: doesnt seem that offensive.</li>
<li>P43: This seems alright. </li>
<li>P52: Doesn't matter if it's someone I care about.</li>
<li>P54: This experiment doesn't seem harmful or unethical.</li>
<li>P55: It would be be helpful to the community to be able to know what security warnings are effective. The people I care about should learn better what real and fake security threats look like.</li>
<li>P56: It would be good practice for the person I care about to face a security warning. They will know how to react if they see it again in real life.</li>
<li>P59: they would contribute to better security warnings</li>
<li>P60: It makes sense and I can see why they would do it. I wouldn't mind if someone I cared about was a participant.</li>
<li>P61: I am getting creeped out as in beginning to wonder if somehow I am part of a computer security experiment in addition to taking a survey on MTurk??????</li>
<li>P65: I would prefer it not, that's all.</li>
<li>P69: I DONT SEE A REASON NOT TOO</li>
<li>P77: In this case participants have consented to complete a HIT of some sort.  The nature of HITs in many cases requires at least some degree of lack of awareness or knowledge on the part of the worker with regard to the purposes of the work involved.  As such, participants who consent to complete any HIT necessarily consent to complete work for purposes of which they may be unaware or uncertain.  </li>
<li>P79: Not too worried about risks.</li>
<li>P80: Learning experience.</li>
<li>P84: people should be up to date on security measures.</li>
<li>P96: There does not seem to be any serious risk to them from being a part of this experiment that I would not want them to be included so it would not matter to me either way if they were.</li>
<li>P97: I wouldn't want them to think they were facing a security risk. </li>
<li>P101: I would want someone I know to be included because there are no risks involved.</li>
<li>P106: Because no harm would be done and the research yielded would be worthwhile</li>
<li>P117: The false warning could cause the participant to take real action that would be harmful to his/her computer.</li>
<li>P119: They may panic and believe something is wrong</li>
<li>P122: This would be good information to have</li>
<li>P132: I would not want a friend to think their computer was at risk, it is stressful to have computer problems.</li>
<li>P135: Participants aren't exposed to any risks.</li>
<li>P143: I would not be concerned if someone I cared about participated, but it would be up to that person to decide.</li>
<li>P145: It seems useless.</li>
<li>P152: It's a safe study and will teach them new and better techniques for handling their online security.</li>
<li>P156: This would make me panic and feel like I have messed up and I wouldn't want anyone else to go through that.</li>
<li>P159: This will teach people to be more careful with their Online activities.</li>
<li>P161: I feel that taking on that perceived risk would be up to the person in question</li>
<li>P166: No real harm done.</li>
<li>P169: This seems like valuable research, and the risk of harm during participation is low.</li>
<li>P171: Again, a beneficial learning tool. Maybe I lesson someone I care about should learn. </li>
<li>P179: There are no negative effects</li>
<li>P184: They would learn from the experince and so be better aware of security risks, and it would cause no harm to them</li>
<li>P185: It sounds like a good idea and sounds legal.</li>
<li>P188: I really would not care either way. It would be helpful to the researchers and no harm to the person, so either way is preferable.</li>
<li>P190: There is consent given even if not for the real purpose for the study is unknown.</li>
<li>P192: I don't think it si right to mess with somebody's head and stress them out over having a potential "virus", but it is a necessary evil I suppose to learn more about it. So, I don't care either way.</li>
<li>P198: I just don't like any of the experiments that these researchers are proposing.</li>
<li>P200: I don't see any reason for any person to not be a participant in this experiment.</li>
<li>P206: It's entirely up to them. There's no risk involved and the data is anonymous so I take a neutral stance on this one.</li>
<li>P208: I dont believe in experiments where the researchers are not upfront about the purpose</li>
<li>P211: I would not want them to be stressed out over this</li>
<li>P215: Research is necessary to further a field</li>
<li>P218: this experiment doesn't cause any harm, so I don't really care</li>
<li>P220: No one should be experimented on with out prior consent. </li>
<li>P231: This study seems harmless, so I would not mind if someone I cared for was a part of it.</li>
<li>P232: Does not seem to cause any harm</li>
<li>P239: No physical harm or real emotional harm would be perceived, real or not.</li>
<li>P248: I think using the MTurk HIT for this study will not be the effective methodology. I think you can use the "focus group" method within the university itself. </li>
<li>P253: It poses no risk, and may educate them on proper web security</li>
<li>P258: Again, no harm could come of it.</li>
<li>P270: I think it could scare someone too much.</li>
<li>P271: I see no risk or "down side" to being included in the experiment</li>
<li>P272: Again, wakeup call to people about security.</li>
<li>P279: No real risk</li>
<li>P282: Well thought out experiment</li>
<li>P284: i see nothing wrong with this experiment.</li>
<li>P289: At least. in the end they will know what was really going on.</li>
<li>P292: I wouldn't personally want somebody I know to be put through such an experiment. That doesn't mean however that I think the experiment is wrong.</li>
<li>P297: Just seems like it could cause someone alot of anxiety</li>
<li>P302: person could exit out and miss out on hit</li>
<li>P308: Since the participants are never at risk, my friend or loved one wouldn't be harmed and might learn something new.</li>
<li>P309: This study seems interesting and helpful.</li>
<li>P317: I do human intelligence tasks and I do not want to be deceived when I am trying to be very productive.</li>
<li>P320: I don't feel like they would be in any harm.</li>
<li>P322: since there is no actual risk, and they are just studying responses in order to make warnings more or less effective, I think that this research is ok</li>
<li>P327: it is not hurting them in any type of way. </li>
<li>P334: There are several fake warnings out there now, and there needs to be a means of knowing if it is really a threat or not.</li>
<li>P347: I feel that the chances of any danger to  the person's identity and personal information is not a problem.</li>
<li>P350: I don't see any harm in this experiment.</li>
<li>P369: Most experiments involving humans seem to involve deception. I do not believe in this case, many would mind it. They should just be told they are in an experiment and unexpected things could happen, but that they are safe.</li>
<li>P370: Sounds like another idea for greater online security.</li>
<li>P371: There is no real risk involved.</li>
<li>P374: It's not a particularly dangerous experiment so if someone I cared about wanted to be included or didn't want to be included it wouldn't matter to me.</li>
<li>P376: I think that researchers needs to examine this topic because security is a very important feature of a computer. </li>
<li>P390: I feel like this could spark some anxiety in select individuals. </li>
<li>P402: I don't see any harms in this experiment.</li>
<li>P409: Because the purpose will be fully disclosed at the completion of the hit.  This benefits the participant plus the researchers</li>
<li>P412: If there is no actual threat, I would support this research.</li>
<li>P415: think that this is a topic that needs to be addressed</li>
<li>P417: If they had consented to be tested and were immediately informed of the false security threat once the finish/try to withdraw, I see no serious issue.</li>
<li>P419: It doesn't seem to have any personal risks.</li>
<li>P422: If there is no actual risk, then I don't see a problem.</li>
<li>P425: only if they knew about it before it happened.</li>
<li>P427: I don't think there is anything wrong with this experiment.  There are no privacy issues being violated.  People could learn a lot from this.</li>
<li>P428: they are not encountering any risk</li>
<li>P429: seems safe enough</li>
<li>P437: There is no harm.</li>
<li>P442: It may cause a panic to the participants.</li>
<li>P444: I know there is no real harm</li>
<li>P446: it is a good experiment</li>
<li>P449: there are HITs like this somewhat often. not this specific issue, but "trick" HITs</li>
<li>P450: they might get freaked out when they get the security warning and things might escalate from there. </li>
<li>P453: I wonder how may people would stop and panic and how many would ignore the warning</li>
<li>P458: One can never be too safe online</li>
<li>P467: This is allowable and a good idea.</li>
<li>P470: I would want someone I cared about to participate because I believe it could not only help the researchers but also the participant. </li>
<li>P472: Doesn't seem like it's harmful to anyone</li>
<li>P473: Yes, because it's not going to have real consequences.</li>
<li>P475: Unless they're getting paid, doesn't bother me.</li>
<li>P476: they will be debriefed afterward no harm by the experiment</li>
<li>P480: its a great idea</li>
<li>P485: It seems harmless, but nothing makes me want my friends to do this.</li>
<li>P486: There is no actual exposure to a security risk. </li>
<li>P491: Threat to participant is minimal. </li>
<li>P496: Sounds like a useful experiment. People tend to click through popups and warnings without actually reading them, so this would hopefully lead to better security for everyone. </li>
<li>P505: I would be okay with them choosing to use their results but would understand if they were upset and didn't want to.</li>
<li>P513: I think its good to teach people about these things. </li>
<li>P517: This is a tricky  form of research I do not trust.</li>
<li>P519: I'm not as suspicious or hesitant towards this experiment as some of the others because it measures behavior without collecting personal information. </li>
<li>P525: There is no real harm or risk so I do not have any reason to not want the person included.</li>
<li>P528: No harm done, but might learn to be more cautious. </li>
<li>P531: Computer security is critical.  It is important to learn the most effective way to warn users when they are at risk.</li>
<li>P538: It seems pretty harmless</li>
<li>P539: This one is OK.  No personal information is being divulged--it's more or less a ruse for the real reason of the experiment.  </li>
<li>P541: No objections to this one but up to the individual.</li>
<li>P548: I think this study is worth looking into. Although, again, it involved the participant not entirely realizing what is happening, at least the concented to a study.</li>
<li>P553: Anything to do with security warnings to a consumer is always a good practice. We need more security online that is for sure.</li>
<li>P554: Because I know that the security risk wasn't real.</li>
<li>P555: No participants would be identified and would remain anonymous and they would not be exposed to any real security risk </li>
<li>P558: A person is opting into doing a HIT, so privacy expectations are different, and you're not gathering information like passwords.</li>
<li>P573: It's a good idea for users to be more aware of what a security warning may potentially mean and what steps he/she would need to take to prevent any issues.  Raising awareness is always a good thing.</li>
<li>P578: I might be OK with it if it were on total strangers.  I wouldn't want it done to someone I cared about.</li>
<li>P579: security warnings could end up as malware, in my opinion</li>
<li>P583: Awareness</li>
<li>P590: This study can gain a result without the participants giving personal information, so it is acceptable.</li>
<li>P591: Good information for someone to be aware of</li>
<li>P594: I would not want someone I care about to be a participant in this experiment because it violates their rights. They did not agree to this HIT because they are being lied to that it is something different. </li>
<li>P606: As long as there is a way to end a task after the security warning appears, then I see no problem with it. </li>
<li>P608: No risk involved, plus it needs to be done.</li>
<li>P610: i like the fact that they tell you it was an experiment at the end</li>
<li>P612: I would not someone I cared about to think for one second that they are facing a security risk. That would make them worry for no reason.</li>
<li>P622: dont think there is much risk just testing security warnings.</li>
<li>P626: It could cause stress to the individual.</li>
<li>P628: interesting for them when giving the explanation.</li>
<li>P629: It seems to provide good data and is ethical, especially with motivation of participants.</li>
<li>P633: This is an important topic and ethical safeguards are being followed. </li>
<li>P634: As long as the researchers could truly confirm no confidential information was compromised then there should be no issue.</li>
<li>P643: I dont know if this experiment would be negative in any way</li>
<li>P646: I think if a person comes across a security risk in a HIT, even a false one, they will return said hit. I know I would. I think it's kind of obvious that if you pose a risk people will avoid it. But maybe some people wouldn't so why not. I personally would just completely toss the hit aside asap. Something to take into account.</li>
<li>P647: I think it's a good experiment. We should make it better for users to deal with threats. I don't have a problem with it. If it helps me or someone I know not get a virus or other malware in the future, good. </li>
<li>P652: I do not see how this research can harm anyone. It can help them learn how to help people in the future when there is security decisions. </li>
<li>P657: yes </li>
<li>P658: As long as there is no threat to the privacy of the participant it is harmless.</li>
<li>P668: they could decide for their selves</li>
<li>P672: Doesn't help with anything. Why study it?</li>
<li>P676: This one is innocuous, and actually useful, and has no Big Brother overtones.</li>
<li>P678: its about security not a life or death situation</li>
<li>P682: This practice is deceptive.</li>
<li>P684: I believe they are impartial and would be a good match for the experiment</li>
<li>P685: I don't think this is a big deal one way or the other.</li>
<li>P691: No one's privacy was compromised</li>
<li>P692: As long as it wasn't my parents or elderly relatives I wouldn't have any issues with someone I cared about participating.  </li>
<li>P694: i believe this study will be helpful for the future </li>
<li>P696: It doesn't seem like anyone would be hurt from this deception so I would not care if someone I cared about participated.</li>
<li>P702: You could really scare someone into thinking they are facing risks and I do not want anyone I care for to be scared. </li>
<li>P704: It is still not a true test because any intelligent user who comes across a security warning is going to exit the program and no data will be gathered.</li>
<li>P705: while the study may be deceptive and ethically questionable, they would not face any real security risk.</li>
<li>P708: It's a good idea for people to test their ability to deal with security threats.</li>
<li>P709: As long as the faux threat isn't something traumatizing there are no ethical worries.</li>
<li>P710: personal decision</li>
<li>P721: I think it's fine - as long as there really is no risk.</li>
<li>P722: People run into this situation and handle it very often, so it wouldn't seem atypical.</li>
<li>P729: I am a little unsure about letting people think that they were a security risk.</li>
<li>P732: I'm curious to see the results</li>
<li>P735: The deception is not acceptable. I would tell any "participants" to have their information taken out of this experiment.</li>
<li>P737: This research has a valid concern its addressing and is well worth any risk associated.</li>
<li>P761: It is unethical</li>
<li>P763: Goes in the direction of the Milgrom experiment whereby it creates risk of anxiety. Also, might the user not completely abandon the hit and immediately look for assistance with an issue with their computer?</li>
<li>P772: Nothing personal or sensitive is being taken.</li>
<li>P776: It seems to me that members of Mechanicil Turks often take surveys that measure something other than what the survey "sound like". If makes sense that if we were always aware of what was being measured, our responses wold be "colored".</li>
<li>P780: Its good to be aware of what sites could cause damage, viruses, or potential hacking issues</li>
<li>P787: There is no risk to them and it would help the research. As long as I trust that there is truly no risk and everything is simply to measure reactions, I would encourage them to participate. </li>
<li>P793: sometimes people who aren't computer savvy get scared by warnings and those warnings make it harder to for those people to try new things--even not associated with the computer</li>
<li>P794: I see no real harm in the experiment. I've seen security risk warnings on the computer; the most they do is cause a little bit of nervousness, I think.</li>
<li>P796: It would cause no real harm.</li>
<li>P800: This seems perfectly reasonable. There is no damage that could occur to the person's emotional state or computer.</li>
<li>P802: In the end there is no harm to the participant other than being deceived for part of experiment. </li>
<li>P803: This sounds interesting and there is no risk. </li>
<li>P811: This research will help users to recognize which warnings to take seriously and which ones they can ignore.</li>
<li>P812: If there is no actual security risk, I don't see the harm. This is beneficial in the end.</li>
<li>P816: This is an interesting experiment and I don't think it would cause emotional harm</li>
<li>P817: I do not like deception tactics.</li>
<li>P820: I don't seen any real harm in it and it might make them more aware of warnings. </li>
<li>P821: Tests like these are very valuable and necessary. Security is a huge risk so any study aimed to work on it is helpful in my eyes. </li>
<li>P824: like I said before I feel like that would be taking advantage of someone I care about</li>
<li>P828: There is minimal actual risk involved with the experiment because there is no actual security risk.</li>
<li>P835: No risk.</li>
<li>P836: i would show how easy people can be fooled into thinking things are safe</li>
<li>P837: The task doesn't put them at risk, beyond basic initial concern generated by the warning.</li>
<li>P842: I see no reason they couldn't be part of it. There's no potential harm that could come to them so it doesn't matter to me either way. </li>
<li>P847: This experiment poses no risk to the participants.</li>
<li>P865: it is harmless so i would not mind either way.</li>
<li>P866: It is not suitable for all people.</li>
<li>P870: I would want them to participate because they are helping in understanding how to present security warnings to users.</li>
<li>P874: There is no risk involved in this study since the security risk prevented is not real</li>
<li>P881: The security warning doesn't intimidate me. I would care about the compensation.</li>
<li>P882: I think that the results could be used to find the most effective warning regarding computer security.</li>
<li>P884: I think its a great experiment to teach the average user what they should and shouldn't do on the interenet</li>
<li>P886: Seems relatively harmless, if someone I cared about wanted to participate, I'd have no issue with it.</li>
<li>P890: I think this could be beneficial for people I know who are not concerned with internet security.</li>
<li>P898: i dont think it would really bother me one way or another</li>
<li>P900: It isn't harmful.</li>
<li>P901: Though deceptive at first, the study seems fine.</li>
<li>P905: It is important for researchers to have a diverse amount of participants to improve computer security warnings.</li>
<li>P906: Yes, I can not think of any other way to test their security designs.</li>
<li>P908: I don't see anything wrong with it</li>
<li>P912: could be beneficial but not sure since most people ignore the warnings anyways</li>
<li>P914: I would one some one I cared about to take part in this study because computer security is such a large issue.</li>
<li>P921: They would not be in any real risk and can learn how to deal with security risks.</li>
<li>P925: this would unduly scare people and possibly cause them to invest money to ensure that their computer is safe - I expect not everyone reads all of the stuff that is posted when the survey is completed.</li>
<li>P926: I think this study will reveal important information. </li>
<li>P927: as this is regarding security risk and it can be conducted in this manner,i would allow people to participate in this</li>
<li>P934: I think it will be a interesting experiment and learn about them too.</li>
<li>P936: A great idea</li>
<li>P939: I think the experiment is harmless. I have noticed that if I'm on my PC, I get "security" type warnings all the time. But if I'm on my Mac, I hardly ever get a security warning. I guess the only way it could be a little harmful, is if you're not used to getting any warnings at all. One might think something bad has actually happened, and it can cause them a great deal of stress.</li>
<li>P942: as long as the participants are adults I have no reservations about the experiment</li>
<li>P948: It's just a BS warning</li>
<li>P951: they may be adversely affected by thinking there is a security problem</li>
<li>P953: This seems like a good idea.</li>
<li>P955: I do not understand completely what the statement refers to when they say "security warnings". Is this something related to potential breeches in privacy (such as credit card transactions online that might be compromised?) I do not have enough information to feel I would be comfortable with someone I cared about participating in this study. I am not quite sure what the point of this study is, and while it doesn't sound harmful or deceitful like the previous study, I don't have enough information to support it.</li>
<li>P957: I do not think anyone should participate in this study because it is stated above that researchers plan to deceive participants.  I do not think any participant should be deceived, or unwittingly become part of an experiment without their consent.</li>
<li>P963: I don't see the harm in participating.</li>
<li>P972: If it's a warning, I don't think it imposes any real risk.</li>
<li>P984: It isn't harmful and doesn't take any personal info.</li>
<li>P986: Yes if they where willing to help out the research.</li>
<li>P989: My family might be startled by security warnings, especially since they are not very computer savvy.</li>
<li>P1004: They will not be put at risk by the experiment, so I will not mind if they are chosen, but I do not particularly care if they are or aren't.</li>
<li>P1005: I would. I think understanding how to deal with these threats are very important. Yes, I would want my family to participate, just to see how we do.</li>
<li>P1007: this isn't an invasion of privacy, just sneaky</li>
<li>P1008: yes, assuming this person agreed to participant in a research experiment even if this aspect of the experiment was not explained to them</li>
<li>P1010: It appears that it can be harmful and helpful, so I am in the middle of this one.</li>
<li>P1016: I would want that person to make the decision.  I wouldn't want to decide for the person.</li>
<li>P1017: my parents would fall for this and it would be a pain to explain/fix if real</li>
<li>P1018: no preference</li>
<li>P1019: the experiment seems pretty harmless, the deception is revealed in the debriefing </li>
<li>P1026: This seems safe, but I wouldn't want to decide whether someone I cared about would participate or not.  I also do not see a great deal of value in the study. </li>
<li>P1028: For the sake of science I can stand to be deceived for a few minutes.</li>
<li>P1031: This experiment is not as invasive as the other ones presented because there is no actual risk to the subjects' computers. </li>
<li>P1039: It's an important research question and it doesn't hurt anyone.</li>
<li>P1050: It would be a good experience for the candidate, and would help to improve our knowledge as a society.</li>
<li>P1055: This seems the safest of all the options.  The person keeps their passwords safe, it sounds like someone has taken their passowords.</li>
<li>P1056: Seems interesting and fun</li>
<li>P1058: It is completely up to them if they would like to participate or not. I don't think there are any real risks because it is unlawful to do so anyways. </li>
<li>P1059: It doesn't appear to have any real benefits or detriments.</li>
<li>P1062: This study yields no risk and potentially great results.</li>
<li>P1063: They would be a willing participant and be compensated</li>
<li>P1076: It's up to the person</li>
<li>P1081: I think this is a good research experiment.</li>
<li>P1083: because i would want them to take security warnings serious and to be cautious from then on.</li>
<li>P1088: I feel that is the option of the person being asked to take the risk.  </li>
<li>P1089: I think that the people I know need to be more aware of their safety online and this would help them.</li>
<li>P1108: It wouldn't bother me if someone chose to do this because it isn't real. it's just a study.</li>
<li>P1109: People tend not to realize how often a common website could have security flaws.</li>
<li>P1110: I don't believe that the people I care for are tech savvy enough to understand that their computer is not at risk. I think they would believe that their computer is at risk of a security threat and then download a program that IS a security threat to remedy the perceived security threat.</li>
<li>P1111: Everything is anonymous and controlled, so there seems to be no harm to the participant.</li>
<li>P1112: This sounds like an experiment that could result in improvements in security warnings.  Since no real security breach would occur I think it would be ok.</li>
<li>P1119: I would want this person to be included as a participant because they would never be in any real danger, and plus the researchers will have gathered more data for their study.</li>
<li>P1123: I think it is an interesting experiment but I do not lean towards a yes or no for someone I care to do this.</li>
<li>P1130: A good test</li>
<li>P1131: Good to learn about computer security and risks</li>
<li>P1140: I don't think they would mind.</li>
<li>P1147: There is very minimal harm in participating and deception is revealed at the end.</li>
<li>P1157: Such deception could cause, and will cause for a certain portion of participants, a needless emotional reaction ranging from anger to fear and even panic.  That is unacceptable.  For the tactic to be revealed as a hoax after the fact is irrelevant and may even exacerbate the negative emotional responses mentioned above.  People who are under financial stress, have health issues,are coping with severe life conditions,or who have other issues that render them unusually vulnerable to emotional volatility, should never be made to experience artificial anxiety or other emotions that could trigger unexpected reactions.</li>
<li>P1158: This is a reasonable way to study the effect of warnings and make them more effective.</li>
<li>P1159: I think that there would be no harm to someone involved in this experiment, as long as it was explained at the end. </li>
<li>P1162: the study is harmless and serves a purpose for the greater good</li>
<li>P1163: The experiment does not harm the subject in anyway and although it is misleading the information obtained is very valuable.</li>
<li>P1165: They would probably try to fix their computers because of the security warning, and maybe spend money on it or screw up their computer trying to fix it.</li>
<li>P1174: its not a big deal</li>
<li>P1176: This reaction to security messages is a good way to test security protocols.  Im for it</li>
<li>P1178: This seems like a good way to measure security.</li>
<li>P1179: Yes, because there is no real risk for the participant. </li>
<li>P1180: This sounds fairly ethical and there's no risk to the participants of their information being used for any negative purposes, so I don't have any feelings over who participates. </li>
<li>P1183: Because there is no real security risks</li>
<li>P1191: This may also raise awareness to security risks to those who are unaware.</li>
<li>P1192: I dont think the way a security message is received is going to vary in the manner it's percieved.  A security warning is heeded pretty much the same regardless of how its delivered.</li>
<li>P1195: there doesn't seem like any harm is being done to participants.</li>
<li>P1196: If they take proper precautions when using their computers, it will not matter if this is a test or not.</li>
<li>P1199: it would be nice to see how these types of security warnings effect people. No harm in the study.</li>
<li>P1203: I fell they need to get data like this, but unsure if I'd want someone to participate. </li>
<li>P1211: I feel that the results of this study would be useful for computer security researchers. </li>
<li>P1216: I dont see anything unethical in the experiment.  The deception is fully explained at the end of the experiment.  That's widely accepted as an ethical use of deception in experiments.</li>
<li>P1217: This seems harmless and could be helpful in the long run</li>
<li>P1220: It is a violation of privacy and it can jeopardize security of that person. It can be harmful.</li>
<li>P1227: No real danger to the person.</li>
<li>P1230: If it doesn't hurt them, it would be up to them if they wanted to participate.</li>
<li>P1231: To every risk there is a downfall of effects.</li>
<li>P1233: People need to learn about security warnings. I have found that too many of today's users are non-nonchalant about security.</li>
<li>P1238: I have no problem with this experiment.</li>
<li>P1242: I would not want them to participate because they may develop health issues due to the anxiety that they will encounter from the security issues.</li>
<li>P1247: It sounds like the people participating are aware that they are participating.</li>
<li>P1248: I don't see any real risk or threat to the participant.</li>
<li>P1253: The participants are not being tricked by false information, so it should be ok.</li>
<li>P1260: IT would be very confusing and make someone think they are facing a security breach.</li>
<li>P1261: After they are told about the warning it will make them aware of it. </li>
<li>P1262: Would not really have to be someone I cared about to participate, so I would rather they not than to participate.</li>
<li>P1264: I believe we need to be cautious about the types and severity of deception we create for the sake of research. Security warnings may cause significant upset to some individuals.</li>
<li>P1266: I think this could be very well controlled. It is not coming from outside this system and would not involve outside parties as Facebook or the spam experiment would.  I think it would be very beneficial.</li>
<li>P1267: I feel the participants should be notified. </li>
<li>P1269: This is a valuable research project.</li>
<li>P1270: it seems more like they would be learning a lesson</li>
<li>P1272: Use your friends, not mine.</li>
<li>P1273: It is a participants choice, not mine.</li>
<li>P1283: They were not asked beforehand to participate.</li>
<li>P1288: I think each person is able to assess his or her own level of comfort with risk.</li>
<li>P1289: Participants will not be harmed and will provide useful information in an important study.  The deception is necessary for the greater good.</li>
<li>P1295: There are two extremes when it comes to security warnings.  Either people will ignore it or take their computer to the shop which could cost the unsuspecting user money.  </li>
<li>P1296: It would help teach proper computer/web safety.</li>
<li>P1299: Just doesn't seem ethical</li>
<li>P1300: They need to learn not to take security risks.</li>
<li>P1301: This is a good experiment to teach people not to just click on anything they see in the internet.</li>
<li>P1302: This is the best way to test if the experiment will work, by keeping participants unaware. </li>
<li>P1303: I can't see a lasting harm and participation might actually cause my family member to bolster security and learn more about it.</li>
<li>P1310: I think it may cause someone distress.</li>
<li>P1311: This seems even less harmful than a prank!</li>
<li>P1318: There are no harms and is more research so it don't matter too much.</li>
<li>P1319: There seems like no risk</li>
<li>P1328: It might lead to helpful information</li>
<li>P1331: I think that the experiment sounds alright a lot of surveys use some type of deception or masking in order to get more authentic results. I don't see how this could harm the person involved so I have no preference if they participate or not. </li>
<li>P1332: This seems fairly safe since they are never in danger.</li>
<li>P1333: It's scientific research and has value.</li>
<li>P1340: No because I believe thAt the person I care about will not be happy with unsecured security. </li>
<li>P1343: As long as the participants are informed afterwards I have no problem with this. </li>
<li>P1344: Sounds like a good experiment.</li>
<li>P1346: The experiment's results could be very beneficial to many people.</li>
<li>P1350: Yes, not only researchers but also users (participants) can learn a lot from the experiment. If I have a feeling I really face a risk, it would make me more careful and I would protect my computer better.</li>
<li>P1356: No personal information is being exchanged. Im ok with this</li>
<li>P1357: No real risk</li>
<li>P1360: It is important to show computer users what kinds of security warnings that they may encounter and ways to avoid these types of warnings while online.</li>
<li>P1363: Seems there is no harm</li>
<li>P1371: Netsec is important, and studying what reactions users have to a warning based on how it is presented may lead to more effective security measures</li>
<li>P1373: no harm done</li>
<li>P1374: It seems that when the participants are notified at the end what had happened they will become more aware of security and that seems to be beneficial to them, not harmful.</li>
<li>P1386: If this experiment only comes up in HITS on Mturk, then I think it's ok.</li>
<li>P1395: With no harm done to the "someone," I feel it would be a good learning experience.</li>
<li>P1406: The research seems honest.</li>
<li>P1410: yawn</li>
<li>P1419: Participant would remain anonymous.  This would not pose a risk to the participant.  Any research done to help to alert a security concern would be helpful for the welfare and protection of the future security needs.  </li>
<li>P1421: It doesn't seem to be harmful and looks like an interesting study that might be helpful in the future to try to help people be safer</li>
<li>P1427: There seems to be little risk associated with this study, there's no reason I can see not to do this. </li>
<li>P1432: Dealing with issues like this is a common problem for many people on the internet and I think that this could benefit many people</li>
<li>P1433: I think a lot of people aren't careful with their online security, so this could be interesting.</li>
<li>P1446: They are taken proper precautions and disclosure. </li>
<li>P1452: Informative and helpful to many computer users.</li>
<li>P1456: I trust the researchers but frankly despite all the fine words there is no real proof that the information will not be used by improper people, I mean both the government and the telecoms have been "Betraying" people for years so why not the University etc?,.....</li>
<li>P1465: It doesn't seem as if this experiment would have any negative side effects to the participant.</li>
<li>P1470: I wold not want them to be manipulated without their permission.</li>
<li>P1472: Many people fall for these actual threats often</li>
<li>P1479: I wouldn't want someone I cared about to think they were in a security risk when they are not.</li>
<li>P1486: This seems safe and won't cause any harm</li>
<li>P1487: I wouldn't oppose it, since I do not oppose any of the proposed measures, but I don't necessarily support it since the person may resent being deceived.</li>
<li>P1488: this would make websites safer</li>
<li>P1489: It wouldn't matter to me because people go to websites they want to.</li>
<li>P1492: I could see this not working out well. If I were to see a security risk warning pop up during a HIT I would most likely close my browser, flush my cache, and run a malware/virus scan then return the HIT not finishing it. This would have to be designed in such a way so that doesn't happen but that would probably invalidate the results. </li>
<li>P1497: This doesn't seem to be divulging any sensitive data about the participant </li>
<li>P1503: why not? it isn't dangerous and it would help the computer community</li>
<li>P1507: I believe the pool should be as random as possible therefore they should choose any participant.</li>
<li>P1508: it may make people do things they otherwise wouldn't have which might compromise their computer</li>
<li>P1514: dont really care about others buisness.</li>
<li>P1517: I wouldn't want someone I cared about as a candidate for this experiment because I believe it would cause them a great amount of stress.</li>
<li>P1519: It may make someone unnecessarily nervous, but I can understand the reason behind the study.</li>
<li>P1522: It doesn't make a difference to me.</li>
<li>P1524: It sounds like there is no real risk, so I wouldn't mind if someone I knew was involved.</li>
<li>P1525: Really the trickery is not that bad</li>
<li>P1526: It feels manipulative.</li>
<li>P1528: Good learning experience</li>
<li>P1538: While the ethics around deceiving participants is questionable, I see no real harm done in the experiment and I can understand it's value.</li>
<li>P1540: They are in no real danger and there is no real risk. </li>
<li>P1543: I would allow this experiment to take place.  </li>
<li>P1546: It will help people learn how to manage security risks.</li>
<li>P1547: I wouldn't want my grandmother to go through the stress of that.  Some people, especially if they aren't completely familiar with the internet, freak out over internet security.</li>
<li>P1550: 0</li>
<li>P1551: I'd hope that the people involved were more computer savvy rather than less.  People who are not very computer literate could be very freaked out by the warning.</li>
<li>P1552: their choice not mine</li>
<li>P1553: As long as there is no real risk it does not matter.</li>
<li>P1554: seems useful</li>
<li>P1556: It is a very important topic of research.</li>
<li>P1563: Does not seem to be anything wrong with testing this type of idea.</li>
<li>P1580: It sounds like an important study, and sounds like acontrolled experiment.</li>
<li>P1582: I would hope that the person I cared about had a good protection program on their computer, like everybody really should.  Then they would get the warning and not click on anything like they normally would.  </li>
<li>P1583: Since there is no real risk, I do not think that it matters who does and who does not participate.</li>
<li>P1593: Lesson learned about just clicking "yes" without considering consequences</li>
<li>P1597: There is no real threat and participants remain anonymous. By participating in this experiment, the individual(s) will learn more about potential risks and factors surrounding such.</li>
<li>P1598: Increasing computer security is a good thing, but a person over reacting to a non-existent threat can actually damage data.</li>
<li>P1610: there is no true risk and they are notified about it afterwards</li>
<li>P1612: I don't think there is any harm to the participants.</li>
<li>P1614: I think it's for the greater good to deceive the participants in this experiment.  It allows the researchers to test security warnings.</li>
<li>P1616: It sounds stressful since they don't know what </li>
<li>P1617: I don't really think that is my concern.</li>
<li>P1629: The study is designed to improve security warnings, it is not harmful nor is the participant's information revealed. </li>
<li>P1633: Everything seems very safe and very tame with this study. I can perceive no negative effects. </li>
<li>P1650: i'm answering the same questions over and over</li>
<li>P1651: It wouldn't be a danger to the user. I would think some people would just close it out and not complete the survey at that point, though. </li>
<li>P1655: Since there is no real harm in the study other than the fake risk.</li>
<li>P1658: No harm would be done and it would be a learning experience for the participant.</li>
<li>P1664: It really depends on the person themselves. The experiment does not seem harmful in any way.</li>
<li>P1668: This experiment doesn't seem to be too bad on the participants. I wouldn't care either way if someone I cared for participated. </li>
<li>P1671: The study seems harmless, and in the end, the study is honest with the participant. I think it's very fair.</li>
<li>P1674: Nothing much to lose, and I don't think anybody would feel too offended</li>
<li>P1678: As long as the security risk is not real. </li>
<li>P1680: I don't really have a preference because the experiment is ethical. So it's up to the person if they want to participate or not.</li>
<li>P1681: I don't see why not, maybe they can learn something at the end of the experiment.</li>
<li>P1682: Participating in HITs means you are agreeing to testing and experiments.  So if they agree then yes, I would want them to be included</li>
<li>P1683: i know some people who dont pay attention and hopefully this can make them aware when there is a risk.</li>
<li>P1686: It might help people become more aware of security risks.</li>
<li>P1693: I still believe that it will help the person see their mistakes on the internet</li>
<li>P1701: It is an important experiment </li>
<li>P1704: This seems like a harmless study and might actually encourage the participant to be more aware of security warnings.</li>
<li>P1705: increasing understanding of threats is a good idea</li>
<li>P1707: Scientific experiments are there to increase positive life theories.</li>
<li>P1708: yes, because they'll be familiar with it.</li>
<li>P1709: I feel like the study would allow the person I cared about to realize their security faults and improve on them/</li>
<li>P1710: This seems like a good idea</li>
<li>P1723: There is no actual security risk. I would pick no if the candidate was not comfortable using computers in general.</li>
<li>P1724: I feel it is an invasion of privacy</li>
<li>P1725: As long as participants are made aware of the study afterwards, I see no harm.</li>
<li>P1733: There doesn't appear to be any real risks here and I think it would be beneficial research.</li>
<li>P1738: I'm less sure about this since the only person I know who does HITs is myself and I know how I would respond and that would be by stopping the task immediately and getting angry so I don't know if that would help you or me.</li>
<li>P1744: It seems interesting and wouldn't harm the person I know </li>
<li>P1746: There is no harm in participating. There was never any real threat.</li>
<li>P1751: It should be their right for it to be up to them.</li>
<li>P1752: it has potentially positive benefits</li>
<li>P1753: again the researchers will not be hurting the person i care about and will be helping them in the long run. </li>
<li>P1757: It may have an end result of educating the participant.</li>
<li>P1758: I don't see anything wrong with this. Deception is used all the time in research and as long as the participant is debriefed I feel that this is okay. </li>
<li>P1761: They're at no real risk </li>
<li>P1763: But only if they got paid.</li>
<li>P1770: Seems like there is no harm in this experiment</li>
<li>P1771: While my friend will be "duped" at first, the researchers do explain that it isn't a real risk and is very helpful to improving security warning in the future.</li>
<li>P1773: I feel like this experiment is being conducted ethically.</li>
<li>P1774: I don't have any major objections to this study. I realize there is some deception involved, but I feel the negative effects of this deception are mostly harmless and the participants receive an explanation after completing the study.</li>
<li>P1775: I am older and I hate it when I feel my security has been breached. I am not a computer guru, so I do not have the expertise to fix the problem and I just shut down my computer. I would never follow the information the test gave me. I got malware from my computer that way. I would not want my friends to have to deal with that.</li>
<li>P1777: I think this would be good research for online security and the results would be anonymous. </li>
<li>P1783: This experiment seems ethical</li>
<li>P1785: This can be a real scare for them if they think there is a security issue.</li>
<li>P1786: It is not stated which ways are planned to reveal a security warning, and doing so in certain ways may actually cause the participant enough fear that they exit the experiment with out completing it, thinking there is a real issue, and go through a lot of time trying to work on their computer figuring it out and never know it was part of the experiment. </li>
<li>P1788: As long as no personal info is collected I think it is fine</li>
<li>P1793: The participants are not exposed to any risks</li>
<li>P1803: It wouldn't matter to me.</li>
<li>P1806: It's not going to hurt the person to participate in the experiment so why not do it and help others out. </li>
<li>P1811: There is no harm in the study</li>
<li>P1835: The research doesn't seem that useful to me but it isn't harmful so I wouldn't care either way</li>
<li>P1836: Its an experiment with no risk, it couldn't hurt.</li>
<li>P1837: I think it would be a good experience, as long as there are no real threats</li>
<li>P1839: You are giving the user the choice to say yes or no to the security warning and there is no risk for danger.</li>
<li>P1848: There is no real harm in the experiment.</li>
<li>P1850: there may be temporary discomfort but a benefit in the end.</li>
<li>P1851: The behavior would be interesting to see.</li>
<li>P1853: This doesn't sound dangerous in anyway so it wouldn't matter to me. </li>
<li>P1857: While I think it is a valid way to test how people behave when facing a security risk, I don't have strong feelings in either direction whether or not I'd want someone I cared about participating. I don't think there is much actual risk involved in the HIT and they are made aware of the misdirection in a timely manner. </li>
<li>P1864: Its a small hassle, but its also harmless, so I could go either way.</li>
<li>P1865: Studying security decision making is not easy. With that said, I would not appreciate being deceived about what type of research study I am in. </li>
<li>P1870: There is no risk to the participant.</li>
<li>P1871: Again, security exploits need to be taught and the typical user needs to know the risks with using interwebs</li>
<li>P1873: I don't see how they would be harmed, except for perhaps their pride when they found out they were part of an experiment.</li>
<li>P1874: I want people I know and care about to be safer, and if this could help then I would be completely for them being a part of it.</li>
<li>P1875: This might cause health problems for my loved ones such as a heart attack or unnecessary anxiety or worry.</li>
<li>P1876: Same as before if the researchers are not collecting data then no harm done.</li>
<li>P1877: I see no harm in it, and I like learning things about the world (and therefore like others to, as well).</li>
<li>P1878: it could show them not to ignore the safety/security warnings</li>
<li>P1884: It doesn't seem like it will cause them any harm. </li>
<li>P1890: No risk involved and experiment will be done through HITS.</li>
<li>P1893: No harm is done, it could be educational.</li>
<li>P1897: All should be allowed to do it.</li>
<li>P1901: Sure.  It would be up to them.</li>
<li>P1904: Individuals do not understand the severity of their actions online.</li>
<li>P1913: I wouldn't want to put someone I know in that stressful situation</li>
<li>P1916: I would want them to be a candidate because I believe critical thinking is essential and helpful to analyze as well.  </li>
<li>P1917: I find this to be helpful. It makes the participant aware of the risks. </li>
<li>P1929: Internet security is very important</li>
<li>P1942: These researchers have a good cause.</li>
<li>P1951: Because I think it would help educate a person I care for about computer threats. All the people close to me don't really know much about computers.</li>
<li>P1953: The research seems valuable and could help develop more effective security warnings, so I would support anyone take part in the research since it seems to have no real risks involved.</li>
<li>P1955: Most of the people who I know would still find it interesting, and would probably expect that they were not actually at risk. This probably makes the, bad candidates for the experiment in the first place.</li>
<li>P1960: They would not face any real risk.</li>
<li>P1963: I think that this type of research could be very helpful, but don't care either way if someone I cared about was a participant. </li>
<li>P1970: There appears to be no harm to this experiment and the information gained would be useful</li>
<li>P1971: There is no actual security risk, and this is made clear to participants after the fact.</li>
<li>P1977: It is deceitful.</li>
<li>P1978: I would not want my friends to do this unless I discussed it several times over a one to two week period first.</li>
<li>P1979: I think others should decide for themselves as to whether or not to participate.</li>
<li>P1989: Since there is no actual computer security threat, I think the experiment is a good idea.</li>
<li>P1991: I would worry about the potential for an accidental real security risk. </li>
<li>P1998: I don't see how anyone is harmed here. Yes, the experiment might be a bit startling. But it does not involve protracted deception or the collection of sensitive data, or violation of privacy.</li>
<li>P2002: I would not want fake warnings coming up on my computer.</li>
<li>P2003: I want for my friends to get as many HITs as possible, but at the same time, this could cause them to return the HIT and be a waste of their time.</li>
<li>P2006: No information was gathered and participants are aware that they are in a study.</li>
<li>P2009: I don't think there's any risk posed so I think it'd be ok for that person to be in the experiment.</li>
<li>P2016: If there in no real risk I don't see a reason not to allow it.</li>
<li>P2025: It might make them more aware of the warning signs for this activity.</li>
<li>P2026: It poses no real risk, so it's up to the person I cared about to decide what they wanted to do. </li>
<li>P2027: i see no reason not to. it seems harmless and helpful</li>
<li>P2032: This could cause someone to tweak a computer that does not need tweaking, possible loss of data and such.</li>
<li>P2039: would help out with the security warnings and prevent it</li>
<li>P2040: I wouldn't mind if they were included or if they weren't included.</li>
<li>P2044: the candidates remain anonymous and aren't affected by the research at all.</li>
<li>P2047: It would not harm them</li>
<li>P2048: There is no real violation or threat, and it would be explained, and for the greater good, with no lasting consequences.  I believe thy would want to be included.</li>
<li>P2053: I think it would be useful to see what security warnings work</li>
<li>P2060: It is a typical experiment where deception has to occur.</li>
<li>P2063: Since there is no real security risk, I see no harm in participating in this experiment.</li>
<li>P2065: I don't think most people would mind this experiment</li>
<li>P2070: Seems fine</li>
<li>P2072: Deception for the purpose of a study of this type seems reasonable.</li>
<li>P2074: I would prefer my loved ones to ensure they protect their computers from viruses, trojans and malware.</li>
<li>P2082: I would back out of the study, and return the hit.</li>
<li>P2083: I would see no reason for them to opt out of the experiment because there is no presented risk by participating.</li>
<li>P2094: The temporary deceit and the emotional affect it may have on participants is a minimal and worthwhile risk in pursuit of more effective security warnings.</li>
<li>P2100: They are not at risk.</li>
<li>P2103: I believe that informing the participants after the study will give them an opportunity to learn from their mistakes. </li>
<li>P2105: It's at their discretion</li>
<li>P2114: Some people get really panicky when they get those security warnings and do not known how to react to them.</li>
<li>P2117: I see no ethical violation here. </li>
<li>P2119: It sounds fine as long as you do what you stated above. :-)</li>
<li>P2121: I would want someone I cared about to understand their security.</li>
<li>P2122: It's a harmless experiment that may be useful for something good. </li>
<li>P2123: so that they can be part of the experiment</li>
<li>P2125: If there was really no harm, then yes, I would want there to be as many participants as possible.  All in the name of science.</li>
<li>P2126: it seems like an interesting experiment and I see no harm in it since participants are not actually experiencing a real security risk and the participants will be anonymous in published results</li>
<li>P2130: Because I want that person to learn many valuable things in surveys.</li>
<li>P2131: Since no participant will suffer from this experiment, then it is important to participate in research studies.</li>
<li>P2132: Don't trust the requests.</li>
<li>P2134: No harm done. </li>
<li>P2135: It would be funny to hear about their story afterwards. </li>
<li>P2144: There isn't a risk but it's making the participant believe there's a risk so it's a neutral situation. </li>
<li>P2149: I'd rather my family not be involved</li>
<li>P2155: The survey poses no threat.</li>
<li>P2156: THis could make them aware of future attacks </li>
<li>P2172: It would make the participants more aware of activities that could present a security risk in the future.</li>
<li>P2175: I am not a fan of deception. It seems to easy for corporations and scientists to explain away their unethical behavior by claiming that they NEEDED to deceive people.</li>
<li>P2177: Little risk, many benefits.  Seems fine to me.</li>
<li>P2181: Depends on the type of risk that they will be involved in and whether it will have a lasting effect on them</li>
<li>P2183: I feel the benefits would outweigh the disadvantages.</li>
<li>P2189: As long as they're in no real risk, I think it would be important for them to participate.</li>
<li>P2193: This is actually a good one to be part of because it sees how one tries to take preventive measures when confronted with security risks.</li>
<li>P2194: I don't want to do anything on my computer that might damage it so I would want something done to prevent it.</li>
<li>P2204: Does no harm to the participant. </li>
<li>P2205: Are you're saying put the participants in situation where they are not aware they are being monitored for research purposes? If so I would not care as the intentions is academic.</li>
<li>P2208: It seems harmless if no actual information is taken.</li>
<li>P2212: After the previous section, I feel that the methods used to approach this experiment do violate the rights of individuals</li>
<li>P2213: This is actually a good experiment, and I think it would be okay for someone to participate in it.There is no deception, and the participant is aware that they are in an experiment.</li>
<li>P2216: The deception here seems harmless</li>
<li>P2218: It may cause my friend to lose trust in the (Hit) system in general</li>
<li>P2219: This could cause unneeded stress</li>
<li>P2221: This experiment does not violate any privacy.</li>
<li>P2227: It is against their rights as citizens.  </li>
<li>P2233: I think this study could be beneficial to the person</li>
<li>P2234: It is a good way to learn what way to present security warnings</li>
<li>P2237: No preference.</li>
<li>P2238: No risk.</li>
<li>P2244: Many times we are faced with security warnings on the internet but choose to ignore them or think that they can really be that "bad".  However there are subsequent consequences to those actions that can prove to be detrimental.</li>
<li>P2245: People generally don't like to be deceived, even for money.</li>
<li>P2250: I think if someone was not very computer savvy then it could make that person leery of Mturk </li>
<li>P2253: I would want someone to know if they are not being careful with their online security</li>
<li>P2254: security is a critical part of safe computer use and should be researched and studied</li>
<li>P2260: There is no true risk or harm in the study. </li>
<li>P2261: Like the first experiment, I think this has a lesson for people. </li>
<li>P2273: I think this one would be fine. No  passwords or  information is being taken from Participants.  As long as  no  virus or anything  were being used  I think it would be interesting to know  how many people  continue and how many do not  preced when faced with   security  risk   possibilities.</li>
<li>P2275: no real risk involved</li>
<li>P2276: These sorts of studies are necessary for us to learn.</li>
<li>P2280: If someone is not smart enough to avoid a risk AFTER being warned of a potential security breach, I'm not sure they are capable of making an informed decsion</li>
<li>P2281: I do believe that candidates should remain anonymous but I do not like the methods used in gathering this information.</li>
<li>P2284: Seems safe enough.  Not sure it would benefit the participant though.</li>
<li>P2285: If they were never at any real risk, then I wouldn't mind them participating. Other than that, I can't say I'd "want" them to participate because not enough info was given as to what changes the results would dictate</li>
<li>P2286: the risk is non-existent and the subject matter is important.</li>
<li>P2289: It would be fine for them to be in the experiment.</li>
<li>P2302: It wuld make me uncomfortable to know they were lied to.</li>
<li>P2305: Because they might learn more about their own online behavior and how to keep themselves safe in the face of security warnings.</li>
<li>P2307: This would help them with security risks, so it is a good thing for them.</li>
<li>P2308: I feel it would make them more aware in a setting that doesn't pose a real risk. </li>
<li>P2309: In this study, it appears that participants are aware they are consenting to participate in the study up front, and no personal information is being intercepted without the participant's knowledge.</li>
<li>P2314: There are no real security risks so it would be fine.</li>
<li>P2316: Yes, only if they can presented the security warnings and how to avoid them. </li>
<li>P2318: It does no actually harm to their computer and can be used as a teaching experiment.</li>
<li>P2321: All HITS that I have been a part of have been up-front and trustworthy. I don't think it's worth losing people over and that is what I feel may happen if they do this study in deception.</li>
<li>P2324: Sounds like a worthy experiment since you can see how different situations and warnings affect peoples decisions with computers and can help in creating better warnings.</li>
<li>P2325: Again, the more information the researchers are able to aquire the better understanding they will have.</li>
<li>P2326: My cared for person is not being hurt so I don't care.</li>
<li>P2328: Depending on the security warning, you could cause somebody to reformat their drive and reload windows.  There is too much potential for unnecessary harm.</li>
<li>P2329: no risk</li>
<li>P2330: It doesn't matter whether I know or care about a person subjected to the test. The test should have randomized selections of participants without the test team knowing who they are or what their backgrounds or experiences are.</li>
<li>P2340: If you give people a false security warning it will make them trust the real ones less.</li>
<li>P2341: Same as prior answer.</li>
<li>P2348: It wouldn't matter to me</li>
<li>P2349: It seems harmless the researchers are not exposing them to anything that may hurt them.</li>
<li>P2350: The experiment sounds harmless and could prove to be beneficial to help design future computer security warnings.</li>
<li>P2351: It is harmless. There is no real security risk.</li>
<li>P2354: Yes, it is for a good cause and they will be anonymous.</li>
<li>P2357: Seems harmless</li>
<li>P2367: Thinking you facing a security risk is stress inducing, and may lead to the unnecessary manipulation of other computer files and programs.</li>
<li>P2368: It's up to them if they want to participate.</li>
<li>P2370: it is up to them whether or not they would like to.</li>
<li>P2372: This is to close to behaviour manipulation.</li>
<li>P2378: I see no negative impacts for this experiment.</li>
<li>P2382: There's no actual risk involved for the participants and it's a study about how they psychologically react to this situation. I see no problem in conducting this experiment.</li>
<li>P2386: The whole idea doesn't sound as safe and secure as described.  I can see something going wrong with this experiment.</li>
<li>P2391: It really would not matter to me</li>
<li>P2396: It might get them to smarten up if they're bad with security once the results are known.</li>
<li>P2397: I think it would be interesting to see how they would react under these circumstances being that most people in my family are not "computer people" so they are in a specific demographic. I do not believe that the experiment in question is really traumatizing in any way so I would have no problem with a loved one's participation.  </li>
<li>P2401: I believe that people I know would want to help with the research so that this issue can be better understood. </li>
<li>P2403: I understand why this needs to occur.</li>
<li>P2408: The debriefing seems sufficient for the experiment.</li>
<li>P2409: It is no big deal. No lasting harm can come from being a part of this.</li>
<li>P2411: participant could be deceived into thinking the research is legitimate and secure when it could be used by hackers.</li>
<li>P2412: I feel like the HIT interface is more acceptable than using completely random selection.</li>
<li>P2419: This would not hurt anyone, but help make them aware of security risks.</li>
<li>P2432: Yes, I would want my love one to be a apart of the study because there is no physical harm being done to them and it helps prevent security risks.</li>
<li>P2435: Not sure if I would want someone I cared about to participate in this or not although I don't think it would be a problem. I think that we all would like our computers and internet usage more secure from those who try to hack and get our personal information. So it could only be a good thing I would think. </li>
<li>P2445: It sounds like this experiment can only help improve computer security.</li>
<li>P2449: as long as they signed up to do something they are free game to monitor their behavior</li>
<li>P2450: Sure we all can learn what to watch out for. When we are doing something on the internet</li>
<li>P2451: For the value of the research </li>
<li>P2452: I would not want someone I cared about to every be concerned that they had a security risk, even if it is temporary and fake.</li>
<li>P2453: This is a important study to help make sure security warnings are afective.</li>
<li>P2456: This doesn't place anything important at risk so I have no problem with it.</li>
<li>P2457: this seems like a useful experiment</li>
<li>P2463: This sounds harmless and a big problem today. A lot of safe and harmless sites have ads not being monitored that act as a security warning with bad intentions. </li>
<li>P2466: I don't think that deception is appropriate for an experiment. Participants should not be lied to.</li>
<li>P2475: Its harmless. No consequences could be coming from it.</li>
<li>P2480: Sounds like a safe experiment for the greater good</li>
<li>P2483: This type of study will assist in future deterrent practices for individuals.</li>
<li>P2485: sounds useful</li>
<li>P2488: Again, I would have no say in the matter.  This experiment seems safe as well, so there would be no real harm done.</li>
<li>P2495: they should know what to do when this happens and why it happens</li>
<li>P2496:  I would like to see how I handle the security threat. </li>
<li>P2501: There do not seem to be any risks to this study so I see no reason why this person should not participate</li>
<li>P2513: It sounds like a devious way to steal information.</li>
<li>P2522: I think the information gained from such an experiment is important so I would not be bothered by someone I care about participating.</li>
<li>P2527: This may be a good educational technique for users.</li>
<li>P2528: Behavior concerning security benefits everyone.</li>
<li>P2530: These people are willing to be a part of the experiment. I can condone that. </li>
<li>P2532: The experiment wouldn't be intrusive or dangerous</li>
<li>P2533: As long as the person is never under any real risk I believe it is fine.</li>
<li>P2536: Up to them</li>
<li>P2539: I don't think it is necessary to study this issue, it should be obvious how an effective security warning can be presented. Not necessary to create the false alarm.</li>
<li>P2542: This seems harmless and is something that could actually be beneficial. </li>
<li>P2543: This is scary and involuntary research.</li>
<li>P2545: I think that it would be a good way for them to become aware of their reactions to security risks without actually being put in any real danger. </li>
<li>P2546: Teaches legitimate security risks in a controlled environment </li>
<li>P2547: Because it is a security, they need to learn how to listen to risks, and not take them when it comes to their computer. </li>
<li>P2549: It seems harmless so it wouldn't matter to me if someone I cared about participated.</li>
<li>P2556: help them to be safer</li>
<li>P2561: This is no different that many other studies.  If people are participating in a study they would expect to do various tasks and they often do not care what the purpose of the study is.</li>
<li>P2563: I don't like experiments where the subject is unaware & has not given consent to be a participant in such an experiment. Plus, receiving a security warning can be alarming & since it is only an experiment may cause unnecessary duress. </li>
<li>P2565: It seems like people who do HITs know that they are assuming risk regarding malware risk etc.</li>
<li>P2571: I really see no harm in it.</li>
<li>P2572: it is not important to me what they do</li>
<li>P2574: No real harm is being done in this study. </li>
<li>P2575: I do not trust this.</li>
<li>P2578: This experiment does not seem to cause any risk to participants.</li>
<li>P2579: I don't like for anyone to be deceived and I know they say there is no risk but there could possibly be.</li>
<li>P2582: Some people easily stress out of the smallest of things.</li>
<li>P2590: I don't like deception, but this doesn't seem harmful.</li>
<li>P2595: It really wouldn't matter to me, it is harmless and there were never any real risks by participating.</li>
<li>P2596: the participant agreed to a task. no passwords were collected. so yes, this is ok.</li>
<li>P2599: All the people I know wouldn't freak out too terribly about a security risk.  Most would stay level headed and figure out how to fix it.</li>
<li>P2601: By having them as part of the experiment, it's more likely that there will be an improvement of security based on the data received from them.</li>
<li>P2610: Nearly all of my friends and family would know better than to go with it and ignore the warning screen</li>
<li>P2612: It sounds like this will be set up in a way that will not interfere with someone's actual accounts, passwords or personal information. </li>
<li>P2617: Yes I would because it might help them be more aware.</li>
<li>P2618: I don't think it's a big deal if they do or not. Would kind of feel bad about them being deceived, but it seems like it's for a good cause if they put the data to use. Could cut down on the calls I get because parents or grandparent computers aren't working.</li>
<li>P2619: I think in this case, since there is no risk, and no personal info is being requested, this would be a helpful study.</li>
<li>P2623: I have no issue with this warning</li>
<li>P2626: That person would not mind.</li>
<li>P2627: yes i would like them to be included the more people to do the experiment the better</li>
<li>P2628: They will figure it out themselves</li>
<li>P2638: Doesn't seem to be any risk. </li>
<li>P2644: To scare them and help them realize risk with computer security. It's very over looked from the common man perspective. </li>
<li>P2664: If I knew they weren't in actual danger I would be ok with it if they were healthy and I knew they could handle it. And they were compensated well for it.</li>
<li>P2669: What happens on computers is personal, private and nobody should be messing with someone else's computer</li>
<li>P2674: yes it is harmless</li>
<li>P2677: for i don't think that it's nice to be deceived </li>
<li>P2682: No preference.</li>
<li>P2686: My friend will not know about the study so I have no preference whether or not they participate.</li>
<li>P2689: Harmless and may be beneficial to participants</li>
<li>P2690: Because i think a lot of us have gone through this.</li>
<li>P2691: I don't feel it matters who the candidates are. What matters is that the researchers are able to design a good security warning.</li>
<li>P2692: Sounds exciting</li>
<li>P2699: Security warnings should not be ignored as they sometimes are, and there is no risk for participant.</li>
<li>P2713: I'm not comfortable with the deception. I know it happens all the time but it's still deception. If a security risk notification popped up on my computer I would exit the program.</li>
<li>P2716: This does not appear to have any negative effect on the users.</li>
<li>P2723: i think its not that big of a deal - its just an experiment</li>
<li>P2725: I have no preference because no harm is done.</li>
<li>P2727: I don't see any problem with this kind of study.</li>
<li>P2735: No risk for participating and it's for a good cause.</li>
<li>P2740: Yes. There is no risk </li>
<li>P2747: keeping a secure computer is ideal however there are always security risks the more a person gets use to looking for warnings the better off they will be</li>
<li>P2749: I see no harm in it to the participant.</li>
<li>P2750: dont sound that bad</li>
<li>P2751: Would be fine with any of these studies but definitely in the case where they are debriefed afterwords </li>
<li>P2757: This seems like a neat experiment! </li>
<li>P2758: This may cause undue anxiety</li>
<li>P2759: If an older person were exposed or a young child it would freak them out. </li>
<li>P2771: Seems harmless</li>
<li>P2777: Sure, if they helped in some way and weren't in any danger.</li>
<li>P2781: Some participants might believe the security risk is real.</li>
<li>P2786: My actual answer is I'm not sure, but that's not an option.  It just seems like it could upset some people.  I know I would end up returning the HIT, and would be bothered by it.  If it's not even real, that means me, and anyone else who did the sane thing, would lose money.  It doesn't even seem effective.</li>
<li>P2787: Since there is no real risk, I wouldnt mind either way.</li>
<li>P2792: The research would not cause any issues, so it would not be of any consequence.  I think it is unintrusive, but doesn't provide much help to the individual either, so I have strong opinion. </li>
<li>P2793: If this was just a security warning test, I would feel comfortable participating.</li>
<li>P2795: If there is no wrong doing and it is disclosed.</li>
<li>P2800: It doesn't seem like a bad idea. </li>
<li>P2802: I think that this is a good way to analyze how effective security warnings are.  I would be happy for any of my friends to help with research like this.</li>
<li>P2804: I wouldn't really want someone I cared about to be subjected to something that would upset them.</li>
<li>P2807: It sounds like there is no potential risk for the participant, and as a result, would be a valuable education and research tool.</li>
<li>P2811: again, this is the type of thing that not only shows the person first hand how easy it is to expose themselves to danger, yet keeps them safe from the harm that could have been done. This type of experiment is very good for the people that need to actually be affected before they listen and will help many people.</li>
<li>P2813: It really doesn't matter to me. You are saying that their identification will remain anonymous so it wouldn't matter. </li>
<li>P2818: I could be doing this now for all i know</li>
<li>P2819: Because they are gonna do whatever they want to do.</li>
<li>P2821: as long as nothing were ACTUALLY being done and only different types of warnings were tried i see no harm</li>
<li>P2822: i Agree </li>
<li>P2823: I wouldn't want to give anyone I cared about the scare of receiving a security warning. It would cause them a lot of discomfort. </li>
<li>P2827: no harm would come to them</li>
<li>P2828: As in the first experiment since I would be willing to participate, I would have no qualms about another person participating.</li>
<li>P2829: I would want them to participate as long as there were no real security risk</li>
<li>P2830: It could cause someone I care about to take this security test very seriously and not knowing it was a experiment take actions </li>
<li>P2834: Yes, but only if one of those cautionary clauses that we frequently see before HIT's was included. Like call this number if you should be come upset after completing this task.</li>
<li>P2837: I disagree empirically with any psychology study that does not include informed consent.</li>
<li>P2838: I believe the effectiveness of a design is an important endeavor. </li>
<li>P2841: It's not real</li>
<li>P2844: They won't get hurt in the research and might help find ways to keep people from becoming victims.</li>
<li>P2845: Mild deception isn't harmful so there's no reason to object</li>
<li>P2848: mTurk is related to real work and money, and it should not be toyed with in this manner.</li>
<li>P2850: If they were a willing participant then it is ok. There are often different types of deception in these activities and this is just another form.</li>
<li>P2853: There doesn't seem to be any risks of confidentiality or invasion of privacy. This may scare some computer users, however.</li>
<li>P2856: It would teach people how to protect computers, my family can be very ignorant at times</li>
<li>P2860: At the end of the HIT, the participant is told that they were deceived and the purpose of the study.</li>
<li>P2861: IT WOULD HELP TO EDUCATE THEM.</li>
<li>P2865: I am not involved, and don't foresee anyone needing to call me to fix their machine.</li>
<li>P2872: It sounds safe.</li>
<li>P2874: No risks are involved.</li>
<li>P2879: I have participated in such a study and I deemed it to be safe. However, my study was very straight forward about the warnings being variations to determine which variation would sound most legitimate.</li>
<li>P2880: There is no real risk and will help make risk warnings more effective.</li>
<li>P2882: I do not think that participants should be deceived unless they agree to not knowing everything from the start.</li>
<li>P2888: It's all for the overall better, it can only help. </li>
<li>P2892: good information to know how to protect people</li>
<li>P2896: I think either way their life will be fine. </li>
<li>P2905: i see no harm in this...and since "reality" effects action i see no other way to do what you describe!</li>
<li>P2908: I would want the individual to take security warnings seriously and this might help make them more aware.</li>
<li>P2910: There's no real threat and it's only for the good of their actual interests.</li>
<li>P2913: It really would matter.</li>
<li>P2920: This seems like a very good study, no risks are involved as far as revealing personal information.</li>
<li>P2923: It can't hurt them and might help them be more careful</li>
<li>P2924: seems harmless</li>
<li>P2929: Several people I know would actually benefit from learning about computer security.  An experiment like this that doesn't actually collect real information or make them enter real passwords would make them think about security more without the risk.</li>
<li>P2930: I would not want them to feel threatened.</li>
<li>P2934: It seems that it is a fairly harmless experiment. It might be beneficial to the person I care for to see how they react under a stressful situation. It allows one to become more aware of how their brain and body work. Perhaps they could use it to react more efficiently/safely in the future.</li>
<li>P2939: I think the person should be made aware.</li>
<li>P2941: The experiment does not seem to be that useful so I wouldn't insist that they should join this experiment</li>
<li>P2946: I think they would need to have all different types of people to have a valid study.  I don't see how anyone could be hurt in it.</li>
<li>P2947: It is research that could make a difference to someone, and the participants were at no real risk.</li>
<li>P2948: Some of the people I know are really unaware of how many risks they take on the internet; this could be a good way to make them aware</li>
<li>P2956: The results can help people know which security warnings are real and which are fake.</li>
<li>P2959: If it is performed in a sanitized pc it would be acceptable.</li>
<li>P2964: If we know before we would most likly do more to help</li>
<li>P2966: It would be their choice</li>
<li>P2972: Because it does not appear to reveal their identity nor does it appear to require and personal information. </li>
<li>P2979: There is no real risk</li>
<li>P2983: Please make this HIT.</li>
<li>P2984: It could cause mental stress without consent. </li>
<li>P3001: I feel it has its pros and cons.</li>
<li>P3002: I think this is a worthwhile study and can lead to valuable and it appears to be safe for the participants.</li>
<li>P3003: Helpful and harmless, and potentially educational.</li>
<li>P3009: I don't see any major harm coming to the user but possibly a (-) reaction after the experiment but unlikely to be severe.</li>
<li>P3016: yes.i think he will be able to take care of himself </li>
<li>P3019: There is no real security risk.</li>
<li>P3028: because he can learn much about this.</li>
<li>P3032: As long as it's clearly explained that there is not a legitimate security risk then it should be fine.</li>
<li>P3034: I find there to be no moral issues with this sort of experiment.</li>
<li>P3036: See no danger and would be very helpful</li>
<li>P3039: Too deceiving.</li>
<li>P3043: Computer security is an important issue, and a good cause--the people are never at any risk for anything.</li>
<li>P3045: Well if they are at no risk it would be safe for them to do and would be curious how they did in it.</li>
<li>P3046: yes , it would be interesting to see how they answer.</li>
<li>P3047: This doesn't benefit the participant, however, it could Improve the effectiveness of future security warnings. </li>
<li>P3061: I don't think it would harm them, but I don't think it would benefit them at that time either.</li>
<li>P3062: I wouldn't really care if they did or not. They wouldn't be facing any personal harm or giving up any personal information.</li>
<li>P3063: It is important to know what is on your screen and how to comprehend it.</li>
<li>P3064: I think the results could improve people's reactions to security warnings, i.e. make them more proactive by seeing what "clicks" with people.</li>
<li>P3066: for real this question is a stupid one</li>
<li>P3068: Some people put any information on the internet they should be more careful </li>
<li>P3069: I don't like deceit.</li>
<li>P3077: this seems safe</li>
<li>P3079: It is important to be aware of such warnings and to know how to proceed.</li>
<li>P3084: It doesn't seem to do any real harm.</li>
<li>P3086: Results are anonymous, and there is no real security risk.</li>
<li>P3090: Any sort of deception is wrong- they should be forthright about the nature of the study, even if it makes the results less meaningful.</li>
<li>P3095: This research would help improve future security.</li>
<li>P3099: its a survey. I am neutral</li>
<li>P3100: If someone is doing a human intelligence task, they should expect that this sort of thing may happen. </li>
<li>P3102: Internet security is important and deception may be necessary to provide valid behavioral examples</li>
<li>P3103: I would not subject my friends or family to the potential stress.</li>
<li>P3110: It seems a perfectly acceptable way to handle the situation. The participant is made aware of everything eventually and no harm actually comes about.</li>
<li>P3117: The person may learn about how to be more secure when using the internet.</li>
<li>P3126: Seems like a better concept than the last without actual security risk.</li>
<li>P3129: It would not matter to me.</li>
<li>P3130: Because legitimate risks are so prevalent, I wouldn't wish to bring that stress on another.</li>
<li>P3132: I see no harm in this at all.  Someone might worry they have a security threat but once everything is explained, there is no real threat.</li>
<li>P3136: I don't see this harming the participants at all since the threat was never really there.</li>
<li>P3148: I have no preference because so many security warnings are so trivial and unnecessary. I believe a good portion of security warnings should be labeled the crying Wolf. But I know the importance of Them, but don't really think this is a critical study compared to hackers getting your password.</li>
<li>P3152: The deception is fully disclosed at the end. It's like being on Candid Camera.</li>
<li>P3159: It seems valuable.</li>
<li>P3161: Improving security is always good.</li>
<li>P3166: This area is one of people being careful and is worth this type of investigation</li>
<li>P3168: I think it would help to increase the wariness of individuals putting their information in online.</li>
<li>P3170: No one is hurt.</li>
<li>P3171: This is of no harm to them, so it doesn't matter</li>
<li>P3176: I would just quit the experiment and then I would lose out on payment.</li>
<li>P3177: Participants know they are taking place in a study and will be given the real reason for it upon completion.</li>
<li>P3182: It is not actually going to harm them, but I would not want them to be nervous or worried about it</li>
<li>P3183: so they learn about computer security</li>
<li>P3185: The experiment does not seem to pose a threat to the participants. It seems fairly innocuous.</li>
<li>P3202: It sounds to be an okay study of the there is no personal information offered.</li>
<li>P3203: It's a learning experience everyone should be a part of.</li>
<li>P3207: Would be a pointless study. If they return the hit because of a pretend security issue you'll only get data from the ones that continued through the security risk</li>
<li>P3208: Through the study, the person I cared about could learn more about warnings and know to be on the lookout for them in the future.</li>
<li>P3209: The person will be manipulated but no info is taken</li>
<li>P3217: This sounds like an interesting way to measure reactions, without actually having someone's personal information or passwords tied up in the research.</li>
<li>P3223: again i don't want people i care about being lied too</li>
<li>P3225: There will be an issue with returned hits due to the security warning. How will researchers distinguish this group from others who have returned the HIT for other reasons. Secondly, participants will not get paid for returned hits which creates another dilemma if there responses are meant to still be used.</li>
<li>P3228: It seems like an interesting experiment to run.</li>
<li>P3236: does it matter?</li>
<li>P3240: There is no harm and they will be assisting researchers in their computer warning systems and have them make better commputer warning systems that people would actually benefit from.</li>
<li>P3243: This will serve as a great warning to users selected</li>
<li>P3245: I wouldn't be able to tell how positively or negatively it will affect any of my loved ones, but they'd be in no real danger, so I have no preference. </li>
<li>P3246: Knowing what to look for in internet security is important</li>
<li>P3247: The risk is minimal</li>
<li>P3258: Some individuals are not aware of security warnings on the computer.  As with the phishing experiment, this can be greatly educational.</li>
<li>P3260: It's up to them.</li>
<li>P3269: While this may be a helpful experiment for the researchers, I fear the anxiety caused by it would be traumatic for someone I cared about.</li>
<li>P3273: If there is no real risk or harm to the participant, I dont see a problem</li>
<li>P3274: It does not matter</li>
<li>P3275: This experiment seems to do no harm to the participant.</li>
<li>P3276: If there is no real threat, it will add to the results of the study, which is always a good thing, and a learning experience.</li>
<li>P3289: I wouldn't want to see anyone subjected to the fear of a security breach.</li>
<li>P3296: Again, I think this is a good experiment with merit. </li>
<li>P3301: This experiment is not harmful, and will help in cyber security.</li>
<li>P3306: The participants are not placed at any risk.</li>
<li>P3311: I believe the general public is not aware of security risks.</li>
<li>P3314: There would be no harm in participating.</li>
<li>P3316: This experiment sounds important, therefore any candidates might be important to the study.</li>
<li>P3319: I think it is important to determine the most effective way of warning individuals about possible risks.</li>
<li>P3320: Again, being informed after the experiment is a plus. I would not mind this, though if I were a participant, I would just close the site. Would that be one of the anticipated effects? </li>
<li>P3322: The study results could be worthwhile</li>
<li>P3326: There is no hazard, and no negative repercussions, so it would be fine, but I have desire to have somebody involved.</li>
<li>P3331: I think this would be a helpful measure who ever it was tested on.</li>
<li>P3333: I don't believe this experiment would have any negative consequences.</li>
<li>P3338: Seems like a helpful experiment.</li>
<li>P3340: Yes.</li>
<li>P3341: No risk, beneficial info</li>
<li>P3343: There is no real risk here.</li>
<li>P3344: Many people seem to act very rashly with computer threats, I could see this going very wrong and being drastic for many of these people participating.</li>
<li>P3351: Participants will remain anonymous and will not be exposed to any real security threats. </li>
<li>P3358: Seems pretty harmless</li>
<li>P3359: Sounds interesting.</li>
<li>P3360: it sounds like good research to find out which security warnings work.  it is ok to deceive these participants because they willngly enter into a situation where it is ok to deceive them</li>
<li>P3367: It will help people learn to protect themselves.</li>
<li>P3373: The criteria I would use in determining a person's acceptability for inclusion in this experiment are more related to their ability to pay attention to detail and offer thoughtful answers than how much I care about them personally.</li>
<li>P3378: Yea, everyone today uses computers and if you can see how you yourself are susceptible to going along with potentially risky behavior while on the computer, it's good to know</li>
<li>P3387: It would help someone learn if they are too frivolous with security warnings which is worth some deception. </li>
<li>P3389: It's a good cause and no one will be harmed. </li>
<li>P3391: Its not harful but it could upset them</li>
<li>P3393: I think that often times the people I know don't read dialog and warning boxes and having them take part in a study like this will make them more aware that it is a problem and hopefully force them to pay more attention.</li>
<li>P3397: security is important</li>
<li>P3402: it would not be an issue and nobody would be harmed in the study</li>
<li>P3403: No risk</li>
<li>P3406: It will not be harmful</li>
<li>P3408: N/A.</li>
<li>P3412: I think it would be a harmless experiment, that posed no real danger. The psychological impact would be minimal.</li>
<li>P3413: Because i support the researchers idea and it's probably for a good purpose.</li>
<li>P3415: they're anonymous and at no real risk, so I see no reason as to swing either way, honestly.</li>
<li>P3416: Even though the experimenter claims there is no risk, one can truly never tell.</li>
<li>P3426: I am pretty much the IT person in the family and I think being exposed to something like this would be good for the people I care about.</li>
<li>P3427: People should understand security risks and how they relate to their personal data. The fact that the researchers reveal the true deception makes this educational to the participant.</li>
<li>P3428:  This is a good study for checking how people respond to security alerts. Don't see any harm in it.</li>
<li>P3431: Some people don't know how to react to such things and do things like turn their computer off right away, and not properly.</li>
<li>P3434: No actual harm is being done, there was no risk.</li>
<li>P3438: Informing users on potential risk and ways to avoid it is important.</li>
<li>P3440: I think it looks like a controller experiment with no risk to participants.</li>
<li>P3442: The experiment is harmless to I wouldn't have a problem with it.</li>
<li>P3445: There is no actual threat if they participate. Also, it is for scientific gain as well as helping people avoid security risks in the future.</li>
<li>P3447: There is no danger in taking part in such an experiment. I wouldn't warn anyone, because that would cause them to react differently to the test</li>
<li>P3453: This does not look to be harmful to anyone. No important personal data is needed.</li>
<li>P3456: I see no harm in this experiment.</li>
<li>P3467: Sure, it sounds harmless enough.</li>
<li>P3469: I would assume that they would get the security warning and stop the experiment and therefore not be paid.</li>
<li>P3472: i would like to see what they do.</li>
<li>P3483: I don't think there is any harm in the experiment and it helps us in the future.</li>
<li>P3487: I think that this is a useful project, and no one is actually exposed in any way to a real threat.</li>
<li>P3489: I can't think of any reason not to.</li>
<li>P3495: Because it will help people in the long run.</li>
<li>P3498: I think it's interesting but I would not say they should or should not.</li>
<li>P3503: I would not want someone I cared about to be part of this without giving their permission.</li>
<li>P3508: It will help prevent computer security.</li>
<li>P3510: no harm can be done and its a good for them to learn.</li>
<li>P3516: I don't believe any harm can occur.</li>
<li>P3518: I could see this experiment not going the right way and users start worrying </li>
<li>P3524: I think that this might be useful, and seems relatively harmless.</li>
<li>P3525: It may prove helpful towards teaching this person about internet safety</li>
<li>P3526: It would help to further security warnings for everyone.</li>
<li>P3532: Since nobody is at real risk I don't mind.</li>
<li>P3534: This experiment seems to have put all safety measures in place for participants.</li>
<li>P3536: It's up to them. There's nothing particularly harmful about this experiment so they don't have anything to worry about really.</li></ul>	</div>
</div>



<hr style='clear:both;'/>

<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<div class='cap' style='max-width:20%;'>
	<div class='header closed'>BotnetSpam study</div>
	<div class='body'>
<p>10 participants (0.5%) were aware of this study. 5 participants (0.2%) reported that they thought they participated.</p> <p>Answers to proceed question:</p><table class='simple' cellspacing='0'><tr><th class='l'>no</td><td>518</td><td>24.6%</td></tr>
<tr><th class='l'>unsure</td><td>316</td><td>15%</td></tr>
<tr><th class='l'>caution</td><td>739</td><td>35.2%</td></tr>
<tr><th class='l'>yes</td><td>529</td><td>25.2%</td></tr>
</table><p>Answers to surrogate question:</p><table class='simple' cellspacing='0'><tr><th class='l'>no</td><td>961</td><td>45.7%</td></tr>
<tr><th class='l'>indifferent</td><td>634</td><td>30.2%</td></tr>
<tr><th class='l'>yes</td><td>507</td><td>24.1%</td></tr>
</table></div>
</div>
<div class='cap' style='max-width:20%;'>
	<div class='header closed'>OSCredentialSpoofing study</div>
	<div class='body'>
<p>46 participants (2.2%) were aware of this study. 24 participants (1.1%) reported that they thought they participated.</p> <p>Answers to proceed question:</p><table class='simple' cellspacing='0'><tr><th class='l'>no</td><td>326</td><td>15.5%</td></tr>
<tr><th class='l'>unsure</td><td>169</td><td>8%</td></tr>
<tr><th class='l'>caution</td><td>848</td><td>40.3%</td></tr>
<tr><th class='l'>yes</td><td>759</td><td>36.1%</td></tr>
</table><p>Answers to surrogate question:</p><table class='simple' cellspacing='0'><tr><th class='l'>no</td><td>592</td><td>28.2%</td></tr>
<tr><th class='l'>indifferent</td><td>624</td><td>29.7%</td></tr>
<tr><th class='l'>yes</td><td>886</td><td>42.2%</td></tr>
</table></div>
</div>
<div class='cap' style='max-width:20%;'>
	<div class='header closed'>SocialPhishing study</div>
	<div class='body'>
<p>24 participants (1.1%) were aware of this study. 5 participants (0.2%) reported that they thought they participated.</p> <p>Answers to proceed question:</p><table class='simple' cellspacing='0'><tr><th class='l'>no</td><td>603</td><td>28.7%</td></tr>
<tr><th class='l'>unsure</td><td>240</td><td>11.4%</td></tr>
<tr><th class='l'>caution</td><td>721</td><td>34.3%</td></tr>
<tr><th class='l'>yes</td><td>538</td><td>25.6%</td></tr>
</table><p>Answers to surrogate question:</p><table class='simple' cellspacing='0'><tr><th class='l'>no</td><td>950</td><td>45.2%</td></tr>
<tr><th class='l'>indifferent</td><td>493</td><td>23.5%</td></tr>
<tr><th class='l'>yes</td><td>659</td><td>31.4%</td></tr>
</table></div>
</div>
<div class='cap' style='max-width:20%;'>
	<div class='header closed'>WarningsDeception study</div>
	<div class='body'>
<p>68 participants (3.2%) were aware of this study. 61 participants (2.9%) reported that they thought they participated.</p> <p>Answers to proceed question:</p><table class='simple' cellspacing='0'><tr><th class='l'>no</td><td>138</td><td>6.6%</td></tr>
<tr><th class='l'>unsure</td><td>132</td><td>6.3%</td></tr>
<tr><th class='l'>caution</td><td>644</td><td>30.6%</td></tr>
<tr><th class='l'>yes</td><td>1188</td><td>56.5%</td></tr>
</table><p>Answers to surrogate question:</p><table class='simple' cellspacing='0'><tr><th class='l'>no</td><td>306</td><td>14.6%</td></tr>
<tr><th class='l'>indifferent</td><td>735</td><td>35%</td></tr>
<tr><th class='l'>yes</td><td>1061</td><td>50.5%</td></tr>
</table></div>
</div>



</body></html>
