\section{Experimental scenarios}
\label{sec:scenarios}

We created two scenarios for experiments from the past decade that were the subject of ethical debate in the research community, two scenarios for experiments that we had run and gauged participants' ethical response to at the time of the experiment, and one scenario (with ten variants) for the recent Facebook experiment.  In no description of these experimental scenarios did we mention that the experiment described was a real experiment or, in the case of the university studies, that it had been approved by an ethics board.

%These scenarios represent deception experiments run, in part, by members of our team.  Both received IRB approval from Carnegie Mellon University.  We selected these experiments because we have been collecting feedback from participants to gauge their feelings about whether these experiments should have been allowed to proceed.  Both experiments included consent forms, but both also included deceptions in which participants were not informed of the true purpose of the study until they had completed the experimental task.  In order to make these scenarios more closely resemble the controversial ones, we elided the consent forms entirely from our scenario descriptions.

\TreatmentSection{SP}
We wrote this experimental scenario around the ``Social Phishing'' experiment performed by researchers at Indiana University~\cite{Jagatic2007:SocialPhishing}.  In their experiment, researchers sent students phishing emails to see if they could be deceived into revealing their passwords on a website that impersonated a university system.  Some of the emails researchers sent were customized based on participants' public Facebook profiles. The researchers collected passwords from those who entered them and tested them against a university password database to determine if they were valid.  The exact wording of this scenario is in Appendix~\TreatmentNum{SP}.

We did not mention that participants were exposed to the experiment without their consent.

\TreatmentSection{BS}
The second experimental scenario describes an experiment to measure the economics of spam performed by researchers at the University of California~\cite{Kanich2008:Spamalytics}.  In this experiment, the researchers allowed a computer to be infected with software used to send spam.  The researchers then modified the spam to direct recipients to servers controlled by the researchers, instead of the spammers.  Thus, recipients of attackers' spam became unwitting participants in this study.  The exact wording of this scenario is in Appendix~\TreatmentNum{BS}.

As with the previous study, we did not explicitly state that spam recipients did not opt into the study via a consent form, though we did indicate that spam recipients who visited the impersonated store would not be informed that it was not the genuine store run by spammers.

\TreatmentSection{OSCS}
This scenario describes an experiment by researchers at Carnegie Mellon University and Microsoft Research to determine whether malicious websites can trick users into revealing their device (computer) password by mimicking (spoofing) security dialogs that are normally generated by the device's operating system~\cite{BravoLillo2012:MistakenIdentity}.  The researchers presented the experiment to participants as an evaluation of online gaming websites.  When participants visited a website run by the researchers, the researchers mimicked the operating system window used to download a software component.  The window indicated that it required the user's (participant's) device username and password to install the software component.  The researchers observed whether participants could be deceived to enter that information.  (Unlike the Indiana University phishing study, the researchers did not actually collect passwords without participants consent.)  The exact wording of this scenario is in Appendix~\TreatmentNum{OSCS}.

The experiment on which this scenario was run by a team that includes two authors of our ethical-response survey (and the paper you are reading now).  The experiment, which was led by Carnegie Mellon University and performed in collaboration with Microsoft Research, was was approved by the Institutional Review Board of Carnegie Mellon University.

Participants in the actual experiment had received a consent form explaining that they were part of a University experiment, though the consent form did not disclose that security was the focus of the experiment.  The researchers informed study participants of the deception during a debriefing at the end of the experiment.  We elided the presence of the consent form in order to make the scenario more similar to the other, more controversial, experiments described in this survey.

\TreatmentSection{WD}
This scenario describes an experiment by researchers at Carnegie Mellon University and Microsoft Research to improve security warning dialogs~\cite{BravoLillo2013:Attention}.  Like the previous study, it is a deception experiment in which researchers led participants to believe that online games were the focus of the study.  Unlike the previous study, users were not tricked into typing passwords.  Rather, they were shown a warning about the risk of installing software and the researchers tested to see whether participants could identify signs of danger in the warning.  Regardless of how participants responded to the install warning, no harm would come to them.  The exact wording presented of the scenario is in Appendix~\TreatmentNum{WD}.

As with the previous scenario, the experiment on which this scenario was run by a team that includes two authors of our ethical-response survey (and the paper you are reading now).  The experiment, which was led by Carnegie Mellon University and performed in collaboration with Microsoft Research, was was approved by the Institutional Review Board of Carnegie Mellon University.
Participants in the actual experiment had received a consent form explaining that they were part of a university experiment, though the consent form did not disclose that security was the focus of the experiment.  Further, the researchers collected data to monitor participants' ethical responses during the study to ensure harm was minimal.  We elided these facts in order to make the scenario more similar to the more controversial experiments described in this survey.

\TreatmentSection{F}
\label{scenario:Facebook}
\sscomment{Box this}
This scenario, presented in Figure~\ref{fig:facebookscenario}, describes Facebook's emotional contagion experiment, based on our understanding of the experiment from reading their paper.  The scenario focuses on facts about the experimental goals and methodology and so avoids touching on many issues that have been a subject of public debate.  Specifically, it does not discuss oversight, terms of service, or the participation of university researchers in the experiment.  As is consistent with the other scenarios, we do not explicitly state that the researchers did not obtain consent from participants.

However, many respondents did not receive this exact scenario (our control), but instead received one of the variants (treatments) that are described in the next section.

\begin{figure}[t]
\fcolorbox{boxbordercolor}{boxbgcolor}{
\begin{minipage}{0.95\columnwidth}
\footnotesize
Researchers at Facebook want to study whether users are more likely to share positive (happy) thoughts if their friends have been posting positive thoughts, and whether they are more likely to share negative (unhappy) thoughts if their friends have been sharing negative thoughts.
\begin{packed_itemize}
\item To increase the proportion of positive posts in some users' news feeds, the researchers will randomly exclude some fraction of friends' negative posts each time the news feed is loaded.
\item To increase the proportion of negative posts in some users' news feeds, the researchers will randomly exclude some fraction of friends' positive posts each time the news feed is loaded.
\item The researchers will use an automated algorithm to measure whether users' posts are of a positive or negative mood.
\item The researchers will publish the anonymized aggregate results of the experiment in a scientific paper.
\item Participants will not be identified and will remain anonymous.
\end{packed_itemize}
%
If the researchers are not allowed to perform this experiment, they will not be able to make a valid scientific determination of whether users' moods are affected by the moods of their friends' posts. Therefore, the researchers will not be able to produce features that might protect the moods of psychologically-vulnerable users.
\end{minipage}}
\caption{The experimental scenario description we used for Facebook's emotional contagion experiment.}
\label{fig:facebookscenario}
\end{figure}
